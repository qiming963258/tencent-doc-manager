#!/usr/bin/env python3
"""æµ‹è¯•åŸºçº¿æ–‡ä»¶å¤šè¡Œè¾“å…¥å’ŒåŒåæ–‡ä»¶è½¯åˆ é™¤åŠŸèƒ½"""

import sys
import os
import json
import re
import shutil
from datetime import datetime
import pytz

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/root/projects/tencent-doc-manager')

from production.core_modules.tencent_export_automation import TencentDocAutoExporter
from production.core_modules.week_time_manager import WeekTimeManager

def parse_multiline_urls(text):
    """è§£æå¤šè¡ŒURLè¾“å…¥ï¼Œæ”¯æŒè…¾è®¯æ–‡æ¡£åˆ†äº«æ ¼å¼"""
    urls = []
    lines = text.strip().split('\n')

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # åŒ¹é…ã€è…¾è®¯æ–‡æ¡£ã€‘æ ¼å¼
        if 'ã€è…¾è®¯æ–‡æ¡£ã€‘' in line:
            # æå–æ–‡æ¡£åç§°
            name_match = re.search(r'ã€è…¾è®¯æ–‡æ¡£ã€‘(.+?)https?://', line)
            name = name_match.group(1).strip() if name_match else None

            # æå–URL
            url_match = re.search(r'https?://[^\s]+', line)
            url = url_match.group(0) if url_match else None

            if url:
                urls.append({
                    'name': name,
                    'url': url
                })
        # ç›´æ¥URLæ ¼å¼
        elif line.startswith('http'):
            urls.append({
                'name': None,
                'url': line
            })

    return urls

def soft_delete_existing_files(baseline_dir, filename_pattern):
    """è½¯åˆ é™¤å·²å­˜åœ¨çš„åŒåæ–‡ä»¶"""
    deleted_dir = os.path.join(baseline_dir, '.deleted')
    os.makedirs(deleted_dir, exist_ok=True)

    deleted_files = []

    # æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
    for file in os.listdir(baseline_dir):
        if file.startswith('.'):
            continue

        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒåæ–‡ä»¶ï¼ˆå¿½ç•¥æ—¶é—´æˆ³éƒ¨åˆ†ï¼‰
        # æå–æ–‡æ¡£åç§°éƒ¨åˆ†
        if '_' in file:
            parts = file.split('_')
            if len(parts) >= 2:
                # æ¯”è¾ƒå‰ä¸¤éƒ¨åˆ†ï¼ˆtencent_æ–‡æ¡£åï¼‰
                file_prefix = '_'.join(parts[:2])

                # æ£€æŸ¥æ˜¯å¦åŒ¹é…
                if filename_pattern in file_prefix:
                    # è½¯åˆ é™¤ï¼šç§»åŠ¨åˆ°.deletedæ–‡ä»¶å¤¹
                    old_path = os.path.join(baseline_dir, file)

                    # æ·»åŠ åˆ é™¤æ—¶é—´æˆ³
                    beijing_tz = pytz.timezone('Asia/Shanghai')
                    now = datetime.now(beijing_tz)
                    timestamp = now.strftime('%Y%m%d_%H%M%S')

                    deleted_filename = f"deleted_{timestamp}_{file}"
                    new_path = os.path.join(deleted_dir, deleted_filename)

                    shutil.move(old_path, new_path)
                    deleted_files.append({
                        'original': file,
                        'deleted_to': deleted_filename
                    })
                    print(f"   ğŸ—‘ï¸ è½¯åˆ é™¤: {file} -> .deleted/{deleted_filename}")

    return deleted_files

def test_multiline_baseline_download():
    """æµ‹è¯•å¤šè¡ŒURLè¾“å…¥çš„åŸºçº¿æ–‡ä»¶ä¸‹è½½"""

    print("ğŸ“Š æµ‹è¯•åŸºçº¿æ–‡ä»¶å¤šè¡Œè¾“å…¥å’ŒåŒåæ–‡ä»¶è½¯åˆ é™¤åŠŸèƒ½")
    print("=" * 60)

    # åˆå§‹åŒ–æ—¶é—´ç®¡ç†å™¨
    wtm = WeekTimeManager()
    week_info = wtm.get_current_week_info()
    current_week = week_info['week_number']
    print(f"ğŸ“… å½“å‰å‘¨æ•°: ç¬¬{current_week}å‘¨")

    # åˆ›å»ºåŸºçº¿æ–‡ä»¶å¤¹
    baseline_dir = f"/root/projects/tencent-doc-manager/csv_versions/2025_W{current_week}/baseline"
    os.makedirs(baseline_dir, exist_ok=True)
    print(f"ğŸ“ åŸºçº¿æ–‡ä»¶å¤¹: {baseline_dir}")

    # è¯»å–Cookie
    with open('/root/projects/tencent-doc-manager/config/cookies.json', 'r') as f:
        cookie_data = json.load(f)
    cookie_string = cookie_data.get('current_cookies', '')
    print(f"ğŸ”‘ Cookieé•¿åº¦: {len(cookie_string)} å­—ç¬¦")

    # æ¨¡æ‹Ÿå¤šè¡ŒURLè¾“å…¥ï¼ˆåŒ…å«ä¹‹å‰å·²ä¸‹è½½çš„æ–‡æ¡£ï¼‰
    multiline_input = """
ã€è…¾è®¯æ–‡æ¡£ã€‘111æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨ https://docs.qq.com/sheet/DWEFNU25TemFnZXJN?tab=BB08J2
ã€è…¾è®¯æ–‡æ¡£ã€‘111æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨ https://docs.qq.com/sheet/DWFJzdWNwd0RGbU5R?tab=000001
https://docs.qq.com/sheet/DWEFNU25TemFnZXJN?tab=BB08J2
    """

    print(f"\nğŸ“ æ¨¡æ‹Ÿå¤šè¡Œè¾“å…¥:")
    print("---")
    print(multiline_input.strip())
    print("---")

    # è§£æURL
    urls = parse_multiline_urls(multiline_input)
    print(f"\nâœ… è§£æå‡º {len(urls)} ä¸ªURL:")
    for i, item in enumerate(urls, 1):
        print(f"   {i}. {item['name'] or '(æœªå‘½å)'}: {item['url']}")

    # åˆå§‹åŒ–ä¸‹è½½å™¨
    exporter = TencentDocAutoExporter()

    # ä¸‹è½½æ¯ä¸ªæ–‡æ¡£
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡ä¸‹è½½åŸºçº¿æ–‡ä»¶...")
    for i, item in enumerate(urls, 1):
        print(f"\n[{i}/{len(urls)}] ä¸‹è½½: {item['name'] or item['url']}")

        # æå–æ–‡æ¡£åç§°ç”¨äºè½¯åˆ é™¤æ£€æŸ¥
        doc_name = item['name']
        if doc_name and '111æµ‹è¯•ç‰ˆæœ¬-' in doc_name:
            doc_name = doc_name.replace('111æµ‹è¯•ç‰ˆæœ¬-', '')

        # æ£€æŸ¥å¹¶è½¯åˆ é™¤åŒåæ–‡ä»¶
        if doc_name:
            print(f"   ğŸ” æ£€æŸ¥åŒåæ–‡ä»¶: {doc_name}")
            deleted = soft_delete_existing_files(baseline_dir, doc_name)
            if deleted:
                print(f"   âœ… è½¯åˆ é™¤äº† {len(deleted)} ä¸ªåŒåæ–‡ä»¶")

        try:
            # è°ƒç”¨å¯¼å‡ºæ–¹æ³•
            result = exporter.export_document(
                url=item['url'],
                cookies=cookie_string,
                format='csv',
                download_dir=baseline_dir
            )

            if result['success']:
                print(f"   âœ… ä¸‹è½½æˆåŠŸ!")

                # é‡å‘½åä¸ºåŸºçº¿æ–‡ä»¶æ ¼å¼
                if 'file_path' in result:
                    old_path = result['file_path']

                    # ç”ŸæˆåŸºçº¿æ–‡ä»¶å
                    beijing_tz = pytz.timezone('Asia/Shanghai')
                    now = datetime.now(beijing_tz)
                    timestamp = now.strftime('%Y%m%d_%H%M')

                    # ä½¿ç”¨æ–‡æ¡£åç§°æˆ–ä»URLæå–
                    if doc_name:
                        clean_name = doc_name
                    else:
                        clean_name = f"document_{i}"

                    # ç”Ÿæˆæ–°æ–‡ä»¶å
                    new_filename = f"tencent_{clean_name}_{timestamp}_baseline_W{current_week}.csv"
                    new_path = os.path.join(baseline_dir, new_filename)

                    # é‡å‘½åæ–‡ä»¶
                    if os.path.exists(old_path):
                        os.rename(old_path, new_path)
                        print(f"   ğŸ“ ä¿å­˜ä¸º: {new_filename}")

            else:
                print(f"   âŒ ä¸‹è½½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        except Exception as e:
            print(f"   âŒ å¼‚å¸¸: {str(e)}")

    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    print(f"\nğŸ“Š åŸºçº¿æ–‡ä»¶å¤¹æœ€ç»ˆå†…å®¹:")
    print(f"ğŸ“ ä¸»ç›®å½•: {baseline_dir}")

    # åˆ—å‡ºä¸»ç›®å½•æ–‡ä»¶
    main_files = []
    for file in os.listdir(baseline_dir):
        if not file.startswith('.'):
            file_path = os.path.join(baseline_dir, file)
            if os.path.isfile(file_path):
                file_size = os.path.getsize(file_path) / 1024  # KB
                main_files.append((file, file_size))

    if main_files:
        print(f"\nâœ… å½“å‰åŸºçº¿æ–‡ä»¶ ({len(main_files)} ä¸ª):")
        for file, size in sorted(main_files):
            print(f"   - {file} ({size:.1f} KB)")

    # åˆ—å‡ºè½¯åˆ é™¤æ–‡ä»¶
    deleted_dir = os.path.join(baseline_dir, '.deleted')
    if os.path.exists(deleted_dir):
        deleted_files = os.listdir(deleted_dir)
        if deleted_files:
            print(f"\nğŸ—‘ï¸ è½¯åˆ é™¤æ–‡ä»¶ ({len(deleted_files)} ä¸ª):")
            for file in sorted(deleted_files):
                file_path = os.path.join(deleted_dir, file)
                file_size = os.path.getsize(file_path) / 1024  # KB
                print(f"   - {file} ({file_size:.1f} KB)")

    # éªŒè¯è½¯åˆ é™¤æœºåˆ¶
    print(f"\nâœ… è½¯åˆ é™¤æœºåˆ¶éªŒè¯:")
    print(f"   1. åŒåæ–‡ä»¶è¢«ç§»åŠ¨åˆ° .deleted æ–‡ä»¶å¤¹")
    print(f"   2. åˆ é™¤çš„æ–‡ä»¶æ·»åŠ æ—¶é—´æˆ³å‰ç¼€")
    print(f"   3. ä¸»ç›®å½•åªä¿ç•™æœ€æ–°ç‰ˆæœ¬")
    print(f"   4. è½¯åˆ é™¤çš„æ–‡ä»¶ä¸ä¼šè¢«æŸ¥æ‰¾å‡½æ•°å‘ç°")

if __name__ == "__main__":
    test_multiline_baseline_download()