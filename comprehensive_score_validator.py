#!/usr/bin/env python3
"""
ç»¼åˆæ‰“åˆ†æ–‡ä»¶ä¸¥æ ¼éªŒè¯å™¨
å®Œå…¨æŒ‰ç…§10-ç»¼åˆæ‰“åˆ†ç»å¯¹è§„èŒƒè¿›è¡ŒéªŒè¯
ä¸ç¬¦åˆè§„èŒƒçš„æ–‡ä»¶ç›´æ¥æŠ¥é”™ï¼Œä¸å°è¯•ç”Ÿæˆå›¾åƒ
å¢å¼ºç‰ˆï¼šç²¾ç¡®æŠ¥å‘Šé”™è¯¯ä½ç½®
"""

import json
import os
import sys
from typing import Dict, List, Any, Tuple

# å¯¼å…¥æ ‡å‡†åˆ—é…ç½®
sys.path.append('/root/projects/tencent-doc-manager')
from standard_columns_config import STANDARD_COLUMNS, validate_columns

class ComprehensiveScoreValidator:
    """ç»¼åˆæ‰“åˆ†æ–‡ä»¶éªŒè¯å™¨"""

    # å¿…éœ€çš„é¡¶å±‚å­—æ®µ
    REQUIRED_TOP_FIELDS = [
        'metadata',
        'summary',
        'table_names',
        'column_names',
        'heatmap_data',
        'table_details',
        'hover_data',
        'statistics'
    ]

    # metadataå¿…éœ€å­—æ®µ
    REQUIRED_METADATA_FIELDS = [
        'version',
        'timestamp',
        'week',
        'generator',
        'total_params',
        'processing_time'
    ]

    # summaryå¿…éœ€å­—æ®µ
    REQUIRED_SUMMARY_FIELDS = [
        'total_tables',
        'total_columns',
        'total_modifications',
        'overall_risk_score',
        'processing_status'
    ]

    # table_detailsä¸­æ¯ä¸ªè¡¨å¿…éœ€å­—æ®µ
    REQUIRED_TABLE_FIELDS = [
        'table_id',
        'table_name',
        'table_index',
        'total_rows',
        'total_modifications',
        'overall_risk_score',
        'excel_url',
        'column_details'
    ]

    # column_detailsä¸­æ¯åˆ—å¿…éœ€å­—æ®µ
    REQUIRED_COLUMN_FIELDS = [
        'column_name',
        'column_index',
        'modification_count',
        'modified_rows',
        'score'
    ]

    # statisticså¿…éœ€å­—æ®µ
    REQUIRED_STATISTICS_FIELDS = [
        'table_modifications',
        'table_row_counts',
        'column_total_modifications',
        'risk_distribution'
    ]

    @classmethod
    def validate_file(cls, file_path: str) -> Tuple[bool, List[str], Dict]:
        """
        éªŒè¯ç»¼åˆæ‰“åˆ†æ–‡ä»¶
        è¿”å›: (æ˜¯å¦æœ‰æ•ˆ, é”™è¯¯åˆ—è¡¨, æ•°æ®)
        """
        errors = []

        # 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(file_path):
            return False, ["æ–‡ä»¶ä¸å­˜åœ¨"], {}

        # 2. åŠ è½½JSON
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            return False, [f"JSONè§£æé”™è¯¯: {e}"], {}
        except Exception as e:
            return False, [f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}"], {}

        # 3. éªŒè¯é¡¶å±‚å­—æ®µ
        for field in cls.REQUIRED_TOP_FIELDS:
            if field not in data:
                errors.append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")

        if errors:
            return False, errors, data

        # 4. éªŒè¯metadata
        metadata_errors = cls._validate_metadata(data.get('metadata', {}))
        errors.extend(metadata_errors)

        # 5. éªŒè¯summary
        summary_errors = cls._validate_summary(data.get('summary', {}))
        errors.extend(summary_errors)

        # 6. éªŒè¯table_nameså’Œcolumn_names
        if not isinstance(data.get('table_names'), list):
            errors.append("ã€ä½ç½®ã€‘é¡¶å±‚ > table_namesï¼šå¿…é¡»æ˜¯æ•°ç»„")
        elif len(data['table_names']) == 0:
            errors.append("ã€ä½ç½®ã€‘é¡¶å±‚ > table_namesï¼šä¸èƒ½ä¸ºç©º")

        # ä¸¥æ ¼éªŒè¯åˆ—åå¿…é¡»ä¸æ ‡å‡†19åˆ—å®Œå…¨ä¸€è‡´
        if not isinstance(data.get('column_names'), list):
            errors.append("ã€ä½ç½®ã€‘é¡¶å±‚ > column_namesï¼šå¿…é¡»æ˜¯æ•°ç»„")
        else:
            columns = data.get('column_names', [])
            if len(columns) != 19:
                errors.append(f"ã€ä½ç½®ã€‘é¡¶å±‚ > column_namesï¼šå¿…é¡»æœ‰19ä¸ªåˆ—åï¼Œå½“å‰{len(columns)}ä¸ª")

            # ä½¿ç”¨æ ‡å‡†åˆ—é…ç½®è¿›è¡ŒéªŒè¯
            columns_valid, column_errors = validate_columns(columns)
            if not columns_valid:
                for col_error in column_errors:
                    errors.append(f"ã€ä½ç½®ã€‘é¡¶å±‚ > column_names > {col_error}")

        # 7. éªŒè¯heatmap_data
        heatmap_errors = cls._validate_heatmap(data.get('heatmap_data', {}),
                                               len(data.get('table_names', [])))
        errors.extend(heatmap_errors)

        # 8. éªŒè¯table_details
        table_errors = cls._validate_table_details(data.get('table_details', []),
                                                   data.get('table_names', []))
        errors.extend(table_errors)

        # 9. éªŒè¯hover_data
        hover_errors = cls._validate_hover_data(data.get('hover_data', {}),
                                                len(data.get('table_names', [])))
        errors.extend(hover_errors)

        # 10. éªŒè¯statistics
        stat_errors = cls._validate_statistics(data.get('statistics', {}),
                                               len(data.get('table_names', [])))
        errors.extend(stat_errors)

        # 11. éªŒè¯å‚æ•°æ€»æ•°
        if data.get('metadata', {}).get('total_params', 0) < 5200:
            errors.append(f"å‚æ•°æ€»æ•°ä¸è¶³5200ï¼Œå½“å‰: {data.get('metadata', {}).get('total_params', 0)}")

        return len(errors) == 0, errors, data

    @classmethod
    def _validate_metadata(cls, metadata: Dict) -> List[str]:
        """éªŒè¯metadataéƒ¨åˆ†"""
        errors = []
        for field in cls.REQUIRED_METADATA_FIELDS:
            if field not in metadata:
                errors.append(f"metadataç¼ºå°‘å­—æ®µ: {field}")

        # éªŒè¯ç‰ˆæœ¬å·
        if metadata.get('version') != '2.0':
            errors.append(f"ç‰ˆæœ¬å·å¿…é¡»æ˜¯2.0ï¼Œå½“å‰: {metadata.get('version')}")

        return errors

    @classmethod
    def _validate_summary(cls, summary: Dict) -> List[str]:
        """éªŒè¯summaryéƒ¨åˆ†"""
        errors = []
        for field in cls.REQUIRED_SUMMARY_FIELDS:
            if field not in summary:
                errors.append(f"summaryç¼ºå°‘å­—æ®µ: {field}")

        # éªŒè¯åˆ—æ•°å¿…é¡»æ˜¯19
        if summary.get('total_columns') != 19:
            errors.append(f"åˆ—æ•°å¿…é¡»æ˜¯19ï¼Œå½“å‰: {summary.get('total_columns')}")

        return errors

    @classmethod
    def _validate_heatmap(cls, heatmap: Dict, expected_rows: int) -> List[str]:
        """éªŒè¯heatmap_dataéƒ¨åˆ†"""
        errors = []

        if 'matrix' not in heatmap:
            errors.append("heatmap_dataç¼ºå°‘matrixå­—æ®µ")
            return errors

        matrix = heatmap['matrix']
        if not isinstance(matrix, list):
            errors.append("matrixå¿…é¡»æ˜¯æ•°ç»„")
            return errors

        # éªŒè¯çŸ©é˜µå¤§å°
        if len(matrix) != expected_rows:
            errors.append(f"çŸ©é˜µè¡Œæ•°ä¸åŒ¹é…ï¼ŒæœŸæœ›{expected_rows}è¡Œï¼Œå®é™…{len(matrix)}è¡Œ")

        for i, row in enumerate(matrix):
            if not isinstance(row, list):
                errors.append(f"çŸ©é˜µç¬¬{i}è¡Œä¸æ˜¯æ•°ç»„")
                continue
            if len(row) != 19:
                errors.append(f"çŸ©é˜µç¬¬{i}è¡Œåˆ—æ•°ä¸æ˜¯19ï¼Œå®é™…{len(row)}")

            # éªŒè¯å€¼åŸŸ[0.05-1.0]
            for j, val in enumerate(row):
                if not isinstance(val, (int, float)):
                    errors.append(f"çŸ©é˜µ[{i}][{j}]ä¸æ˜¯æ•°å­—: {val}")
                elif val < 0.05 or val > 1.0:
                    errors.append(f"çŸ©é˜µ[{i}][{j}]å€¼è¶…å‡ºèŒƒå›´[0.05-1.0]: {val}")

        return errors

    @classmethod
    def _validate_table_details(cls, table_details: List, table_names: List) -> List[str]:
        """éªŒè¯table_detailséƒ¨åˆ†"""
        errors = []

        if not isinstance(table_details, list):
            errors.append("table_detailså¿…é¡»æ˜¯æ•°ç»„")
            return errors

        if len(table_details) != len(table_names):
            errors.append(f"table_detailsæ•°é‡({len(table_details)})ä¸table_names({len(table_names)})ä¸åŒ¹é…")

        for i, table in enumerate(table_details):
            if not isinstance(table, dict):
                errors.append(f"table_details[{i}]ä¸æ˜¯å¯¹è±¡")
                continue

            # éªŒè¯å¿…éœ€å­—æ®µ
            for field in cls.REQUIRED_TABLE_FIELDS:
                if field not in table:
                    errors.append(f"table_details[{i}]ç¼ºå°‘å­—æ®µ: {field}")

            # éªŒè¯column_details
            if 'column_details' in table:
                col_details = table['column_details']
                if not isinstance(col_details, list):
                    errors.append(f"table_details[{i}].column_detailsä¸æ˜¯æ•°ç»„")
                elif len(col_details) < 19:
                    # å¯ä»¥å°‘äº19ï¼ˆç¤ºä¾‹ä¸­ç®€åŒ–äº†ï¼‰ï¼Œä½†ä¸èƒ½æ²¡æœ‰
                    pass
                else:
                    for j, col in enumerate(col_details[:19]):
                        for field in cls.REQUIRED_COLUMN_FIELDS:
                            if field not in col:
                                errors.append(f"table_details[{i}].column_details[{j}]ç¼ºå°‘å­—æ®µ: {field}")

        return errors

    @classmethod
    def _validate_hover_data(cls, hover_data: Dict, expected_tables: int) -> List[str]:
        """éªŒè¯hover_dataéƒ¨åˆ†"""
        errors = []

        if 'data' not in hover_data:
            errors.append("hover_dataç¼ºå°‘dataå­—æ®µ")
            return errors

        data = hover_data['data']
        if not isinstance(data, list):
            errors.append("hover_data.dataå¿…é¡»æ˜¯æ•°ç»„")
            return errors

        if len(data) != expected_tables:
            errors.append(f"hover_data.dataæ•°é‡({len(data)})ä¸è¡¨æ ¼æ•°é‡({expected_tables})ä¸åŒ¹é…")

        for i, item in enumerate(data):
            if 'column_modifications' not in item:
                errors.append(f"hover_data.data[{i}]ç¼ºå°‘column_modifications")
            elif len(item['column_modifications']) != 19:
                errors.append(f"hover_data.data[{i}].column_modificationså¿…é¡»æœ‰19ä¸ªå€¼")

        return errors

    @classmethod
    def _validate_statistics(cls, statistics: Dict, expected_tables: int) -> List[str]:
        """éªŒè¯statisticséƒ¨åˆ†"""
        errors = []

        for field in cls.REQUIRED_STATISTICS_FIELDS:
            if field not in statistics:
                errors.append(f"statisticsç¼ºå°‘å­—æ®µ: {field}")

        # éªŒè¯æ•°ç»„é•¿åº¦
        if 'table_modifications' in statistics:
            if len(statistics['table_modifications']) != expected_tables:
                errors.append(f"table_modificationsé•¿åº¦ä¸åŒ¹é…")

        if 'table_row_counts' in statistics:
            if len(statistics['table_row_counts']) != expected_tables:
                errors.append(f"table_row_countsé•¿åº¦ä¸åŒ¹é…")

        if 'column_total_modifications' in statistics:
            if len(statistics['column_total_modifications']) != 19:
                errors.append(f"column_total_modificationså¿…é¡»æœ‰19ä¸ªå€¼")

        return errors


def validate_and_report(file_path: str):
    """éªŒè¯æ–‡ä»¶å¹¶ç”ŸæˆæŠ¥å‘Š"""
    print("=" * 60)
    print("ğŸ“‹ ç»¼åˆæ‰“åˆ†æ–‡ä»¶éªŒè¯")
    print("=" * 60)
    print(f"æ–‡ä»¶: {file_path}")
    print()

    validator = ComprehensiveScoreValidator()
    is_valid, errors, data = validator.validate_file(file_path)

    if is_valid:
        print("âœ… æ–‡ä»¶ç¬¦åˆè§„èŒƒï¼")
        print()
        print("ğŸ“Š æ–‡ä»¶ä¿¡æ¯:")
        print(f"  - ç‰ˆæœ¬: {data['metadata']['version']}")
        print(f"  - å‘¨æ•°: {data['metadata']['week']}")
        print(f"  - è¡¨æ ¼æ•°: {data['summary']['total_tables']}")
        print(f"  - æ€»å‚æ•°: {data['metadata']['total_params']}")
        print(f"  - æ€»ä¿®æ”¹æ•°: {data['summary']['total_modifications']}")
    else:
        print("âŒ æ–‡ä»¶ä¸ç¬¦åˆè§„èŒƒï¼")
        print()
        print("ğŸš« é”™è¯¯åˆ—è¡¨:")
        for i, error in enumerate(errors, 1):
            print(f"  {i}. {error}")
        print()
        print("âš ï¸ ç³»ç»Ÿå°†æ‹’ç»æ¸²æŸ“æ­¤æ–‡ä»¶")

    return is_valid


if __name__ == "__main__":
    # æµ‹è¯•æœ€æ–°çš„ç»¼åˆæ‰“åˆ†æ–‡ä»¶
    test_file = "/root/projects/tencent-doc-manager/scoring_results/comprehensive/comprehensive_score_W38_clustered.json"

    if os.path.exists(test_file):
        validate_and_report(test_file)
    else:
        print(f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")