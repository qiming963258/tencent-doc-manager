#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦åˆ†æè…¾è®¯æ–‡æ¡£EJSæ ¼å¼å’Œåçˆ¬è™«æœºåˆ¶
"""

import json
import os
import struct
import base64
import gzip
import re
from typing import Dict, Any, Optional
from datetime import datetime

class EJSAnalyzer:
    """EJSæ ¼å¼æ·±åº¦åˆ†æå™¨"""
    
    def __init__(self):
        self.downloads_dir = "/root/projects/tencent-doc-manager/downloads"
        
    def analyze_ejs_structure(self, filepath: str) -> Dict[str, Any]:
        """åˆ†æEJSæ–‡ä»¶ç»“æ„"""
        print(f"\n{'='*60}")
        print(f"åˆ†ææ–‡ä»¶: {os.path.basename(filepath)}")
        print(f"{'='*60}")
        
        analysis = {
            'file': filepath,
            'file_size': os.path.getsize(filepath),
            'format': None,
            'structure': {},
            'contains_data': False,
            'data_location': None,
            'compression': None,
            'encryption': None
        }
        
        with open(filepath, 'rb') as f:
            content = f.read()
            
        # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
        if content.startswith(b'PK\x03\x04'):
            analysis['format'] = 'ZIP/XLSX (çœŸæ­£çš„Excelæ–‡ä»¶)'
            print("âœ… è¿™æ˜¯çœŸæ­£çš„ExceläºŒè¿›åˆ¶æ–‡ä»¶!")
            return analysis
            
        if content.startswith(b'head\njson\n'):
            analysis['format'] = 'EJS (è…¾è®¯è‡ªå®šä¹‰æ ¼å¼)'
            print("ğŸ“„ è¿™æ˜¯EJSæ ¼å¼æ–‡ä»¶")
            
            # è§£æEJSç»“æ„
            try:
                lines = content.decode('utf-8', errors='ignore').split('\n', 3)
                if len(lines) >= 4:
                    header = lines[0]  # "head"
                    format_type = lines[1]  # "json"
                    json_length = int(lines[2])  # JSONé•¿åº¦
                    json_content = lines[3][:json_length]  # JSONå†…å®¹
                    
                    analysis['structure'] = {
                        'header': header,
                        'format': format_type,
                        'json_length': json_length,
                        'has_binary_data': len(lines[3]) > json_length
                    }
                    
                    # è§£æJSONå†…å®¹
                    json_data = json.loads(json_content)
                    analysis['json_data'] = self._analyze_json_structure(json_data)
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰åç»­çš„äºŒè¿›åˆ¶æ•°æ®
                    if len(lines[3]) > json_length:
                        binary_data = lines[3][json_length:].encode('utf-8', errors='ignore')
                        analysis['binary_analysis'] = self._analyze_binary_data(binary_data)
                        
            except Exception as e:
                print(f"è§£æEJSå¤±è´¥: {e}")
                
        return analysis
        
    def _analyze_json_structure(self, json_data: Dict) -> Dict:
        """åˆ†æJSONæ•°æ®ç»“æ„"""
        structure = {
            'keys': list(json_data.keys()),
            'has_sheet_data': False,
            'has_grid_data': False,
            'has_cell_data': False,
            'data_fields': [],
            'metadata': {}
        }
        
        # æŸ¥æ‰¾è¡¨æ ¼æ•°æ®ç›¸å…³å­—æ®µ
        if 'bodyData' in json_data:
            body_data = json_data['bodyData']
            
            # æ£€æŸ¥å„ç§å¯èƒ½çš„æ•°æ®å­—æ®µ
            data_keys = ['sheetData', 'gridData', 'cells', 'data', 'content', 
                        'rows', 'columns', 'values', 'table', 'sheet']
            
            for key in data_keys:
                if key in body_data:
                    structure['data_fields'].append(key)
                    structure[f'has_{key}'] = True
                    
            # æ£€æŸ¥padHTML
            if 'padHTML' in body_data:
                html_content = body_data['padHTML']
                if '<table' in html_content.lower():
                    structure['has_html_table'] = True
                    structure['html_length'] = len(html_content)
                    
        # æå–å…ƒæ•°æ®
        metadata_keys = ['padId', 'ownerId', 'title', 'createdDate', 'modifyDate']
        for key in metadata_keys:
            if key in json_data.get('clientVars', {}):
                structure['metadata'][key] = json_data['clientVars'][key]
                
        return structure
        
    def _analyze_binary_data(self, binary_data: bytes) -> Dict:
        """åˆ†æäºŒè¿›åˆ¶æ•°æ®éƒ¨åˆ†"""
        analysis = {
            'size': len(binary_data),
            'likely_compressed': False,
            'likely_encrypted': False,
            'format_signatures': []
        }
        
        # æ£€æŸ¥å¸¸è§çš„æ–‡ä»¶ç­¾å
        signatures = {
            b'PK\x03\x04': 'ZIP/XLSX',
            b'\x1f\x8b': 'GZIP',
            b'BM': 'BMP',
            b'\x89PNG': 'PNG',
            b'\xff\xd8\xff': 'JPEG',
            b'%PDF': 'PDF'
        }
        
        for sig, format_name in signatures.items():
            if binary_data.startswith(sig):
                analysis['format_signatures'].append(format_name)
                
        # æ£€æŸ¥æ˜¯å¦æ˜¯å‹ç¼©æ•°æ®
        try:
            decompressed = gzip.decompress(binary_data)
            analysis['likely_compressed'] = True
            analysis['decompressed_size'] = len(decompressed)
        except:
            pass
            
        # æ£€æŸ¥ç†µå€¼åˆ¤æ–­æ˜¯å¦åŠ å¯†
        entropy = self._calculate_entropy(binary_data[:1000])
        if entropy > 7.5:
            analysis['likely_encrypted'] = True
            analysis['entropy'] = entropy
            
        return analysis
        
    def _calculate_entropy(self, data: bytes) -> float:
        """è®¡ç®—æ•°æ®ç†µå€¼"""
        import math
        if not data:
            return 0.0
            
        frequency = {}
        for byte in data:
            frequency[byte] = frequency.get(byte, 0) + 1
            
        entropy = 0.0
        data_len = len(data)
        for count in frequency.values():
            if count > 0:
                probability = count / data_len
                entropy -= probability * math.log2(probability)
                
        return entropy
        
    def analyze_all_downloads(self) -> Dict:
        """åˆ†ææ‰€æœ‰ä¸‹è½½çš„æ–‡ä»¶"""
        results = {
            'total_files': 0,
            'xlsx_files': [],
            'ejs_files': [],
            'csv_files': [],
            'analysis_summary': {}
        }
        
        for filename in os.listdir(self.downloads_dir):
            filepath = os.path.join(self.downloads_dir, filename)
            if os.path.isfile(filepath):
                results['total_files'] += 1
                
                if filename.endswith('.xlsx'):
                    analysis = self.analyze_ejs_structure(filepath)
                    if analysis['format'] == 'EJS (è…¾è®¯è‡ªå®šä¹‰æ ¼å¼)':
                        results['ejs_files'].append({
                            'file': filename,
                            'size': analysis['file_size'],
                            'has_data': analysis.get('json_data', {}).get('data_fields', [])
                        })
                    else:
                        results['xlsx_files'].append(filename)
                        
                elif filename.endswith('.csv'):
                    results['csv_files'].append(filename)
                    
        return results

def generate_security_assessment():
    """ç”Ÿæˆå®‰å…¨è¯„ä¼°æŠ¥å‘Š"""
    print("\n" + "="*80)
    print("è…¾è®¯æ–‡æ¡£åçˆ¬è™«æœºåˆ¶å’ŒEJSæ ¼å¼æ·±åº¦åˆ†ææŠ¥å‘Š")
    print("="*80)
    
    assessment = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'anti_scraping_analysis': {
            'current_measures': [],
            'difficulty_level': '',
            'bypass_feasibility': '',
            'risks': []
        },
        'ejs_format_analysis': {
            'format_description': '',
            'parsing_difficulty': '',
            'open_source_solutions': [],
            'custom_parser_feasibility': ''
        },
        'future_risks': [],
        'alternative_solutions': [],
        'recommendations': []
    }
    
    # 1. åçˆ¬è™«æœºåˆ¶åˆ†æ
    print("\nã€1. åçˆ¬è™«æœºåˆ¶æŠ€æœ¯è¯„ä¼°ã€‘")
    print("-" * 40)
    
    anti_scraping = {
        'measures': [
            {
                'name': 'EJSæ ¼å¼å°è£…',
                'description': 'å°†Excelæ•°æ®å°è£…åœ¨è‡ªå®šä¹‰EJSæ ¼å¼ä¸­ï¼Œè€Œéæ ‡å‡†äºŒè¿›åˆ¶',
                'difficulty': 'ä¸­ç­‰',
                'bypass': 'éœ€è¦è§£æEJSæ ¼å¼ï¼Œæå–å†…éƒ¨æ•°æ®'
            },
            {
                'name': 'APIç«¯ç‚¹éšè—',
                'description': 'çœŸå®ä¸‹è½½ç«¯ç‚¹ä¸å…¬å¼€ï¼Œé€šè¿‡JavaScriptåŠ¨æ€ç”Ÿæˆ',
                'difficulty': 'é«˜',
                'bypass': 'éœ€è¦é€†å‘å·¥ç¨‹JavaScriptä»£ç æˆ–ç›‘æ§ç½‘ç»œè¯·æ±‚'
            },
            {
                'name': 'XSRF TokenéªŒè¯',
                'description': 'æ‰€æœ‰APIè¯·æ±‚éœ€è¦æœ‰æ•ˆçš„XSRF Token',
                'difficulty': 'ä½',
                'bypass': 'å·²å®ç°ï¼Œä»é¡µé¢æå–Tokenå³å¯'
            },
            {
                'name': 'è¯·æ±‚ç­¾åéªŒè¯',
                'description': 'å¯èƒ½å­˜åœ¨è¯·æ±‚å‚æ•°ç­¾åæœºåˆ¶',
                'difficulty': 'é«˜',
                'bypass': 'éœ€è¦é€†å‘ç­¾åç®—æ³•'
            }
        ],
        'overall_difficulty': 'ä¸­é«˜',
        'success_rate': '40-60%'
    }
    
    for measure in anti_scraping['measures']:
        print(f"\nğŸ“Œ {measure['name']}")
        print(f"   æè¿°: {measure['description']}")
        print(f"   éš¾åº¦: {measure['difficulty']}")
        print(f"   ç»•è¿‡æ–¹æ³•: {measure['bypass']}")
    
    # 2. EJSæ ¼å¼ç ´è§£åˆ†æ
    print("\n\nã€2. EJSç ´è§£éš¾åº¦å’Œå¯è¡Œæ€§åˆ†æã€‘")
    print("-" * 40)
    
    ejs_analysis = {
        'format_structure': 'head\\njson\\n[length]\\n[JSON content][optional binary]',
        'complexity': 'ä¸­ç­‰',
        'main_challenges': [
            '1. JSONä¸­å¯èƒ½ä¸åŒ…å«å®é™…è¡¨æ ¼æ•°æ®',
            '2. æ•°æ®å¯èƒ½åœ¨åç»­çš„äºŒè¿›åˆ¶éƒ¨åˆ†ï¼ˆåŠ å¯†/å‹ç¼©ï¼‰',
            '3. æ•°æ®å¯èƒ½éœ€è¦é¢å¤–APIè°ƒç”¨æ‰èƒ½è·å–',
            '4. æ ¼å¼å¯èƒ½éšæ—¶å˜åŒ–'
        ],
        'parsing_feasibility': 'æŠ€æœ¯ä¸Šå¯è¡Œï¼Œä½†éœ€è¦æŒç»­ç»´æŠ¤'
    }
    
    print(f"\næ ¼å¼ç»“æ„: {ejs_analysis['format_structure']}")
    print(f"å¤æ‚åº¦: {ejs_analysis['complexity']}")
    print("\nä¸»è¦æŒ‘æˆ˜:")
    for challenge in ejs_analysis['main_challenges']:
        print(f"  {challenge}")
    
    # 3. å¼€æºè§£å†³æ–¹æ¡ˆè°ƒç ”
    print("\n\nã€3. å¼€æºè§£å†³æ–¹æ¡ˆè°ƒç ”ã€‘")
    print("-" * 40)
    
    open_source = [
        {
            'name': 'Playwright/Puppeteer',
            'description': 'æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼Œæ¨¡æ‹Ÿç”¨æˆ·æ“ä½œå¯¼å‡º',
            'pros': 'å¯é ï¼Œèƒ½å¤„ç†åŠ¨æ€å†…å®¹',
            'cons': 'èµ„æºæ¶ˆè€—å¤§ï¼Œé€Ÿåº¦æ…¢',
            'recommendation': 'âœ… æ¨èä½œä¸ºä¸»è¦æ–¹æ¡ˆ'
        },
        {
            'name': 'è‡ªå®šä¹‰EJSè§£æå™¨',
            'description': 'åŸºäºæ ¼å¼åˆ†æç¼–å†™è§£æå™¨',
            'pros': 'é€Ÿåº¦å¿«ï¼Œèµ„æºæ¶ˆè€—å°',
            'cons': 'ç»´æŠ¤æˆæœ¬é«˜ï¼Œæ˜“å¤±æ•ˆ',
            'recommendation': 'âš ï¸ ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ'
        },
        {
            'name': 'mitmproxy',
            'description': 'ä¸­é—´äººä»£ç†æ•è·çœŸå®ä¸‹è½½',
            'pros': 'èƒ½è·å–çœŸå®æ•°æ®',
            'cons': 'éƒ¨ç½²å¤æ‚ï¼Œå¯èƒ½è§¦å‘å®‰å…¨æ£€æµ‹',
            'recommendation': 'âŒ ä¸æ¨è'
        }
    ]
    
    for solution in open_source:
        print(f"\nğŸ”§ {solution['name']}")
        print(f"   æè¿°: {solution['description']}")
        print(f"   ä¼˜åŠ¿: {solution['pros']}")
        print(f"   åŠ£åŠ¿: {solution['cons']}")
        print(f"   æ¨èåº¦: {solution['recommendation']}")
    
    # 4. é£é™©è¯„ä¼°
    print("\n\nã€4. é£é™©è¯„ä¼°å’Œåº”å¯¹ç­–ç•¥ã€‘")
    print("-" * 40)
    
    risks = [
        {
            'risk': 'è…¾è®¯å‡çº§åçˆ¬ç­–ç•¥',
            'probability': 'é«˜',
            'impact': 'ç³»ç»Ÿå¤±æ•ˆ',
            'mitigation': 'ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–ä½œä¸ºåå¤‡æ–¹æ¡ˆ'
        },
        {
            'risk': 'IP/è´¦å·å°ç¦',
            'probability': 'ä¸­',
            'impact': 'æ— æ³•è®¿é—®',
            'mitigation': 'æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œä½¿ç”¨ä»£ç†æ± '
        },
        {
            'risk': 'EJSæ ¼å¼å˜æ›´',
            'probability': 'ä¸­',
            'impact': 'è§£æå¤±è´¥',
            'mitigation': 'ç›‘æ§æ ¼å¼å˜åŒ–ï¼Œå¿«é€Ÿé€‚é…'
        },
        {
            'risk': 'æ³•å¾‹åˆè§„é£é™©',
            'probability': 'ä½',
            'impact': 'æ³•å¾‹çº çº·',
            'mitigation': 'ä»…ç”¨äºå·²æˆæƒæ–‡æ¡£ï¼Œéµå®ˆæœåŠ¡æ¡æ¬¾'
        }
    ]
    
    for risk in risks:
        print(f"\nâš ï¸ é£é™©: {risk['risk']}")
        print(f"   æ¦‚ç‡: {risk['probability']}")
        print(f"   å½±å“: {risk['impact']}")
        print(f"   ç¼“è§£æªæ–½: {risk['mitigation']}")
    
    # 5. æ›¿ä»£æŠ€æœ¯æ–¹æ¡ˆ
    print("\n\nã€5. æ›¿ä»£æŠ€æœ¯æ–¹æ¡ˆå»ºè®®ã€‘")
    print("-" * 40)
    
    alternatives = [
        {
            'name': 'æ–¹æ¡ˆA: å®Œå…¨æµè§ˆå™¨è‡ªåŠ¨åŒ–',
            'description': 'ä½¿ç”¨Playwrightæ§åˆ¶çœŸå®æµè§ˆå™¨ï¼Œæ¨¡æ‹Ÿç”¨æˆ·ç‚¹å‡»å¯¼å‡ºæŒ‰é’®',
            'implementation': 'å·²æœ‰enterprise_download_systemå®ç°',
            'reliability': '95%',
            'performance': 'æ…¢ï¼ˆ5-10ç§’/æ–‡æ¡£ï¼‰',
            'recommendation': 'âœ… æœ€å¯é çš„æ–¹æ¡ˆ'
        },
        {
            'name': 'æ–¹æ¡ˆB: API + æµè§ˆå™¨æ··åˆ',
            'description': 'APIè·å–å…ƒæ•°æ®ï¼Œæµè§ˆå™¨è·å–å®é™…æ•°æ®',
            'implementation': 'éœ€è¦å¼€å‘',
            'reliability': '85%',
            'performance': 'ä¸­ç­‰ï¼ˆ3-5ç§’/æ–‡æ¡£ï¼‰',
            'recommendation': 'â­ å¹³è¡¡æ–¹æ¡ˆ'
        },
        {
            'name': 'æ–¹æ¡ˆC: è…¾è®¯å®˜æ–¹API',
            'description': 'ç”³è¯·è…¾è®¯æ–‡æ¡£å¼€æ”¾å¹³å°APIæƒé™',
            'implementation': 'éœ€è¦ä¼ä¸šè®¤è¯',
            'reliability': '100%',
            'performance': 'å¿«ï¼ˆ<1ç§’/æ–‡æ¡£ï¼‰',
            'recommendation': 'ğŸ¯ é•¿æœŸæœ€ä½³æ–¹æ¡ˆï¼ˆå¦‚æœå¯è·å¾—ï¼‰'
        },
        {
            'name': 'æ–¹æ¡ˆD: CSVå¯¼å‡ºä¸ºä¸»',
            'description': 'CSVæ ¼å¼æ›´å®¹æ˜“è·å–ï¼ŒExcelä½œä¸ºè¡¥å……',
            'implementation': 'å·²å®ç°',
            'reliability': '90%',
            'performance': 'å¿«ï¼ˆ1-2ç§’/æ–‡æ¡£ï¼‰',
            'recommendation': 'âœ… å½“å‰å¯ç”¨æ–¹æ¡ˆ'
        }
    ]
    
    for alt in alternatives:
        print(f"\nğŸ’¡ {alt['name']}")
        print(f"   æè¿°: {alt['description']}")
        print(f"   å®ç°çŠ¶æ€: {alt['implementation']}")
        print(f"   å¯é æ€§: {alt['reliability']}")
        print(f"   æ€§èƒ½: {alt['performance']}")
        print(f"   æ¨è: {alt['recommendation']}")
    
    # 6. æœ€ç»ˆå»ºè®®
    print("\n\nã€6. æœ€ç»ˆå»ºè®®ã€‘")
    print("-" * 40)
    print("""
ğŸ“‹ ç»¼åˆå»ºè®®:

1. **çŸ­æœŸç­–ç•¥** (ç«‹å³å®æ–½):
   - ç»§ç»­ä½¿ç”¨CSVå¯¼å‡ºä½œä¸ºä¸»è¦æ•°æ®è·å–æ–¹å¼
   - ä¿æŒç°æœ‰çš„XSRF Tokenè®¤è¯æœºåˆ¶
   - ä¼˜åŒ–Playwrightæµè§ˆå™¨è‡ªåŠ¨åŒ–ä½œä¸ºExcelä¸‹è½½å¤‡ç”¨æ–¹æ¡ˆ

2. **ä¸­æœŸç­–ç•¥** (1-3ä¸ªæœˆ):
   - å¼€å‘EJSæ ¼å¼åŸºç¡€è§£æå™¨ï¼Œæå–å¯ç”¨çš„å…ƒæ•°æ®
   - å»ºç«‹æ ¼å¼å˜åŒ–ç›‘æ§æœºåˆ¶
   - å®ç°è¯·æ±‚é¢‘ç‡æ§åˆ¶å’Œä»£ç†è½®æ¢

3. **é•¿æœŸç­–ç•¥** (3-6ä¸ªæœˆ):
   - æ¢ç´¢ç”³è¯·è…¾è®¯æ–‡æ¡£å®˜æ–¹APIçš„å¯èƒ½æ€§
   - å»ºç«‹å¤šå±‚æ¬¡çš„é™çº§ç­–ç•¥
   - è€ƒè™‘ä¸è…¾è®¯æ–‡æ¡£çš„åˆä½œå¯èƒ½

4. **é£é™©æ§åˆ¶**:
   - ä¸¥æ ¼æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼ˆå»ºè®®: 1è¯·æ±‚/3ç§’ï¼‰
   - ä½¿ç”¨å¤šä¸ªè´¦å·è½®æ¢
   - å»ºç«‹å¼‚å¸¸æ£€æµ‹å’Œè‡ªåŠ¨æš‚åœæœºåˆ¶
   - ä¿æŒæ•°æ®è·å–çš„åˆæ³•åˆè§„æ€§

5. **æŠ€æœ¯å‚¨å¤‡**:
   - æŒç»­ç ”ç©¶EJSæ ¼å¼å˜åŒ–
   - å…³æ³¨è…¾è®¯æ–‡æ¡£æ›´æ–°åŠ¨æ€
   - ä¿æŒå¤šç§æŠ€æœ¯æ–¹æ¡ˆå¹¶è¡Œ
    """)
    
    return assessment

def main():
    """ä¸»å‡½æ•°"""
    # åˆ›å»ºåˆ†æå™¨
    analyzer = EJSAnalyzer()
    
    # åˆ†ææ‰€æœ‰ä¸‹è½½æ–‡ä»¶
    print("\nåˆ†ædownloadsç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶...")
    results = analyzer.analyze_all_downloads()
    
    print(f"\nğŸ“Š åˆ†æç»“æœæ±‡æ€»:")
    print(f"   æ€»æ–‡ä»¶æ•°: {results['total_files']}")
    print(f"   çœŸå®Excelæ–‡ä»¶: {len(results['xlsx_files'])}")
    print(f"   EJSæ ¼å¼æ–‡ä»¶: {len(results['ejs_files'])}")
    print(f"   CSVæ–‡ä»¶: {len(results['csv_files'])}")
    
    if results['ejs_files']:
        print(f"\n   EJSæ–‡ä»¶è¯¦æƒ…:")
        for ejs in results['ejs_files']:
            print(f"     - {ejs['file'][:50]}...")
            print(f"       å¤§å°: {ejs['size']} bytes")
            print(f"       æ•°æ®å­—æ®µ: {ejs['has_data']}")
    
    # ç”Ÿæˆå®‰å…¨è¯„ä¼°æŠ¥å‘Š
    assessment = generate_security_assessment()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = "/root/projects/tencent-doc-manager/EJS_ANALYSIS_REPORT.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump({
            'analysis_results': results,
            'security_assessment': assessment,
            'timestamp': datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

if __name__ == "__main__":
    main()