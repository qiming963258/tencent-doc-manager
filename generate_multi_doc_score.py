#!/usr/bin/env python3
"""
ç”Ÿæˆå¤šæ–‡æ¡£ç»¼åˆæ‰“åˆ†æ–‡ä»¶
æ¨¡æ‹Ÿå¤šä¸ªæ–‡æ¡£çš„çƒ­åŠ›å›¾æ•°æ®
"""

import json
from datetime import datetime
from pathlib import Path

def generate_multi_document_score():
    """ç”ŸæˆåŒ…å«3ä¸ªæ–‡æ¡£çš„ç»¼åˆæ‰“åˆ†æ–‡ä»¶"""

    # ä¸‰ä¸ªé…ç½®çš„æ–‡æ¡£
    documents = [
        "å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨",
        "å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨",
        "æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨"
    ]

    # æ ‡å‡†19åˆ—
    columns = [
        "åºå·", "é¡¹ç›®ç±»å‹", "æ¥æº", "ä»»åŠ¡å‘èµ·æ—¶é—´", "ç›®æ ‡å¯¹é½",
        "å…³é”®KRå¯¹é½", "å…·ä½“è®¡åˆ’å†…å®¹", "é‚“æ€»æŒ‡å¯¼ç™»è®°", "è´Ÿè´£äºº", "ååŠ©äºº",
        "ç›‘ç£äºº", "é‡è¦ç¨‹åº¦", "é¢„è®¡å®Œæˆæ—¶é—´", "å®Œæˆè¿›åº¦", "å®Œæˆé“¾æ¥",
        "ç»ç†åˆ†æå¤ç›˜", "æœ€æ–°å¤ç›˜æ—¶é—´", "å¯¹ä¸Šæ±‡æŠ¥", "åº”ç”¨æƒ…å†µ"
    ]

    # ç”Ÿæˆ3è¡Œçƒ­åŠ›å›¾çŸ©é˜µï¼ˆæ¯ä¸ªæ–‡æ¡£ä¸€è¡Œï¼‰
    heatmap_matrix = []
    for doc_idx, doc_name in enumerate(documents):
        row = []
        for col_idx, col in enumerate(columns):
            # æ¨¡æ‹Ÿä¸åŒçš„é£é™©ç­‰çº§
            if col == "é‡è¦ç¨‹åº¦" and doc_idx == 2:  # å°çº¢ä¹¦éƒ¨é—¨çš„é‡è¦ç¨‹åº¦åˆ—
                heat_value = 0.90  # é«˜é£é™©ï¼ˆçº¢è‰²ï¼‰- å¯¹åº”92å¤„å˜æ›´
            elif col in ["æ¥æº", "ä»»åŠ¡å‘èµ·æ—¶é—´", "ç›®æ ‡å¯¹é½"]:
                heat_value = 0.60  # ä¸­é£é™©ï¼ˆæ©™è‰²ï¼‰
            elif col in ["å®Œæˆè¿›åº¦", "å®Œæˆé“¾æ¥"]:
                heat_value = 0.30  # ä½é£é™©ï¼ˆç»¿è‰²ï¼‰
            else:
                heat_value = 0.05  # æ— ä¿®æ”¹ï¼ˆè“è‰²ï¼‰
            row.append(heat_value)
        heatmap_matrix.append(row)

    # æ„å»ºç»¼åˆæ‰“åˆ†æ•°æ®
    comprehensive_data = {
        "metadata": {
            "version": "2.0",
            "timestamp": datetime.now().isoformat(),
            "week": "W39",
            "generator": "multi_document_generator",
            "source_type": "multi_document_scoring"
        },
        "summary": {
            "total_tables": 3,
            "total_columns": 19,
            "total_modifications": 150,  # æ¨¡æ‹Ÿæ€»ä¿®æ”¹æ•°
            "l1_modifications": 92,  # ä¸»è¦æ˜¯å°çº¢ä¹¦çš„é‡è¦ç¨‹åº¦åˆ—
            "l2_modifications": 38,
            "l3_modifications": 20,
            "overall_risk_score": 0.65
        },
        "table_names": documents,
        "column_names": columns,
        "heatmap_data": {
            "matrix": heatmap_matrix,
            "rows": 3,
            "cols": 19,
            "generation_method": "multi_document_simulation"
        },
        "table_details": {
            documents[0]: {
                "total_rows": 270,
                "modified_rows": 35,
                "excel_url": "https://docs.qq.com/sheet/DWEFNU25TemFnZXJN"
            },
            documents[1]: {
                "total_rows": 180,
                "modified_rows": 23,
                "excel_url": "https://docs.qq.com/sheet/DWGZDZkxpaGVQaURr"
            },
            documents[2]: {
                "total_rows": 270,
                "modified_rows": 92,
                "excel_url": "https://docs.qq.com/sheet/DWFJzdWNwd0RGbU5R"
            }
        },
        "excel_urls": {
            documents[0]: "https://docs.qq.com/sheet/DWEFNU25TemFnZXJN",
            documents[1]: "https://docs.qq.com/sheet/DWGZDZkxpaGVQaURr",
            documents[2]: "https://docs.qq.com/sheet/DWFJzdWNwd0RGbU5R"
        }
    }

    # ä¿å­˜åˆ°å¤šä¸ªä½ç½®
    output_dir = Path('/root/projects/tencent-doc-manager/scoring_results/comprehensive')
    week_dir = Path('/root/projects/tencent-doc-manager/scoring_results/2025_W39')

    output_dir.mkdir(parents=True, exist_ok=True)
    week_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜æ–‡ä»¶
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # 1. comprehensiveç›®å½•çš„latestæ–‡ä»¶
    latest_file = output_dir / 'comprehensive_score_W39_latest.json'
    with open(latest_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ç”Ÿæˆ: {latest_file}")

    # 2. å‘¨ç›®å½•çš„å¸¦æ—¶é—´æˆ³æ–‡ä»¶
    timestamped_file = week_dir / f'comprehensive_score_W39_MULTI_{timestamp}.json'
    with open(timestamped_file, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ç”Ÿæˆ: {timestamped_file}")

    # 3. å‘¨ç›®å½•çš„latestæ–‡ä»¶
    week_latest = week_dir / 'comprehensive_score_W39_latest.json'
    with open(week_latest, 'w', encoding='utf-8') as f:
        json.dump(comprehensive_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ç”Ÿæˆ: {week_latest}")

    print(f"\nğŸ“Š ç”Ÿæˆçš„å¤šæ–‡æ¡£ç»¼åˆæ‰“åˆ†:")
    print(f"   - æ–‡æ¡£æ•°é‡: {len(documents)}")
    print(f"   - çƒ­åŠ›å›¾è¡Œæ•°: {len(heatmap_matrix)}")
    print(f"   - æ€»ä¿®æ”¹æ•°: 150")
    print(f"\nğŸ”¥ åŒ…å«çš„æ–‡æ¡£:")
    for i, doc in enumerate(documents, 1):
        print(f"   {i}. {doc}")

if __name__ == "__main__":
    generate_multi_document_score()