#!/usr/bin/env python3
"""
8089çƒ­åŠ›å›¾æœåŠ¡å™¨å¢å¼ºåŠŸèƒ½
åŒ…å«URLè½¯åˆ é™¤ç®¡ç†å’ŒåŸºçº¿æ–‡ä»¶ç®¡ç†
"""

import os
import json
import datetime
import shutil
from typing import Dict, List, Any, Optional

class URLManager:
    """URLè½¯åˆ é™¤ç®¡ç†å™¨"""
    
    def __init__(self, config_file: str):
        self.config_file = config_file
        self.config_dir = os.path.dirname(config_file)
        
    def save_links_with_soft_delete(self, links: List[Dict]) -> bool:
        """ä¿å­˜é“¾æ¥é…ç½®ï¼ˆæ”¯æŒè½¯åˆ é™¤ï¼‰"""
        try:
            if not os.path.exists(self.config_dir):
                os.makedirs(self.config_dir)
            
            # è¯»å–ç°æœ‰é…ç½®ä»¥ä¿ç•™è½¯åˆ é™¤çš„é“¾æ¥
            existing_config = {}
            if os.path.exists(self.config_file):
                try:
                    with open(self.config_file, 'r', encoding='utf-8') as f:
                        existing_config = json.load(f)
                except:
                    existing_config = {}
            
            # è·å–å·²è½¯åˆ é™¤çš„é“¾æ¥
            deleted_links = existing_config.get('deleted_links', [])
            
            # æ£€æŸ¥å“ªäº›é“¾æ¥è¢«åˆ é™¤äº†
            current_urls = [link.get('url') for link in links]
            if 'document_links' in existing_config:
                for old_link in existing_config['document_links']:
                    if old_link.get('url') not in current_urls:
                        # æ·»åŠ åˆ°è½¯åˆ é™¤åˆ—è¡¨
                        old_link['deleted_at'] = datetime.datetime.now().isoformat()
                        old_link['active'] = False
                        deleted_links.append(old_link)
            
            # ä¿å­˜é…ç½®
            config = {
                'document_links': links,  # å½“å‰æ´»è·ƒçš„é“¾æ¥
                'deleted_links': deleted_links,  # è½¯åˆ é™¤çš„é“¾æ¥
                'last_updated': datetime.datetime.now().isoformat()
            }
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ä¿å­˜äº† {len(links)} ä¸ªæ´»è·ƒæ–‡æ¡£é“¾æ¥")
            if deleted_links:
                print(f"ğŸ“‹ è½¯åˆ é™¤é“¾æ¥æ•°: {len(deleted_links)}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜é…ç½®å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def get_active_links(self) -> List[Dict]:
        """è·å–æ´»è·ƒçš„é“¾æ¥ï¼ˆä¸åŒ…å«è½¯åˆ é™¤çš„ï¼‰"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                return config.get('document_links', [])
            return []
        except:
            return []


class BaselineFileManager:
    """åŸºçº¿æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_dir = '/root/projects/tencent-doc-manager/csv_versions'
        
    def get_current_week(self) -> int:
        """è·å–å½“å‰å‘¨æ•°"""
        from production.core_modules.week_time_manager import WeekTimeManager
        week_manager = WeekTimeManager()
        return week_manager.get_current_week()
    
    def get_baseline_dir(self) -> str:
        """è·å–å½“å‰å‘¨çš„åŸºçº¿æ–‡ä»¶å¤¹è·¯å¾„"""
        current_week = self.get_current_week()
        return os.path.join(
            self.base_dir,
            f'2025_W{current_week:02d}',
            'baseline'
        )
    
    def list_baseline_files(self) -> Dict[str, Any]:
        """åˆ—å‡ºåŸºçº¿æ–‡ä»¶"""
        baseline_dir = self.get_baseline_dir()
        files = []
        
        if os.path.exists(baseline_dir):
            for filename in os.listdir(baseline_dir):
                if filename.endswith('.csv') or filename.endswith('.xlsx'):
                    file_path = os.path.join(baseline_dir, filename)
                    files.append({
                        'name': filename,
                        'path': file_path,
                        'size': os.path.getsize(file_path),
                        'modified': datetime.datetime.fromtimestamp(
                            os.path.getmtime(file_path)
                        ).isoformat()
                    })
        
        return {
            'success': True,
            'files': files,
            'week': self.get_current_week(),
            'path': baseline_dir
        }
    
    def download_baseline_file(self, url: str, cookie_string: str) -> Dict[str, Any]:
        """ä¸‹è½½åŸºçº¿æ–‡ä»¶"""
        try:
            baseline_dir = self.get_baseline_dir()
            os.makedirs(baseline_dir, exist_ok=True)
            
            # å¯¼å…¥ä¸‹è½½æ¨¡å—
            import sys
            sys.path.append('/root/projects/tencent-doc-manager')
            from production.core_modules.tencent_export_automation import TencentExporter
            
            exporter = TencentExporter(cookie_string=cookie_string)
            
            # ä¸‹è½½æ–‡ä»¶
            success, result = exporter.download_single_document(url)
            
            if success:
                # ç§»åŠ¨æ–‡ä»¶åˆ°åŸºçº¿æ–‡ä»¶å¤¹
                source_path = result.get('file_path')
                if source_path and os.path.exists(source_path):
                    filename = os.path.basename(source_path)
                    target_path = os.path.join(baseline_dir, filename)
                    
                    shutil.move(source_path, target_path)
                    
                    return {
                        'success': True,
                        'file': {
                            'name': filename,
                            'path': target_path
                        }
                    }
            
            return {
                'success': False,
                'error': result.get('error', 'ä¸‹è½½å¤±è´¥') if result else 'ä¸‹è½½å¤±è´¥'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def delete_baseline_file(self, filename: str) -> Dict[str, Any]:
        """è½¯åˆ é™¤åŸºçº¿æ–‡ä»¶"""
        try:
            baseline_dir = self.get_baseline_dir()
            file_path = os.path.join(baseline_dir, filename)
            
            if os.path.exists(file_path):
                # è½¯åˆ é™¤ï¼šç§»åŠ¨åˆ°å·²åˆ é™¤æ–‡ä»¶å¤¹
                deleted_dir = os.path.join(baseline_dir, '.deleted')
                os.makedirs(deleted_dir, exist_ok=True)
                
                timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
                deleted_filename = f"{timestamp}_{filename}"
                deleted_path = os.path.join(deleted_dir, deleted_filename)
                
                shutil.move(file_path, deleted_path)
                
                return {
                    'success': True,
                    'message': f'æ–‡ä»¶å·²è½¯åˆ é™¤: {filename}'
                }
            else:
                return {
                    'success': False,
                    'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
                }
                
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


# å¢å¼ºçš„æ—¥å¿—æ ¼å¼åŒ–å‡½æ•°
def format_log_with_icons(message: str, level: str = 'info') -> Dict[str, Any]:
    """æ ¼å¼åŒ–æ—¥å¿—æ¶ˆæ¯ï¼Œæ·»åŠ å›¾æ ‡å’Œæ ·å¼"""
    icons = {
        'info': 'â„¹ï¸',
        'success': 'âœ…',
        'warning': 'âš ï¸',
        'error': 'âŒ',
        'processing': 'â³',
        'download': 'ğŸ“¥',
        'upload': 'ğŸ“¤',
        'analysis': 'ğŸ”',
        'complete': 'ğŸ‰'
    }
    
    # æ ¹æ®æ¶ˆæ¯å†…å®¹è‡ªåŠ¨é€‰æ‹©å›¾æ ‡
    if 'æˆåŠŸ' in message or 'å®Œæˆ' in message:
        icon = icons['success']
        level = 'success'
    elif 'é”™è¯¯' in message or 'å¤±è´¥' in message:
        icon = icons['error']
        level = 'error'
    elif 'ä¸‹è½½' in message:
        icon = icons['download']
    elif 'ä¸Šä¼ ' in message:
        icon = icons['upload']
    elif 'åˆ†æ' in message or 'å¤„ç†' in message:
        icon = icons['analysis']
    elif 'å¼€å§‹' in message or 'å‡†å¤‡' in message:
        icon = icons['processing']
    else:
        icon = icons.get(level, '')
    
    return {
        'time': datetime.datetime.now().isoformat(),
        'level': level,
        'message': f"{icon} {message}" if icon else message,
        'icon': icon
    }


# Reactç»„ä»¶å¢å¼ºä»£ç ç‰‡æ®µ
REACT_ENHANCEMENTS = """
// åŸºçº¿æ–‡ä»¶ç®¡ç†çŠ¶æ€
const [baselineExpanded, setBaselineExpanded] = React.useState(false);
const [baselineUrl, setBaselineUrl] = React.useState('');
const [baselineFiles, setBaselineFiles] = React.useState([]);
const [currentWeek, setCurrentWeek] = React.useState(0);
const [baselinePath, setBaselinePath] = React.useState('');
const [downloadingBaseline, setDownloadingBaseline] = React.useState(false);
const [storedUrls, setStoredUrls] = React.useState([]);

// åŠ è½½åŸºçº¿æ–‡ä»¶åˆ—è¡¨
const loadBaselineFiles = async () => {
    try {
        const response = await fetch('/api/baseline-files');
        const data = await response.json();
        if (data.success) {
            setBaselineFiles(data.files || []);
            setCurrentWeek(data.week || 0);
            setBaselinePath(data.path || '');
        }
    } catch (error) {
        console.error('åŠ è½½åŸºçº¿æ–‡ä»¶å¤±è´¥:', error);
    }
};

// ä¸‹è½½åŸºçº¿æ–‡ä»¶
const handleDownloadBaseline = async () => {
    if (!baselineUrl) {
        alert('è¯·è¾“å…¥åŸºçº¿æ–‡ä»¶URL');
        return;
    }
    
    setDownloadingBaseline(true);
    try {
        const response = await fetch('/api/baseline-files', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                url: baselineUrl,
                cookie: cookieInput
            })
        });
        
        const data = await response.json();
        if (data.success) {
            alert(`åŸºçº¿æ–‡ä»¶ä¸‹è½½æˆåŠŸ: ${data.file.name}`);
            setBaselineUrl('');
            await loadBaselineFiles();  // åˆ·æ–°æ–‡ä»¶åˆ—è¡¨
        } else {
            alert(`ä¸‹è½½å¤±è´¥: ${data.error}`);
        }
    } catch (error) {
        alert(`ä¸‹è½½å‡ºé”™: ${error.message}`);
    } finally {
        setDownloadingBaseline(false);
    }
};

// åˆ é™¤åŸºçº¿æ–‡ä»¶
const handleDeleteBaseline = async (filename) => {
    if (!confirm(`ç¡®å®šè¦åˆ é™¤æ–‡ä»¶: ${filename}?`)) {
        return;
    }
    
    try {
        const response = await fetch('/api/baseline-files', {
            method: 'DELETE',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({filename})
        });
        
        const data = await response.json();
        if (data.success) {
            alert(data.message);
            await loadBaselineFiles();  // åˆ·æ–°æ–‡ä»¶åˆ—è¡¨
        } else {
            alert(`åˆ é™¤å¤±è´¥: ${data.error}`);
        }
    } catch (error) {
        alert(`åˆ é™¤å‡ºé”™: ${error.message}`);
    }
};
"""


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    config_file = '/root/projects/tencent-doc-manager/config/download_config.json'
    
    # æµ‹è¯•URLç®¡ç†å™¨
    url_manager = URLManager(config_file)
    test_links = [
        {"url": "https://docs.qq.com/sheet/test1", "name": "æµ‹è¯•æ–‡æ¡£1", "enabled": True},
        {"url": "https://docs.qq.com/sheet/test2", "name": "æµ‹è¯•æ–‡æ¡£2", "enabled": True}
    ]
    url_manager.save_links_with_soft_delete(test_links)
    
    # æµ‹è¯•åŸºçº¿æ–‡ä»¶ç®¡ç†å™¨
    baseline_manager = BaselineFileManager()
    files_info = baseline_manager.list_baseline_files()
    print(f"åŸºçº¿æ–‡ä»¶ä¿¡æ¯: {json.dumps(files_info, ensure_ascii=False, indent=2)}")