#!/usr/bin/env python3
"""åˆ†æCSVæ–‡ä»¶æ ¼å¼å·®å¼‚"""

import csv
import json

def analyze_csv_column(file_path, column_name='é‡è¦ç¨‹åº¦'):
    """åˆ†æCSVæ–‡ä»¶ä¸­æŒ‡å®šåˆ—çš„å†…å®¹"""
    print(f"\nğŸ“ åˆ†ææ–‡ä»¶: {file_path.split('/')[-1]}")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)

            # è·³è¿‡å‰é¢çš„ç©ºè¡Œ
            for _ in range(2):
                next(reader)

            # é‡æ–°è¯»å–å¸¦æœ‰æ­£ç¡®headerçš„CSV
            f.seek(0)
            lines = f.readlines()

            # æ‰¾åˆ°å®é™…çš„headerè¡Œï¼ˆé€šå¸¸æ˜¯ç¬¬3è¡Œï¼‰
            header_line = None
            for i, line in enumerate(lines[:5]):
                if 'é¡¹ç›®ç±»å‹' in line and 'é‡è¦ç¨‹åº¦' in line:
                    header_line = i
                    break

            if header_line is None:
                print("  âŒ æ‰¾ä¸åˆ°æ ‡é¢˜è¡Œ")
                return None

            # é‡æ–°è§£æCSV
            f.seek(0)
            for _ in range(header_line):
                f.readline()

            reader = csv.DictReader(f)

            # åˆ†æå‰20è¡Œæ•°æ®
            column_values = []
            unique_formats = set()

            for i, row in enumerate(reader):
                if i >= 20:  # åªåˆ†æå‰20è¡Œ
                    break

                if column_name in row:
                    value = row[column_name]
                    if value and value.strip():
                        column_values.append(value)

                        # æ£€æµ‹æ ¼å¼ç±»å‹
                        if 'â˜…' in value:
                            unique_formats.add('stars')
                        elif value.isdigit():
                            unique_formats.add('numbers')
                        else:
                            unique_formats.add('other')

            print(f"  âœ… æ‰¾åˆ° {len(column_values)} ä¸ªéç©ºå€¼")
            print(f"  ğŸ“Š æ ¼å¼ç±»å‹: {', '.join(unique_formats) if unique_formats else 'æ— æ•°æ®'}")

            # æ˜¾ç¤ºå‰5ä¸ªæ ·æœ¬
            print(f"  ğŸ“‹ å‰5ä¸ªæ ·æœ¬:")
            for j, val in enumerate(column_values[:5], 1):
                # æ˜¾ç¤ºåŸå§‹å­—ç¬¦å’Œå®ƒä»¬çš„Unicodeç¼–ç 
                print(f"     {j}. '{val}' (é•¿åº¦: {len(val)})")
                if 'â˜…' in val:
                    star_count = val.count('â˜…')
                    empty_star_count = val.count('â˜†')
                    print(f"        â†’ {star_count} ä¸ªå®å¿ƒæ˜Ÿ + {empty_star_count} ä¸ªç©ºå¿ƒæ˜Ÿ")

            return {
                'format_types': list(unique_formats),
                'sample_values': column_values[:5],
                'total_values': len(column_values)
            }

    except Exception as e:
        print(f"  âŒ é”™è¯¯: {e}")
        return None

# åˆ†æä¸¤ä¸ªæ–‡ä»¶
baseline_file = '/root/projects/tencent-doc-manager/csv_versions/2025_W39/baseline/tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_20250915_0145_baseline_W39.csv'
target_file = '/root/projects/tencent-doc-manager/csv_versions/2025_W39/midweek/tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_20250925_1956_midweek_W39.csv'

print("=" * 60)
print("ğŸ” CSVæ ¼å¼å·®å¼‚åˆ†æ")
print("=" * 60)

baseline_result = analyze_csv_column(baseline_file)
target_result = analyze_csv_column(target_file)

print("\n" + "=" * 60)
print("ğŸ“Š åˆ†æç»“æœæ€»ç»“")
print("=" * 60)

if baseline_result and target_result:
    print(f"\nâœ… åŸºçº¿æ–‡ä»¶æ ¼å¼: {baseline_result['format_types']}")
    print(f"âœ… ç›®æ ‡æ–‡ä»¶æ ¼å¼: {target_result['format_types']}")

    if baseline_result['format_types'] != target_result['format_types']:
        print("\nâš ï¸ æ ¼å¼ä¸ä¸€è‡´ï¼")
        print("ğŸ”§ åŸå› åˆ†æ:")
        print("  1. è…¾è®¯æ–‡æ¡£åœ¨9æœˆ15æ—¥åˆ°9æœˆ25æ—¥æœŸé—´æ›´æ”¹äº†å¯¼å‡ºè®¾ç½®")
        print("  2. å¯èƒ½æœ‰äººæ‰‹åŠ¨ç¼–è¾‘äº†å…¶ä¸­ä¸€ä¸ªæ–‡ä»¶")
        print("  3. ä¸åŒçš„å¯¼å‡ºæ–¹å¼ï¼ˆç½‘é¡µç‰ˆ vs å®¢æˆ·ç«¯ï¼‰")
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("  éœ€è¦åœ¨å¯¹æ¯”å‰è¿›è¡Œæ ¼å¼æ ‡å‡†åŒ–å¤„ç†")
        print("  å°†æ˜Ÿçº§(â˜…â˜…â˜…â˜…â˜…)è½¬æ¢ä¸ºæ•°å­—(5)è¿›è¡Œç»Ÿä¸€æ¯”è¾ƒ")
    else:
        print("\nâœ… æ ¼å¼ä¸€è‡´")