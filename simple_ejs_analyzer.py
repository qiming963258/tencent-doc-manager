#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•çš„EJSæ ¼å¼åˆ†æå™¨ - ä¸ä¾èµ–pandas
"""

import json
import urllib.parse
import base64
import gzip
import io
from pathlib import Path

def analyze_ejs_file(file_path):
    """åˆ†æEJSæ ¼å¼æ–‡ä»¶çš„ç»“æ„"""
    print(f"\n{'='*60}")
    print(f"åˆ†ææ–‡ä»¶: {file_path}")
    print(f"{'='*60}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    print(f"æ–‡ä»¶è¡Œæ•°: {len(lines)}")
    
    # åˆ†ææ¯ä¸€è¡Œ
    for i, line in enumerate(lines[:10], 1):  # åªçœ‹å‰10è¡Œ
        line = line.strip()
        if not line:
            continue
            
        print(f"\nç¬¬{i}è¡Œ:")
        print(f"é•¿åº¦: {len(line)} å­—ç¬¦")
        
        # æ£€æŸ¥è¡Œç±»å‹
        if line == 'head':
            print("ç±»å‹: EJSæ–‡ä»¶å¤´æ ‡è¯†")
        elif line == 'json':
            print("ç±»å‹: JSONæ•°æ®å¼€å§‹æ ‡è¯†")
        elif line == 'text':
            print("ç±»å‹: æ–‡æœ¬æ•°æ®æ ‡è¯†")
        elif line.isdigit():
            print(f"ç±»å‹: æ•°æ®é•¿åº¦æ ‡è¯† ({line} å­—ç¬¦)")
        elif line.startswith('{'):
            print("ç±»å‹: JSONå¯¹è±¡")
            # å°è¯•è§£æJSON
            try:
                data = json.loads(line)
                print(f"JSON keys: {list(data.keys())[:5]}")
                
                # æ£€æŸ¥å…³é”®å­—æ®µ
                if 'clientVars' in data:
                    print("  - åŒ…å«clientVars (ç”¨æˆ·ä¿¡æ¯)")
                if 'bodyData' in data:
                    print("  - åŒ…å«bodyData (æ–‡æ¡£æ•°æ®)")
                    body = data['bodyData']
                    if isinstance(body, dict):
                        print(f"    bodyData keys: {list(body.keys())[:5]}")
                if 'workbook' in data:
                    print("  - åŒ…å«workbook (è¡¨æ ¼æ•°æ®)")
                    
            except:
                print("  JSONè§£æå¤±è´¥")
        elif line.startswith('%'):
            print("ç±»å‹: URLç¼–ç æ•°æ®")
            print(f"å‰50å­—ç¬¦: {line[:50]}...")
            
            # å°è¯•URLè§£ç 
            try:
                decoded = urllib.parse.unquote(line)
                print(f"URLè§£ç åé•¿åº¦: {len(decoded)}")
                
                # æ£€æŸ¥è§£ç åæ˜¯å¦æ˜¯JSON
                if decoded.startswith('{'):
                    try:
                        decoded_data = json.loads(decoded)
                        print(f"URLè§£ç åæ˜¯JSON, keys: {list(decoded_data.keys())[:5]}")
                        
                        if 'workbook' in decoded_data:
                            workbook = decoded_data['workbook']
                            print(f"å‘ç°workbookå­—æ®µ, é•¿åº¦: {len(workbook)}")
                            
                            # å°è¯•Base64è§£ç workbook
                            try:
                                workbook_bytes = base64.b64decode(workbook)
                                print(f"Base64è§£ç æˆåŠŸ, å­—èŠ‚æ•°: {len(workbook_bytes)}")
                                
                                # å°è¯•gzipè§£å‹
                                try:
                                    with gzip.open(io.BytesIO(workbook_bytes), 'rt', encoding='utf-8') as gz:
                                        workbook_data = gz.read()
                                    print(f"Gzipè§£å‹æˆåŠŸ, æ•°æ®é•¿åº¦: {len(workbook_data)}")
                                    print(f"è§£å‹åæ•°æ®é¢„è§ˆ: {workbook_data[:200]}...")
                                except:
                                    # å¦‚æœä¸æ˜¯gzipï¼Œå°è¯•ç›´æ¥è§£ç 
                                    try:
                                        workbook_text = workbook_bytes.decode('utf-8')
                                        print(f"ç›´æ¥UTF-8è§£ç æˆåŠŸ, é•¿åº¦: {len(workbook_text)}")
                                        print(f"æ•°æ®é¢„è§ˆ: {workbook_text[:200]}...")
                                    except:
                                        print("æ— æ³•è§£ç workbookæ•°æ®")
                            except Exception as e:
                                print(f"Base64è§£ç å¤±è´¥: {e}")
                    except:
                        print("URLè§£ç åä¸æ˜¯JSON")
            except:
                print("URLè§£ç å¤±è´¥")
        else:
            print(f"ç±»å‹: å…¶ä»–")
            print(f"å‰50å­—ç¬¦: {line[:50]}...")

def extract_table_data(file_path):
    """å°è¯•æå–è¡¨æ ¼æ•°æ®"""
    print(f"\n{'='*60}")
    print("å°è¯•æå–è¡¨æ ¼æ•°æ®...")
    print(f"{'='*60}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æŸ¥æ‰¾åŒ…å«workbookçš„è¡Œ
    for i, line in enumerate(lines):
        line = line.strip()
        if not line or len(line) < 100:
            continue
            
        # å¦‚æœæ˜¯URLç¼–ç çš„æ•°æ®
        if '%' in line[:100]:
            try:
                decoded = urllib.parse.unquote(line)
                if 'workbook' in decoded:
                    print(f"åœ¨ç¬¬{i+1}è¡Œå‘ç°workbookæ•°æ®")
                    
                    # è§£æJSON
                    data = json.loads(decoded)
                    workbook = data.get('workbook', '')
                    
                    if workbook:
                        # Base64è§£ç 
                        try:
                            wb_bytes = base64.b64decode(workbook)
                            
                            # å°è¯•å¤šç§è§£ç æ–¹å¼
                            # 1. å°è¯•gzip
                            try:
                                with gzip.open(io.BytesIO(wb_bytes), 'rt', encoding='utf-8') as gz:
                                    wb_data = gz.read()
                                print("âœ… Gzipè§£å‹æˆåŠŸ")
                            except:
                                # 2. å°è¯•ç›´æ¥UTF-8
                                try:
                                    wb_data = wb_bytes.decode('utf-8')
                                    print("âœ… UTF-8è§£ç æˆåŠŸ")
                                except:
                                    # 3. å°è¯•å…¶ä»–ç¼–ç 
                                    wb_data = wb_bytes.decode('utf-8', errors='ignore')
                                    print("âœ… UTF-8(å¿½ç•¥é”™è¯¯)è§£ç æˆåŠŸ")
                            
                            print(f"è§£ç åæ•°æ®é•¿åº¦: {len(wb_data)}")
                            
                            # åˆ†ææ•°æ®å†…å®¹
                            if ',' in wb_data[:1000] or '\t' in wb_data[:1000]:
                                print("ğŸ“Š çœ‹èµ·æ¥æ˜¯CSVæ ¼å¼æ•°æ®")
                                # æå–å‰å‡ è¡Œ
                                lines = wb_data.split('\n')[:10]
                                print("\nå‰10è¡Œæ•°æ®:")
                                for j, line in enumerate(lines, 1):
                                    if line:
                                        print(f"  {j}: {line[:100]}{'...' if len(line) > 100 else ''}")
                                
                                # ä¿å­˜ä¸ºCSVæ–‡ä»¶
                                csv_file = file_path.replace('.csv', '_extracted.csv')
                                with open(csv_file, 'w', encoding='utf-8') as f:
                                    f.write(wb_data)
                                print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {csv_file}")
                                
                                return True
                                
                            elif '[' in wb_data[:100] or '{' in wb_data[:100]:
                                print("ğŸ“Š çœ‹èµ·æ¥æ˜¯JSONæ ¼å¼æ•°æ®")
                                try:
                                    json_data = json.loads(wb_data)
                                    print(f"JSONæ•°æ®ç±»å‹: {type(json_data)}")
                                    if isinstance(json_data, dict):
                                        print(f"Keys: {list(json_data.keys())[:10]}")
                                    elif isinstance(json_data, list):
                                        print(f"æ•°ç»„é•¿åº¦: {len(json_data)}")
                                        if json_data:
                                            print(f"ç¬¬ä¸€ä¸ªå…ƒç´ : {json_data[0]}")
                                except:
                                    print("JSONè§£æå¤±è´¥ï¼Œä½†åŒ…å«JSONç‰¹å¾")
                                    
                        except Exception as e:
                            print(f"Workbookè§£ç å¤±è´¥: {e}")
                            
            except Exception as e:
                continue
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    test_files = [
        "/root/projects/tencent-doc-manager/test_DWEVjZndkR2xVSWJN_CSVæ ¼å¼_20250827_231718.csv",
        "/root/projects/tencent-doc-manager/test_DWEVjZndkR2xVSWJN_Excelæ ¼å¼_20250827_231720.xlsx"
    ]
    
    success_count = 0
    
    for file_path in test_files:
        if not Path(file_path).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        # åˆ†ææ–‡ä»¶ç»“æ„
        analyze_ejs_file(file_path)
        
        # æå–è¡¨æ ¼æ•°æ®
        if extract_table_data(file_path):
            success_count += 1
    
    print(f"\n{'='*60}")
    print(f"åˆ†æå®Œæˆ: {success_count}/{len(test_files)} æ–‡ä»¶æˆåŠŸæå–æ•°æ®")
    print(f"{'='*60}")
    
    if success_count > 0:
        print("âœ… æˆåŠŸä»EJSæ ¼å¼æå–è¡¨æ ¼æ•°æ®!")
        print("ğŸ’¡ ä¸‹ä¸€æ­¥: å¯ä»¥å°†æå–çš„æ•°æ®è½¬æ¢ä¸ºæ ‡å‡†Excelæ ¼å¼")
    else:
        print("âŒ æœªèƒ½æˆåŠŸæå–è¡¨æ ¼æ•°æ®")
        print("ğŸ’¡ éœ€è¦è¿›ä¸€æ­¥åˆ†æEJSæ ¼å¼çš„ç¼–ç æ–¹å¼")

if __name__ == "__main__":
    main()