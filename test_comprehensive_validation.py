#!/usr/bin/env python3
"""
æµ‹è¯•ç»¼åˆæ‰“åˆ†æ–‡ä»¶éªŒè¯å’Œé”™è¯¯æŠ¥å‘Š
æµ‹è¯•å„ç§ä¸ç¬¦åˆè§„èŒƒçš„æƒ…å†µ
"""

import json
import os
import sys
from datetime import datetime

sys.path.append('/root/projects/tencent-doc-manager')
from comprehensive_score_validator import ComprehensiveScoreValidator
from standard_columns_config import STANDARD_COLUMNS

def create_invalid_file_wrong_columns():
    """åˆ›å»ºä¸€ä¸ªåˆ—åé”™è¯¯çš„æ–‡ä»¶"""
    data = {
        "metadata": {
            "version": "2.0",
            "timestamp": datetime.now().isoformat(),
            "week": "W38",
            "generator": "test",
            "total_params": 5200,
            "processing_time": 1.0
        },
        "summary": {
            "total_tables": 3,
            "total_columns": 19,
            "total_modifications": 100,
            "overall_risk_score": 0.5,
            "processing_status": "complete"
        },
        "table_names": ["è¡¨1", "è¡¨2", "è¡¨3"],
        # æ•…æ„ä½¿ç”¨é”™è¯¯çš„åˆ—å
        "column_names": [
            "é”™è¯¯åˆ—1", "é”™è¯¯åˆ—2", "é”™è¯¯åˆ—3", "é”™è¯¯åˆ—4", "é”™è¯¯åˆ—5",
            "é”™è¯¯åˆ—6", "é”™è¯¯åˆ—7", "é”™è¯¯åˆ—8", "é”™è¯¯åˆ—9", "é”™è¯¯åˆ—10",
            "é”™è¯¯åˆ—11", "é”™è¯¯åˆ—12", "é”™è¯¯åˆ—13", "é”™è¯¯åˆ—14", "é”™è¯¯åˆ—15",
            "é”™è¯¯åˆ—16", "é”™è¯¯åˆ—17", "é”™è¯¯åˆ—18", "é”™è¯¯åˆ—19"
        ],
        "heatmap_data": {
            "matrix": [[0.1] * 19 for _ in range(3)]
        },
        "table_details": [],
        "hover_data": {"data": []},
        "statistics": {
            "table_modifications": [10, 20, 30],
            "table_row_counts": [100, 200, 300],
            "column_total_modifications": [5] * 19,
            "risk_distribution": {"high": 1, "medium": 2, "low": 3}
        }
    }

    filename = '/tmp/test_wrong_columns.json'
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return filename

def create_invalid_file_wrong_column_count():
    """åˆ›å»ºä¸€ä¸ªåˆ—æ•°é”™è¯¯çš„æ–‡ä»¶"""
    data = {
        "metadata": {
            "version": "2.0",
            "timestamp": datetime.now().isoformat(),
            "week": "W38",
            "generator": "test",
            "total_params": 5200,
            "processing_time": 1.0
        },
        "summary": {
            "total_tables": 3,
            "total_columns": 15,  # é”™è¯¯çš„åˆ—æ•°
            "total_modifications": 100,
            "overall_risk_score": 0.5,
            "processing_status": "complete"
        },
        "table_names": ["è¡¨1", "è¡¨2", "è¡¨3"],
        # åªæœ‰15ä¸ªåˆ—å
        "column_names": STANDARD_COLUMNS[:15],
        "heatmap_data": {
            "matrix": [[0.1] * 15 for _ in range(3)]  # é”™è¯¯çš„çŸ©é˜µå¤§å°
        },
        "table_details": [],
        "hover_data": {"data": []},
        "statistics": {
            "table_modifications": [10, 20, 30],
            "table_row_counts": [100, 200, 300],
            "column_total_modifications": [5] * 15,  # é”™è¯¯çš„é•¿åº¦
            "risk_distribution": {"high": 1, "medium": 2, "low": 3}
        }
    }

    filename = '/tmp/test_wrong_count.json'
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return filename

def create_invalid_file_missing_fields():
    """åˆ›å»ºä¸€ä¸ªç¼ºå°‘å¿…éœ€å­—æ®µçš„æ–‡ä»¶"""
    data = {
        "metadata": {
            "version": "2.0",
            # ç¼ºå°‘timestamp
            "week": "W38",
            "generator": "test",
            # ç¼ºå°‘total_params
            "processing_time": 1.0
        },
        # ç¼ºå°‘summary
        "table_names": ["è¡¨1", "è¡¨2", "è¡¨3"],
        "column_names": STANDARD_COLUMNS,
        # ç¼ºå°‘heatmap_data
        "table_details": [],
        # ç¼ºå°‘hover_data
        # ç¼ºå°‘statistics
    }

    filename = '/tmp/test_missing_fields.json'
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    return filename

def test_validation():
    """æµ‹è¯•å„ç§éªŒè¯æƒ…å†µ"""
    print("=" * 60)
    print("ğŸ§ª ç»¼åˆæ‰“åˆ†æ–‡ä»¶éªŒè¯æµ‹è¯•")
    print("=" * 60)

    validator = ComprehensiveScoreValidator()

    # æµ‹è¯•1ï¼šåˆ—åé”™è¯¯
    print("\nğŸ“‹ æµ‹è¯•1ï¼šåˆ—åé”™è¯¯")
    print("-" * 40)
    file1 = create_invalid_file_wrong_columns()
    is_valid, errors, _ = validator.validate_file(file1)

    if not is_valid:
        print(f"âŒ éªŒè¯å¤±è´¥ï¼ˆé¢„æœŸï¼‰")
        print("\né”™è¯¯è¯¦æƒ…:")
        for i, error in enumerate(errors[:5], 1):
            print(f"  {i}. {error}")
    else:
        print("âš ï¸ éªŒè¯é€šè¿‡ï¼ˆä¸åº”è¯¥ï¼‰")

    # æµ‹è¯•2ï¼šåˆ—æ•°é”™è¯¯
    print("\nğŸ“‹ æµ‹è¯•2ï¼šåˆ—æ•°é”™è¯¯")
    print("-" * 40)
    file2 = create_invalid_file_wrong_column_count()
    is_valid, errors, _ = validator.validate_file(file2)

    if not is_valid:
        print(f"âŒ éªŒè¯å¤±è´¥ï¼ˆé¢„æœŸï¼‰")
        print("\né”™è¯¯è¯¦æƒ…:")
        for i, error in enumerate(errors[:5], 1):
            print(f"  {i}. {error}")
    else:
        print("âš ï¸ éªŒè¯é€šè¿‡ï¼ˆä¸åº”è¯¥ï¼‰")

    # æµ‹è¯•3ï¼šç¼ºå°‘å¿…éœ€å­—æ®µ
    print("\nğŸ“‹ æµ‹è¯•3ï¼šç¼ºå°‘å¿…éœ€å­—æ®µ")
    print("-" * 40)
    file3 = create_invalid_file_missing_fields()
    is_valid, errors, _ = validator.validate_file(file3)

    if not is_valid:
        print(f"âŒ éªŒè¯å¤±è´¥ï¼ˆé¢„æœŸï¼‰")
        print("\né”™è¯¯è¯¦æƒ…:")
        for i, error in enumerate(errors[:10], 1):
            print(f"  {i}. {error}")
    else:
        print("âš ï¸ éªŒè¯é€šè¿‡ï¼ˆä¸åº”è¯¥ï¼‰")

    # æµ‹è¯•4ï¼šéªŒè¯æ­£ç¡®çš„æ–‡ä»¶
    print("\nğŸ“‹ æµ‹è¯•4ï¼šéªŒè¯æ­£ç¡®çš„æ–‡ä»¶")
    print("-" * 40)
    correct_file = '/root/projects/tencent-doc-manager/scoring_results/comprehensive/comprehensive_score_W38_clustered.json'

    if os.path.exists(correct_file):
        is_valid, errors, data = validator.validate_file(correct_file)

        if is_valid:
            print("âœ… éªŒè¯é€šè¿‡ï¼ˆé¢„æœŸï¼‰")
            print(f"  - ç‰ˆæœ¬: {data['metadata']['version']}")
            print(f"  - è¡¨æ ¼æ•°: {data['summary']['total_tables']}")
            print(f"  - å‚æ•°æ•°: {data['metadata']['total_params']}")
        else:
            print("âŒ éªŒè¯å¤±è´¥ï¼ˆä¸åº”è¯¥ï¼‰")
            for error in errors[:5]:
                print(f"  - {error}")

    # æ¸…ç†æµ‹è¯•æ–‡ä»¶
    for f in [file1, file2, file3]:
        if os.path.exists(f):
            os.remove(f)

    print("\n" + "=" * 60)
    print("âœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    test_validation()