#!/usr/bin/env python3
"""
è…¾è®¯æ–‡æ¡£ä¸‹è½½åŠŸèƒ½ç¨³å®šæ€§æµ‹è¯•ç¨‹åº
æµ‹è¯•å¤šä¸ªæ–‡æ¡£çš„CSVå’ŒXLSXæ ¼å¼ä¸‹è½½ï¼Œè®°å½•è¯¦ç»†æ€§èƒ½æ•°æ®å’Œå¤±è´¥åŸå› åˆ†æ
"""

import os
import sys
import time
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple
from dataclasses import dataclass, asdict
import traceback
from pathlib import Path
import statistics

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/projects/tencent-doc-manager/production/core_modules')

try:
    from stable_cookie_downloader import StableCookieDownloader
except ImportError as e:
    print(f"å¯¼å…¥ä¸‹è½½å™¨å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿ stable_cookie_downloader.py å­˜åœ¨ä¸”å¯è®¿é—®")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/root/projects/tencent-doc-manager/download_test.log')
    ]
)
logger = logging.getLogger(__name__)


@dataclass
class TestResult:
    """å•æ¬¡ä¸‹è½½æµ‹è¯•ç»“æœ"""
    document_name: str
    url: str
    export_format: str
    success: bool
    download_time: float
    file_size: int
    endpoint_used: str
    error_message: str
    timestamp: str
    doc_id: str
    retry_count: int = 0


@dataclass
class TestSummary:
    """æµ‹è¯•æ€»ç»“æŠ¥å‘Š"""
    total_tests: int
    successful_downloads: int
    failed_downloads: int
    success_rate: float
    average_download_time: float
    total_download_time: float
    total_file_size: int
    test_duration: float
    csv_success_rate: float
    xlsx_success_rate: float
    endpoint_performance: Dict
    failure_reasons: Dict
    recommendations: List[str]


class TencentDocDownloadTester:
    """è…¾è®¯æ–‡æ¡£ä¸‹è½½ç¨³å®šæ€§æµ‹è¯•å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        self.test_documents = [
            {
                'name': 'æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨',
                'url': 'https://docs.qq.com/sheet/DWEVjZndkR2xVSWJN',
                'description': 'å°çº¢ä¹¦éƒ¨é—¨å·¥ä½œè¡¨'
            },
            {
                'name': 'æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨',
                'url': 'https://docs.qq.com/sheet/DRFppYm15RGZ2WExN',
                'description': 'å›å›½é”€å”®ä¸šåŠ¡è®¡åˆ’è¡¨'
            },
            {
                'name': 'æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨',
                'url': 'https://docs.qq.com/sheet/DRHZrS1hOS3pwRGZB',
                'description': 'å‡ºå›½é”€å”®ä¸šåŠ¡è®¡åˆ’è¡¨'
            }
        ]
        
        self.export_formats = ['csv', 'xlsx']
        self.test_results: List[TestResult] = []
        self.cookie_file = '/root/projects/tencent-doc-manager/config/cookies_new.json'
        self.output_dir = '/root/projects/tencent-doc-manager/test_results'
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_dir, exist_ok=True)
        os.makedirs('/root/projects/tencent-doc-manager/downloads', exist_ok=True)
        
        logger.info("ğŸš€ è…¾è®¯æ–‡æ¡£ä¸‹è½½ç¨³å®šæ€§æµ‹è¯•å™¨å·²åˆå§‹åŒ–")
        logger.info(f"æµ‹è¯•æ–‡æ¡£æ•°é‡: {len(self.test_documents)}")
        logger.info(f"æµ‹è¯•æ ¼å¼: {', '.join(self.export_formats)}")
        logger.info(f"æ€»æµ‹è¯•æ•°: {len(self.test_documents) * len(self.export_formats)}")
    
    def validate_cookie_config(self) -> bool:
        """éªŒè¯Cookieé…ç½®"""
        try:
            if not os.path.exists(self.cookie_file):
                logger.error(f"âŒ Cookieé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {self.cookie_file}")
                return False
            
            with open(self.cookie_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            if not config.get('current_cookies'):
                logger.error("âŒ Cookieé…ç½®ä¸­æ²¡æœ‰current_cookies")
                return False
            
            if not config.get('is_valid', False):
                logger.warning("âš ï¸  Cookieé…ç½®æ ‡è®°ä¸ºæ— æ•ˆï¼Œä½†ç»§ç»­æµ‹è¯•")
            
            logger.info("âœ… Cookieé…ç½®éªŒè¯é€šè¿‡")
            logger.info(f"Cookieæ›´æ–°æ—¶é—´: {config.get('last_update', 'Unknown')}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Cookieé…ç½®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def run_single_test(self, document: Dict, export_format: str, 
                       downloader: StableCookieDownloader, retry_count: int = 0) -> TestResult:
        """æ‰§è¡Œå•ä¸ªä¸‹è½½æµ‹è¯•"""
        start_time = time.time()
        
        logger.info(f"ğŸ“¥ æµ‹è¯•ä¸‹è½½: {document['name']} (æ ¼å¼: {export_format})")
        
        try:
            # æ‰§è¡Œä¸‹è½½
            result = downloader.download_document(
                url=document['url'],
                export_type=export_format,
                save_dir='/root/projects/tencent-doc-manager/downloads'
            )
            
            download_time = time.time() - start_time
            
            if result.get('success', False):
                # æˆåŠŸä¸‹è½½
                file_size = result.get('file_size', 0)
                logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {file_size/1024:.1f} KB, {download_time:.2f}ç§’")
                
                return TestResult(
                    document_name=document['name'],
                    url=document['url'],
                    export_format=export_format,
                    success=True,
                    download_time=download_time,
                    file_size=file_size,
                    endpoint_used=result.get('endpoint_used', 'unknown'),
                    error_message='',
                    timestamp=datetime.now().isoformat(),
                    doc_id=result.get('doc_id', ''),
                    retry_count=retry_count
                )
            else:
                # ä¸‹è½½å¤±è´¥
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {error_msg}")
                
                return TestResult(
                    document_name=document['name'],
                    url=document['url'],
                    export_format=export_format,
                    success=False,
                    download_time=download_time,
                    file_size=0,
                    endpoint_used=result.get('endpoint_used', 'none'),
                    error_message=error_msg,
                    timestamp=datetime.now().isoformat(),
                    doc_id=result.get('doc_id', ''),
                    retry_count=retry_count
                )
                
        except Exception as e:
            download_time = time.time() - start_time
            error_msg = f"æµ‹è¯•å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ {error_msg}")
            logger.debug(traceback.format_exc())
            
            return TestResult(
                document_name=document['name'],
                url=document['url'],
                export_format=export_format,
                success=False,
                download_time=download_time,
                file_size=0,
                endpoint_used='error',
                error_message=error_msg,
                timestamp=datetime.now().isoformat(),
                doc_id='',
                retry_count=retry_count
            )
    
    def run_comprehensive_test(self, retry_failed: bool = True, max_retries: int = 2) -> List[TestResult]:
        """æ‰§è¡Œå…¨é¢ä¸‹è½½æµ‹è¯•"""
        logger.info("ğŸ” å¼€å§‹å…¨é¢ä¸‹è½½æµ‹è¯•...")
        test_start_time = time.time()
        
        # éªŒè¯Cookie
        if not self.validate_cookie_config():
            logger.error("Cookieé…ç½®æ— æ•ˆï¼Œæµ‹è¯•ä¸­æ­¢")
            return []
        
        # åˆå§‹åŒ–ä¸‹è½½å™¨
        downloader = StableCookieDownloader(cookie_file=self.cookie_file)
        results = []
        
        # æ‰§è¡Œä¸»è¦æµ‹è¯•
        total_tests = len(self.test_documents) * len(self.export_formats)
        current_test = 0
        
        for document in self.test_documents:
            for export_format in self.export_formats:
                current_test += 1
                logger.info(f"[{current_test}/{total_tests}] æµ‹è¯•è¿›è¡Œä¸­...")
                
                # æ‰§è¡Œæµ‹è¯•
                result = self.run_single_test(document, export_format, downloader)
                results.append(result)
                
                # æµ‹è¯•é—´éš”
                time.sleep(3)
        
        # é‡è¯•å¤±è´¥çš„æµ‹è¯•
        if retry_failed and max_retries > 0:
            failed_results = [r for r in results if not r.success]
            if failed_results:
                logger.info(f"ğŸ”„ é‡è¯• {len(failed_results)} ä¸ªå¤±è´¥çš„æµ‹è¯•...")
                
                for failed_result in failed_results:
                    for retry in range(max_retries):
                        logger.info(f"é‡è¯• {retry + 1}/{max_retries}: {failed_result.document_name}")
                        
                        # æ‰¾åˆ°å¯¹åº”çš„æ–‡æ¡£
                        doc = next(d for d in self.test_documents 
                                 if d['name'] == failed_result.document_name)
                        
                        retry_result = self.run_single_test(
                            doc, failed_result.export_format, downloader, retry + 1
                        )
                        results.append(retry_result)
                        
                        if retry_result.success:
                            logger.info("âœ… é‡è¯•æˆåŠŸ")
                            break
                        
                        time.sleep(5)  # é‡è¯•é—´éš”æ›´é•¿
        
        test_duration = time.time() - test_start_time
        logger.info(f"ğŸ æµ‹è¯•å®Œæˆï¼Œæ€»è€—æ—¶: {test_duration:.1f}ç§’")
        
        self.test_results = results
        return results
    
    def analyze_results(self, results: List[TestResult]) -> TestSummary:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        logger.info("ğŸ“Š åˆ†ææµ‹è¯•ç»“æœ...")
        
        if not results:
            logger.warning("æ²¡æœ‰æµ‹è¯•ç»“æœå¯åˆ†æ")
            return TestSummary(
                total_tests=0, successful_downloads=0, failed_downloads=0,
                success_rate=0.0, average_download_time=0.0, total_download_time=0.0,
                total_file_size=0, test_duration=0.0, csv_success_rate=0.0,
                xlsx_success_rate=0.0, endpoint_performance={},
                failure_reasons={}, recommendations=[]
            )
        
        # åŸºç¡€ç»Ÿè®¡
        total_tests = len(results)
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        successful_count = len(successful)
        failed_count = len(failed)
        success_rate = successful_count / total_tests * 100
        
        # æ—¶é—´ç»Ÿè®¡
        total_download_time = sum(r.download_time for r in results)
        avg_download_time = statistics.mean([r.download_time for r in results]) if results else 0
        
        # æ–‡ä»¶å¤§å°ç»Ÿè®¡
        total_file_size = sum(r.file_size for r in successful)
        
        # æŒ‰æ ¼å¼ç»Ÿè®¡
        csv_results = [r for r in results if r.export_format == 'csv']
        xlsx_results = [r for r in results if r.export_format == 'xlsx']
        
        csv_success_rate = len([r for r in csv_results if r.success]) / len(csv_results) * 100 if csv_results else 0
        xlsx_success_rate = len([r for r in xlsx_results if r.success]) / len(xlsx_results) * 100 if xlsx_results else 0
        
        # ç«¯ç‚¹æ€§èƒ½ç»Ÿè®¡
        endpoint_stats = {}
        for result in successful:
            endpoint = result.endpoint_used
            if endpoint not in endpoint_stats:
                endpoint_stats[endpoint] = {'count': 0, 'total_time': 0, 'avg_time': 0}
            endpoint_stats[endpoint]['count'] += 1
            endpoint_stats[endpoint]['total_time'] += result.download_time
        
        for endpoint in endpoint_stats:
            stats = endpoint_stats[endpoint]
            stats['avg_time'] = stats['total_time'] / stats['count']
        
        # å¤±è´¥åŸå› ç»Ÿè®¡
        failure_reasons = {}
        for result in failed:
            reason = result.error_message
            if reason not in failure_reasons:
                failure_reasons[reason] = 0
            failure_reasons[reason] += 1
        
        # ç”Ÿæˆå»ºè®®
        recommendations = []
        
        if success_rate < 80:
            recommendations.append("æˆåŠŸç‡è¾ƒä½ï¼Œå»ºè®®æ£€æŸ¥Cookieæœ‰æ•ˆæ€§å’Œç½‘ç»œè¿æ¥")
        
        if csv_success_rate > xlsx_success_rate + 20:
            recommendations.append("XLSXä¸‹è½½å¤±è´¥ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨CSVæ ¼å¼")
        
        if avg_download_time > 10:
            recommendations.append("å¹³å‡ä¸‹è½½æ—¶é—´è¾ƒé•¿ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œç¯å¢ƒæˆ–ä½¿ç”¨CDN")
        
        if len(failure_reasons) > 0:
            recommendations.append("å­˜åœ¨ä¸‹è½½å¤±è´¥ï¼Œå»ºè®®åˆ†æå¤±è´¥åŸå› å¹¶ä¼˜åŒ–é‡è¯•æœºåˆ¶")
        
        if not endpoint_stats:
            recommendations.append("æ²¡æœ‰ç«¯ç‚¹ä½¿ç”¨ç»Ÿè®¡ï¼Œå¯èƒ½æ‰€æœ‰è¯·æ±‚éƒ½å¤±è´¥äº†")
        
        return TestSummary(
            total_tests=total_tests,
            successful_downloads=successful_count,
            failed_downloads=failed_count,
            success_rate=success_rate,
            average_download_time=avg_download_time,
            total_download_time=total_download_time,
            total_file_size=total_file_size,
            test_duration=total_download_time,
            csv_success_rate=csv_success_rate,
            xlsx_success_rate=xlsx_success_rate,
            endpoint_performance=endpoint_stats,
            failure_reasons=failure_reasons,
            recommendations=recommendations
        )
    
    def generate_report(self, results: List[TestResult], summary: TestSummary) -> str:
        """ç”Ÿæˆè¯¦ç»†æµ‹è¯•æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = os.path.join(self.output_dir, f'download_stability_report_{timestamp}.json')
        
        # æ„å»ºæŠ¥å‘Šæ•°æ®
        report_data = {
            'test_metadata': {
                'test_time': datetime.now().isoformat(),
                'test_type': 'Download Stability Test',
                'tester_version': '1.0.0',
                'cookie_file': self.cookie_file,
                'documents_tested': len(self.test_documents),
                'formats_tested': self.export_formats
            },
            'summary': asdict(summary),
            'detailed_results': [asdict(r) for r in results],
            'document_performance': self._analyze_document_performance(results),
            'format_performance': self._analyze_format_performance(results),
            'time_series_analysis': self._analyze_time_series(results)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return report_file
    
    def _analyze_document_performance(self, results: List[TestResult]) -> Dict:
        """åˆ†æå„æ–‡æ¡£çš„ä¸‹è½½æ€§èƒ½"""
        doc_stats = {}
        
        for doc in self.test_documents:
            doc_results = [r for r in results if r.document_name == doc['name']]
            successful = [r for r in doc_results if r.success]
            
            doc_stats[doc['name']] = {
                'total_attempts': len(doc_results),
                'successful_downloads': len(successful),
                'success_rate': len(successful) / len(doc_results) * 100 if doc_results else 0,
                'avg_download_time': statistics.mean([r.download_time for r in successful]) if successful else 0,
                'total_file_size': sum(r.file_size for r in successful),
                'formats_tested': list(set(r.export_format for r in doc_results))
            }
        
        return doc_stats
    
    def _analyze_format_performance(self, results: List[TestResult]) -> Dict:
        """åˆ†æå„æ ¼å¼çš„ä¸‹è½½æ€§èƒ½"""
        format_stats = {}
        
        for fmt in self.export_formats:
            fmt_results = [r for r in results if r.export_format == fmt]
            successful = [r for r in fmt_results if r.success]
            
            format_stats[fmt] = {
                'total_attempts': len(fmt_results),
                'successful_downloads': len(successful),
                'success_rate': len(successful) / len(fmt_results) * 100 if fmt_results else 0,
                'avg_download_time': statistics.mean([r.download_time for r in successful]) if successful else 0,
                'avg_file_size': statistics.mean([r.file_size for r in successful]) if successful else 0,
                'total_file_size': sum(r.file_size for r in successful)
            }
        
        return format_stats
    
    def _analyze_time_series(self, results: List[TestResult]) -> Dict:
        """åˆ†ææ—¶é—´åºåˆ—æ€§èƒ½"""
        if not results:
            return {}
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_results = sorted(results, key=lambda r: r.timestamp)
        
        # è®¡ç®—æ€§èƒ½è¶‹åŠ¿
        download_times = [r.download_time for r in sorted_results if r.success]
        
        return {
            'test_start_time': sorted_results[0].timestamp,
            'test_end_time': sorted_results[-1].timestamp,
            'performance_trend': {
                'min_download_time': min(download_times) if download_times else 0,
                'max_download_time': max(download_times) if download_times else 0,
                'median_download_time': statistics.median(download_times) if download_times else 0
            }
        }
    
    def print_console_summary(self, summary: TestSummary):
        """åœ¨æ§åˆ¶å°æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ è…¾è®¯æ–‡æ¡£ä¸‹è½½ç¨³å®šæ€§æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {summary.total_tests}")
        print(f"   æˆåŠŸä¸‹è½½: {summary.successful_downloads}")
        print(f"   å¤±è´¥ä¸‹è½½: {summary.failed_downloads}")
        print(f"   æˆåŠŸç‡: {summary.success_rate:.1f}%")
        
        print(f"\nâ±ï¸  æ€§èƒ½æŒ‡æ ‡:")
        print(f"   å¹³å‡ä¸‹è½½æ—¶é—´: {summary.average_download_time:.2f}ç§’")
        print(f"   æ€»ä¸‹è½½æ—¶é—´: {summary.total_download_time:.1f}ç§’")
        print(f"   æ€»æ–‡ä»¶å¤§å°: {summary.total_file_size/1024:.1f} KB")
        
        print(f"\nğŸ“ æ ¼å¼æ€§èƒ½:")
        print(f"   CSVæˆåŠŸç‡: {summary.csv_success_rate:.1f}%")
        print(f"   XLSXæˆåŠŸç‡: {summary.xlsx_success_rate:.1f}%")
        
        if summary.endpoint_performance:
            print(f"\nğŸŒ ç«¯ç‚¹æ€§èƒ½:")
            for endpoint, stats in summary.endpoint_performance.items():
                print(f"   {endpoint}: {stats['count']}æ¬¡ (å¹³å‡{stats['avg_time']:.2f}ç§’)")
        
        if summary.failure_reasons:
            print(f"\nâŒ å¤±è´¥åŸå› :")
            for reason, count in summary.failure_reasons.items():
                print(f"   {reason}: {count}æ¬¡")
        
        if summary.recommendations:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(summary.recommendations, 1):
                print(f"   {i}. {rec}")
        
        print("="*60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è…¾è®¯æ–‡æ¡£ä¸‹è½½ç¨³å®šæ€§æµ‹è¯•...")
    
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = TencentDocDownloadTester()
        
        # æ‰§è¡Œæµ‹è¯•
        results = tester.run_comprehensive_test(retry_failed=True, max_retries=2)
        
        if not results:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            return
        
        # åˆ†æç»“æœ
        summary = tester.analyze_results(results)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = tester.generate_report(results, summary)
        
        # æ‰“å°æ§åˆ¶å°æ‘˜è¦
        tester.print_console_summary(summary)
        
        # ä¿å­˜ç®€åŒ–æ‘˜è¦
        summary_file = os.path.join(tester.output_dir, f'test_summary_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(asdict(summary), f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print(f"ğŸ“‹ æ‘˜è¦æŠ¥å‘Š: {summary_file}")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"æµ‹è¯•æ‰§è¡Œé”™è¯¯: {e}")
        logger.debug(traceback.format_exc())
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    main()