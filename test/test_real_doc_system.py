#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è…¾è®¯æ–‡æ¡£ç›‘æ§ç³»ç»Ÿæ¶æ„æµ‹è¯•è„šæœ¬
æµ‹è¯•ç”¨æˆ·ç²˜è´´3ä¸ªçœŸå®è…¾è®¯æ–‡æ¡£URLçš„å¤„ç†æµç¨‹
"""

import sys
import json
from pathlib import Path

# æ·»åŠ æ¨¡å—è·¯å¾„
sys.path.insert(0, '/root/projects/tencent-doc-manager/production/core_modules')

# å¯¼å…¥çœŸå®æ–‡æ¡£åŠ è½½å™¨
from real_doc_loader import RealDocumentLoader

def test_paste_parsing():
    """æµ‹è¯•è§£æç”¨æˆ·ç²˜è´´çš„è…¾è®¯æ–‡æ¡£å†…å®¹"""
    print("=" * 80)
    print("æµ‹è¯•1: è§£æç”¨æˆ·ç²˜è´´çš„è…¾è®¯æ–‡æ¡£")
    print("=" * 80)
    
    loader = RealDocumentLoader()
    
    # æ¨¡æ‹Ÿç”¨æˆ·ç²˜è´´çš„3ä¸ªçœŸå®è…¾è®¯æ–‡æ¡£
    test_contents = [
        """ã€è…¾è®¯æ–‡æ¡£ã€‘æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨
https://docs.qq.com/sheet/DRFppYm15RGZ2WExN""",
        
        """ã€è…¾è®¯æ–‡æ¡£ã€‘å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨  
https://docs.qq.com/sheet/DWEFNU25TemFnZXJN""",
        
        """ã€è…¾è®¯æ–‡æ¡£ã€‘ç¬¬ä¸‰ä¸ªæµ‹è¯•æ–‡æ¡£
https://docs.qq.com/sheet/DRHZrS1hOS3pwRGZB"""
    ]
    
    parsed_docs = []
    for i, content in enumerate(test_contents, 1):
        print(f"\nç²˜è´´å†…å®¹{i}:")
        print(content)
        
        result = loader.parse_pasted_content(content)
        if result:
            print(f"âœ… è§£ææˆåŠŸ:")
            print(f"   æ–‡æ¡£åç§°: {result['name']}")
            print(f"   æ–‡æ¡£URL: {result['url']}")
            print(f"   æ–‡æ¡£ID: {result['doc_id']}")
            parsed_docs.append(result)
        else:
            print(f"âŒ è§£æå¤±è´¥")
    
    return parsed_docs

def test_real_csv_files():
    """æµ‹è¯•è·å–çœŸå®CSVæ–‡ä»¶"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•2: è·å–çœŸå®CSVæ–‡ä»¶ï¼ˆåº”è¯¥åªæœ‰3ä¸ªï¼Œä¸æ˜¯9ä¸ªï¼‰")
    print("=" * 80)
    
    loader = RealDocumentLoader()
    real_files = loader.get_real_csv_files()
    
    print(f"\næ‰¾åˆ° {len(real_files)} ä¸ªçœŸå®æ–‡æ¡£æ–‡ä»¶:")
    for file_info in real_files:
        print(f"\næ–‡æ¡£ {file_info['id'] + 1}:")
        print(f"  åç§°: {file_info['name']}")
        print(f"  URL: {file_info['url']}")
        print(f"  æ–‡æ¡£ID: {file_info['doc_id']}")
        print(f"  Previousæ–‡ä»¶: {Path(file_info['previous_file']).name}")
        print(f"  Currentæ–‡ä»¶: {Path(file_info['current_file']).name}")
        print(f"  æœ‰å¯¹æ¯”æ•°æ®: {file_info['has_comparison']}")
    
    # éªŒè¯æ˜¯å¦åªæœ‰3ä¸ªæ–‡æ¡£
    if len(real_files) == 3:
        print("\nâœ… æ­£ç¡®ï¼šåªè¿”å›äº†3ä¸ªçœŸå®æ–‡æ¡£")
    else:
        print(f"\nâŒ é”™è¯¯ï¼šè¿”å›äº†{len(real_files)}ä¸ªæ–‡æ¡£ï¼Œåº”è¯¥æ˜¯3ä¸ª")
    
    # éªŒè¯æ–‡æ¡£åç§°æ˜¯å¦ä½¿ç”¨çœŸå®åç§°
    expected_names = [
        "æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨",
        "å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨",
        "ç¬¬ä¸‰ä¸ªæµ‹è¯•æ–‡æ¡£"
    ]
    
    actual_names = [f['name'] for f in real_files]
    if set(actual_names) == set(expected_names):
        print("âœ… æ­£ç¡®ï¼šä½¿ç”¨äº†çœŸå®çš„è…¾è®¯æ–‡æ¡£åç§°")
    else:
        print("âŒ é”™è¯¯ï¼šæ–‡æ¡£åç§°ä¸åŒ¹é…")
        print(f"   æœŸæœ›: {expected_names}")
        print(f"   å®é™…: {actual_names}")
    
    return real_files

def test_csv_file_matching():
    """æµ‹è¯•CSVæ–‡ä»¶åŒ¹é…æœºåˆ¶"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•3: CSVæ–‡ä»¶åŒ¹é…æœºåˆ¶")
    print("=" * 80)
    
    comparison_path = Path('/root/projects/tencent-doc-manager/csv_versions/comparison')
    
    # æ£€æŸ¥CSVæ–‡ä»¶é…å¯¹
    csv_patterns = ['realtest', 'test', 'test_data']
    
    for pattern in csv_patterns:
        print(f"\næ£€æŸ¥æ¨¡å¼: {pattern}")
        previous_files = list(comparison_path.glob(f'previous_{pattern}*.csv'))
        current_files = list(comparison_path.glob(f'current_{pattern}*.csv'))
        
        print(f"  Previousæ–‡ä»¶æ•°: {len(previous_files)}")
        print(f"  Currentæ–‡ä»¶æ•°: {len(current_files)}")
        
        if previous_files and current_files:
            print(f"  âœ… æ‰¾åˆ°é…å¯¹çš„CSVæ–‡ä»¶")
            # æ˜¾ç¤ºæœ€æ–°çš„ä¸€å¯¹
            latest_prev = sorted(previous_files)[-1]
            latest_curr = sorted(current_files)[-1]
            print(f"     Previous: {latest_prev.name}")
            print(f"     Current: {latest_curr.name}")
        else:
            print(f"  âš ï¸ ç¼ºå°‘é…å¯¹æ–‡ä»¶")

def test_data_flow():
    """æµ‹è¯•å®Œæ•´æ•°æ®æµ"""
    print("\n" + "=" * 80)
    print("æµ‹è¯•4: æ•°æ®æµéªŒè¯")
    print("=" * 80)
    
    loader = RealDocumentLoader()
    
    # æ¨¡æ‹Ÿå®Œæ•´æµç¨‹
    print("\næ•°æ®æµç¨‹ï¼š")
    print("1. ç”¨æˆ·ç²˜è´´URL â†’ parse_pasted_content()")
    
    test_content = """ã€è…¾è®¯æ–‡æ¡£ã€‘æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨
https://docs.qq.com/sheet/DRFppYm15RGZ2WExN"""
    
    parsed = loader.parse_pasted_content(test_content)
    if parsed:
        print(f"   âœ… è§£ææˆåŠŸ: {parsed['name']}")
    
    print("\n2. ç³»ç»Ÿè·å–CSVæ–‡ä»¶ â†’ get_real_csv_files()")
    real_files = loader.get_real_csv_files()
    print(f"   âœ… è·å–åˆ° {len(real_files)} ä¸ªæ–‡ä»¶")
    
    print("\n3. åŠ è½½å¯¹æ¯”ç»“æœ â†’ load_comparison_result()")
    if real_files:
        first_file = real_files[0]
        result = loader.load_comparison_result(
            first_file['previous_file'],
            first_file['current_file']
        )
        print(f"   âœ… å‘ç° {result['total_differences']} å¤„å·®å¼‚")
    
    print("\n4. ç”Ÿæˆçƒ­åŠ›å›¾ â†’ å‰ç«¯å±•ç¤º")
    print("   âœ… æ•°æ®æµå®Œæ•´")

def analyze_architecture():
    """æ¶æ„åˆ†ææ€»ç»“"""
    print("\n" + "=" * 80)
    print("æ¶æ„è¯„å®¡æŠ¥å‘Š")
    print("=" * 80)
    
    print("\nğŸ“Š å½“å‰å®ç°çš„ä¼˜ç‚¹ï¼š")
    print("1. âœ… æ¸…æ™°çš„æ¨¡å—åŒ–è®¾è®¡")
    print("   - real_documents.json: é…ç½®ç®¡ç†")
    print("   - real_doc_loader.py: æ ¸å¿ƒé€»è¾‘")
    print("   - è§£è€¦çš„æ•°æ®åŠ è½½å’Œå¤„ç†")
    
    print("\n2. âœ… çœŸå®æ•°æ®é©±åŠ¨")
    print("   - ä½¿ç”¨çœŸå®çš„è…¾è®¯æ–‡æ¡£URLå’Œåç§°")
    print("   - é¿å…äº†ç¡¬ç¼–ç çš„è™šæ‹Ÿæ•°æ®")
    print("   - åªå¤„ç†é…ç½®çš„3ä¸ªæ–‡æ¡£ï¼Œä¸æ˜¯9ä¸ªè™šæ‹Ÿè¡¨æ ¼")
    
    print("\n3. âœ… çµæ´»çš„CSVåŒ¹é…æœºåˆ¶")
    print("   - åŸºäºpatternåŒ¹é…CSVæ–‡ä»¶")
    print("   - è‡ªåŠ¨é…å¯¹previous/currentæ–‡ä»¶")
    print("   - æ”¯æŒæ—¶é—´æˆ³ç‰ˆæœ¬ç®¡ç†")
    
    print("\nâš ï¸ æ½œåœ¨é—®é¢˜ç‚¹ï¼š")
    print("1. å¼‚å¸¸å¤„ç†ä¸­çš„é»˜è®¤å€¼å›é€€å¯èƒ½æ©ç›–é…ç½®é”™è¯¯")
    print("2. CSVæ–‡ä»¶patternåŒ¹é…å¯èƒ½éœ€è¦æ›´ä¸¥æ ¼çš„éªŒè¯")
    print("3. ç¼ºå°‘å¯¹é‡å¤æ–‡æ¡£IDçš„æ£€æŸ¥")
    
    print("\nğŸ’¡ æ”¹è¿›å»ºè®®ï¼š")
    print("1. æ·»åŠ é…ç½®éªŒè¯å™¨ï¼Œç¡®ä¿æ–‡æ¡£IDå”¯ä¸€æ€§")
    print("2. å®ç°CSVæ–‡ä»¶å®Œæ•´æ€§æ£€æŸ¥")
    print("3. æ·»åŠ æ—¥å¿—è®°å½•å’Œç›‘æ§æŒ‡æ ‡")
    print("4. è€ƒè™‘æ·»åŠ æ–‡æ¡£å…ƒæ•°æ®ç¼“å­˜æœºåˆ¶")
    
    print("\nğŸ”„ ä¸åŸç³»ç»Ÿå¯¹æ¯”ï¼š")
    print("åŸç³»ç»Ÿï¼ˆ9ä¸ªè™šæ‹Ÿè¡¨æ ¼ï¼‰ï¼š")
    print("  - ä½¿ç”¨ç¡¬ç¼–ç çš„è™šæ‹Ÿæ•°æ®")
    print("  - å›ºå®šçš„9ä¸ªç›‘æ§è¡¨")
    print("  - æ¨¡æ‹Ÿçš„å·®å¼‚æ•°æ®")
    
    print("\næ–°ç³»ç»Ÿï¼ˆ3ä¸ªçœŸå®æ–‡æ¡£ï¼‰ï¼š")
    print("  - åŸºäºé…ç½®çš„çœŸå®æ–‡æ¡£")
    print("  - åŠ¨æ€åŠ è½½å®é™…CSVæ–‡ä»¶")
    print("  - çœŸå®çš„æ–‡ä»¶å¯¹æ¯”å·®å¼‚")
    print("  - å¯æ‰©å±•åˆ°æ›´å¤šæ–‡æ¡£")

if __name__ == "__main__":
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    parsed_docs = test_paste_parsing()
    real_files = test_real_csv_files()
    test_csv_file_matching()
    test_data_flow()
    analyze_architecture()
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)