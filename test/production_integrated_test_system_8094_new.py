#!/usr/bin/env python3
"""
å¢å¼ºå‹CSVä¸“ä¸šå¯¹æ¯”ç³»ç»Ÿ v2.0
- è¯¦ç»†çš„æ­¥éª¤æ—¥å¿—è¾“å‡º
- æ™ºèƒ½æ–‡ä»¶åŒ¹é…é€»è¾‘ï¼ˆä¼˜å…ˆçœŸå®æ–‡æ¡£ï¼‰
- ä¸¥æ ¼éµå¾ª03è§„èŒƒï¼Œæ— é™çº§æœºåˆ¶
"""

import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f"enhanced_comparison_{datetime.now().strftime('%Y%m%d')}.log")
    ]
)
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/root/projects/tencent-doc-manager')
sys.path.insert(0, '/root/projects/tencent-doc-manager/production/core_modules')

class EnhancedCSVComparator:
    """å¢å¼ºå‹CSVå¯¹æ¯”å™¨ - è¯¦ç»†æ—¥å¿—è¾“å‡ºç‰ˆæœ¬"""
    
    def __init__(self):
        self.logger = logger
        self.csv_versions_dir = "/root/projects/tencent-doc-manager/csv_versions"
        self.comparison_results_dir = "/root/projects/tencent-doc-manager/comparison_results"
        
    def execute_comparison(self, doc_name: str = "", prefer_real: bool = True) -> Dict:
        """æ‰§è¡Œå®Œæ•´çš„CSVå¯¹æ¯”æµç¨‹"""
        
        self.logger.info("=" * 80)
        self.logger.info("ğŸ”¬ ã€ä¸“ä¸šCSVå¯¹æ¯”ç³»ç»Ÿ v2.0ã€‘å¯åŠ¨")
        self.logger.info("=" * 80)
        self.logger.info(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"ğŸ“ è¯·æ±‚å‚æ•°: doc_name='{doc_name}', prefer_real={prefer_real}")
        self.logger.info(f"ğŸ“ æ‰§è¡Œæ¨¡å¼: ä¸¥æ ¼03è§„èŒƒæ¨¡å¼ï¼ˆæ— é™çº§æœºåˆ¶ï¼‰")
        self.logger.info("=" * 80)
        
        try:
            # æ­¥éª¤1: æ—¶é—´ç­–ç•¥åˆ†æ
            time_context = self._analyze_time_strategy()
            
            # æ­¥éª¤2: æŸ¥æ‰¾åŸºçº¿æ–‡ä»¶
            baseline_files = self._find_baseline_files(time_context)
            
            # æ­¥éª¤3: æ™ºèƒ½æ–‡ä»¶åˆ†ç±»
            categorized_files = self._categorize_files(baseline_files, prefer_real)
            
            # æ­¥éª¤4: åŒ¹é…åŸºçº¿å’Œç›®æ ‡æ–‡ä»¶å¯¹
            matched_pairs = self._match_file_pairs(categorized_files, time_context)
            
            # æ­¥éª¤5: é€‰æ‹©æœ€ä½³å¯¹æ¯”å¯¹
            selected_pair = self._select_best_pair(matched_pairs, prefer_real)
            
            # æ­¥éª¤6: æ‰§è¡ŒCSVå¯¹æ¯”
            comparison_result = self._execute_csv_comparison(selected_pair)
            
            # æ­¥éª¤7: ä¿å­˜ç»“æœ
            result_file = self._save_results(comparison_result, selected_pair)
            
            # æ­¥éª¤8: ç”ŸæˆæŠ¥å‘Š
            final_report = self._generate_report(comparison_result, selected_pair, result_file)
            
            self.logger.info("=" * 80)
            self.logger.info("âœ… ã€å¯¹æ¯”å®Œæˆã€‘æ‰€æœ‰æ­¥éª¤æ‰§è¡ŒæˆåŠŸ")
            self.logger.info("=" * 80)
            
            return final_report
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
            raise
    
    def _analyze_time_strategy(self) -> Dict:
        """æ­¥éª¤1: åˆ†ææ—¶é—´ç­–ç•¥"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤1/8ã€‘: æ—¶é—´ç­–ç•¥åˆ†æ")
        self.logger.info("="*60)
        
        now = datetime.now()
        weekday = now.weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ...6=å‘¨æ—¥
        hour = now.hour
        week_info = now.isocalendar()
        
        self.logger.info(f"ğŸ“… å½“å‰æ—¶é—´: {now.strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"ğŸ“… æ˜ŸæœŸ: å‘¨{['ä¸€','äºŒ','ä¸‰','å››','äº”','å…­','æ—¥'][weekday]}")
        self.logger.info(f"ğŸ• å°æ—¶: {hour}ç‚¹")
        self.logger.info(f"ğŸ“Š å‘¨æ•°: ç¬¬{week_info[1]}å‘¨ (W{week_info[1]:02d})")
        
        # åˆ¤æ–­ä½¿ç”¨å“ªä¸€å‘¨çš„æ•°æ®
        if weekday < 1 or (weekday == 1 and hour < 12):
            target_week = week_info[1] - 1
            week_context = "previous_week"
            self.logger.info("ğŸ¯ åŸºçº¿ç­–ç•¥: ä½¿ç”¨ã€ä¸Šå‘¨ã€‘åŸºçº¿ï¼ˆå‘¨ä¸€å…¨å¤©æˆ–å‘¨äºŒ12ç‚¹å‰ï¼‰")
        else:
            target_week = week_info[1]
            week_context = "current_week"
            self.logger.info("ğŸ¯ åŸºçº¿ç­–ç•¥: ä½¿ç”¨ã€æœ¬å‘¨ã€‘åŸºçº¿ï¼ˆå‘¨äºŒ12ç‚¹åï¼‰")
        
        # åˆ¤æ–­ç›®æ ‡æ–‡ä»¶ç‰ˆæœ¬ç±»å‹
        if weekday == 5 and hour >= 19:  # å‘¨å…­æ™šä¸Š7ç‚¹å
            target_version = "weekend"
            self.logger.info("ğŸ¯ ç›®æ ‡ç‰ˆæœ¬: ä½¿ç”¨ã€weekendã€‘ç‰ˆæœ¬ï¼ˆå‘¨å…­19ç‚¹åï¼‰")
        else:
            target_version = "midweek"
            self.logger.info("ğŸ¯ ç›®æ ‡ç‰ˆæœ¬: ä½¿ç”¨ã€midweekã€‘ç‰ˆæœ¬")
        
        return {
            'week_context': week_context,
            'target_week': target_week,
            'target_version': target_version,
            'year': week_info[0],
            'weekday': weekday,
            'hour': hour
        }
    
    def _find_baseline_files(self, time_context: Dict) -> List[str]:
        """æ­¥éª¤2: æŸ¥æ‰¾åŸºçº¿æ–‡ä»¶"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤2/8ã€‘: æŸ¥æ‰¾åŸºçº¿æ–‡ä»¶")
        self.logger.info("="*60)
        
        baseline_dir = f"{self.csv_versions_dir}/{time_context['year']}_W{time_context['target_week']:02d}/baseline"
        self.logger.info(f"ğŸ“ æŸ¥æ‰¾ç›®å½•: {baseline_dir}")
        
        if not os.path.exists(baseline_dir):
            self.logger.error(f"âŒ åŸºçº¿ç›®å½•ä¸å­˜åœ¨: {baseline_dir}")
            raise FileNotFoundError(f"E001: åŸºçº¿ç›®å½•ä¸å­˜åœ¨")
        
        import glob
        pattern = f"{baseline_dir}/*_baseline_W{time_context['target_week']:02d}.csv"
        files = glob.glob(pattern)
        
        self.logger.info(f"ğŸ” æŸ¥æ‰¾æ¨¡å¼: *_baseline_W{time_context['target_week']:02d}.csv")
        self.logger.info(f"ğŸ“Š æ‰¾åˆ° {len(files)} ä¸ªåŸºçº¿æ–‡ä»¶")
        
        if files:
            for i, f in enumerate(files[:5], 1):
                self.logger.info(f"   [{i}] {os.path.basename(f)}")
            if len(files) > 5:
                self.logger.info(f"   ... è¿˜æœ‰ {len(files)-5} ä¸ªæ–‡ä»¶")
        else:
            self.logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åŸºçº¿æ–‡ä»¶")
            raise FileNotFoundError("E001: åŸºçº¿æ–‡ä»¶ç¼ºå¤±")
        
        return sorted(files)
    
    def _categorize_files(self, files: List[str], prefer_real: bool) -> Dict:
        """æ­¥éª¤3: æ™ºèƒ½æ–‡ä»¶åˆ†ç±»"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤3/8ã€‘: æ™ºèƒ½æ–‡ä»¶åˆ†ç±»")
        self.logger.info("="*60)
        
        real_docs = []
        test_docs = []
        
        for f in files:
            basename = os.path.basename(f)
            if 'test' in basename.lower():
                test_docs.append(f)
            else:
                real_docs.append(f)
        
        self.logger.info(f"ğŸ“Š æ–‡ä»¶åˆ†ç±»ç»“æœ:")
        self.logger.info(f"   ğŸ¢ çœŸå®æ–‡æ¡£: {len(real_docs)}ä¸ª")
        self.logger.info(f"   ğŸ§ª æµ‹è¯•æ–‡æ¡£: {len(test_docs)}ä¸ª")
        
        if real_docs:
            self.logger.info("   çœŸå®æ–‡æ¡£åˆ—è¡¨:")
            for i, doc in enumerate(real_docs[:3], 1):
                self.logger.info(f"      [{i}] {os.path.basename(doc)}")
            if len(real_docs) > 3:
                self.logger.info(f"      ... è¿˜æœ‰{len(real_docs)-3}ä¸ª")
        
        if test_docs:
            self.logger.info("   æµ‹è¯•æ–‡æ¡£åˆ—è¡¨:")
            for i, doc in enumerate(test_docs[:3], 1):
                self.logger.info(f"      [{i}] {os.path.basename(doc)}")
        
        # æ ¹æ®prefer_realæ’åº
        if prefer_real:
            sorted_files = real_docs + test_docs
            self.logger.info("   âœ… ä¼˜å…ˆçº§: çœŸå®æ–‡æ¡£ä¼˜å…ˆ")
        else:
            sorted_files = files
            self.logger.info("   â„¹ï¸ ä¼˜å…ˆçº§: ä¸åŒºåˆ†æ–‡æ¡£ç±»å‹")
        
        return {
            'all': sorted_files,
            'real': real_docs,
            'test': test_docs
        }
    
    def _match_file_pairs(self, categorized_files: Dict, time_context: Dict) -> List[Dict]:
        """æ­¥éª¤4: åŒ¹é…åŸºçº¿å’Œç›®æ ‡æ–‡ä»¶å¯¹"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤4/8ã€‘: åŒ¹é…åŸºçº¿å’Œç›®æ ‡æ–‡ä»¶å¯¹")
        self.logger.info("="*60)
        
        matched_pairs = []
        target_dir = f"{self.csv_versions_dir}/{time_context['year']}_W{time_context['target_week']:02d}/{time_context['target_version']}"
        
        self.logger.info(f"ğŸ“ ç›®æ ‡ç›®å½•: {target_dir}")
        
        for idx, baseline_file in enumerate(categorized_files['all'], 1):
            basename = os.path.basename(baseline_file)
            is_real = 'test' not in basename.lower()
            doc_type = "ğŸ¢ çœŸå®" if is_real else "ğŸ§ª æµ‹è¯•"
            
            self.logger.info(f"\nğŸ“„ [{idx}/{len(categorized_files['all'])}] å¤„ç†åŸºçº¿: {basename}")
            self.logger.info(f"   ç±»å‹: {doc_type}")
            
            # æå–æ–‡æ¡£åç§°
            doc_name_parts = basename.split('_csv_')[0]
            if doc_name_parts.startswith('tencent_'):
                doc_name = doc_name_parts[8:]
            else:
                doc_name = doc_name_parts
            
            self.logger.info(f"   æå–æ–‡æ¡£å: {doc_name}")
            
            # æŸ¥æ‰¾åŒ¹é…çš„ç›®æ ‡æ–‡ä»¶
            import glob
            target_pattern = f"{target_dir}/*{doc_name}*_{time_context['target_version']}_W{time_context['target_week']:02d}.csv"
            target_files = glob.glob(target_pattern)
            
            if target_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œä½¿ç”¨æœ€æ–°çš„
                target_files.sort(key=os.path.getmtime, reverse=True)
                target_file = target_files[0]
                self.logger.info(f"   âœ… æ‰¾åˆ°ç›®æ ‡: {os.path.basename(target_file)}")
                
                matched_pairs.append({
                    'baseline': baseline_file,
                    'target': target_file,
                    'doc_name': doc_name,
                    'is_real': is_real,
                    'doc_type': doc_type
                })
            else:
                self.logger.info(f"   âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡æ–‡ä»¶")
                matched_pairs.append({
                    'baseline': baseline_file,
                    'target': None,
                    'doc_name': doc_name,
                    'is_real': is_real,
                    'doc_type': doc_type
                })
        
        # ç»Ÿè®¡
        valid_pairs = [p for p in matched_pairs if p['target']]
        real_pairs = [p for p in valid_pairs if p['is_real']]
        test_pairs = [p for p in valid_pairs if not p['is_real']]
        
        self.logger.info(f"\nğŸ“ˆ åŒ¹é…ç»Ÿè®¡:")
        self.logger.info(f"   æ€»åŸºçº¿æ–‡ä»¶: {len(matched_pairs)}")
        self.logger.info(f"   æœ‰æ•ˆå¯¹æ¯”å¯¹: {len(valid_pairs)}")
        self.logger.info(f"   çœŸå®æ–‡æ¡£å¯¹: {len(real_pairs)}")
        self.logger.info(f"   æµ‹è¯•æ–‡æ¡£å¯¹: {len(test_pairs)}")
        
        return matched_pairs
    
    def _select_best_pair(self, matched_pairs: List[Dict], prefer_real: bool) -> Dict:
        """æ­¥éª¤5: é€‰æ‹©æœ€ä½³å¯¹æ¯”å¯¹"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤5/8ã€‘: é€‰æ‹©æœ€ä½³å¯¹æ¯”å¯¹")
        self.logger.info("="*60)
        
        valid_pairs = [p for p in matched_pairs if p['target']]
        real_pairs = [p for p in valid_pairs if p['is_real']]
        test_pairs = [p for p in valid_pairs if not p['is_real']]
        
        selected = None
        
        if prefer_real and real_pairs:
            selected = real_pairs[0]
            self.logger.info(f"âœ… é€‰æ‹©çœŸå®æ–‡æ¡£å¯¹: {selected['doc_name']}")
        elif valid_pairs:
            selected = valid_pairs[0]
            self.logger.info(f"âš ï¸ ä½¿ç”¨æµ‹è¯•æ–‡æ¡£å¯¹: {selected['doc_name']}")
        elif matched_pairs:
            selected = matched_pairs[0]
            self.logger.info(f"âš ï¸ ä»…æœ‰åŸºçº¿æ–‡ä»¶: {selected['doc_name']}")
        else:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ–‡ä»¶å¯¹")
        
        self.logger.info(f"   åŸºçº¿: {os.path.basename(selected['baseline'])}")
        self.logger.info(f"   ç›®æ ‡: {os.path.basename(selected['target']) if selected['target'] else 'æ— '}")
        self.logger.info(f"   ç±»å‹: {selected['doc_type']}")
        
        return selected
    
    def _execute_csv_comparison(self, pair: Dict) -> Dict:
        """æ­¥éª¤6: æ‰§è¡ŒCSVå¯¹æ¯”"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤6/8ã€‘: æ‰§è¡Œä¸“ä¸šCSVå¯¹æ¯”")
        self.logger.info("="*60)
        
        if not pair['target']:
            self.logger.info("âš ï¸ æ²¡æœ‰ç›®æ ‡æ–‡ä»¶ï¼Œè·³è¿‡å¯¹æ¯”")
            return {
                'similarity_score': 1.0,
                'total_changes': 0,
                'message': 'ä»…æœ‰åŸºçº¿æ–‡ä»¶ï¼Œæ— æ³•å¯¹æ¯”'
            }
        
        self.logger.info(f"ğŸ” å¼€å§‹å¯¹æ¯”å¤„ç†...")
        start_time = datetime.now()
        
        # è°ƒç”¨ç»Ÿä¸€å¯¹æ¯”æ¥å£ï¼ˆç®€åŒ–ç‰ˆï¼‰
        try:
            from unified_csv_comparator import UnifiedCSVComparator
            comparator = UnifiedCSVComparator()
            result = comparator.compare(pair['baseline'], pair['target'])
            self.logger.info("   ä½¿ç”¨: ç»Ÿä¸€CSVå¯¹æ¯”å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰")
        except:
            # é™çº§åˆ°ç®€å•å¯¹æ¯”
            from simple_comparison_handler import simple_csv_compare
            result = simple_csv_compare(pair['baseline'], pair['target'])
            self.logger.info("   ä½¿ç”¨: å¤‡ç”¨CSVå¯¹æ¯”å™¨")
        
        end_time = datetime.now()
        elapsed = (end_time - start_time).total_seconds()
        
        self.logger.info(f"â±ï¸ å¯¹æ¯”è€—æ—¶: {elapsed:.2f}ç§’")
        
        if result:
            self.logger.info(f"ğŸ“Š å¯¹æ¯”ç»“æœ:")
            self.logger.info(f"   ç›¸ä¼¼åº¦: {result.get('similarity_score', 0):.1%}")
            self.logger.info(f"   æ€»å˜æ›´: {result.get('total_changes', 0)}")
            self.logger.info(f"   æ–°å¢è¡Œ: {result.get('added_rows', 0)}")
            self.logger.info(f"   åˆ é™¤è¡Œ: {result.get('deleted_rows', 0)}")
            self.logger.info(f"   ä¿®æ”¹è¡Œ: {result.get('modified_rows', 0)}")
        
        result['execution_time'] = elapsed
        result['document_info'] = {
            'name': pair['doc_name'],
            'type': pair['doc_type'],
            'is_real': pair['is_real']
        }
        
        return result
    
    def _save_results(self, result: Dict, pair: Dict) -> str:
        """æ­¥éª¤7: ä¿å­˜ç»“æœ"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤7/8ã€‘: ä¿å­˜å¯¹æ¯”ç»“æœ")
        self.logger.info("="*60)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = f"{self.comparison_results_dir}/enhanced_comparison_{timestamp}.json"
        
        # æ·»åŠ å…ƒæ•°æ®
        result['metadata'] = {
            'timestamp': timestamp,
            'baseline_file': pair['baseline'],
            'target_file': pair['target'],
            'document_name': pair['doc_name'],
            'document_type': pair['doc_type'],
            'is_real_document': pair['is_real']
        }
        
        os.makedirs(self.comparison_results_dir, exist_ok=True)
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {os.path.basename(result_file)}")
        
        return result_file
    
    def _generate_report(self, result: Dict, pair: Dict, result_file: str) -> Dict:
        """æ­¥éª¤8: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š"""
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“‚ ã€æ­¥éª¤8/8ã€‘: ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        self.logger.info("="*60)
        
        report = {
            'success': True,
            'result': result,
            'result_file': result_file,
            'baseline_file': pair['baseline'],
            'target_file': pair['target'],
            'document_info': {
                'name': pair['doc_name'],
                'type': pair['doc_type'],
                'is_real': pair['is_real']
            },
            'execution_time': result.get('execution_time', 0),
            'timestamp': datetime.now().isoformat()
        }
        
        self.logger.info("ğŸ“Š æŠ¥å‘Šæ‘˜è¦:")
        self.logger.info(f"   æ–‡æ¡£: {pair['doc_name']}")
        self.logger.info(f"   ç±»å‹: {pair['doc_type']}")
        self.logger.info(f"   ç›¸ä¼¼åº¦: {result.get('similarity_score', 0):.1%}")
        self.logger.info(f"   æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}ç§’")
        
        return report


def main():
    """ä¸»å‡½æ•° - æµ‹è¯•å¢å¼ºå‹å¯¹æ¯”ç³»ç»Ÿ"""
    comparator = EnhancedCSVComparator()
    
    # æ‰§è¡Œå¯¹æ¯”ï¼ˆä¼˜å…ˆä½¿ç”¨çœŸå®æ–‡æ¡£ï¼‰
    result = comparator.execute_comparison(prefer_real=True)
    
    print("\n" + "="*80)
    print("ğŸ‰ å¢å¼ºå‹CSVå¯¹æ¯”ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
    print(f"ğŸ“„ ç»“æœæ–‡ä»¶: {result['result_file']}")
    print(f"ğŸ“Š ç›¸ä¼¼åº¦: {result['result'].get('similarity_score', 0):.1%}")
    print("="*80)


if __name__ == '__main__':
    main()