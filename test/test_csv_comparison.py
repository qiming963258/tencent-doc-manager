#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSVå¯¹æ¯”æµ‹è¯•è„šæœ¬ - æµ‹è¯•å®é™…çš„CSVæ–‡ä»¶æ¯”å¯¹åŠŸèƒ½
"""

import os
import sys
import csv
import json

# æ·»åŠ ç”Ÿäº§æ¨¡å—è·¯å¾„
sys.path.append('/root/projects/tencent-doc-manager/production/core_modules')

def load_csv_as_table_data(file_path):
    """åŠ è½½CSVæ–‡ä»¶ä¸ºè¡¨æ ¼æ•°æ®æ ¼å¼ï¼Œå¤„ç†å¤šè¡Œæ ‡é¢˜ç»“æ„"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8-sig') as f:  # å¤„ç†BOM
        reader = csv.reader(f)
        data = list(reader)
    
    if not data:
        raise ValueError(f"æ–‡ä»¶ä¸ºç©º: {file_path}")
    
    # æ£€æµ‹å¹¶å¤„ç†å¤šè¡Œæ ‡é¢˜ç»“æ„
    if len(data) >= 3:
        # æ£€æŸ¥ç¬¬1è¡Œæ˜¯å¦ä¸ºæ ‡é¢˜è¡Œï¼ˆå¤§éƒ¨åˆ†åˆ—ä¸ºç©ºï¼‰
        first_row = data[0]
        if first_row[0] and not any(first_row[1:10]):  # ç¬¬ä¸€åˆ—æœ‰å†…å®¹ï¼Œåé¢å¤§éƒ¨åˆ†ä¸ºç©º
            print(f"ğŸ·ï¸ æ£€æµ‹åˆ°æ ‡é¢˜è¡Œ: {first_row[0]}")
            # åˆå¹¶ç¬¬2ã€3è¡Œä½œä¸ºåˆ—åï¼Œä»ç¬¬4è¡Œå¼€å§‹ä½œä¸ºæ•°æ®
            if len(data) >= 4:
                header1 = data[1]  # ä¸»è¦åˆ—å
                header2 = data[2]  # è¡¥å……åˆ—å
                
                # åˆå¹¶åˆ—åï¼šä¼˜å…ˆä½¿ç”¨éç©ºçš„åˆ—å
                merged_header = []
                max_cols = max(len(header1), len(header2))
                for i in range(max_cols):
                    col1 = header1[i] if i < len(header1) else ""
                    col2 = header2[i] if i < len(header2) else ""
                    # ä¼˜å…ˆä½¿ç”¨éç©ºä¸”æœ‰æ„ä¹‰çš„åˆ—å
                    final_col = col1 if col1.strip() else col2
                    merged_header.append(final_col)
                
                # æ„å»ºæ–°çš„æ•°æ®ç»“æ„ï¼š[åˆå¹¶åçš„æ ‡é¢˜] + [æ•°æ®è¡Œ]
                processed_data = [merged_header] + data[3:]
                print(f"ğŸ“‹ å¤„ç†åç»“æ„: {len(processed_data)}è¡Œ x {len(merged_header)}åˆ—")
                print(f"ğŸ“‹ ä¸»è¦åˆ—å: {merged_header[:10]}...")  # æ˜¾ç¤ºå‰10ä¸ªåˆ—å
                return processed_data
    
    return data

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” å¼€å§‹CSVæ–‡ä»¶æ¯”å¯¹æµ‹è¯•...")
    
    # æ–‡ä»¶è·¯å¾„
    baseline_file = "/root/projects/tencent-doc-manager/csv_versions/2025_W34/baseline/tencent_csv_20250818_1200_baseline_W34.csv"
    current_file = "/root/projects/tencent-doc-manager/csv_versions/current_å°çº¢ä¹¦éƒ¨é—¨å·¥ä½œè¡¨2_20250818_1400_v001.csv"
    
    try:
        # 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
        print(f"ğŸ“ åŸºå‡†æ–‡ä»¶: {baseline_file}")
        print(f"ğŸ“ å½“å‰æ–‡ä»¶: {current_file}")
        
        if not os.path.exists(baseline_file):
            print(f"âŒ åŸºå‡†æ–‡ä»¶ä¸å­˜åœ¨: {baseline_file}")
            return
        
        if not os.path.exists(current_file):
            print(f"âŒ å½“å‰æ–‡ä»¶ä¸å­˜åœ¨: {current_file}")
            return
        
        # 2. åŠ è½½æ–‡ä»¶æ•°æ®
        print("\nğŸ“‹ åŠ è½½CSVæ–‡ä»¶æ•°æ®...")
        baseline_data = load_csv_as_table_data(baseline_file)
        current_data = load_csv_as_table_data(current_file)
        
        print(f"âœ… åŸºå‡†æ–‡ä»¶åŠ è½½æˆåŠŸ: {len(baseline_data)}è¡Œ x {len(baseline_data[0]) if baseline_data else 0}åˆ—")
        print(f"âœ… å½“å‰æ–‡ä»¶åŠ è½½æˆåŠŸ: {len(current_data)}è¡Œ x {len(current_data[0]) if current_data else 0}åˆ—")
        
        # 3. å¯¼å…¥å¹¶åˆå§‹åŒ–å¯¹æ¯”å™¨
        print("\nğŸ”§ åˆå§‹åŒ–è‡ªé€‚åº”è¡¨æ ¼å¯¹æ¯”å™¨...")
        from adaptive_table_comparator import AdaptiveTableComparator
        
        comparator = AdaptiveTableComparator()
        print("âœ… å¯¹æ¯”å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        # 4. å‡†å¤‡è¡¨æ ¼æ•°æ®
        current_tables = [
            {
                "name": "å½“å‰ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨å·¥ä½œè¡¨2",
                "data": current_data
            }
        ]
        
        reference_tables = [
            {
                "name": "åŸºå‡†ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨å·¥ä½œè¡¨2", 
                "data": baseline_data
            }
        ]
        
        # 5. æ‰§è¡Œå¯¹æ¯”åˆ†æ
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œè‡ªé€‚åº”è¡¨æ ¼å¯¹æ¯”...")
        result = comparator.adaptive_compare_tables(
            current_tables=current_tables,
            reference_tables=reference_tables
        )
        
        # 6. è¾“å‡ºç»“æœ
        print("\nğŸ“Š å¯¹æ¯”åˆ†æå®Œæˆ!")
        print("=" * 60)
        
        # å¤„ç†æŠ¥å‘Š
        print("ğŸ“‹ å¤„ç†æŠ¥å‘Š:")
        print(result['processing_report'])
        
        # è´¨é‡æ±‡æ€»
        print("\nğŸ“ˆ è´¨é‡æ±‡æ€»:")
        quality_summary = result['quality_summary']
        print(f"â€¢ å¹³å‡è´¨é‡åˆ†æ•°: {quality_summary['average_quality_score']:.3f}")
        print(f"â€¢ å¤„ç†æˆåŠŸç‡: {quality_summary['processing_success_rate']:.1%}")
        print(f"â€¢ æ£€æµ‹åˆ°çš„å˜æ›´æ•°: {quality_summary['total_changes_detected']}")
        
        # é£é™©åˆ†å¸ƒ
        risk_dist = quality_summary['risk_distribution']
        print(f"â€¢ é£é™©åˆ†å¸ƒ: L1={risk_dist['L1']}, L2={risk_dist['L2']}, L3={risk_dist['L3']}")
        
        # æ ‡å‡†åŒ–çŸ©é˜µ
        matrix = result['standardized_matrix']
        print(f"\nğŸ”¥ æ ‡å‡†åŒ–çŸ©é˜µ: {len(matrix)}è¡Œ x {len(matrix[0]) if matrix else 0}åˆ—")
        
        # è¯¦ç»†ç»“æœï¼ˆç¬¬ä¸€ä¸ªè¡¨æ ¼ï¼‰
        if result['comparison_results']:
            first_result = result['comparison_results'][0]
            if 'matching_result' in first_result:
                print("\nğŸ¯ åˆ—åŒ¹é…è¯¦æƒ…:")
                matching = first_result['matching_result']
                print(f"â€¢ åŒ¹é…æˆåŠŸ: {len(matching['mapping'])}åˆ—")
                print(f"â€¢ æœªåŒ¹é…åˆ—: {len(matching['unmatched_columns'])}åˆ—")
                print(f"â€¢ ç¼ºå¤±æ ‡å‡†åˆ—: {len(matching['missing_columns'])}åˆ—")
                
                if matching['unmatched_columns']:
                    print(f"â€¢ æœªåŒ¹é…åˆ—åˆ—è¡¨: {matching['unmatched_columns']}")
                
            if 'change_detection_result' in first_result and first_result['change_detection_result']:
                change_result = first_result['change_detection_result']
                changes = change_result.get('changes', [])
                print(f"\nğŸ” å˜æ›´æ£€æµ‹:")
                print(f"â€¢ æ€»å˜æ›´æ•°: {len(changes)}")
                
                # æ˜¾ç¤ºå‰5ä¸ªå˜æ›´ç¤ºä¾‹
                for i, change in enumerate(changes[:5]):
                    print(f"  {i+1}. è¡Œ{change['row_index']} {change['column_name']}: '{change['original_value']}' â†’ '{change['new_value']}' (é£é™©:{change['risk_level']})")
                
                if len(changes) > 5:
                    print(f"  ... è¿˜æœ‰ {len(changes) - 5} ä¸ªå˜æ›´")
        
        print("\nâœ… CSVå¯¹æ¯”æµ‹è¯•å®Œæˆ!")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = "/root/projects/tencent-doc-manager/csv_versions/comparison_cache/test_comparison_result.json"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"ğŸ“„ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()