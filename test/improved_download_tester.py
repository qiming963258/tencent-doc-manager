#!/usr/bin/env python3
"""
åŸºäºè¯Šæ–­ç»“æœæ”¹è¿›çš„è…¾è®¯æ–‡æ¡£ä¸‹è½½æµ‹è¯•ç¨‹åº
ä½¿ç”¨å‘ç°çš„æœ‰æ•ˆç«¯ç‚¹è¿›è¡Œå®é™…ä¸‹è½½æµ‹è¯•
"""

import os
import sys
import time
import json
import requests
import re
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
import logging
from urllib.parse import urlencode, parse_qs, urlparse
from bs4 import BeautifulSoup
import statistics

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DownloadResult:
    """ä¸‹è½½ç»“æœ"""
    document_name: str
    doc_id: str
    export_format: str
    success: bool
    download_time: float
    file_size: int
    file_path: str
    endpoint_used: str
    error_message: str
    timestamp: str
    actual_download_url: str = ""
    response_status: int = 0


class ImprovedTencentDownloader:
    """æ”¹è¿›ç‰ˆè…¾è®¯æ–‡æ¡£ä¸‹è½½å™¨"""
    
    def __init__(self, cookie_file: str = None):
        self.cookie_file = cookie_file or '/root/projects/tencent-doc-manager/config/cookies_new.json'
        self.cookies = self._load_cookies()
        self.output_dir = '/root/projects/tencent-doc-manager/downloads'
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åŸºäºè¯Šæ–­ç»“æœçš„æœ‰æ•ˆç«¯ç‚¹
        self.working_endpoints = [
            {
                'name': 'direct_sheet_export',
                'url_template': 'https://docs.qq.com/sheet/{doc_id}/export',
                'params': {
                    'format': '{format}',
                    'download': '1'
                },
                'method': 'GET',
                'needs_parsing': True  # éœ€è¦è§£æHTMLé¡µé¢è·å–çœŸå®ä¸‹è½½é“¾æ¥
            },
            {
                'name': 'sheet_with_export_param',
                'url_template': 'https://docs.qq.com/sheet/{doc_id}',
                'params': {
                    'export': '{format}',
                    'download': '1'
                },
                'method': 'GET',
                'needs_parsing': True
            }
        ]
        
        # æµ‹è¯•æ–‡æ¡£
        self.test_documents = [
            {
                'name': 'æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨',
                'url': 'https://docs.qq.com/sheet/DWEVjZndkR2xVSWJN',
                'doc_id': 'DWEVjZndkR2xVSWJN'
            },
            {
                'name': 'æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨',
                'url': 'https://docs.qq.com/sheet/DRFppYm15RGZ2WExN',
                'doc_id': 'DRFppYm15RGZ2WExN'
            },
            {
                'name': 'æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨',
                'url': 'https://docs.qq.com/sheet/DRHZrS1hOS3pwRGZB',
                'doc_id': 'DRHZrS1hOS3pwRGZB'
            }
        ]
        
        self.export_formats = ['csv', 'xlsx']
        self.results: List[DownloadResult] = []
        
    def _load_cookies(self) -> str:
        """åŠ è½½Cookie"""
        try:
            with open(self.cookie_file, 'r') as f:
                config = json.load(f)
            return config.get('current_cookies', '')
        except Exception as e:
            logger.error(f"åŠ è½½Cookieå¤±è´¥: {e}")
            return ""
    
    def _build_headers(self) -> Dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        return {
            'Cookie': self.cookies,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'same-origin',
            'Cache-Control': 'max-age=0'
        }
    
    def _extract_download_url(self, html_content: str) -> Optional[str]:
        """ä»HTMLé¡µé¢ä¸­æå–çœŸå®ä¸‹è½½URL"""
        try:
            # æ–¹æ³•1: æŸ¥æ‰¾dop-apié“¾æ¥
            dop_api_pattern = r'//docs\.qq\.com/dop-api/opendoc\?[^"]*'
            match = re.search(dop_api_pattern, html_content)
            if match:
                url = 'https:' + match.group(0).replace('&amp;', '&')
                logger.info(f"æ‰¾åˆ°dop-apiä¸‹è½½é“¾æ¥: {url}")
                return url
                
            # æ–¹æ³•2: æŸ¥æ‰¾preloadé“¾æ¥
            preload_pattern = r'rel="preload"[^>]*href="([^"]*dop-api[^"]*)"'
            match = re.search(preload_pattern, html_content)
            if match:
                url = match.group(1).replace('&amp;', '&')
                if not url.startswith('http'):
                    url = 'https:' + url
                logger.info(f"æ‰¾åˆ°preloadä¸‹è½½é“¾æ¥: {url}")
                return url
                
            # æ–¹æ³•3: ä½¿ç”¨BeautifulSoupè§£æ
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # æŸ¥æ‰¾åŒ…å«dop-apiçš„linkæ ‡ç­¾
            link_tags = soup.find_all('link', href=True)
            for link in link_tags:
                href = link.get('href', '')
                if 'dop-api/opendoc' in href:
                    url = href.replace('&amp;', '&')
                    if not url.startswith('http'):
                        url = 'https:' + url
                    logger.info(f"é€šè¿‡BeautifulSoupæ‰¾åˆ°ä¸‹è½½é“¾æ¥: {url}")
                    return url
                    
            # æŸ¥æ‰¾scriptä¸­çš„ä¸‹è½½é“¾æ¥
            scripts = soup.find_all('script')
            for script in scripts:
                if script.string:
                    dop_match = re.search(r'dop-api/opendoc\?[^"\']*', script.string)
                    if dop_match:
                        url = 'https://docs.qq.com/' + dop_match.group(0)
                        logger.info(f"åœ¨scriptä¸­æ‰¾åˆ°ä¸‹è½½é“¾æ¥: {url}")
                        return url
                        
        except Exception as e:
            logger.error(f"è§£æä¸‹è½½URLå¤±è´¥: {e}")
            
        return None
    
    def _download_file(self, download_url: str, filename: str) -> Tuple[bool, int, str]:
        """ä¸‹è½½æ–‡ä»¶"""
        try:
            headers = self._build_headers()
            # ä¿®æ”¹Acceptå¤´ä»¥æœŸæœ›æ–‡ä»¶ä¸‹è½½
            headers['Accept'] = 'application/octet-stream,*/*;q=0.8'
            
            logger.info(f"å¼€å§‹ä¸‹è½½æ–‡ä»¶: {download_url}")
            
            response = requests.get(
                download_url,
                headers=headers,
                stream=True,
                timeout=30,
                allow_redirects=True
            )
            
            if response.status_code != 200:
                return False, 0, f"HTTP {response.status_code}"
            
            # æ£€æŸ¥å†…å®¹ç±»å‹
            content_type = response.headers.get('Content-Type', '').lower()
            logger.info(f"å“åº”å†…å®¹ç±»å‹: {content_type}")
            
            # ä¿å­˜æ–‡ä»¶
            filepath = os.path.join(self.output_dir, filename)
            file_size = 0
            
            with open(filepath, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        file_size += len(chunk)
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            actual_size = os.path.getsize(filepath)
            if actual_size < 100:
                # æ–‡ä»¶å¤ªå°ï¼Œå¯èƒ½æ˜¯é”™è¯¯é¡µé¢ï¼Œæ£€æŸ¥å†…å®¹
                with open(filepath, 'rb') as f:
                    content = f.read(500)
                    if b'<html' in content.lower() or b'error' in content.lower():
                        logger.warning(f"ä¸‹è½½çš„æ–‡ä»¶ä¼¼ä¹æ˜¯HTMLé”™è¯¯é¡µé¢")
                        os.remove(filepath)
                        return False, 0, "ä¸‹è½½çš„æ–‡ä»¶æ˜¯HTMLé”™è¯¯é¡µé¢"
            
            logger.info(f"æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {filepath} ({actual_size} bytes)")
            return True, actual_size, filepath
            
        except Exception as e:
            logger.error(f"ä¸‹è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False, 0, str(e)
    
    def _attempt_download(self, document: Dict, export_format: str, endpoint: Dict) -> DownloadResult:
        """å°è¯•ä½¿ç”¨æŒ‡å®šç«¯ç‚¹ä¸‹è½½æ–‡æ¡£"""
        start_time = time.time()
        doc_id = document['doc_id']
        
        try:
            # æ„å»ºURLå’Œå‚æ•°
            url = endpoint['url_template'].format(doc_id=doc_id)
            params = {}
            for key, value in endpoint['params'].items():
                params[key] = value.format(format=export_format, doc_id=doc_id)
            
            logger.info(f"ğŸ”„ å°è¯•ç«¯ç‚¹: {endpoint['name']}")
            logger.info(f"   URL: {url}")
            logger.info(f"   å‚æ•°: {params}")
            
            # ç¬¬ä¸€æ­¥: è·å–åŒ…å«ä¸‹è½½é“¾æ¥çš„é¡µé¢
            headers = self._build_headers()
            response = requests.get(
                url,
                params=params,
                headers=headers,
                timeout=15,
                allow_redirects=True
            )
            
            if response.status_code != 200:
                error_msg = f"è·å–ä¸‹è½½é¡µé¢å¤±è´¥: HTTP {response.status_code}"
                logger.error(error_msg)
                return self._create_failed_result(document, export_format, endpoint, error_msg, start_time)
            
            # ç¬¬äºŒæ­¥: ä»HTMLä¸­æå–çœŸå®ä¸‹è½½URL
            if endpoint['needs_parsing']:
                download_url = self._extract_download_url(response.text)
                if not download_url:
                    error_msg = "æ— æ³•ä»é¡µé¢ä¸­æå–ä¸‹è½½é“¾æ¥"
                    logger.error(error_msg)
                    return self._create_failed_result(document, export_format, endpoint, error_msg, start_time)
            else:
                download_url = url + '?' + urlencode(params)
            
            # ç¬¬ä¸‰æ­¥: å®é™…ä¸‹è½½æ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{document['name']}_{export_format}_{timestamp}.{export_format}"
            
            success, file_size, result_info = self._download_file(download_url, filename)
            
            download_time = time.time() - start_time
            
            if success:
                logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {filename} ({file_size/1024:.1f} KB, {download_time:.2f}s)")
                return DownloadResult(
                    document_name=document['name'],
                    doc_id=doc_id,
                    export_format=export_format,
                    success=True,
                    download_time=download_time,
                    file_size=file_size,
                    file_path=result_info,
                    endpoint_used=endpoint['name'],
                    error_message="",
                    timestamp=datetime.now().isoformat(),
                    actual_download_url=download_url,
                    response_status=200
                )
            else:
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {result_info}")
                return self._create_failed_result(document, export_format, endpoint, result_info, start_time, download_url)
                
        except Exception as e:
            error_msg = f"ä¸‹è½½å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            return self._create_failed_result(document, export_format, endpoint, error_msg, start_time)
    
    def _create_failed_result(self, document: Dict, export_format: str, endpoint: Dict, 
                             error_msg: str, start_time: float, download_url: str = "") -> DownloadResult:
        """åˆ›å»ºå¤±è´¥ç»“æœ"""
        return DownloadResult(
            document_name=document['name'],
            doc_id=document['doc_id'],
            export_format=export_format,
            success=False,
            download_time=time.time() - start_time,
            file_size=0,
            file_path="",
            endpoint_used=endpoint['name'],
            error_message=error_msg,
            timestamp=datetime.now().isoformat(),
            actual_download_url=download_url,
            response_status=0
        )
    
    def run_comprehensive_test(self) -> List[DownloadResult]:
        """è¿è¡Œå…¨é¢ä¸‹è½½æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹æ”¹è¿›ç‰ˆè…¾è®¯æ–‡æ¡£ä¸‹è½½æµ‹è¯•...")
        
        if not self.cookies:
            logger.error("âŒ Cookieæ— æ•ˆï¼Œæ— æ³•è¿›è¡Œæµ‹è¯•")
            return []
        
        results = []
        total_tests = len(self.test_documents) * len(self.export_formats)
        current_test = 0
        
        for document in self.test_documents:
            for export_format in self.export_formats:
                current_test += 1
                logger.info(f"\n[{current_test}/{total_tests}] æµ‹è¯•: {document['name']} ({export_format})")
                
                # å°è¯•æ‰€æœ‰å¯ç”¨ç«¯ç‚¹ç›´åˆ°æˆåŠŸ
                success = False
                for endpoint in self.working_endpoints:
                    if success:
                        break
                        
                    result = self._attempt_download(document, export_format, endpoint)
                    results.append(result)
                    
                    if result.success:
                        success = True
                        logger.info(f"âœ… ä½¿ç”¨ç«¯ç‚¹ {endpoint['name']} ä¸‹è½½æˆåŠŸ")
                    else:
                        logger.warning(f"âŒ ç«¯ç‚¹ {endpoint['name']} å¤±è´¥: {result.error_message}")
                        time.sleep(2)  # å¤±è´¥åç­‰å¾…
                
                if not success:
                    logger.error(f"âŒ æ‰€æœ‰ç«¯ç‚¹éƒ½å¤±è´¥: {document['name']} ({export_format})")
                
                time.sleep(3)  # æµ‹è¯•é—´éš”
        
        self.results = results
        logger.info(f"\nğŸ æµ‹è¯•å®Œæˆï¼Œå…± {len(results)} ä¸ªç»“æœ")
        return results
    
    def analyze_results(self, results: List[DownloadResult]) -> Dict:
        """åˆ†ææµ‹è¯•ç»“æœ"""
        if not results:
            return {}
        
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]
        
        # åŸºç¡€ç»Ÿè®¡
        analysis = {
            'test_summary': {
                'total_tests': len(results),
                'successful_downloads': len(successful),
                'failed_downloads': len(failed),
                'success_rate': len(successful) / len(results) * 100 if results else 0
            },
            'performance_metrics': {
                'average_download_time': statistics.mean([r.download_time for r in successful]) if successful else 0,
                'total_download_time': sum(r.download_time for r in results),
                'total_file_size': sum(r.file_size for r in successful),
                'average_file_size': statistics.mean([r.file_size for r in successful]) if successful else 0
            },
            'format_performance': {},
            'endpoint_performance': {},
            'document_performance': {},
            'failure_analysis': {},
            'recommendations': []
        }
        
        # æŒ‰æ ¼å¼åˆ†æ
        for fmt in self.export_formats:
            fmt_results = [r for r in results if r.export_format == fmt]
            fmt_success = [r for r in fmt_results if r.success]
            analysis['format_performance'][fmt] = {
                'total_attempts': len(fmt_results),
                'successful': len(fmt_success),
                'success_rate': len(fmt_success) / len(fmt_results) * 100 if fmt_results else 0,
                'avg_download_time': statistics.mean([r.download_time for r in fmt_success]) if fmt_success else 0,
                'avg_file_size': statistics.mean([r.file_size for r in fmt_success]) if fmt_success else 0
            }
        
        # æŒ‰ç«¯ç‚¹åˆ†æ
        endpoint_stats = {}
        for result in successful:
            endpoint = result.endpoint_used
            if endpoint not in endpoint_stats:
                endpoint_stats[endpoint] = {'successes': 0, 'total_time': 0, 'total_size': 0}
            endpoint_stats[endpoint]['successes'] += 1
            endpoint_stats[endpoint]['total_time'] += result.download_time
            endpoint_stats[endpoint]['total_size'] += result.file_size
        
        for endpoint, stats in endpoint_stats.items():
            analysis['endpoint_performance'][endpoint] = {
                'success_count': stats['successes'],
                'avg_download_time': stats['total_time'] / stats['successes'],
                'avg_file_size': stats['total_size'] / stats['successes']
            }
        
        # æŒ‰æ–‡æ¡£åˆ†æ
        for doc in self.test_documents:
            doc_results = [r for r in results if r.document_name == doc['name']]
            doc_success = [r for r in doc_results if r.success]
            analysis['document_performance'][doc['name']] = {
                'total_attempts': len(doc_results),
                'successful': len(doc_success),
                'success_rate': len(doc_success) / len(doc_results) * 100 if doc_results else 0,
                'formats_tested': len(set(r.export_format for r in doc_results))
            }
        
        # å¤±è´¥åŸå› åˆ†æ
        for result in failed:
            reason = result.error_message
            if reason not in analysis['failure_analysis']:
                analysis['failure_analysis'][reason] = 0
            analysis['failure_analysis'][reason] += 1
        
        # ç”Ÿæˆå»ºè®®
        success_rate = analysis['test_summary']['success_rate']
        if success_rate >= 80:
            analysis['recommendations'].append("ä¸‹è½½æˆåŠŸç‡è‰¯å¥½ï¼Œç³»ç»Ÿè¿è¡Œæ­£å¸¸")
        elif success_rate >= 50:
            analysis['recommendations'].append("ä¸‹è½½æˆåŠŸç‡ä¸­ç­‰ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œè¿æ¥æˆ–Cookieç®¡ç†")
        else:
            analysis['recommendations'].append("ä¸‹è½½æˆåŠŸç‡è¾ƒä½ï¼Œéœ€è¦æ£€æŸ¥Cookieæœ‰æ•ˆæ€§å’ŒAPIç«¯ç‚¹")
        
        if endpoint_stats:
            best_endpoint = max(endpoint_stats.items(), key=lambda x: x[1]['successes'])
            analysis['recommendations'].append(f"æ¨èä½¿ç”¨ç«¯ç‚¹: {best_endpoint[0]} (æˆåŠŸ {best_endpoint[1]['successes']} æ¬¡)")
        
        return analysis
    
    def save_report(self, results: List[DownloadResult], analysis: Dict) -> str:
        """ä¿å­˜æµ‹è¯•æŠ¥å‘Š"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f'/root/projects/tencent-doc-manager/test_results/improved_download_report_{timestamp}.json'
        
        os.makedirs('/root/projects/tencent-doc-manager/test_results', exist_ok=True)
        
        report_data = {
            'test_metadata': {
                'test_time': datetime.now().isoformat(),
                'test_type': 'Improved Download Test',
                'tester_version': '2.0.0',
                'documents_tested': len(self.test_documents),
                'formats_tested': self.export_formats,
                'endpoints_tested': len(self.working_endpoints)
            },
            'results': [asdict(r) for r in results],
            'analysis': analysis
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“‹ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return report_file
    
    def print_summary(self, analysis: Dict):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ æ”¹è¿›ç‰ˆè…¾è®¯æ–‡æ¡£ä¸‹è½½æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        summary = analysis.get('test_summary', {})
        performance = analysis.get('performance_metrics', {})
        
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•æ•°: {summary.get('total_tests', 0)}")
        print(f"   æˆåŠŸä¸‹è½½: {summary.get('successful_downloads', 0)}")
        print(f"   å¤±è´¥ä¸‹è½½: {summary.get('failed_downloads', 0)}")
        print(f"   æˆåŠŸç‡: {summary.get('success_rate', 0):.1f}%")
        
        print(f"\nâ±ï¸  æ€§èƒ½æŒ‡æ ‡:")
        print(f"   å¹³å‡ä¸‹è½½æ—¶é—´: {performance.get('average_download_time', 0):.2f}ç§’")
        print(f"   æ€»ä¸‹è½½æ—¶é—´: {performance.get('total_download_time', 0):.1f}ç§’")
        print(f"   æ€»æ–‡ä»¶å¤§å°: {performance.get('total_file_size', 0)/1024:.1f} KB")
        print(f"   å¹³å‡æ–‡ä»¶å¤§å°: {performance.get('average_file_size', 0)/1024:.1f} KB")
        
        format_perf = analysis.get('format_performance', {})
        if format_perf:
            print(f"\nğŸ“ æ ¼å¼æ€§èƒ½:")
            for fmt, stats in format_perf.items():
                print(f"   {fmt.upper()}: æˆåŠŸç‡ {stats['success_rate']:.1f}% "
                      f"({stats['successful']}/{stats['total_attempts']})")
        
        endpoint_perf = analysis.get('endpoint_performance', {})
        if endpoint_perf:
            print(f"\nğŸŒ ç«¯ç‚¹æ€§èƒ½:")
            for endpoint, stats in endpoint_perf.items():
                print(f"   {endpoint}: {stats['success_count']}æ¬¡æˆåŠŸ "
                      f"(å¹³å‡{stats['avg_download_time']:.2f}ç§’)")
        
        failure_analysis = analysis.get('failure_analysis', {})
        if failure_analysis:
            print(f"\nâŒ å¤±è´¥åŸå› :")
            for reason, count in failure_analysis.items():
                print(f"   {reason}: {count}æ¬¡")
        
        recommendations = analysis.get('recommendations', [])
        if recommendations:
            print(f"\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")
        
        print("="*60)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨æ”¹è¿›ç‰ˆè…¾è®¯æ–‡æ¡£ä¸‹è½½æµ‹è¯•...")
    
    try:
        downloader = ImprovedTencentDownloader()
        results = downloader.run_comprehensive_test()
        
        if results:
            analysis = downloader.analyze_results(results)
            downloader.print_summary(analysis)
            report_file = downloader.save_report(results, analysis)
            print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        else:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœ")
            
    except Exception as e:
        logger.error(f"æµ‹è¯•ç¨‹åºå¼‚å¸¸: {e}")
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")


if __name__ == "__main__":
    main()