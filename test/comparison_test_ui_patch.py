#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
8094ç«¯å£å¹¶è¡Œä¸‹è½½è¡¥ä¸
è§£å†³502è¶…æ—¶é—®é¢˜ - å°†ä¸²è¡Œä¸‹è½½æ”¹ä¸ºå¹¶è¡Œä¸‹è½½
"""

import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path
import json
import shutil

def parallel_download_handler(request_data, download_func, base_dir):
    """
    å¹¶è¡Œä¸‹è½½å¤„ç†å™¨ - åŒæ—¶ä¸‹è½½åŸºçº¿å’Œç›®æ ‡æ–‡ä»¶
    
    Args:
        request_data: åŒ…å«åŸºçº¿å’Œç›®æ ‡URLåŠCookieçš„å­—å…¸
        download_func: download_file_from_urlå‡½æ•°å¼•ç”¨
        base_dir: åŸºç¡€ç›®å½•è·¯å¾„
    
    Returns:
        dict: åŒ…å«ä¸¤ä¸ªæ–‡ä»¶ä¸‹è½½ç»“æœçš„å­—å…¸
    """
    
    BASELINE_DIR = base_dir / 'comparison_baseline'
    TARGET_DIR = base_dir / 'comparison_target'
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    BASELINE_DIR.mkdir(parents=True, exist_ok=True)
    TARGET_DIR.mkdir(parents=True, exist_ok=True)
    
    results = {
        'baseline': None,
        'target': None,
        'total_time': 0,
        'parallel': True
    }
    
    start_time = time.time()
    
    # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
    download_tasks = []
    
    # åŸºçº¿æ–‡ä»¶ä»»åŠ¡
    baseline_url = request_data.get('baseline_url')
    baseline_cookie = request_data.get('baseline_cookie', '')
    
    if baseline_url:
        download_tasks.append({
            'type': 'baseline',
            'url': baseline_url,
            'cookie': baseline_cookie,
            'dest_dir': BASELINE_DIR
        })
    
    # ç›®æ ‡æ–‡ä»¶ä»»åŠ¡
    target_url = request_data.get('target_url')
    target_cookie = request_data.get('target_cookie', '')
    
    if target_url:
        download_tasks.append({
            'type': 'target',
            'url': target_url,
            'cookie': target_cookie,
            'dest_dir': TARGET_DIR
        })
    
    # å®šä¹‰ä¸‹è½½å‡½æ•°
    def download_file(task):
        """å•ä¸ªæ–‡ä»¶ä¸‹è½½ä»»åŠ¡"""
        task_type = task['type']
        print(f"\n[å¹¶è¡Œä¸‹è½½] å¼€å§‹ä¸‹è½½{task_type}æ–‡ä»¶: {task['url'][:50]}...")
        
        # ä¿å­˜Cookieåˆ°é…ç½®æ–‡ä»¶
        if task['cookie']:
            config_file = base_dir / 'config.json'
            try:
                with open(config_file, 'w', encoding='utf-8') as f:
                    json.dump({'cookie': task['cookie']}, f, ensure_ascii=False, indent=2)
                print(f"[{task_type}] Cookieå·²ä¿å­˜ï¼Œé•¿åº¦: {len(task['cookie'])}")
            except Exception as e:
                print(f"[{task_type}] ä¿å­˜Cookieå¤±è´¥: {e}")
        
        # æ‰§è¡Œä¸‹è½½
        task_start = time.time()
        try:
            result = download_func(task['url'], format_type='csv')
            download_time = time.time() - task_start
            print(f"[{task_type}] ä¸‹è½½å®Œæˆï¼Œè€—æ—¶: {download_time:.2f}ç§’")
            
            # å¤„ç†ä¸‹è½½ç»“æœ
            if result and result.get('success'):
                if result.get('files'):
                    first_file = result['files'][0]
                    source_path = Path(first_file.get('path', ''))
                    if source_path.exists():
                        dest_path = task['dest_dir'] / source_path.name
                        shutil.copy(source_path, dest_path)
                        print(f"[{task_type}] æ–‡ä»¶å·²å¤åˆ¶åˆ°: {dest_path}")
                        
                        return {
                            'type': task_type,
                            'success': True,
                            'path': str(dest_path),
                            'name': dest_path.name,
                            'size': f"{dest_path.stat().st_size:,} bytes",
                            'download_time': download_time,
                            'result': result
                        }
            
            return {
                'type': task_type,
                'success': False,
                'error': result.get('error', 'ä¸‹è½½å¤±è´¥'),
                'download_time': download_time
            }
            
        except Exception as e:
            download_time = time.time() - task_start
            print(f"[{task_type}] ä¸‹è½½å¼‚å¸¸: {e}")
            return {
                'type': task_type,
                'success': False,
                'error': str(e),
                'download_time': download_time
            }
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œä¸‹è½½
    print(f"[å¹¶è¡Œä¸‹è½½] å¯åŠ¨{len(download_tasks)}ä¸ªå¹¶è¡Œä¸‹è½½ä»»åŠ¡...")
    
    with ThreadPoolExecutor(max_workers=2) as executor:
        # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        future_to_task = {executor.submit(download_file, task): task for task in download_tasks}
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for future in as_completed(future_to_task):
            task = future_to_task[future]
            try:
                download_result = future.result(timeout=70)  # å•ä¸ªä»»åŠ¡æœ€å¤š70ç§’
                
                if download_result['type'] == 'baseline':
                    results['baseline'] = download_result
                elif download_result['type'] == 'target':
                    results['target'] = download_result
                    
            except Exception as e:
                print(f"[å¹¶è¡Œä¸‹è½½] ä»»åŠ¡å¼‚å¸¸: {e}")
                if task['type'] == 'baseline':
                    results['baseline'] = {
                        'success': False,
                        'error': str(e)
                    }
                elif task['type'] == 'target':
                    results['target'] = {
                        'success': False,
                        'error': str(e)
                    }
    
    total_time = time.time() - start_time
    results['total_time'] = total_time
    
    print(f"\n[å¹¶è¡Œä¸‹è½½] æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
    print(f"[å¹¶è¡Œä¸‹è½½] åŸºçº¿æ–‡ä»¶: {'æˆåŠŸ' if results['baseline'] and results['baseline'].get('success') else 'å¤±è´¥'}")
    print(f"[å¹¶è¡Œä¸‹è½½] ç›®æ ‡æ–‡ä»¶: {'æˆåŠŸ' if results['target'] and results['target'].get('success') else 'å¤±è´¥'}")
    
    return results


# å¯¼å‡ºè¡¥ä¸å‡½æ•°
def apply_parallel_download_patch():
    """
    åº”ç”¨å¹¶è¡Œä¸‹è½½è¡¥ä¸åˆ°comparison_test_ui.py
    è¿™ä¸ªå‡½æ•°éœ€è¦åœ¨comparison_test_ui.pyä¸­é›†æˆ
    """
    print("âœ¨ å¹¶è¡Œä¸‹è½½è¡¥ä¸å·²å‡†å¤‡å°±ç»ª")
    print("ğŸ“Œ ä½¿ç”¨æ–¹æ³•ï¼š")
    print("1. åœ¨comparison_test_ui.pyä¸­å¯¼å…¥: from comparison_test_ui_patch import parallel_download_handler")
    print("2. æ›¿æ¢compareå‡½æ•°ä¸­çš„ä¸²è¡Œä¸‹è½½éƒ¨åˆ†")
    print("3. è°ƒç”¨parallel_download_handler(data, download_file_from_url, BASE_DIR)")
    return True


if __name__ == "__main__":
    print("ğŸš€ 8094ç«¯å£å¹¶è¡Œä¸‹è½½è¡¥ä¸")
    print("=" * 60)
    print("æ­¤è¡¥ä¸å°†ä¸²è¡Œä¸‹è½½æ”¹ä¸ºå¹¶è¡Œä¸‹è½½ï¼Œè§£å†³502è¶…æ—¶é—®é¢˜")
    print("é¢„æœŸæ•ˆæœï¼š")
    print("- åŸè€—æ—¶: ~105ç§’ï¼ˆä¸²è¡Œï¼‰")
    print("- æ–°è€—æ—¶: ~45ç§’ï¼ˆå¹¶è¡Œï¼‰")
    print("- é¿å…502 Bad Gatewayé”™è¯¯")
    apply_parallel_download_patch()