#!/usr/bin/env python3
"""
è¯„ä¼°åœ¨æ–‡ä»¶åä¸­åŠ å…¥URLä½œä¸ºå”¯ä¸€æ ‡è¯†çš„å½±å“å’Œå¯è¡Œæ€§åˆ†æ
"""
import os
import re
import json
from urllib.parse import urlparse, quote, unquote

def analyze_current_naming():
    """åˆ†æå½“å‰çš„å‘½åè§„åˆ™"""
    print("ğŸ“‹ å½“å‰å‘½åè§„åˆ™åˆ†æ")
    print("=" * 60)

    # å½“å‰å‘½åæ ¼å¼
    current_format = "tencent_{æ–‡æ¡£å}_{æ—¶é—´æˆ³}_{ç‰ˆæœ¬ç±»å‹}_W{å‘¨æ•°}.{æ‰©å±•å}"
    print(f"å½“å‰æ ¼å¼: {current_format}")

    # ç¤ºä¾‹æ–‡ä»¶å
    examples = [
        "tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_20250915_0145_baseline_W39.csv",
        "tencent_å›å›½é”€å”®è®¡åˆ’è¡¨_20250914_2309_baseline_W39.csv",
        "tencent_å°çº¢ä¹¦éƒ¨é—¨_20250915_0146_baseline_W39.csv"
    ]

    print("\nç¤ºä¾‹æ–‡ä»¶å:")
    for ex in examples:
        print(f"  - {ex}")
        # è§£ææ–‡ä»¶å
        match = re.search(r'^tencent_(.+?)_(\d{8}_\d{4})_(baseline|midweek)_W(\d+)\.(\w+)$', ex)
        if match:
            doc_name, timestamp, version, week, ext = match.groups()
            print(f"    è§£æ: æ–‡æ¡£={doc_name}, æ—¶é—´={timestamp}, ç‰ˆæœ¬={version}, å‘¨={week}")

    return examples

def propose_url_naming_schemes():
    """æå‡ºåŒ…å«URLçš„å‘½åæ–¹æ¡ˆ"""
    print("\n\nğŸ’¡ æå‡ºçš„URLå‘½åæ–¹æ¡ˆ")
    print("=" * 60)

    # æµ‹è¯•URL
    test_url = "https://docs.qq.com/sheet/DWEFNU25TemFnZXJN"
    doc_id = urlparse(test_url).path.split('/')[-1]  # DWEFNU25TemFnZXJN

    print(f"æµ‹è¯•URL: {test_url}")
    print(f"æå–çš„æ–‡æ¡£ID: {doc_id}")

    schemes = {}

    # æ–¹æ¡ˆ1: åœ¨æ–‡æ¡£ååæ·»åŠ æ–‡æ¡£ID
    schemes["æ–¹æ¡ˆ1"] = {
        "æ ¼å¼": "tencent_{æ–‡æ¡£å}_{æ–‡æ¡£ID}_{æ—¶é—´æˆ³}_{ç‰ˆæœ¬}_W{å‘¨}.{ext}",
        "ç¤ºä¾‹": f"tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_{doc_id}_20250915_0145_baseline_W39.csv",
        "ä¼˜ç‚¹": ["æ–‡æ¡£IDå”¯ä¸€æ ‡è¯†", "å‘åå…¼å®¹", "URLå¯åæ¨"],
        "ç¼ºç‚¹": ["æ–‡ä»¶åå˜é•¿", "éœ€è¦IDåˆ°URLæ˜ å°„è¡¨"],
        "å½±å“": "ä½ - åªéœ€ä¿®æ”¹æ–‡ä»¶åç”Ÿæˆå’Œè§£æé€»è¾‘"
    }

    # æ–¹æ¡ˆ2: ä½¿ç”¨ç®€åŒ–çš„å“ˆå¸ŒID
    import hashlib
    hash_id = hashlib.md5(test_url.encode()).hexdigest()[:8]
    schemes["æ–¹æ¡ˆ2"] = {
        "æ ¼å¼": "tencent_{æ–‡æ¡£å}_{å“ˆå¸ŒID}_{æ—¶é—´æˆ³}_{ç‰ˆæœ¬}_W{å‘¨}.{ext}",
        "ç¤ºä¾‹": f"tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_{hash_id}_20250915_0145_baseline_W39.csv",
        "ä¼˜ç‚¹": ["IDæ›´çŸ­", "å”¯ä¸€æ€§å¥½"],
        "ç¼ºç‚¹": ["éœ€è¦å“ˆå¸Œæ˜ å°„è¡¨", "ä¸å¯åæ¨URL"],
        "å½±å“": "ä¸­ - éœ€è¦ç»´æŠ¤å“ˆå¸Œæ˜ å°„è¡¨"
    }

    # æ–¹æ¡ˆ3: å»ºç«‹ç‹¬ç«‹çš„æ˜ å°„æ–‡ä»¶(æ¨è)
    schemes["æ–¹æ¡ˆ3"] = {
        "æ ¼å¼": "ä¿æŒç°æœ‰æ ¼å¼ä¸å˜",
        "æ˜ å°„æ–‡ä»¶": "baseline_url_mapping.json",
        "ç¤ºä¾‹": {
            "tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_20250915_0145_baseline_W39.csv": {
                "url": test_url,
                "doc_id": doc_id,
                "doc_name": "å‡ºå›½é”€å”®è®¡åˆ’è¡¨",
                "download_time": "2025-09-15 01:45"
            }
        },
        "ä¼˜ç‚¹": ["é›¶æ”¹åŠ¨ç°æœ‰ä»£ç ", "å®Œæ•´ä¿¡æ¯è®°å½•", "çµæ´»æ‰©å±•"],
        "ç¼ºç‚¹": ["éœ€è¦ç»´æŠ¤æ˜ å°„æ–‡ä»¶"],
        "å½±å“": "æœ€å° - ä»…æ–°å¢æ˜ å°„æ–‡ä»¶è¯»å†™"
    }

    for name, scheme in schemes.items():
        print(f"\n{name}:")
        for key, value in scheme.items():
            if isinstance(value, list):
                print(f"  {key}:")
                for item in value:
                    print(f"    - {item}")
            elif isinstance(value, dict):
                print(f"  {key}: {json.dumps(value, ensure_ascii=False, indent=4)}")
            else:
                print(f"  {key}: {value}")

    return schemes

def analyze_impact_on_existing_code():
    """åˆ†æå¯¹ç°æœ‰ä»£ç çš„å½±å“"""
    print("\n\nğŸ“Š å¯¹ç°æœ‰ä»£ç çš„å½±å“åˆ†æ")
    print("=" * 60)

    # æ£€æŸ¥æ‰€æœ‰ä½¿ç”¨åŸºçº¿æ–‡ä»¶çš„åœ°æ–¹
    affected_files = {
        "production_integrated_test_system_8093.py": {
            "å½±å“ç‚¹": ["åŸºçº¿åŒ¹é…é€»è¾‘", "æ–‡ä»¶åè§£æ"],
            "ä¿®æ”¹é‡": "ä¸­ç­‰",
            "å…³é”®ä»£ç ": "if doc_name in basename:"
        },
        "week_time_manager.py": {
            "å½±å“ç‚¹": ["åŸºçº¿æ–‡ä»¶æŸ¥æ‰¾"],
            "ä¿®æ”¹é‡": "å°",
            "å…³é”®ä»£ç ": "glob.glob(pattern)"
        },
        "final_heatmap_server.py": {
            "å½±å“ç‚¹": ["åŸºçº¿æ–‡ä»¶æ˜¾ç¤º"],
            "ä¿®æ”¹é‡": "æ— ",
            "å…³é”®ä»£ç ": "ä¸ç›´æ¥ä½¿ç”¨æ–‡ä»¶å"
        }
    }

    print("å—å½±å“çš„æ–‡ä»¶:")
    for file, info in affected_files.items():
        print(f"\nğŸ“„ {file}")
        for key, value in info.items():
            if isinstance(value, list):
                print(f"  {key}: {', '.join(value)}")
            else:
                print(f"  {key}: {value}")

    # è¯„ä¼°æ€»ä½“å½±å“
    print("\n\nğŸ¯ æ€»ä½“å½±å“è¯„ä¼°:")
    print("-" * 40)

    if os.path.exists("production_integrated_test_system_8093.py"):
        with open("production_integrated_test_system_8093.py", "r") as f:
            content = f.read()
            # ç»Ÿè®¡ç›¸å…³ä»£ç è¡Œæ•°
            baseline_refs = len(re.findall(r'baseline', content, re.IGNORECASE))
            basename_refs = len(re.findall(r'os\.path\.basename', content))
            print(f"baselineç›¸å…³å¼•ç”¨: {baseline_refs}æ¬¡")
            print(f"æ–‡ä»¶åè§£æå¼•ç”¨: {basename_refs}æ¬¡")

    return affected_files

def recommend_solution():
    """æ¨èæœ€ä½³è§£å†³æ–¹æ¡ˆ"""
    print("\n\nâœ… æ¨èè§£å†³æ–¹æ¡ˆ")
    print("=" * 60)

    recommendation = {
        "çŸ­æœŸæ–¹æ¡ˆï¼ˆç«‹å³å¯è¡Œï¼‰": {
            "æ–¹æ³•": "æ”¹è¿›åŒ¹é…é€»è¾‘ + æ˜ å°„æ–‡ä»¶",
            "æ­¥éª¤": [
                "1. ä¿®æ”¹åŒ¹é…é€»è¾‘ä¸ºç²¾ç¡®åŒ¹é…ï¼ˆè§£å†³é—®é¢˜1ï¼‰",
                "2. åˆ›å»ºbaseline_url_mapping.jsonè®°å½•URLæ˜ å°„ï¼ˆè§£å†³é—®é¢˜3ï¼‰",
                "3. ä¿æŒæ–‡ä»¶åæ ¼å¼ä¸å˜ï¼ˆé¿å…é¢ è¦†æ€§æ”¹åŠ¨ï¼‰"
            ],
            "ä»£ç ç¤ºä¾‹": """
# ç²¾ç¡®åŒ¹é…é€»è¾‘
def extract_doc_name(filename):
    match = re.search(r'^tencent_(.+?)_\\d{8}_\\d{4}', filename)
    return match.group(1) if match else None

# åŒ¹é…æ”¹è¿›
if extract_doc_name(baseline) == doc_name:
    matched_baseline = baseline

# URLæ˜ å°„è®°å½•
mapping = {
    filename: {
        "url": download_url,
        "doc_name": doc_name,
        "timestamp": timestamp
    }
}
"""
        },
        "é•¿æœŸæ–¹æ¡ˆï¼ˆæ¶æ„ä¼˜åŒ–ï¼‰": {
            "æ–¹æ³•": "å»ºç«‹æ–‡æ¡£ç®¡ç†ç³»ç»Ÿ",
            "ç‰¹æ€§": [
                "ç»Ÿä¸€çš„æ–‡æ¡£å…ƒæ•°æ®ç®¡ç†",
                "URLã€æ–‡ä»¶åã€ç‰ˆæœ¬çš„å®Œæ•´æ˜ å°„",
                "æ”¯æŒå¤šç‰ˆæœ¬è¿½è¸ª",
                "APIæ¥å£æŸ¥è¯¢"
            ]
        }
    }

    print("ğŸ“Œ æ¨èé‡‡ç”¨çŸ­æœŸæ–¹æ¡ˆï¼ŒåŸå› ï¼š")
    print("  1. âœ… æ”¹åŠ¨æœ€å°ï¼Œä¸å½±å“ç°æœ‰ç³»ç»Ÿ")
    print("  2. âœ… ç«‹å³è§£å†³æ–‡ä»¶åŒ¹é…é—®é¢˜")
    print("  3. âœ… ä¿ç•™URLä¿¡æ¯ç”¨äºè¿½è¸ª")
    print("  4. âœ… å¯é€æ­¥è¿‡æ¸¡åˆ°é•¿æœŸæ–¹æ¡ˆ")

    print("\nå®æ–½æ­¥éª¤:")
    for key, value in recommendation["çŸ­æœŸæ–¹æ¡ˆï¼ˆç«‹å³å¯è¡Œï¼‰"].items():
        if isinstance(value, list):
            print(f"\n{key}:")
            for item in value:
                print(f"  {item}")
        else:
            print(f"\n{key}:{value}")

    return recommendation

def main():
    print("ğŸ” æ–‡ä»¶å‘½åæ–¹æ¡ˆå½±å“è¯„ä¼°æŠ¥å‘Š")
    print("=" * 80)
    print("è¯„ä¼°æ—¶é—´: 2025-09-24")
    print("ç›®çš„: è¯„ä¼°åœ¨æ–‡ä»¶åä¸­åŠ å…¥URLçš„å¯è¡Œæ€§å’Œå½±å“")
    print("=" * 80)

    # 1. åˆ†æå½“å‰å‘½å
    current_examples = analyze_current_naming()

    # 2. æå‡ºURLæ–¹æ¡ˆ
    schemes = propose_url_naming_schemes()

    # 3. å½±å“åˆ†æ
    impact = analyze_impact_on_existing_code()

    # 4. æ¨èæ–¹æ¡ˆ
    recommendation = recommend_solution()

    print("\n\nğŸ“Š ç»“è®º")
    print("=" * 60)
    print("âœ… ä¸å»ºè®®åœ¨æ–‡ä»¶åä¸­ç›´æ¥åŠ å…¥å®Œæ•´URLï¼ˆä¼šé€ æˆé¢ è¦†æ€§æ”¹åŠ¨ï¼‰")
    print("âœ… å»ºè®®é‡‡ç”¨æ˜ å°„æ–‡ä»¶æ–¹æ¡ˆï¼ˆå½±å“æœ€å°ï¼Œæ•ˆæœæœ€å¥½ï¼‰")
    print("âœ… ç«‹å³å¯è¡Œçš„æ”¹è¿›ï¼šç²¾ç¡®åŒ¹é… + URLæ˜ å°„æ–‡ä»¶")
    print("âœ… é¢„è®¡æ”¹åŠ¨é‡ï¼š< 50è¡Œä»£ç ")
    print("âœ… é£é™©ç­‰çº§ï¼šä½")

    # åˆ›å»ºç¤ºä¾‹æ˜ å°„æ–‡ä»¶
    sample_mapping = {
        "baseline_url_mapping": {
            "tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_20250915_0145_baseline_W39.csv": {
                "url": "https://docs.qq.com/sheet/DWEFNU25TemFnZXJN",
                "doc_id": "DWEFNU25TemFnZXJN",
                "doc_name": "å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨",
                "download_time": "2025-09-15 01:45:00"
            },
            "tencent_å›å›½é”€å”®è®¡åˆ’è¡¨_20250914_2309_baseline_W39.csv": {
                "url": "https://docs.qq.com/sheet/DWGZDZkxpaGVQaURr",
                "doc_id": "DWGZDZkxpaGVQaURr",
                "doc_name": "å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨",
                "download_time": "2025-09-14 23:09:00"
            }
        }
    }

    # ä¿å­˜ç¤ºä¾‹æ˜ å°„æ–‡ä»¶
    mapping_file = "baseline_url_mapping.json"
    with open(mapping_file, "w", encoding="utf-8") as f:
        json.dump(sample_mapping, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… å·²åˆ›å»ºç¤ºä¾‹æ˜ å°„æ–‡ä»¶: {mapping_file}")

if __name__ == "__main__":
    main()