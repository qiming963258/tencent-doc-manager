#!/usr/bin/env python3
"""å…¨é“¾è·¯æµ‹è¯•è„šæœ¬ - æ·±åº¦æ£€æŸ¥å„ä¸ªé˜¶æ®µçš„æ–‡ä»¶å’Œæ•°æ®"""

import sys
import os
import json
import time
from datetime import datetime
import pytz

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/root/projects/tencent-doc-manager')

from production.core_modules.tencent_export_automation import TencentDocAutoExporter
from production.core_modules.week_time_manager import WeekTimeManager
from production.core_modules.adaptive_table_comparator import AdaptiveTableComparator

def log(msg, level="INFO"):
    """æ‰“å°å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    prefix = {
        "INFO": "ğŸ“‹",
        "SUCCESS": "âœ…",
        "ERROR": "âŒ",
        "WARNING": "âš ï¸",
        "PROCESS": "ğŸ”„"
    }.get(level, "ğŸ“Œ")
    print(f"[{timestamp}] {prefix} {msg}")

def test_full_workflow():
    """æ‰§è¡Œå®Œæ•´çš„å…¨é“¾è·¯æµ‹è¯•"""

    log("========== å¼€å§‹å…¨é“¾è·¯æµ‹è¯• ==========", "PROCESS")

    # åˆå§‹åŒ–ç»„ä»¶
    wtm = WeekTimeManager()
    week_info = wtm.get_current_week_info()
    current_week = week_info['week_number']

    # è¯»å–Cookie
    with open('/root/projects/tencent-doc-manager/config/cookies.json', 'r') as f:
        cookie_data = json.load(f)
    cookie_string = cookie_data.get('current_cookies', '')

    log(f"å½“å‰å‘¨æ•°: W{current_week}", "INFO")
    log(f"Cookieé•¿åº¦: {len(cookie_string)} å­—ç¬¦", "INFO")

    # æµ‹è¯•æ–‡æ¡£URLs
    test_docs = [
        {
            "name": "å‡ºå›½é”€å”®è®¡åˆ’è¡¨",
            "url": "https://docs.qq.com/sheet/DWEFNU25TemFnZXJN?tab=BB08J2"
        },
        {
            "name": "å°çº¢ä¹¦éƒ¨é—¨",
            "url": "https://docs.qq.com/sheet/DWFJzdWNwd0RGbU5R?tab=000001"
        }
    ]

    # ========== æ­¥éª¤1: ä¸‹è½½CSVæ–‡ä»¶ ==========
    log("æ­¥éª¤1: ä¸‹è½½CSVæ–‡ä»¶", "PROCESS")

    exporter = TencentDocAutoExporter()
    downloaded_files = []

    for doc in test_docs:
        log(f"ä¸‹è½½: {doc['name']}", "INFO")
        result = exporter.export_document(
            url=doc['url'],
            cookies=cookie_string,
            format='csv'
        )

        if result['success']:
            file_path = result.get('file_path')
            log(f"ä¸‹è½½æˆåŠŸ: {file_path}", "SUCCESS")
            downloaded_files.append(file_path)

            # æ£€æŸ¥æ–‡ä»¶å†…å®¹
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path) / 1024
                log(f"æ–‡ä»¶å¤§å°: {file_size:.1f} KB", "INFO")

                # è¯»å–å‰å‡ è¡Œæ£€æŸ¥æ ¼å¼
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()[:3]
                    log(f"å‰3è¡Œé¢„è§ˆ:", "INFO")
                    for i, line in enumerate(lines, 1):
                        print(f"  è¡Œ{i}: {line[:100].strip()}")
        else:
            log(f"ä¸‹è½½å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}", "ERROR")

    # ========== æ­¥éª¤2: CSVå¯¹æ¯”åˆ†æ ==========
    log("æ­¥éª¤2: CSVå¯¹æ¯”åˆ†æ", "PROCESS")

    if len(downloaded_files) >= 1:
        # æŸ¥æ‰¾åŸºçº¿æ–‡ä»¶
        baseline_dir = f"/root/projects/tencent-doc-manager/csv_versions/2025_W{current_week}/baseline"
        baseline_files = []

        if os.path.exists(baseline_dir):
            for file in os.listdir(baseline_dir):
                if file.endswith('.csv') and not file.startswith('.'):
                    baseline_files.append(os.path.join(baseline_dir, file))

        log(f"æ‰¾åˆ° {len(baseline_files)} ä¸ªåŸºçº¿æ–‡ä»¶", "INFO")

        if baseline_files and downloaded_files:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŸºçº¿å’Œç¬¬ä¸€ä¸ªä¸‹è½½æ–‡ä»¶è¿›è¡Œå¯¹æ¯”
            baseline_file = baseline_files[0]
            target_file = downloaded_files[0]

            log(f"åŸºçº¿: {os.path.basename(baseline_file)}", "INFO")
            log(f"ç›®æ ‡: {os.path.basename(target_file)}", "INFO")

            # åˆå§‹åŒ–å¯¹æ¯”å™¨
            comparator = AdaptiveTableComparator()

            # æ‰§è¡Œå¯¹æ¯”
            log("æ‰§è¡ŒCSVå¯¹æ¯”...", "PROCESS")
            comparison_result = comparator.compare_files(baseline_file, target_file)

            # ä¿å­˜å¯¹æ¯”ç»“æœ
            result_dir = "/root/projects/tencent-doc-manager/comparison_results"
            os.makedirs(result_dir, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            result_file = os.path.join(result_dir, f"test_comparison_{timestamp}.json")

            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(comparison_result, f, ensure_ascii=False, indent=2)

            log(f"å¯¹æ¯”ç»“æœä¿å­˜åˆ°: {result_file}", "SUCCESS")

            # åˆ†æå¯¹æ¯”ç»“æœ
            if comparison_result:
                log("å¯¹æ¯”ç»“æœåˆ†æ:", "INFO")
                print(f"  æ–‡æ¡£åç§°: {comparison_result.get('document_name', 'N/A')}")
                print(f"  æ€»ä½“ç›¸ä¼¼åº¦: {comparison_result.get('overall_similarity', 0):.2%}")
                print(f"  å˜æ›´å•å…ƒæ ¼æ•°: {comparison_result.get('changed_cells_count', 0)}")

                # æ£€æŸ¥æ ‡å‡†åŒ–æ–‡ä»¶
                standardized_file = comparison_result.get('standardized_file')
                if standardized_file:
                    log(f"æ ‡å‡†åŒ–æ–‡ä»¶: {standardized_file}", "SUCCESS")
                else:
                    log("æœªç”Ÿæˆæ ‡å‡†åŒ–æ–‡ä»¶", "WARNING")

                # æ£€æŸ¥è¯¦ç»†æ‰“åˆ†
                detailed_scores = comparison_result.get('detailed_scores', {})
                if detailed_scores:
                    log("è¯¦ç»†æ‰“åˆ†æ•°æ®å­˜åœ¨", "SUCCESS")
                    print(f"  æ‰“åˆ†ç»´åº¦æ•°: {len(detailed_scores)}")
                else:
                    log("ç¼ºå°‘è¯¦ç»†æ‰“åˆ†æ•°æ®", "ERROR")

                # æ£€æŸ¥ç»¼åˆæ‰“åˆ†
                comprehensive_score = comparison_result.get('comprehensive_score')
                if comprehensive_score:
                    log(f"ç»¼åˆæ‰“åˆ†: {comprehensive_score}", "SUCCESS")
                else:
                    log("ç¼ºå°‘ç»¼åˆæ‰“åˆ†", "ERROR")

    else:
        log("æ–‡ä»¶ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå¯¹æ¯”", "WARNING")

    # ========== æ­¥éª¤3: æ£€æŸ¥ä¸­é—´æ–‡ä»¶ ==========
    log("æ­¥éª¤3: æ£€æŸ¥ä¸­é—´æ–‡ä»¶", "PROCESS")

    # æ£€æŸ¥æ ‡å‡†åŒ–åçš„æ–‡ä»¶
    standardized_dir = "/root/projects/tencent-doc-manager/csv_versions/standard_outputs"
    if os.path.exists(standardized_dir):
        files = os.listdir(standardized_dir)
        log(f"æ ‡å‡†åŒ–è¾“å‡ºç›®å½•åŒ…å« {len(files)} ä¸ªæ–‡ä»¶", "INFO")
        for file in files[-5:]:  # æ˜¾ç¤ºæœ€æ–°çš„5ä¸ª
            print(f"  - {file}")

    # ========== æ­¥éª¤4: æ£€æŸ¥æ‰“åˆ†ç»“æœ ==========
    log("æ­¥éª¤4: æ£€æŸ¥æ‰“åˆ†ç»“æœ", "PROCESS")

    scoring_dir = "/root/projects/tencent-doc-manager/scoring_results"
    if os.path.exists(scoring_dir):
        # æ£€æŸ¥è¯¦ç»†æ‰“åˆ†
        detailed_dir = os.path.join(scoring_dir, "detailed")
        if os.path.exists(detailed_dir):
            files = os.listdir(detailed_dir)
            log(f"è¯¦ç»†æ‰“åˆ†ç›®å½•åŒ…å« {len(files)} ä¸ªæ–‡ä»¶", "INFO")

        # æ£€æŸ¥ç»¼åˆæ‰“åˆ†
        comprehensive_dir = os.path.join(scoring_dir, "comprehensive")
        if os.path.exists(comprehensive_dir):
            files = os.listdir(comprehensive_dir)
            log(f"ç»¼åˆæ‰“åˆ†ç›®å½•åŒ…å« {len(files)} ä¸ªæ–‡ä»¶", "INFO")

            # è¯»å–æœ€æ–°çš„ç»¼åˆæ‰“åˆ†æ–‡ä»¶
            if files:
                latest_file = sorted(files)[-1]
                file_path = os.path.join(comprehensive_dir, latest_file)
                log(f"æœ€æ–°ç»¼åˆæ‰“åˆ†æ–‡ä»¶: {latest_file}", "INFO")

                with open(file_path, 'r', encoding='utf-8') as f:
                    score_data = json.load(f)

                # æ£€æŸ¥æ•°æ®æ ¼å¼
                if 'ui_data' in score_data:
                    ui_data = score_data['ui_data']
                    log(f"UIæ•°æ®æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å« {len(ui_data)} ä¸ªè¡¨æ ¼", "SUCCESS")
                else:
                    log("ç»¼åˆæ‰“åˆ†ç¼ºå°‘ui_dataå­—æ®µ", "ERROR")

    # ========== æ­¥éª¤5: æ£€æŸ¥UIé€‚é…æ€§ ==========
    log("æ­¥éª¤5: æ£€æŸ¥UIé€‚é…æ€§", "PROCESS")

    # æ£€æŸ¥8089ç«¯å£æœåŠ¡
    import requests
    try:
        response = requests.get("http://localhost:8089/api/data", timeout=5)
        if response.status_code == 200:
            data = response.json()
            log("8089 UIæœåŠ¡æ­£å¸¸å“åº”", "SUCCESS")

            # æ£€æŸ¥æ•°æ®ç»“æ„
            if 'heatmap_data' in data:
                heatmap = data['heatmap_data']
                log(f"çƒ­åŠ›å›¾æ•°æ®: {len(heatmap)} è¡Œ", "INFO")

            if 'column_headers' in data:
                headers = data['column_headers']
                log(f"åˆ—æ ‡é¢˜æ•°: {len(headers)}", "INFO")

        else:
            log(f"8089æœåŠ¡è¿”å›é”™è¯¯: {response.status_code}", "ERROR")
    except Exception as e:
        log(f"æ— æ³•è¿æ¥8089æœåŠ¡: {str(e)}", "ERROR")

    log("========== å…¨é“¾è·¯æµ‹è¯•å®Œæˆ ==========", "SUCCESS")

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    report = {
        "test_time": datetime.now().isoformat(),
        "week_number": current_week,
        "downloaded_files": len(downloaded_files),
        "baseline_files_found": len(baseline_files) if 'baseline_files' in locals() else 0,
        "comparison_executed": 'comparison_result' in locals(),
        "standardized_file_generated": bool(comparison_result.get('standardized_file')) if 'comparison_result' in locals() else False,
        "detailed_scores_available": bool(comparison_result.get('detailed_scores')) if 'comparison_result' in locals() else False,
        "comprehensive_score_available": bool(comparison_result.get('comprehensive_score')) if 'comparison_result' in locals() else False,
        "ui_service_responsive": 'response' in locals() and response.status_code == 200 if 'response' in locals() else False
    }

    report_file = f"/root/projects/tencent-doc-manager/workflow_test_report_{timestamp}.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    log(f"æµ‹è¯•æŠ¥å‘Šä¿å­˜åˆ°: {report_file}", "SUCCESS")

    return report

if __name__ == "__main__":
    test_full_workflow()