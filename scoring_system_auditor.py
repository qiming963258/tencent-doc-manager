#!/usr/bin/env python3
"""
è¯„åˆ†ç¨‹åºåˆç†æ€§ä¸æ­£ç¡®æ€§å®¡æŸ¥å·¥å…·
å¯¹è…¾è®¯æ–‡æ¡£æ™ºèƒ½ç›‘æ§ç³»ç»Ÿçš„è¯„åˆ†ç®—æ³•è¿›è¡Œå…¨é¢å®¡æŸ¥
"""

import json
import re
from typing import Dict, List, Any, Tuple
from datetime import datetime

class ScoringSystemAuditor:
    """è¯„åˆ†ç³»ç»Ÿå®¡æŸ¥å™¨"""
    
    def __init__(self):
        self.audit_results = {}
        self.issues = []
        self.recommendations = []
        
    def audit_weight_configuration(self) -> Dict[str, Any]:
        """å®¡æŸ¥æƒé‡é…ç½®çš„åˆç†æ€§"""
        print("ğŸ” å®¡æŸ¥æƒé‡é…ç½®åˆç†æ€§...")
        print("=" * 50)
        
        # ä»æ–‡æ¡£ä¸­æå–çš„æƒé‡é…ç½®
        documented_weights = {
            'modificationCount': 0.3,     # ä¿®æ”¹æ¬¡æ•°æƒé‡
            'changeComplexity': 0.25,     # å˜æ›´å¤æ‚åº¦æƒé‡  
            'riskLevel': 0.35,            # é£é™©ç­‰çº§æƒé‡
            'timeRecency': 0.1            # æ—¶é—´æ–°è¿‘åº¦æƒé‡
        }
        
        # ä¸šåŠ¡ä¼˜å…ˆçº§ç†è®ºæƒé‡
        business_expected_weights = {
            'riskLevel': 0.4,             # é£é™©ç­‰çº§åº”è¯¥æ˜¯æœ€é‡è¦çš„
            'modificationCount': 0.25,    # ä¿®æ”¹æ¬¡æ•°æ¬¡é‡è¦
            'changeComplexity': 0.25,     # å˜æ›´å¤æ‚åº¦
            'timeRecency': 0.1           # æ—¶é—´æ–°è¿‘åº¦æœ€ä½
        }
        
        issues = []
        
        # 1. æƒé‡æ€»å’Œæ£€æŸ¥
        total_weight = sum(documented_weights.values())
        print(f"ğŸ“Š æƒé‡æ€»å’Œæ£€æŸ¥: {total_weight}")
        if abs(total_weight - 1.0) > 0.001:
            issues.append({
                "type": "weight_sum_error",
                "severity": "high",
                "message": f"æƒé‡æ€»å’Œåº”ä¸º1.0ï¼Œå®é™…ä¸º{total_weight}",
                "expected": 1.0,
                "actual": total_weight
            })
            print(f"âŒ æƒé‡æ€»å’Œé”™è¯¯: {total_weight} â‰  1.0")
        else:
            print(f"âœ… æƒé‡æ€»å’Œæ­£ç¡®: {total_weight}")
        
        # 2. ä¸šåŠ¡ä¼˜å…ˆçº§åŒ¹é…åº¦æ£€æŸ¥
        print(f"\nğŸ“‹ ä¸šåŠ¡ä¼˜å…ˆçº§åŒ¹é…åº¦åˆ†æ:")
        for factor, expected_weight in business_expected_weights.items():
            actual_weight = documented_weights.get(factor, 0)
            difference = abs(actual_weight - expected_weight)
            
            print(f"   {factor}:")
            print(f"     æœŸæœ›æƒé‡: {expected_weight}")
            print(f"     å®é™…æƒé‡: {actual_weight}")
            print(f"     å·®å¼‚: {difference:.3f}")
            
            if difference > 0.1:  # è¶…è¿‡10%çš„å·®å¼‚è®¤ä¸ºæ˜¯é—®é¢˜
                issues.append({
                    "type": "business_priority_mismatch",
                    "severity": "medium",
                    "factor": factor,
                    "message": f"{factor}æƒé‡ä¸ä¸šåŠ¡ä¼˜å…ˆçº§ä¸åŒ¹é…",
                    "expected": expected_weight,
                    "actual": actual_weight,
                    "difference": difference
                })
                print(f"     âš ï¸ æƒé‡ä¸åŒ¹é…ï¼ˆå·®å¼‚>{10}%ï¼‰")
            else:
                print(f"     âœ… æƒé‡åˆç†")
        
        # 3. æƒé‡æ•æ„Ÿæ€§åˆ†æ
        print(f"\nğŸ”¬ æƒé‡æ•æ„Ÿæ€§åˆ†æ:")
        sensitivity_results = self._analyze_weight_sensitivity(documented_weights)
        
        # 4. ç”Ÿæˆæƒé‡ä¼˜åŒ–å»ºè®®
        recommendations = self._generate_weight_recommendations(
            documented_weights, business_expected_weights, issues
        )
        
        result = {
            "documented_weights": documented_weights,
            "business_expected_weights": business_expected_weights,
            "total_weight": total_weight,
            "issues": issues,
            "sensitivity_analysis": sensitivity_results,
            "recommendations": recommendations,
            "audit_status": "completed"
        }
        
        self.audit_results["weight_configuration"] = result
        return result
    
    def audit_risk_classification(self) -> Dict[str, Any]:
        """å®¡æŸ¥é£é™©åˆ†çº§ä½“ç³»çš„ä¸€è‡´æ€§"""
        print(f"\nğŸ¯ å®¡æŸ¥é£é™©åˆ†çº§ä½“ç³»ä¸€è‡´æ€§...")
        print("=" * 50)
        
        # ä»é£é™©è§„åˆ™æ–‡æ¡£æå–çš„åˆ†ç±»
        documented_classification = {
            "L1": {
                "score_range": "0.9-1.0",
                "description": "çº¢è‰²è­¦æˆ’åŒº",
                "columns": [
                    "ä»»åŠ¡å‘èµ·æ—¶é—´", "é¢„è®¡å®Œæˆæ—¶é—´", "å¤ç›˜æ—¶é—´",
                    "æ¥æº", "åºå·", 
                    "ç›®æ ‡å¯¹é½", "å…³é”®KRå¯¹é½",
                    "å®Œæˆè¿›åº¦", "é‡è¦ç¨‹åº¦"
                ]
            },
            "L2": {
                "score_range": "0.3-0.8", 
                "description": "é»„è‰²ä¿æŠ¤åŒº",
                "columns": [
                    "å…·ä½“è®¡åˆ’å†…å®¹",
                    "é‚“æ€»æŒ‡å¯¼ç™»è®°",
                    "è´Ÿè´£äºº", "ååŠ©äºº", "ç›‘ç£äºº",
                    "å½¢æˆè®¡åˆ’æ¸…å•"
                ]
            },
            "L3": {
                "score_range": "0.1-0.3",
                "description": "ç»¿è‰²è‡ªç”±åŒº", 
                "columns": [
                    "åºå·", "ç¼–å·",  # æ³¨æ„ï¼šåºå·åœ¨è¿™é‡Œä¹Ÿå‡ºç°äº†
                    "å¤ç›˜æ—¶é—´",      # æ³¨æ„ï¼šå¤ç›˜æ—¶é—´åœ¨è¿™é‡Œä¹Ÿå‡ºç°äº†
                    "è¿›åº¦åˆ†æä¸æ€»ç»“", "å‘¨åº¦åˆ†ææ€»ç»“",
                    "å¯¹ä¸Šæ±‡æŠ¥", "åº”ç”¨æƒ…å†µ"
                ]
            }
        }
        
        # ä»æµ‹è¯•ä»£ç æå–çš„åˆ†ç±»
        test_code_classification = {
            "L1": ["æ¥æº", "ä»»åŠ¡å‘èµ·æ—¶é—´"],
            "L2": ["è´Ÿè´£äºº", "ååŠ©äºº", "å…·ä½“è®¡åˆ’å†…å®¹"],  # å¤§éƒ¨åˆ†ä¿®æ”¹ä¸ºL2
            "L3": ["åºå·"]
        }
        
        issues = []
        
        # 1. æ£€æŸ¥é‡å¤åˆ—å
        print("ğŸ” æ£€æŸ¥åˆ—åé‡å¤é—®é¢˜:")
        all_columns = {}
        for level, config in documented_classification.items():
            for column in config["columns"]:
                if column in all_columns:
                    issues.append({
                        "type": "duplicate_column",
                        "severity": "high",
                        "column": column,
                        "levels": [all_columns[column], level],
                        "message": f"åˆ—'{column}'åŒæ—¶å‡ºç°åœ¨{all_columns[column]}å’Œ{level}çº§åˆ«ä¸­"
                    })
                    print(f"âŒ é‡å¤åˆ—å: '{column}' å‡ºç°åœ¨ {all_columns[column]} å’Œ {level}")
                else:
                    all_columns[column] = level
        
        # 2. æ£€æŸ¥æµ‹è¯•ä»£ç ä¸æ–‡æ¡£çš„ä¸€è‡´æ€§
        print(f"\nğŸ”„ æ£€æŸ¥æµ‹è¯•ä»£ç ä¸æ–‡æ¡£ä¸€è‡´æ€§:")
        for level in ["L1", "L2", "L3"]:
            doc_columns = set(documented_classification[level]["columns"])
            test_columns = set(test_code_classification.get(level, []))
            
            print(f"   {level}çº§åˆ«:")
            print(f"     æ–‡æ¡£å®šä¹‰: {len(doc_columns)}ä¸ªåˆ—")
            print(f"     æµ‹è¯•ä»£ç : {len(test_columns)}ä¸ªåˆ—")
            
            missing_in_test = doc_columns - test_columns
            extra_in_test = test_columns - doc_columns
            
            if missing_in_test:
                print(f"     âš ï¸ æµ‹è¯•ä»£ç ç¼ºå¤±: {missing_in_test}")
                issues.append({
                    "type": "test_missing_columns",
                    "severity": "medium",
                    "level": level,
                    "missing_columns": list(missing_in_test),
                    "message": f"{level}çº§åˆ«æµ‹è¯•ä»£ç ç¼ºå¤±åˆ—å®šä¹‰"
                })
            
            if extra_in_test:
                print(f"     âš ï¸ æµ‹è¯•ä»£ç å¤šä½™: {extra_in_test}")
                issues.append({
                    "type": "test_extra_columns", 
                    "severity": "low",
                    "level": level,
                    "extra_columns": list(extra_in_test),
                    "message": f"{level}çº§åˆ«æµ‹è¯•ä»£ç æœ‰å¤šä½™åˆ—å®šä¹‰"
                })
            
            if not missing_in_test and not extra_in_test:
                print(f"     âœ… æ–‡æ¡£ä¸æµ‹è¯•ä»£ç ä¸€è‡´")
        
        # 3. æ£€æŸ¥åˆ†æ•°èŒƒå›´é‡å 
        print(f"\nğŸ“Š æ£€æŸ¥åˆ†æ•°èŒƒå›´é‡å :")
        score_ranges = {}
        for level, config in documented_classification.items():
            range_str = config["score_range"]
            min_score, max_score = map(float, range_str.split('-'))
            score_ranges[level] = (min_score, max_score)
            print(f"   {level}: {min_score}-{max_score}")
        
        # æ£€æŸ¥èŒƒå›´é‡å 
        overlap_found = False
        for level1, (min1, max1) in score_ranges.items():
            for level2, (min2, max2) in score_ranges.items():
                if level1 != level2:
                    if not (max1 < min2 or max2 < min1):  # æœ‰é‡å 
                        issues.append({
                            "type": "score_range_overlap",
                            "severity": "high", 
                            "levels": [level1, level2],
                            "ranges": [f"{min1}-{max1}", f"{min2}-{max2}"],
                            "message": f"{level1}å’Œ{level2}çš„åˆ†æ•°èŒƒå›´æœ‰é‡å "
                        })
                        print(f"     âŒ {level1}({min1}-{max1}) ä¸ {level2}({min2}-{max2}) é‡å ")
                        overlap_found = True
        
        if not overlap_found:
            print(f"     âœ… åˆ†æ•°èŒƒå›´æ— é‡å ")
        
        result = {
            "documented_classification": documented_classification,
            "test_code_classification": test_code_classification,
            "issues": issues,
            "total_columns": len(all_columns),
            "duplicate_columns": len([i for i in issues if i["type"] == "duplicate_column"]),
            "audit_status": "completed"
        }
        
        self.audit_results["risk_classification"] = result
        return result
    
    def _analyze_weight_sensitivity(self, weights: Dict[str, float]) -> Dict[str, Any]:
        """åˆ†ææƒé‡æ•æ„Ÿæ€§"""
        sensitivity = {}
        
        # è®¡ç®—æ¯ä¸ªæƒé‡å˜åŒ–10%å¯¹æ€»åˆ†çš„å½±å“
        for factor, weight in weights.items():
            # æ¨¡æ‹Ÿæƒé‡å˜åŒ–çš„å½±å“
            original_score = self._calculate_mock_score(weights, 1.0, 1.0, 1.0, 1.0)
            
            # å¢åŠ 10%æƒé‡
            modified_weights = weights.copy()
            modified_weights[factor] = weight * 1.1
            
            # é‡æ–°å½’ä¸€åŒ–
            total = sum(modified_weights.values())
            for k in modified_weights:
                modified_weights[k] /= total
            
            modified_score = self._calculate_mock_score(
                modified_weights, 1.0, 1.0, 1.0, 1.0
            )
            
            sensitivity[factor] = {
                "weight_change": 0.1,
                "score_impact": abs(modified_score - original_score),
                "sensitivity_ratio": abs(modified_score - original_score) / 0.1
            }
        
        return sensitivity
    
    def _calculate_mock_score(self, weights: Dict[str, float], 
                            mod_count: float, complexity: float, 
                            risk: float, recency: float) -> float:
        """è®¡ç®—æ¨¡æ‹Ÿåˆ†æ•°"""
        return (weights['modificationCount'] * mod_count +
                weights['changeComplexity'] * complexity +
                weights['riskLevel'] * risk +
                weights['timeRecency'] * recency)
    
    def _generate_weight_recommendations(self, current: Dict[str, float], 
                                       expected: Dict[str, float], 
                                       issues: List[Dict]) -> List[str]:
        """ç”Ÿæˆæƒé‡ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        if any(i["type"] == "weight_sum_error" for i in issues):
            recommendations.append("å°†æƒé‡æ€»å’Œæ ‡å‡†åŒ–ä¸º1.0")
        
        for factor, expected_weight in expected.items():
            current_weight = current.get(factor, 0)
            if abs(current_weight - expected_weight) > 0.05:
                recommendations.append(
                    f"è°ƒæ•´{factor}æƒé‡ä»{current_weight}åˆ°{expected_weight}ï¼Œæ›´ç¬¦åˆä¸šåŠ¡ä¼˜å…ˆçº§"
                )
        
        if not recommendations:
            recommendations.append("å½“å‰æƒé‡é…ç½®åŸºæœ¬åˆç†ï¼Œæ— éœ€é‡å¤§è°ƒæ•´")
        
        return recommendations
    
    def generate_audit_report(self) -> str:
        """ç”Ÿæˆå®Œæ•´çš„å®¡æŸ¥æŠ¥å‘Š"""
        report = []
        report.append("# è¯„åˆ†ç¨‹åºå®¡æŸ¥æŠ¥å‘Š")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # æƒé‡é…ç½®å®¡æŸ¥ç»“æœ
        if "weight_configuration" in self.audit_results:
            weight_result = self.audit_results["weight_configuration"]
            report.append("## ğŸ‹ï¸ æƒé‡é…ç½®å®¡æŸ¥")
            report.append("")
            
            # å½“å‰æƒé‡
            report.append("### å½“å‰æƒé‡é…ç½®")
            for factor, weight in weight_result["documented_weights"].items():
                report.append(f"- **{factor}**: {weight} ({weight*100:.1f}%)")
            report.append("")
            
            # é—®é¢˜æ±‡æ€»
            issues = weight_result["issues"]
            if issues:
                report.append("### å‘ç°çš„é—®é¢˜")
                for issue in issues:
                    severity_icon = "ğŸ”´" if issue["severity"] == "high" else "ğŸŸ¡" if issue["severity"] == "medium" else "ğŸŸ¢"
                    report.append(f"- {severity_icon} **{issue['type']}**: {issue['message']}")
                report.append("")
            
            # å»ºè®®
            report.append("### ä¼˜åŒ–å»ºè®®")
            for rec in weight_result["recommendations"]:
                report.append(f"- {rec}")
            report.append("")
        
        # é£é™©åˆ†çº§å®¡æŸ¥ç»“æœ
        if "risk_classification" in self.audit_results:
            risk_result = self.audit_results["risk_classification"]
            report.append("## ğŸ¯ é£é™©åˆ†çº§ä½“ç³»å®¡æŸ¥")
            report.append("")
            
            # é—®é¢˜æ±‡æ€»
            issues = risk_result["issues"]
            if issues:
                report.append("### å‘ç°çš„é—®é¢˜")
                high_issues = [i for i in issues if i["severity"] == "high"]
                medium_issues = [i for i in issues if i["severity"] == "medium"]
                low_issues = [i for i in issues if i["severity"] == "low"]
                
                if high_issues:
                    report.append("#### ğŸ”´ é«˜ä¼˜å…ˆçº§é—®é¢˜")
                    for issue in high_issues:
                        report.append(f"- **{issue['type']}**: {issue['message']}")
                    report.append("")
                
                if medium_issues:
                    report.append("#### ğŸŸ¡ ä¸­ä¼˜å…ˆçº§é—®é¢˜")
                    for issue in medium_issues:
                        report.append(f"- **{issue['type']}**: {issue['message']}")
                    report.append("")
                
                if low_issues:
                    report.append("#### ğŸŸ¢ ä½ä¼˜å…ˆçº§é—®é¢˜")
                    for issue in low_issues:
                        report.append(f"- **{issue['type']}**: {issue['message']}")
                    report.append("")
            else:
                report.append("### âœ… æœªå‘ç°é‡å¤§é—®é¢˜")
                report.append("")
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•°"""
    auditor = ScoringSystemAuditor()
    
    print("ğŸš€ å¼€å§‹è¯„åˆ†ç¨‹åºåˆç†æ€§ä¸æ­£ç¡®æ€§å®¡æŸ¥")
    print("=" * 60)
    
    # å®¡æŸ¥æƒé‡é…ç½®
    weight_results = auditor.audit_weight_configuration()
    
    # å®¡æŸ¥é£é™©åˆ†çº§
    risk_results = auditor.audit_risk_classification()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = auditor.generate_audit_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_filename = f"scoring_system_audit_report_{int(datetime.now().timestamp())}.md"
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“Š å®¡æŸ¥å®Œæˆ!")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_filename}")
    
    # æ±‡æ€»ç»Ÿè®¡
    total_issues = len(weight_results.get("issues", [])) + len(risk_results.get("issues", []))
    high_issues = sum(1 for issue in weight_results.get("issues", []) + risk_results.get("issues", [])
                     if issue.get("severity") == "high")
    
    print(f"\nğŸ¯ å®¡æŸ¥æ±‡æ€»:")
    print(f"   å‘ç°é—®é¢˜æ€»æ•°: {total_issues}")
    print(f"   é«˜ä¼˜å…ˆçº§é—®é¢˜: {high_issues}")
    print(f"   å®¡æŸ¥çŠ¶æ€: {'âš ï¸ éœ€è¦ä¿®å¤' if high_issues > 0 else 'âœ… åŸºæœ¬åˆæ ¼'}")
    
    return auditor

if __name__ == "__main__":
    auditor = main()