#!/usr/bin/env python3
"""
å‡çº§ç‰ˆUIè¿æ¥æ€§ç®¡ç†å™¨
é›†æˆæ™ºèƒ½æ˜ å°„ç®—æ³•ï¼Œå»ºç«‹çœŸå®æ•°æ®æº
"""

import sys
import os
sys.path.append('/root/projects/tencent-doc-manager/production/core_modules')
sys.path.append('/root/projects/tencent-doc-manager')

import json
import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from csv_security_manager import CSVSecurityManager
from cookie_manager import get_cookie_manager
from intelligent_mapping_algorithm import IntelligentMappingAlgorithm

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class UpgradedUIConnectivityManager:
    """å‡çº§ç‰ˆUIè¿æ¥æ€§ç®¡ç†å™¨"""
    
    def __init__(self, base_dir: str = None):
        """åˆå§‹åŒ–è¿æ¥ç®¡ç†å™¨"""
        self.base_dir = base_dir or "/root/projects/tencent-doc-manager"
        self.ui_data_dir = os.path.join(self.base_dir, "ui_data")
        self.config_dir = os.path.join(self.base_dir, "config")
        
        # åˆ›å»ºç›®å½•
        for directory in [self.ui_data_dir, self.config_dir]:
            os.makedirs(directory, exist_ok=True)
        
        # åˆå§‹åŒ–å­ç³»ç»Ÿ
        self.csv_manager = CSVSecurityManager(self.base_dir)
        self.cookie_manager = get_cookie_manager()
        self.mapping_algorithm = IntelligentMappingAlgorithm()  # æ–°å¢æ™ºèƒ½æ˜ å°„
        
        logger.info("âœ… å‡çº§ç‰ˆUIè¿æ¥æ€§ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def process_real_csv_comparison(self, comparison_file: str) -> Dict[str, Any]:
        """å¤„ç†çœŸå®çš„CSVå¯¹æ¯”æ•°æ®"""
        
        try:
            logger.info(f"ğŸ”— å¤„ç†çœŸå®CSVå¯¹æ¯”: {comparison_file}")
            
            # è¯»å–å¯¹æ¯”ç»“æœ
            with open(comparison_file, 'r', encoding='utf-8') as f:
                comparison_data = json.load(f)
            
            differences = comparison_data.get('differences', [])
            column_mapping = comparison_data.get('file_info', {}).get('metadata', {}).get('column_mapping', {})
            actual_columns = list(column_mapping.get('mapping', {}).keys())
            
            logger.info(f"   å‘ç° {len(differences)} ä¸ªå˜æ›´ï¼Œ{len(actual_columns)} ä¸ªåˆ—")
            
            # ä½¿ç”¨æ™ºèƒ½æ˜ å°„ç®—æ³•è½¬æ¢æ•°æ®
            mapping_result = self.mapping_algorithm.process_csv_to_heatmap(
                differences, actual_columns
            )
            
            # å¢å¼ºç»“æœä¿¡æ¯
            mapping_result.update({
                "source_file": comparison_file,
                "original_comparison_summary": comparison_data.get('comparison_summary', {}),
                "data_integrity_verified": True
            })
            
            return mapping_result
            
        except Exception as e:
            logger.error(f"å¤„ç†CSVå¯¹æ¯”æ•°æ®å¤±è´¥: {e}")
            raise
    
    async def generate_real_heatmap_data(self, source_type: str = "latest") -> Dict[str, Any]:
        """ç”ŸæˆçœŸå®çš„çƒ­åŠ›å›¾æ•°æ®"""
        
        try:
            logger.info(f"ğŸ¯ ç”ŸæˆçœŸå®çƒ­åŠ›å›¾æ•°æ® (source: {source_type})")
            
            # æŸ¥æ‰¾æœ€æ–°çš„å¯¹æ¯”ç»“æœæ–‡ä»¶
            comparison_file = self._find_latest_comparison_file(source_type)
            
            if not comparison_file:
                raise Exception(f"æœªæ‰¾åˆ°{source_type}ç±»å‹çš„å¯¹æ¯”ç»“æœæ–‡ä»¶")
            
            # å¤„ç†å¯¹æ¯”æ•°æ®
            heatmap_result = await self.process_real_csv_comparison(comparison_file)
            
            # ä¿å­˜åˆ°æœåŠ¡å™¨æ•°æ®æ–‡ä»¶
            output_files = {
                'real_time_heatmap': '/root/projects/tencent-doc-manager/production/servers/real_time_heatmap.json',
                'current_heatmap_data': '/root/projects/tencent-doc-manager/production/servers/current_heatmap_data.json'
            }
            
            for file_type, file_path in output_files.items():
                # æ ¹æ®æ–‡ä»¶ç±»å‹è°ƒæ•´æ•°æ®æ ¼å¼
                if file_type == 'real_time_heatmap':
                    save_data = {
                        'heatmap_data': heatmap_result['heatmap_data'],
                        'generation_time': heatmap_result['timestamp'],
                        'data_source': 'intelligent_mapping_real_data_v1',
                        'changes_applied': heatmap_result['processing_info']['source_differences'],
                        'algorithm': 'intelligent_mapping_v1.0',
                        'matrix_size': heatmap_result['matrix_size'],
                        'mapping_info': {
                            'column_coverage': heatmap_result['column_mapping']['coverage_rate'],
                            'row_utilization': heatmap_result['processing_info']['row_utilization'],
                            'source_file': heatmap_result['source_file']
                        }
                    }
                else:
                    save_data = {
                        'success': True,
                        'timestamp': heatmap_result['timestamp'],
                        'data': {
                            'heatmap_data': heatmap_result['heatmap_data'],
                            'generation_time': heatmap_result['timestamp'],
                            'data_source': 'INTELLIGENT_MAPPING_REAL_DATA_V1',
                            'processing_info': {
                                'real_test_applied': True,
                                'changes_applied': heatmap_result['processing_info']['source_differences'],
                                'matrix_generation_algorithm': 'intelligent_mapping_v1.0',
                                'column_mapping': heatmap_result['column_mapping'],
                                'row_mapping': heatmap_result['row_mapping'],
                                'data_integrity_verified': True
                            },
                            'statistics': {
                                'total_changes_detected': heatmap_result['processing_info']['source_differences'],
                                'column_coverage_rate': heatmap_result['column_mapping']['coverage_rate'],
                                'row_utilization_rate': heatmap_result['processing_info']['row_utilization'],
                                'last_update': heatmap_result['timestamp'],
                                'data_freshness': 'REAL_TIME'
                            }
                        }
                    }
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(save_data, f, indent=2, ensure_ascii=False)
                
                logger.info(f"   âœ… ä¿å­˜åˆ°: {Path(file_path).name}")
            
            # è§¦å‘UIåˆ·æ–°
            await self._trigger_ui_refresh()
            
            return heatmap_result
            
        except Exception as e:
            logger.error(f"ç”ŸæˆçœŸå®çƒ­åŠ›å›¾æ•°æ®å¤±è´¥: {e}")
            raise
    
    def _find_latest_comparison_file(self, source_type: str) -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°çš„å¯¹æ¯”ç»“æœæ–‡ä»¶"""
        
        results_dir = os.path.join(self.base_dir, "csv_security_results")
        
        if not os.path.exists(results_dir):
            return None
        
        # æ ¹æ®source_typeé€‰æ‹©æ–‡ä»¶
        if source_type == "real_test":
            pattern = "real_test_comparison.json"
        elif source_type == "latest":
            # æ‰¾æœ€æ–°ä¿®æ”¹çš„æ–‡ä»¶
            comparison_files = [
                f for f in os.listdir(results_dir) 
                if f.endswith('_comparison.json')
            ]
            
            if not comparison_files:
                return None
            
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            latest_file = max(
                comparison_files,
                key=lambda f: os.path.getmtime(os.path.join(results_dir, f))
            )
            pattern = latest_file
        else:
            pattern = f"{source_type}_comparison.json"
        
        file_path = os.path.join(results_dir, pattern)
        return file_path if os.path.exists(file_path) else None
    
    async def _trigger_ui_refresh(self) -> Dict[str, Any]:
        """è§¦å‘UIåˆ·æ–°"""
        
        try:
            import aiohttp
            
            # å°è¯•é€šçŸ¥çƒ­åŠ›å›¾æœåŠ¡å™¨åˆ·æ–°
            update_payload = {
                'type': 'intelligent_mapping_update',
                'timestamp': datetime.now().isoformat(),
                'algorithm_version': 'intelligent_mapping_v1.0'
            }
            
            async with aiohttp.ClientSession() as session:
                try:
                    async with session.post('http://localhost:8089/api/update', 
                                          json=update_payload, timeout=3) as response:
                        if response.status == 200:
                            result = await response.json()
                            logger.info("âœ… UIåˆ·æ–°é€šçŸ¥å‘é€æˆåŠŸ")
                            return {'success': True, 'response': result}
                        else:
                            logger.warning(f"UIåˆ·æ–°å“åº”: HTTP {response.status}")
                except Exception as e:
                    logger.info(f"UIæœåŠ¡å™¨å¯èƒ½æœªå¯åŠ¨: {e}")
            
            return {'success': True, 'method': 'file_update_only'}
            
        except Exception as e:
            logger.warning(f"UIåˆ·æ–°é€šçŸ¥å¤±è´¥: {e}")
            return {'success': False, 'error': str(e)}
    
    async def validate_data_integrity(self) -> Dict[str, Any]:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        
        validation_report = {
            'timestamp': datetime.now().isoformat(),
            'validation_type': 'data_integrity_check',
            'results': {}
        }
        
        try:
            # æ£€æŸ¥å¯¹æ¯”ç»“æœæ–‡ä»¶
            comparison_file = self._find_latest_comparison_file("latest")
            if comparison_file:
                with open(comparison_file, 'r', encoding='utf-8') as f:
                    comparison_data = json.load(f)
                
                validation_report['results']['csv_comparison'] = {
                    'file_found': True,
                    'differences_count': len(comparison_data.get('differences', [])),
                    'source_file': comparison_file
                }
            else:
                validation_report['results']['csv_comparison'] = {
                    'file_found': False,
                    'error': 'æœªæ‰¾åˆ°å¯¹æ¯”ç»“æœæ–‡ä»¶'
                }
            
            # æ£€æŸ¥çƒ­åŠ›å›¾æ•°æ®æ–‡ä»¶
            heatmap_files = [
                '/root/projects/tencent-doc-manager/production/servers/real_time_heatmap.json',
                '/root/projects/tencent-doc-manager/production/servers/current_heatmap_data.json'
            ]
            
            for heatmap_file in heatmap_files:
                file_name = Path(heatmap_file).name
                
                if os.path.exists(heatmap_file):
                    with open(heatmap_file, 'r', encoding='utf-8') as f:
                        heatmap_data = json.load(f)
                    
                    # æ£€æŸ¥æ•°æ®æºæ ‡è¯†
                    data_source = heatmap_data.get('data_source', 'unknown')
                    is_intelligent = 'intelligent_mapping' in data_source.lower()
                    
                    validation_report['results'][file_name] = {
                        'file_found': True,
                        'using_intelligent_mapping': is_intelligent,
                        'data_source': data_source,
                        'changes_applied': heatmap_data.get('changes_applied', 0)
                    }
                else:
                    validation_report['results'][file_name] = {
                        'file_found': False,
                        'error': 'æ–‡ä»¶ä¸å­˜åœ¨'
                    }
            
            # è®¡ç®—æ•´ä½“å®Œæ•´æ€§åˆ†æ•°
            total_checks = len(validation_report['results'])
            passed_checks = sum(1 for r in validation_report['results'].values() if r.get('file_found', False))
            intelligent_checks = sum(1 for r in validation_report['results'].values() 
                                   if r.get('using_intelligent_mapping', False))
            
            validation_report['summary'] = {
                'overall_integrity': passed_checks / total_checks,
                'intelligent_mapping_adoption': intelligent_checks / total_checks,
                'recommendation': 'good' if passed_checks >= total_checks * 0.8 else 'needs_attention'
            }
            
            return validation_report
            
        except Exception as e:
            validation_report['error'] = str(e)
            return validation_report

async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå‡çº§ç‰ˆç³»ç»Ÿä½¿ç”¨"""
    
    print("ğŸš€ å‡çº§ç‰ˆUIè¿æ¥æ€§ç®¡ç†å™¨æµ‹è¯•...")
    
    manager = UpgradedUIConnectivityManager()
    
    # ç”ŸæˆçœŸå®çƒ­åŠ›å›¾æ•°æ®
    print("\n1. ç”ŸæˆçœŸå®çƒ­åŠ›å›¾æ•°æ®:")
    try:
        heatmap_result = await manager.generate_real_heatmap_data("latest")
        print(f"   âœ… æˆåŠŸç”Ÿæˆï¼Œæ•°æ®æº: {heatmap_result['source_file']}")
        print(f"   ğŸ“Š å¤„ç†äº† {heatmap_result['processing_info']['source_differences']} ä¸ªå˜æ›´")
        print(f"   ğŸ¯ åˆ—è¦†ç›–ç‡: {heatmap_result['column_mapping']['coverage_rate']:.2%}")
        print(f"   ğŸ“ˆ è¡Œä½¿ç”¨ç‡: {heatmap_result['processing_info']['row_utilization']:.2%}")
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    print("\n2. éªŒè¯æ•°æ®å®Œæ•´æ€§:")
    validation_result = await manager.validate_data_integrity()
    print(f"   ğŸ“Š æ•´ä½“å®Œæ•´æ€§: {validation_result['summary']['overall_integrity']:.2%}")
    print(f"   ğŸ§  æ™ºèƒ½æ˜ å°„é‡‡ç”¨ç‡: {validation_result['summary']['intelligent_mapping_adoption']:.2%}")
    print(f"   ğŸ’¡ å»ºè®®: {validation_result['summary']['recommendation']}")
    
    # ä¿å­˜å®Œæ•´éªŒè¯æŠ¥å‘Š
    report_file = "/root/projects/tencent-doc-manager/data_integrity_validation_report.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(validation_result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ éªŒè¯æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
    print("ğŸ‰ å‡çº§ç‰ˆç³»ç»Ÿæµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    asyncio.run(main())