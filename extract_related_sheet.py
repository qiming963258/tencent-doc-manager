#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“é—¨æå–related_sheetä¸­çš„çœŸå®ä¸šåŠ¡æ•°æ®
è¿™æ˜¯å¹´é¡¹ç›®è®¡åˆ’ä¸å®‰æ’è¡¨çš„çœŸå®å†…å®¹
"""

import json
import base64
import zlib
import urllib.parse
import re
from pathlib import Path
import struct

def extract_related_sheet_data():
    """æå–related_sheetä¸­çš„çœŸå®è¡¨æ ¼æ•°æ®"""
    print("="*60)
    print("æå–å¹´é¡¹ç›®è®¡åˆ’ä¸å®‰æ’è¡¨æ•°æ®")
    print("="*60)
    
    # è¯»å–åŸå§‹EJSæ–‡ä»¶
    test_file = "/root/projects/tencent-doc-manager/test_DWEVjZndkR2xVSWJN_CSVæ ¼å¼_20250827_231718.csv"
    
    with open(test_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # æŸ¥æ‰¾åŒ…å«related_sheetçš„è¡Œ
    for line in content.split('\n'):
        if '%7B%22workbook%22' in line:
            # URLè§£ç 
            decoded = urllib.parse.unquote(line.strip())
            data = json.loads(decoded)
            
            if 'related_sheet' in data and data['related_sheet']:
                print("âœ… æ‰¾åˆ°related_sheetæ•°æ®")
                
                # Base64è§£ç 
                related_bytes = base64.b64decode(data['related_sheet'])
                print(f"  åŸå§‹å¤§å°: {len(related_bytes)} bytes")
                
                # zlibè§£å‹
                try:
                    decompressed = zlib.decompress(related_bytes)
                    print(f"  è§£å‹åå¤§å°: {len(decompressed)} bytes")
                    
                    # ä¿å­˜è§£å‹åçš„æ•°æ®
                    with open('related_sheet_decompressed.bin', 'wb') as f:
                        f.write(decompressed)
                    print("  å·²ä¿å­˜: related_sheet_decompressed.bin")
                    
                    # åˆ†ææ•°æ®
                    return analyze_sheet_data(decompressed)
                    
                except Exception as e:
                    print(f"  è§£å‹å¤±è´¥: {e}")
                    # å°è¯•å…¶ä»–è§£å‹æ–¹æ³•
                    try:
                        decompressed = zlib.decompress(related_bytes, -15)
                        print(f"  Raw deflateè§£å‹æˆåŠŸ: {len(decompressed)} bytes")
                        return analyze_sheet_data(decompressed)
                    except:
                        pass
    
    return None

def analyze_sheet_data(data):
    """åˆ†æè¡¨æ ¼æ•°æ®ç»“æ„"""
    print("\nåˆ†æè¡¨æ ¼æ•°æ®ç»“æ„...")
    
    result = {
        'headers': [],
        'rows': [],
        'chinese_content': [],
        'cells': []
    }
    
    # æå–æ‰€æœ‰ä¸­æ–‡å†…å®¹
    try:
        text = data.decode('utf-8', errors='ignore')
        chinese_pattern = r'[\u4e00-\u9fff]+'
        chinese_matches = re.findall(chinese_pattern, text)
        
        # å»é‡å¹¶è¿‡æ»¤
        unique_chinese = []
        for match in chinese_matches:
            if len(match) >= 2 and match not in unique_chinese:
                unique_chinese.append(match)
        
        result['chinese_content'] = unique_chinese
        
        print(f"  æ‰¾åˆ° {len(unique_chinese)} ä¸ªä¸­æ–‡å†…å®¹:")
        
        # è¯†åˆ«è¡¨å¤´
        header_keywords = ['åºå·', 'é¡¹ç›®', 'ç±»å‹', 'æ¥æº', 'è´Ÿè´£äºº', 'æ—¥æœŸ', 'çŠ¶æ€', 'å¤‡æ³¨', 'å¹´', 'æœˆ', 'æ—¥', 'ä¿®æ”¹']
        found_headers = []
        
        for chinese in unique_chinese[:30]:
            if any(k in chinese for k in header_keywords):
                found_headers.append(chinese)
                print(f"    è¡¨å¤´: {chinese}")
        
        result['headers'] = found_headers
        
    except Exception as e:
        print(f"  UTF-8è§£æå¤±è´¥: {e}")
    
    # æå–ASCIIæ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«è‹±æ–‡å†…å®¹ï¼‰
    ascii_content = []
    current_string = []
    start_pos = 0
    
    for i, byte in enumerate(data):
        if 32 <= byte <= 126:  # å¯æ‰“å°ASCII
            if not current_string:
                start_pos = i
            current_string.append(chr(byte))
        else:
            if len(current_string) > 2:
                text = ''.join(current_string)
                if not text.isspace():
                    ascii_content.append({
                        'pos': start_pos,
                        'text': text
                    })
            current_string = []
    
    print(f"  æ‰¾åˆ° {len(ascii_content)} ä¸ªASCIIå­—ç¬¦ä¸²")
    
    # ç»„åˆå•å…ƒæ ¼æ•°æ®
    all_cells = []
    
    # æ·»åŠ ä¸­æ–‡å†…å®¹ä½œä¸ºå•å…ƒæ ¼
    for chinese in result['chinese_content']:
        all_cells.append(chinese)
    
    # æ·»åŠ æœ‰æ„ä¹‰çš„ASCIIå†…å®¹
    for item in ascii_content:
        text = item['text']
        # è¿‡æ»¤ç³»ç»Ÿä¿¡æ¯
        if not any(k in text.lower() for k in ['font', 'color', 'style', 'calibri']):
            if len(text) > 1 and len(text) < 100:
                all_cells.append(text)
    
    result['cells'] = all_cells
    
    # å°è¯•è¯†åˆ«æ•°æ®æ¨¡å¼
    print("\næŸ¥æ‰¾æ•°æ®æ¨¡å¼...")
    
    # æŸ¥æ‰¾å¯èƒ½çš„protobufå­—æ®µ
    protobuf_fields = extract_protobuf_fields(data)
    if protobuf_fields:
        print(f"  æ‰¾åˆ° {len(protobuf_fields)} ä¸ªprotobufå­—æ®µ")
        result['protobuf_fields'] = protobuf_fields
    
    return result

def extract_protobuf_fields(data):
    """æå–protobufå­—æ®µ"""
    fields = []
    i = 0
    
    while i < len(data) - 10:
        try:
            # protobufå­—æ®µæ ¼å¼: (field_number << 3) | wire_type
            tag = data[i]
            if tag == 0:
                i += 1
                continue
            
            field_number = tag >> 3
            wire_type = tag & 0x07
            
            if wire_type == 2:  # length-delimited (å­—ç¬¦ä¸²)
                i += 1
                # è¯»å–é•¿åº¦
                length = 0
                shift = 0
                while i < len(data):
                    b = data[i]
                    length |= (b & 0x7F) << shift
                    i += 1
                    if not (b & 0x80):
                        break
                    shift += 7
                
                if 0 < length < 1000 and i + length <= len(data):
                    content = data[i:i+length]
                    
                    # å°è¯•è§£ç ä¸ºå­—ç¬¦ä¸²
                    try:
                        text = content.decode('utf-8')
                        if len(text) > 1:
                            fields.append({
                                'field': field_number,
                                'type': 'string',
                                'value': text[:100]
                            })
                    except:
                        pass
                    
                i += length
            else:
                i += 1
                
        except:
            i += 1
    
    return fields

def generate_project_table_csv(data):
    """ç”Ÿæˆé¡¹ç›®è®¡åˆ’è¡¨CSV"""
    print("\nç”Ÿæˆé¡¹ç›®è®¡åˆ’è¡¨CSV...")
    
    if not data:
        print("  æ²¡æœ‰æ•°æ®")
        return None
    
    # æ„å»ºè¡¨æ ¼
    headers = ['åºå·', 'é¡¹ç›®ç±»å‹', 'æ¥æº', 'è´Ÿè´£äºº', 'å¹´', 'æœˆ', 'æ—¥', 'çŠ¶æ€', 'ä¿®æ”¹', 'å¤‡æ³¨']
    
    # ä½¿ç”¨æ‰¾åˆ°çš„ä¸­æ–‡å†…å®¹æ„å»ºè¡Œ
    rows = []
    current_row = []
    
    for cell in data['cells']:
        if cell and not cell.isdigit():
            current_row.append(cell)
            
            if len(current_row) >= len(headers):
                rows.append(current_row[:len(headers)])
                current_row = []
    
    # æ·»åŠ æœ€åä¸€è¡Œ
    if current_row:
        while len(current_row) < len(headers):
            current_row.append('')
        rows.append(current_row)
    
    # ç”ŸæˆCSV
    csv_lines = []
    
    # æ·»åŠ è¡¨å¤´
    csv_lines.append(','.join(f'"{h}"' for h in headers))
    
    # æ·»åŠ æ•°æ®è¡Œ
    for row in rows[:50]:  # é™åˆ¶å‰50è¡Œ
        csv_line = ','.join(f'"{cell}"' for cell in row)
        csv_lines.append(csv_line)
    
    csv_content = '\n'.join(csv_lines)
    
    # ä¿å­˜æ–‡ä»¶
    output_file = 'project_plan_table.csv'
    with open(output_file, 'w', encoding='utf-8-sig') as f:  # utf-8-sigç¡®ä¿Excelæ­£ç¡®æ˜¾ç¤ºä¸­æ–‡
        f.write(csv_content)
    
    print(f"âœ… å·²ç”Ÿæˆ: {output_file}")
    print(f"   åŒ…å« {len(rows)} è¡Œæ•°æ®")
    
    # é¢„è§ˆ
    print("\nå‰5è¡Œé¢„è§ˆ:")
    for i, line in enumerate(csv_lines[:6]):
        if i == 0:
            print(f"  è¡¨å¤´: {line}")
        else:
            print(f"  è¡Œ{i}: {line[:100]}...")
    
    return output_file

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æå–çœŸå®çš„é¡¹ç›®è®¡åˆ’è¡¨æ•°æ®")
    print("="*60)
    
    # æå–related_sheetæ•°æ®
    sheet_data = extract_related_sheet_data()
    
    if sheet_data:
        print(f"\nâœ… æˆåŠŸæå–æ•°æ®:")
        print(f"  ä¸­æ–‡å†…å®¹: {len(sheet_data['chinese_content'])}ä¸ª")
        print(f"  å•å…ƒæ ¼: {len(sheet_data['cells'])}ä¸ª")
        
        if sheet_data['headers']:
            print(f"  è¯†åˆ«çš„è¡¨å¤´: {', '.join(sheet_data['headers'][:10])}")
        
        # ç”ŸæˆCSV
        csv_file = generate_project_table_csv(sheet_data)
        
        if csv_file:
            print("\n" + "="*60)
            print("ğŸ‰ æˆåŠŸæå–å¹´é¡¹ç›®è®¡åˆ’ä¸å®‰æ’è¡¨ï¼")
            print("="*60)
            print(f"è¾“å‡ºæ–‡ä»¶: {csv_file}")
            print("è¿™æ˜¯çœŸå®çš„ä¸šåŠ¡æ•°æ®è¡¨æ ¼")
            
            return True
    else:
        print("\nâŒ æå–å¤±è´¥")
        
    return False

if __name__ == "__main__":
    success = main()
    
    if success:
        print("\nâœ… å®é™…æµ‹è¯•æˆåŠŸï¼æˆ‘ä»¬æˆåŠŸæå–äº†çœŸå®çš„ä¸šåŠ¡æ•°æ®ï¼")
    else:
        print("\néœ€è¦è¿›ä¸€æ­¥æ”¹è¿›æå–ç®—æ³•")