#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨æœ€æ–°æœ‰æ•ˆCookieçš„ä¸‹è½½å™¨
"""

import asyncio
from pathlib import Path
from playwright.async_api import async_playwright

class UpdatedDownloader:
    def __init__(self):
        self.download_dir = Path("./downloads").resolve()
        self.download_dir.mkdir(exist_ok=True)
        
        # ğŸ”¥ ä½¿ç”¨ä½ æä¾›çš„æœ€æ–°æœ‰æ•ˆCookie
        self.cookie_string = "fingerprint=e979148633684123810b8625c5e988b082; low_login_enable=1; RK=MA/9rNDTsw; ptcz=af0b3d4029bba7dffa892366ad18dd8f4ff5aa12bc499e7dd00e3247fed6cbba; DOC_QQ_APPID=101458937; polish_tooltip=true; pgv_pvid=1277470832102926; _qimei_uuid42=1960c092216100a0a13d2af50c259fa2bbe9316a3d; _qimei_h38=8213826aa13d2af50c259fa202000009a1960c; _qimei_fingerprint=cb237a82a78862fdd0ebd18db76ab2f8; adtag=s_pcqq_liaotianjilu; _clck=3990794656|1|fwy|0; loginTime=1754640043257; DOC_QQ_OPENID=138EA9B807B6C2DCFE96C5B1A650E932; traceid=a473487816; TOK=a473487816963a48; hashkey=a4734878; dark_mode_setting=system; optimal_cdn_domain=docs.qq.com; ES2=f88c0411768984b9; _qpsvr_localtk=0.5895351222297797; uid=144115414584628119; uid_key=EOP1mMQHGiwvK2JLYUhONDRwZGVVWllDbjI4SzdDQnE0TW8vWGRIaWlmalV3SlorUDZJPSKBAmV5SmhiR2NpT2lKQlEwTkJURWNpTENKMGVYQWlPaUpLVjFRaWZRLmV5SlVhVzU1U1VRaU9pSXhORFF4TVRVME1UUTFPRFEyTWpneE1Ua2lMQ0pXWlhJaU9pSXhJaXdpUkc5dFlXbHVJam9pYzJGaGMxOTBiMk1pTENKU1ppSTZJbEZLVWtoWFp5SXNJbVY0Y0NJNk1UYzFPREU1TXprMk9Td2lhV0YwSWpveE56VTFOakF4T1RZNUxDSnBjM01pT2lKVVpXNWpaVzUwSUVSdlkzTWlmUS55Wjg2RzlDaTczekRGeUZuZUlLSkhIUjZBaktQQVFocTZOUm9WdFRfWWJzKLHSr8YGMAE4%2BcewMEIgMTM4RUE5QjgwN0I2QzJEQ0ZFOTZDNUIxQTY1MEU5MzI%3D; utype=qq; env_id=gray-pct25; gray_user=true; DOC_SID=ec95c29d7ca948298ae4869ccdf3d6ac7946c1ae31ef4454b25c723572b0051b; SID=ec95c29d7ca948298ae4869ccdf3d6ac7946c1ae31ef4454b25c723572b0051b; language=zh-CN; backup_cdn_domain=docs.gtimg.com"
        
        self.downloaded_files = []
        print("[SETUP] ä½¿ç”¨æœ€æ–°æœ‰æ•ˆCookie - uid: 144115414584628119")
        print("[SETUP] ä¸‹è½½ç›®å½•:", str(self.download_dir))

    def parse_cookies(self):
        cookies = []
        for cookie_pair in self.cookie_string.split('; '):
            if '=' in cookie_pair:
                name, value = cookie_pair.split('=', 1)
                cookies.append({
                    'name': name.strip(),
                    'value': value.strip(),
                    'domain': '.docs.qq.com',
                    'path': '/'
                })
        return cookies

    async def handle_download(self, download):
        try:
            filename = download.suggested_filename
            download_path = self.download_dir / filename
            print(f"[DOWN] ä¸‹è½½: {filename}")
            await download.save_as(download_path)
            self.downloaded_files.append(str(download_path))
            file_size = download_path.stat().st_size if download_path.exists() else 0
            print(f"[OK] å®Œæˆ: {filename} ({file_size:,} å­—èŠ‚)")
        except Exception as e:
            print(f"[ERROR] ä¸‹è½½å¤±è´¥: {e}")

    async def verify_cookie_works(self):
        """éªŒè¯æ–°Cookieæ˜¯å¦æœ‰æ•ˆ"""
        print("\n[VERIFY] éªŒè¯Cookieæœ‰æ•ˆæ€§...")
        
        try:
            # æµ‹è¯•ç”¨æˆ·ä¿¡æ¯æ¥å£
            response = await self.page.goto(
                'https://docs.qq.com/cgi-bin/online_docs/user_info?xsrf=a473487816963a48&get_vip_info=1&u=',
                wait_until='domcontentloaded',
                timeout=15000
            )
            
            print(f"[API] user_infoçŠ¶æ€ç : {response.status}")
            
            if response.status == 200:
                content = await self.page.content()
                if 'login' not in content.lower() and 'ç™»å½•' not in content:
                    print("[SUCCESS] CookieéªŒè¯æˆåŠŸï¼ç”¨æˆ·å·²è®¤è¯")
                    return True
                else:
                    print("[ERROR] Cookieæ— æ•ˆï¼Œä»éœ€ç™»å½•")
                    return False
            else:
                print(f"[ERROR] APIè°ƒç”¨å¤±è´¥: {response.status}")
                return False
                
        except Exception as e:
            print(f"[ERROR] CookieéªŒè¯å¼‚å¸¸: {e}")
            return False

    async def navigate_to_documents(self):
        """å¯¼èˆªåˆ°æ–‡æ¡£é¡µé¢"""
        print("\n[STEP] è®¿é—®è…¾è®¯æ–‡æ¡£æ¡Œé¢...")
        
        try:
            # è®¿é—®æ¡Œé¢é¡µé¢
            await self.page.goto('https://docs.qq.com/desktop/', 
                                wait_until='domcontentloaded', timeout=30000)
            
            print("[PAGE] æ¡Œé¢é¡µé¢åŠ è½½å®Œæˆ")
            await asyncio.sleep(5)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            
            # æ£€æŸ¥é¡µé¢çŠ¶æ€
            title = await self.page.title()
            print(f"[PAGE] æ ‡é¢˜: {title}")
            
            return True
            
        except Exception as e:
            print(f"[ERROR] é¡µé¢å¯¼èˆªå¤±è´¥: {e}")
            return False

    async def find_and_download_documents(self, max_count=10):
        """æŸ¥æ‰¾å¹¶ä¸‹è½½æ–‡æ¡£"""
        print(f"\n[STEP] æŸ¥æ‰¾å¹¶ä¸‹è½½æœ€å¤š{max_count}ä¸ªæ–‡æ¡£...")
        
        # ç­‰å¾…é¡µé¢å…ƒç´ åŠ è½½
        await asyncio.sleep(8)
        
        # å¤šç§æ–‡æ¡£é€‰æ‹©å™¨ç­–ç•¥
        document_selectors = [
            'a[href*="/doc/"]',           # æ–‡æ¡£é“¾æ¥
            '[class*="file-item"]',        # æ–‡ä»¶é¡¹
            '[class*="document-item"]',    # æ–‡æ¡£é¡¹
            '.file-name',                  # æ–‡ä»¶å
            '[data-test*="file"]',         # æµ‹è¯•å±æ€§
            'tr[class*="file"]',           # è¡¨æ ¼è¡Œ
            '[role="listitem"]',           # åˆ—è¡¨é¡¹
            '[class*="item"]:has(a[href*="/doc/"])'  # åŒ…å«æ–‡æ¡£é“¾æ¥çš„é¡¹ç›®
        ]
        
        found_docs = []
        
        for selector in document_selectors:
            try:
                print(f"[SEARCH] å°è¯•é€‰æ‹©å™¨: {selector}")
                elements = await self.page.query_selector_all(selector)
                
                if elements:
                    print(f"[FOUND] {selector}: æ‰¾åˆ°{len(elements)}ä¸ªå…ƒç´ ")
                    
                    for i, element in enumerate(elements[:max_count]):
                        try:
                            # è·å–æ–‡æœ¬å†…å®¹
                            text = await element.inner_text()
                            if text and len(text.strip()) > 0:
                                found_docs.append((element, text.strip()))
                                print(f"  [DOC {len(found_docs)}] {text[:50]}...")
                                
                        except Exception as e:
                            print(f"  [SKIP] å…ƒç´ {i}è·å–æ–‡æœ¬å¤±è´¥: {e}")
                    
                    if found_docs:
                        break  # æ‰¾åˆ°æ–‡æ¡£å°±åœæ­¢æœç´¢å…¶ä»–é€‰æ‹©å™¨
                        
            except Exception as e:
                print(f"[SKIP] {selector} æœç´¢å¤±è´¥: {e}")
        
        if not found_docs:
            print("[ERROR] æœªæ‰¾åˆ°ä»»ä½•æ–‡æ¡£å…ƒç´ ")
            return []
        
        print(f"\n[START] å¼€å§‹ä¸‹è½½{len(found_docs)}ä¸ªæ–‡æ¡£...")
        downloaded_count = 0
        
        for i, (element, doc_name) in enumerate(found_docs):
            try:
                print(f"\n[DOC {i+1}/{len(found_docs)}] ä¸‹è½½: {doc_name[:30]}...")
                
                # æ»šåŠ¨åˆ°å…ƒç´ å¯è§ä½ç½®
                await element.scroll_into_view_if_needed()
                await asyncio.sleep(1)
                
                # å³é”®ç‚¹å‡»
                await element.click(button='right')
                await asyncio.sleep(2)
                
                # æŸ¥æ‰¾ä¸‹è½½é€‰é¡¹
                download_options = ['text=ä¸‹è½½', 'text=å¯¼å‡º', 'text=Download', 'text=Export']
                
                download_success = False
                for option in download_options:
                    try:
                        download_btn = await self.page.wait_for_selector(option, timeout=3000)
                        if download_btn:
                            await download_btn.click()
                            print(f"[CLICK] ç‚¹å‡»: {option}")
                            download_success = True
                            downloaded_count += 1
                            await asyncio.sleep(3)  # ç­‰å¾…ä¸‹è½½å¼€å§‹
                            break
                    except:
                        continue
                
                if not download_success:
                    print(f"[MISS] æœªæ‰¾åˆ°ä¸‹è½½é€‰é¡¹")
                
                # ç‚¹å‡»ç©ºç™½å¤„å…³é—­å³é”®èœå•
                try:
                    await self.page.click('body', position={'x': 100, 'y': 100})
                    await asyncio.sleep(1)
                except:
                    pass
                    
            except Exception as e:
                print(f"[ERROR] æ–‡æ¡£{i+1}å¤„ç†å¤±è´¥: {e}")
        
        return downloaded_count

    async def run_download_task(self):
        """æ‰§è¡Œä¸‹è½½ä»»åŠ¡"""
        print("\n" + "="*60)
        print("        è…¾è®¯æ–‡æ¡£è‡ªåŠ¨åŒ–ä¸‹è½½ - ä½¿ç”¨æœ€æ–°æœ‰æ•ˆCookie")
        print("="*60)
        
        async with async_playwright() as playwright:
            browser = await playwright.chromium.launch(
                headless=False,  # å¯è§†åŒ–æ¨¡å¼
                args=['--start-maximized', '--no-sandbox']
            )
            
            context = await browser.new_context(
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36',
                accept_downloads=True
            )
            
            # ç›‘å¬ä¸‹è½½
            context.on('download', self.handle_download)
            
            self.page = await context.new_page()
            
            try:
                # 1. è®¾ç½®Cookie
                print("[SETUP] è®¾ç½®Cookie...")
                await context.add_cookies(self.parse_cookies())
                
                # 2. å…ˆå¯¼èˆªåˆ°æ–‡æ¡£é¡µé¢
                if not await self.navigate_to_documents():
                    print("[FAILED] é¡µé¢å¯¼èˆªå¤±è´¥")
                    return False
                
                # 3. åœ¨æ–‡æ¡£é¡µé¢éªŒè¯ç™»å½•çŠ¶æ€
                print("[INFO] åœ¨æ¡Œé¢é¡µé¢æ£€æŸ¥ç™»å½•çŠ¶æ€...")
                
                # 4. æŸ¥æ‰¾å¹¶ä¸‹è½½æ–‡æ¡£
                downloaded_count = await self.find_and_download_documents(10)
                
                # 5. ç­‰å¾…ä¸‹è½½å®Œæˆ
                print(f"\n[WAIT] ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ...")
                await asyncio.sleep(10)
                
                print(f"\n[RESULT] ä»»åŠ¡å®Œæˆ!")
                print(f"[STATS] å°è¯•ä¸‹è½½: {downloaded_count} ä¸ªæ–‡æ¡£")
                print(f"[STATS] å®é™…ä¸‹è½½: {len(self.downloaded_files)} ä¸ªæ–‡ä»¶")
                
                for file_path in self.downloaded_files:
                    print(f"  - {file_path}")
                
                return True
                
            except Exception as e:
                print(f"[ERROR] æ‰§è¡Œå¼‚å¸¸: {e}")
                return False
                
            finally:
                print("\n[WAIT] ä¿æŒæµè§ˆå™¨10ç§’ä¾›è§‚å¯Ÿ...")
                await asyncio.sleep(10)
                await browser.close()

async def main():
    downloader = UpdatedDownloader()
    success = await downloader.run_download_task()
    
    if success:
        print("\n[SUCCESS] ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼")
    else:
        print("\n[FAILED] ä»»åŠ¡æ‰§è¡Œå¤±è´¥")

if __name__ == "__main__":
    asyncio.run(main())