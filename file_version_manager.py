#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶ç‰ˆæœ¬ç®¡ç†å™¨ - æŒ‰ç…§ã€Šæ—¶é—´ç®¡ç†å’Œæ–‡ä»¶ç‰ˆæœ¬è§„æ ¼è¯´æ˜ä¹¦ã€‹å®ç°
å®ç°è§„èŒƒçš„æ–‡ä»¶å‘½åã€ç›®å½•ç»“æ„å’ŒæŸ¥æ‰¾ç­–ç•¥
"""

import os
import re
import hashlib
import glob
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Tuple
import urllib.parse


class FileVersionManager:
    """
    æ–‡ä»¶ç‰ˆæœ¬ç®¡ç†å™¨ - ä¸¥æ ¼æŒ‰ç…§è§„èŒƒå®ç°
    
    åŠŸèƒ½ï¼š
    1. è§„èŒƒæ–‡ä»¶å‘½åï¼štencent_{æ–‡ä»¶å}_{YYYYMMDD_HHMM}_{ç‰ˆæœ¬ç±»å‹}_W{å‘¨æ•°}.{æ‰©å±•å}
    2. è§„èŒƒç›®å½•ç»“æ„ï¼šcsv_versions/2025_W36/baseline/
    3. æ—¶é—´ç­–ç•¥æŸ¥æ‰¾ï¼šæ ¹æ®å½“å‰æ—¶é—´æ™ºèƒ½é€‰æ‹©åŸºå‡†ç‰ˆ
    4. å¹¶è¡Œä¸‹è½½æ”¯æŒï¼šé€šè¿‡ä¸´æ—¶æ–‡ä»¶åå’Œæ–‡ä»¶é”é˜²æ­¢å†²çª
    """
    
    def __init__(self, base_dir: str = None):
        """
        åˆå§‹åŒ–ç‰ˆæœ¬ç®¡ç†å™¨
        
        Args:
            base_dir: åŸºç¡€ç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„csv_versions
        """
        self.base_dir = Path(base_dir or "./csv_versions")
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        # ç‰ˆæœ¬ç±»å‹å®šä¹‰
        self.version_types = {
            'baseline': 'åŸºå‡†ç‰ˆ',
            'midweek': 'å‘¨ä¸­ç‰ˆ', 
            'weekend': 'å‘¨æœ«ç‰ˆ'
        }
    
    def get_time_strategy(self) -> Tuple[str, str, int]:
        """
        ä¸¥æ ¼æ—¶é—´åˆ¤æ–­ç®—æ³• - æ ¸å¿ƒè§„æ ¼å®ç°
        
        Returns:
            tuple: (ç­–ç•¥ç±»å‹, è¯´æ˜æ–‡å­—, å‘¨æ•°ä¿¡æ¯)
        """
        now = datetime.now()
        weekday = now.weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ...
        hour = now.hour
        week_info = now.isocalendar()  # (year, week, weekday)
        
        if weekday < 1 or (weekday == 1 and hour < 12):
            # å‘¨ä¸€å…¨å¤© OR å‘¨äºŒ12ç‚¹å‰
            target_week = week_info[1] - 1  # ä¸Šå‘¨
            return "previous_week", f"ä½¿ç”¨ä¸Šå‘¨W{target_week}åŸºå‡†ç‰ˆ", target_week
        else:
            # å‘¨äºŒ12ç‚¹å OR å‘¨ä¸‰åˆ°å‘¨å…­
            target_week = week_info[1]  # æœ¬å‘¨
            return "current_week", f"ä½¿ç”¨æœ¬å‘¨W{target_week}åŸºå‡†ç‰ˆ", target_week
    
    def extract_filename_from_url(self, url: str) -> str:
        """
        ä»è…¾è®¯æ–‡æ¡£URLä¸­æå–æ–‡ä»¶å
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URL
            
        Returns:
            æå–çš„æ–‡ä»¶å
        """
        # å¦‚æœURLä¸­åŒ…å«æ ‡é¢˜å‚æ•°ï¼Œä¼˜å…ˆå°è¯•æå–
        parsed_url = urllib.parse.urlparse(url)
        if parsed_url.fragment:
            # æ£€æŸ¥fragmentä¸­æ˜¯å¦åŒ…å«æ ‡é¢˜ä¿¡æ¯
            fragment_match = re.search(r'title=([^&]+)', parsed_url.fragment)
            if fragment_match:
                title = urllib.parse.unquote(fragment_match.group(1))
                return title
        
        # æå–æ–‡æ¡£IDç”¨ä½œé»˜è®¤åç§°ï¼ˆä¸å†æ·»åŠ "è…¾è®¯æ–‡æ¡£_"å‰ç¼€ï¼Œé¿å…æœç´¢å¤±è´¥ï¼‰
        doc_id_match = re.search(r'/(?:sheet|doc|slide)/([A-Za-z0-9]+)', url)
        if doc_id_match:
            doc_id = doc_id_match.group(1)
            return f"doc_{doc_id}"  # ä½¿ç”¨ç®€æ´çš„doc_å‰ç¼€ï¼Œé¿å…ä¸­æ–‡å­—ç¬¦
        
        # é»˜è®¤åç§°
        return "unnamed_doc"  # ä½¿ç”¨è‹±æ–‡ï¼Œé¿å…è·¯å¾„é—®é¢˜
    
    def get_standard_filename(self, url: str, filename: str = None, version_type: str = 'baseline', file_extension: str = 'csv') -> str:
        """
        ç”Ÿæˆè§„èŒƒæ–‡ä»¶å - æ”¯æŒåŠ¨æ€æ‰©å±•å
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URL
            filename: åŸå§‹æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
            version_type: ç‰ˆæœ¬ç±»å‹
            file_extension: æ–‡ä»¶æ‰©å±•åï¼ˆé»˜è®¤csvï¼‰
            
        Returns:
            è§„èŒƒæ–‡ä»¶å
        """
        # ç¡®å®šæ–‡ä»¶åå’Œæ‰©å±•å
        if filename:
            # æå–åŸå§‹æ‰©å±•å
            ext_match = re.search(r'\.(csv|xlsx|xls|xlsm)$', filename, flags=re.IGNORECASE)
            if ext_match:
                file_extension = ext_match.group(1).lower()
            # æ¸…ç†åŸå§‹æ–‡ä»¶å
            doc_name = re.sub(r'\.(csv|xlsx|xls|xlsm)$', '', filename, flags=re.IGNORECASE)
            doc_name = re.sub(r'[<>:"/\\|?*]', '', doc_name)  # ç§»é™¤éæ³•å­—ç¬¦
        else:
            doc_name = self.extract_filename_from_url(url)
        
        # è·å–å½“å‰æ—¶é—´ä¿¡æ¯
        now = datetime.now()
        date_str = now.strftime("%Y%m%d")
        time_str = now.strftime("%H%M")
        week_info = now.isocalendar()
        week_str = f"W{week_info[1]}"
        
        # ç”Ÿæˆè§„èŒƒæ–‡ä»¶å - æ–°æ ¼å¼ï¼Œæ”¯æŒåŠ¨æ€æ‰©å±•å
        # æ ¼å¼ï¼štencent_{æ–‡ä»¶å}_{YYYYMMDD_HHMM}_{ç‰ˆæœ¬ç±»å‹}_W{å‘¨æ•°}.{æ‰©å±•å}
        return f"tencent_{doc_name}_{date_str}_{time_str}_{version_type}_{week_str}.{file_extension}"
    
    def get_temp_filename(self, url: str) -> str:
        """
        ç”Ÿæˆä¸´æ—¶æ–‡ä»¶åç”¨äºä¸‹è½½è¿‡ç¨‹ï¼Œé˜²æ­¢å¹¶è¡Œå†²çª
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URL
            
        Returns:
            ä¸´æ—¶æ–‡ä»¶å
        """
        url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()[:8]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        # ä¸´æ—¶æ–‡ä»¶åä¸æŒ‡å®šæ‰©å±•åï¼Œå› ä¸ºä¸‹è½½æ—¶è¿˜ä¸çŸ¥é“å®é™…æ ¼å¼
        return f"temp_download_{url_hash}_{timestamp}.tmp"
    
    def get_save_directory(self, version_type: str = 'baseline') -> Path:
        """
        è·å–è§„èŒƒä¿å­˜ç›®å½•
        
        Args:
            version_type: ç‰ˆæœ¬ç±»å‹
            
        Returns:
            ä¿å­˜ç›®å½•è·¯å¾„
        """
        now = datetime.now()
        week_info = now.isocalendar()
        week_dir = f"{week_info[0]}_W{week_info[1]}"
        
        save_dir = self.base_dir / week_dir / version_type
        save_dir.mkdir(parents=True, exist_ok=True)
        
        return save_dir
    
    def find_file_by_strategy(self, url: str, doc_name: str = None) -> Optional[str]:
        """
        æŒ‰æ—¶é—´ç­–ç•¥æŸ¥æ‰¾æ–‡ä»¶ - æ™ºèƒ½å¤šç­–ç•¥æŸ¥æ‰¾
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URLï¼ˆç”¨äºæå–æ–‡æ¡£ä¿¡æ¯ï¼‰
            doc_name: æ–‡æ¡£åç§°ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ‰¾åˆ°çš„æ–‡ä»¶è·¯å¾„ï¼Œæœªæ‰¾åˆ°è¿”å›None
        """
        strategy, description, target_week = self.get_time_strategy()
        
        print(f"ğŸ¯ æŸ¥æ‰¾ç­–ç•¥: {description}")
        
        # æ„å»ºæŸ¥æ‰¾è·¯å¾„
        now = datetime.now()
        if strategy == "current_week":
            week_dir = f"{now.year}_W{target_week}"
        else:  # previous_week
            # ä¸Šå‘¨å¯èƒ½è·¨å¹´ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if target_week == 0:  # å¦‚æœæ˜¯ç¬¬0å‘¨ï¼Œå®é™…æ˜¯å»å¹´æœ€åä¸€å‘¨
                week_dir = f"{now.year-1}_W52"  # ç®€åŒ–å¤„ç†ï¼Œå‡è®¾å»å¹´æœ‰52å‘¨
            else:
                week_dir = f"{now.year}_W{target_week}"
        
        baseline_dir = self.base_dir / week_dir / "baseline"
        
        if not baseline_dir.exists():
            print(f"âŒ åŸºå‡†ç‰ˆç›®å½•ä¸å­˜åœ¨: {baseline_dir}")
            return None
        
        # æ™ºèƒ½å¤šç­–ç•¥æŸ¥æ‰¾ - è§£å†³æ–‡ä»¶åä¸åŒ¹é…é—®é¢˜
        baseline_files = []
        search_patterns = []
        
        # ç­–ç•¥1: å¦‚æœæä¾›äº†doc_nameï¼Œä¼˜å…ˆä½¿ç”¨
        if doc_name:
            # æ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼å’Œå¤šç§æ‰©å±•å
            for ext in ['csv', 'xlsx', 'xls']:
                # æ–°æ ¼å¼
                pattern1 = f"tencent_{doc_name}_*_baseline_W{target_week}.{ext}"
                pattern2 = f"tencent_*{doc_name}*_*_baseline_W{target_week}.{ext}"
                # æ—§æ ¼å¼ï¼ˆå‘åå…¼å®¹ï¼‰
                pattern3 = f"tencent_{doc_name}_csv_*_baseline_W{target_week}.csv"
                pattern4 = f"tencent_*{doc_name}*_csv_*_baseline_W{target_week}.csv"
                search_patterns.extend([pattern1, pattern2, pattern3, pattern4])
        
        # ç­–ç•¥2: ä»URLæå–æ–‡æ¡£IDè¿›è¡ŒæŸ¥æ‰¾
        doc_id_match = re.search(r'/(?:sheet|doc|slide)/([A-Za-z0-9]+)', url)
        if doc_id_match:
            doc_id = doc_id_match.group(1)
            # ç›´æ¥æŒ‰æ–‡æ¡£IDæŸ¥æ‰¾ï¼Œæ”¯æŒå¤šç§æ‰©å±•å
            for ext in ['csv', 'xlsx', 'xls']:
                pattern_new = f"tencent_*_*_baseline_W{target_week}.{ext}"
                pattern_old = f"tencent_*_csv_*_baseline_W{target_week}.csv"
                search_patterns.extend([pattern_new, pattern_old])
        
        # ç­–ç•¥3: é€šç”¨æ¨¡å¼æŸ¥æ‰¾ï¼Œé€‚ç”¨äºä»»ä½•ç¬¦åˆæ ¼å¼çš„åŸºå‡†ç‰ˆæ–‡ä»¶
        for ext in ['csv', 'xlsx', 'xls']:
            fallback_pattern_new = f"tencent_*_*_baseline_W{target_week}.{ext}"
            fallback_pattern_old = f"tencent_*_csv_*_baseline_W{target_week}.csv"
            if fallback_pattern_new not in search_patterns:
                search_patterns.append(fallback_pattern_new)
            if fallback_pattern_old not in search_patterns:
                search_patterns.append(fallback_pattern_old)
        
        # æ‰§è¡ŒæŸ¥æ‰¾
        for i, pattern in enumerate(search_patterns, 1):
            files = list(baseline_dir.glob(pattern))
            if files:
                baseline_files = files
                print(f"âœ… ç­–ç•¥{i}æ‰¾åˆ°{len(files)}ä¸ªæ–‡ä»¶ï¼Œæ¨¡å¼: {pattern}")
                break
            else:
                print(f"ğŸ” ç­–ç•¥{i}æœªæ‰¾åˆ°æ–‡ä»¶ï¼Œæ¨¡å¼: {pattern}")
        
        if not baseline_files:
            print(f"âŒ æ‰€æœ‰ç­–ç•¥éƒ½æœªæ‰¾åˆ°åŸºå‡†ç‰ˆæ–‡ä»¶ï¼Œç›®å½•: {baseline_dir}")
            return None
        
        # ç­–ç•¥4: å¦‚æœæ‰¾åˆ°å¤šä¸ªæ–‡ä»¶ä¸”æœ‰URLä¸­çš„æ–‡æ¡£IDï¼Œä¼˜å…ˆé€‰æ‹©åŒ…å«è¯¥IDçš„æ–‡ä»¶
        if len(baseline_files) > 1 and doc_id_match:
            doc_id = doc_id_match.group(1)
            id_matched_files = [f for f in baseline_files if doc_id in f.name]
            if id_matched_files:
                baseline_files = id_matched_files
                print(f"âœ… æ–‡æ¡£IDåŒ¹é…è¿‡æ»¤åå‰©ä½™{len(baseline_files)}ä¸ªæ–‡ä»¶")
        
        # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(baseline_files, key=lambda x: x.stat().st_mtime)
        print(f"âœ… æœ€ç»ˆé€‰æ‹©æ–‡ä»¶: {latest_file.name}")
        
        return str(latest_file)
    
    def get_baseline_file(self, url: str, doc_name: str = None, strict: bool = True) -> str:
        """
        è·å–åŸºå‡†ç‰ˆæ–‡ä»¶ - ä¸¥æ ¼æ¨¡å¼
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URL
            doc_name: æ–‡æ¡£åç§°
            strict: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆæ‰¾ä¸åˆ°æ—¶æŠ¥é”™ï¼‰
            
        Returns:
            åŸºå‡†ç‰ˆæ–‡ä»¶è·¯å¾„
            
        Raises:
            FileNotFoundError: ä¸¥æ ¼æ¨¡å¼ä¸‹æ‰¾ä¸åˆ°åŸºå‡†ç‰ˆæ—¶æŠ›å‡º
        """
        baseline_file = self.find_file_by_strategy(url, doc_name)
        
        if baseline_file is None and strict:
            strategy, description, target_week = self.get_time_strategy()
            raise FileNotFoundError(
                f"âŒ {description}ä¸å­˜åœ¨\n"
                f"è¯·æ£€æŸ¥åŸºå‡†ç‰ˆæ–‡ä»¶æ˜¯å¦å·²ç”Ÿæˆæˆ–æ‰‹åŠ¨è¡¥å……åŸºå‡†ç‰ˆ"
            )
        
        return baseline_file
    
    def find_files_by_url_info(self, url: str, download_dir: str, max_age_seconds: int = 300) -> List[str]:
        """
        åŸºäºURLä¿¡æ¯æŸ¥æ‰¾ä¸‹è½½æ–‡ä»¶ - ä¸ä¾èµ–URLå“ˆå¸Œ
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URL
            download_dir: ä¸‹è½½ç›®å½•
            max_age_seconds: æœ€å¤§æ–‡ä»¶å¹´é¾„ï¼ˆç§’ï¼‰
            
        Returns:
            åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        import time
        
        download_path = Path(download_dir)
        if not download_path.exists():
            return []
        
        current_time = time.time()
        matched_files = []
        
        # 1. é¦–å…ˆæŸ¥æ‰¾ä¸´æ—¶æ–‡ä»¶ï¼ˆç”¨äºä¸‹è½½è¿‡ç¨‹ä¸­ï¼‰
        url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()[:8]
        for file_path in download_path.glob(f"temp_download_{url_hash}_*.csv"):
            if current_time - file_path.stat().st_mtime <= max_age_seconds:
                matched_files.append(str(file_path))
        
        # 2. åŸºäºURLæå–æ–‡æ¡£ä¿¡æ¯è¿›è¡ŒåŒ¹é…
        doc_name = self.extract_filename_from_url(url)
        doc_id_match = re.search(r'/(?:sheet|doc|slide)/([A-Za-z0-9]+)', url)
        
        if doc_id_match:
            doc_id = doc_id_match.group(1)
            # æŸ¥æ‰¾åŒ…å«æ–‡æ¡£IDçš„è§„èŒƒæ–‡ä»¶
            for file_path in download_path.glob("tencent_*.csv"):
                if doc_id in file_path.name and current_time - file_path.stat().st_mtime <= max_age_seconds:
                    matched_files.append(str(file_path))
        
        # 3. æœ€åæŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        matched_files.sort(key=lambda x: Path(x).stat().st_mtime, reverse=True)
        
        return matched_files
    
    def organize_downloaded_file(self, downloaded_file: str, url: str, version_type: str = 'baseline') -> Dict[str, any]:
        """
        æ•´ç†ä¸‹è½½çš„æ–‡ä»¶åˆ°è§„èŒƒç›®å½•ç»“æ„
        
        Args:
            downloaded_file: ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
            url: åŸå§‹URL
            version_type: ç‰ˆæœ¬ç±»å‹
            
        Returns:
            æ•´ç†ç»“æœ
        """
        try:
            source_path = Path(downloaded_file)
            if not source_path.exists():
                return {
                    'success': False,
                    'error': f'æºæ–‡ä»¶ä¸å­˜åœ¨: {downloaded_file}'
                }
            
            # ç”Ÿæˆè§„èŒƒæ–‡ä»¶å
            standard_filename = self.get_standard_filename(url, source_path.name, version_type)
            
            # è·å–ä¿å­˜ç›®å½•
            save_dir = self.get_save_directory(version_type)
            target_path = save_dir / standard_filename
            
            # ç§»åŠ¨æ–‡ä»¶
            import shutil
            shutil.move(str(source_path), str(target_path))
            
            print(f"âœ… æ–‡ä»¶å·²æ•´ç†åˆ°è§„èŒƒç›®å½•: {target_path}")
            
            return {
                'success': True,
                'original_file': downloaded_file,
                'standard_file': str(target_path),
                'filename': standard_filename,
                'directory': str(save_dir)
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'æ–‡ä»¶æ•´ç†å¤±è´¥: {str(e)}'
            }
    
    def create_week_directories(self, weeks_ahead: int = 4) -> List[str]:
        """
        åˆ›å»ºæœªæ¥å‡ å‘¨çš„ç›®å½•ç»“æ„
        
        Args:
            weeks_ahead: æå‰åˆ›å»ºçš„å‘¨æ•°
            
        Returns:
            åˆ›å»ºçš„ç›®å½•åˆ—è¡¨
        """
        created_dirs = []
        now = datetime.now()
        
        for i in range(weeks_ahead + 1):  # åŒ…å«å½“å‰å‘¨
            week_info = now.isocalendar()
            target_week = week_info[1] + i
            target_year = week_info[0]
            
            # å¤„ç†è·¨å¹´æƒ…å†µ
            if target_week > 52:
                target_week = target_week - 52
                target_year += 1
            
            week_dir = f"{target_year}_W{target_week}"
            
            for version_type in self.version_types.keys():
                dir_path = self.base_dir / week_dir / version_type
                dir_path.mkdir(parents=True, exist_ok=True)
                created_dirs.append(str(dir_path))
        
        return created_dirs
    
    def validate_file_naming(self, filename: str) -> Dict[str, any]:
        """
        éªŒè¯æ–‡ä»¶å‘½åæ˜¯å¦ç¬¦åˆè§„èŒƒ - æ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼
        
        Args:
            filename: æ–‡ä»¶å
            
        Returns:
            éªŒè¯ç»“æœ
        """
        # æ–°æ ¼å¼ï¼štencent_{æ–‡ä»¶å}_{YYYYMMDD_HHMM}_{ç‰ˆæœ¬ç±»å‹}_W{å‘¨æ•°}.{æ‰©å±•å}
        new_pattern = r'^tencent_(.+?)_(\d{8})_(\d{4})_(baseline|midweek|weekend)_W(\d+)\.(csv|xlsx|xls|xlsm)$'
        # æ—§æ ¼å¼ï¼štencent_{æ–‡ä»¶å}_csv_{YYYYMMDD_HHMM}_{ç‰ˆæœ¬ç±»å‹}_W{å‘¨æ•°}.csv
        old_pattern = r'^tencent_(.+?)_csv_(\d{8})_(\d{4})_(baseline|midweek|weekend)_W(\d+)\.csv$'
        
        # å…ˆå°è¯•æ–°æ ¼å¼
        match = re.match(new_pattern, filename)
        is_new_format = True
        if not match:
            # å°è¯•æ—§æ ¼å¼
            match = re.match(old_pattern, filename)
            is_new_format = False
        
        if not match:
            return {
                'valid': False,
                'error': 'æ–‡ä»¶åæ ¼å¼ä¸ç¬¦åˆè§„èŒƒ',
                'expected_format': 'tencent_{æ–‡ä»¶å}_{YYYYMMDD_HHMM}_{ç‰ˆæœ¬ç±»å‹}_W{å‘¨æ•°}.{æ‰©å±•å}'
            }
        
        if is_new_format:
            doc_name, date_str, time_str, version_type, week_str, file_ext = match.groups()
        else:
            doc_name, date_str, time_str, version_type, week_str = match.groups()
            file_ext = 'csv'
        
        # éªŒè¯æ—¥æœŸæ ¼å¼
        try:
            datetime.strptime(f"{date_str}_{time_str}", "%Y%m%d_%H%M")
        except ValueError:
            return {
                'valid': False,
                'error': 'æ—¥æœŸæ—¶é—´æ ¼å¼æ— æ•ˆ',
                'date_str': date_str,
                'time_str': time_str
            }
        
        return {
            'valid': True,
            'doc_name': doc_name,
            'date': date_str,
            'time': time_str,
            'version_type': version_type,
            'week': week_str,
            'url_hash': 'N/A'  # ä¸å†ä½¿ç”¨URLå“ˆå¸Œ
        }
    
    def get_current_week_info(self) -> Dict[str, any]:
        """
        è·å–å½“å‰å‘¨ä¿¡æ¯
        
        Returns:
            å½“å‰å‘¨ä¿¡æ¯å­—å…¸
        """
        now = datetime.now()
        week_info = now.isocalendar()
        strategy, description, target_week = self.get_time_strategy()
        
        return {
            'current_year': week_info[0],
            'current_week': week_info[1],
            'current_weekday': week_info[2],
            'strategy': strategy,
            'description': description,
            'target_week': target_week,
            'week_directory': f"{week_info[0]}_W{week_info[1]}"
        }


def main():
    """å‘½ä»¤è¡Œå·¥å…·å…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ–‡ä»¶ç‰ˆæœ¬ç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=['info', 'create-dirs', 'find', 'validate'], 
                       help='æ“ä½œç±»å‹')
    parser.add_argument('--url', '-u', help='è…¾è®¯æ–‡æ¡£URL')
    parser.add_argument('--filename', '-f', help='æ–‡ä»¶å')
    parser.add_argument('--base-dir', '-d', help='åŸºç¡€ç›®å½•è·¯å¾„')
    
    args = parser.parse_args()
    
    manager = FileVersionManager(args.base_dir)
    
    if args.action == 'info':
        info = manager.get_current_week_info()
        print("ğŸ“… å½“å‰æ—¶é—´ç­–ç•¥ä¿¡æ¯:")
        print(f"  ç­–ç•¥: {info['strategy']}")
        print(f"  æè¿°: {info['description']}")
        print(f"  ç›®æ ‡å‘¨: {info['target_week']}")
        print(f"  å‘¨ç›®å½•: {info['week_directory']}")
    
    elif args.action == 'create-dirs':
        created_dirs = manager.create_week_directories()
        print(f"âœ… åˆ›å»ºäº† {len(created_dirs)} ä¸ªç›®å½•:")
        for dir_path in created_dirs:
            print(f"  ğŸ“ {dir_path}")
    
    elif args.action == 'find':
        if not args.url:
            print("é”™è¯¯: findæ“ä½œéœ€è¦æä¾›URL (--url)")
            return
        
        baseline_file = manager.find_file_by_strategy(args.url)
        if baseline_file:
            print(f"âœ… æ‰¾åˆ°åŸºå‡†ç‰ˆæ–‡ä»¶: {baseline_file}")
        else:
            print("âŒ æœªæ‰¾åˆ°åŸºå‡†ç‰ˆæ–‡ä»¶")
    
    elif args.action == 'validate':
        if not args.filename:
            print("é”™è¯¯: validateæ“ä½œéœ€è¦æä¾›æ–‡ä»¶å (--filename)")
            return
        
        result = manager.validate_file_naming(args.filename)
        if result['valid']:
            print("âœ… æ–‡ä»¶å‘½åç¬¦åˆè§„èŒƒ")
            print(f"  æ–‡æ¡£å: {result['doc_name']}")
            print(f"  æ—¥æœŸ: {result['date']}")
            print(f"  æ—¶é—´: {result['time']}")
            print(f"  ç‰ˆæœ¬ç±»å‹: {result['version_type']}")
            print(f"  å‘¨æ•°: {result['week']}")
            # URLå“ˆå¸Œå·²ç§»é™¤ï¼Œä¸å†æ˜¾ç¤º
        else:
            print(f"âŒ {result['error']}")
            if 'expected_format' in result:
                print(f"  æœŸæœ›æ ¼å¼: {result['expected_format']}")


if __name__ == "__main__":
    main()