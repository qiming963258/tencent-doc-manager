#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è…¾è®¯æ–‡æ¡£ç®¡ç†é¡¹ç›® - å®Œæ•´é›†æˆæµ‹è¯•ç³»ç»Ÿï¼ˆå¢å¼ºç‰ˆï¼‰
ç«¯å£: 8093
ç‰ˆæœ¬: 5.0.0 - Enhanced Production Integration
åŠŸèƒ½: å®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•æµç¨‹ï¼Œä»åŒæ–‡æ¡£ä¸‹è½½åˆ°æ™ºèƒ½æ¶‚è‰²ä¸Šä¼ 
æ–°å¢: æ–‡ä»¶æµè§ˆå™¨ã€å†å²è®°å½•ã€é¢„è®¾æ¨¡æ¿ã€é«˜çº§é…ç½®ç­‰åŠŸèƒ½
ä½œè€…: ç³»ç»Ÿæ¶æ„å›¢é˜Ÿ
æ—¥æœŸ: 2025-09-10
"""

from flask import Flask, render_template_string, request, jsonify, send_file
import os
import sys
import json
import time
import csv
import logging
import shutil
from pathlib import Path

# åŠ è½½.envæ–‡ä»¶
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
        print(f"âœ… å·²åŠ è½½.envæ–‡ä»¶: {env_path}")
except ImportError:
    print("âš ï¸ dotenvæœªå®‰è£…ï¼Œä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡")
import traceback
import uuid
import threading
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import subprocess
import glob
import hashlib

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/root/projects/tencent-doc-manager')
# ä¿®å¤ï¼šä½¿ç”¨appendè€Œä¸æ˜¯insertï¼Œé¿å…production/core_modulesçš„deepseek_clientè¦†ç›–æ ¹ç›®å½•ç‰ˆæœ¬
sys.path.append('/root/projects/tencent-doc-manager/production/core_modules')

app = Flask(__name__)

# ==================== ç²¾ç¡®åŒ¹é…å‡½æ•° ====================
import re

def extract_doc_id_from_filename(filename):
    """ä»æ–°æ ¼å¼æ–‡ä»¶åä¸­æå–doc_id

    Args:
        filename: æ–‡ä»¶åï¼Œå¦‚ tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_DWEFNU25TemFnZXJN_20250915_0145_baseline_W39.csv

    Returns:
        doc_idï¼Œå¦‚ DWEFNU25TemFnZXJN
    """
    basename = os.path.basename(filename)

    # æ–°æ ¼å¼ï¼štencent_{æ–‡æ¡£å}_{doc_id}_{æ—¶é—´æˆ³}_{ç‰ˆæœ¬}_W{å‘¨}.{æ‰©å±•å}
    # doc_idé€šå¸¸æ˜¯å­—æ¯æ•°å­—ç»„åˆ
    match = re.search(r'^tencent_[^_]+_([A-Za-z0-9]+)_\d{8}_\d{4}_(baseline|midweek|weekend)_W\d+\.\w+$', basename)
    if match:
        return match.group(1)
    return None

def extract_doc_name_from_filename(filename):
    """ä»æ–‡ä»¶åä¸­ç²¾ç¡®æå–æ–‡æ¡£åç§°ï¼ˆä¿ç•™ä»¥å…¼å®¹æ—§ä»£ç ï¼‰

    Args:
        filename: æ–‡ä»¶åï¼Œå¦‚ tencent_å‡ºå›½é”€å”®è®¡åˆ’è¡¨_20250915_0145_baseline_W39.csv

    Returns:
        æ–‡æ¡£åç§°ï¼Œå¦‚ å‡ºå›½é”€å”®è®¡åˆ’è¡¨
    """
    basename = os.path.basename(filename)

    # åŒ¹é…æ ¼å¼ï¼štencent_{æ–‡æ¡£å}_{æ—¶é—´æˆ³}_{ç‰ˆæœ¬}_W{å‘¨}.{æ‰©å±•å}
    match = re.search(r'^tencent_(.+?)_\d{8}_\d{4}_(baseline|midweek)_W\d+\.\w+$', basename)
    if match:
        return match.group(1)

    # å¤‡ç”¨åŒ¹é…ï¼ˆå¦‚æœæ ¼å¼ä¸å®Œå…¨æ ‡å‡†ï¼‰
    match = re.search(r'^tencent_(.+?)_\d{8}_\d{4}', basename)
    if match:
        return match.group(1)

    return None

# ==================== é¡¹ç›®æ­£å¼è·¯å¾„é…ç½® ====================
BASE_DIR = Path('/root/projects/tencent-doc-manager')
DOWNLOAD_DIR = BASE_DIR / 'downloads'
CSV_VERSIONS_DIR = BASE_DIR / 'csv_versions'
COMPARISON_RESULTS_DIR = BASE_DIR / 'comparison_results'
SCORING_RESULTS_DIR = BASE_DIR / 'scoring_results' / 'detailed'
EXCEL_OUTPUTS_DIR = BASE_DIR / 'excel_outputs' / 'marked'
LOG_DIR = BASE_DIR / 'logs'
TEMP_DIR = BASE_DIR / 'temp_workflow'
HISTORY_DIR = BASE_DIR / 'workflow_history'
PRESETS_DIR = BASE_DIR / 'workflow_presets'

# ç¡®ä¿æ‰€æœ‰ç›®å½•å­˜åœ¨
for dir_path in [DOWNLOAD_DIR, CSV_VERSIONS_DIR, COMPARISON_RESULTS_DIR, 
                 SCORING_RESULTS_DIR, EXCEL_OUTPUTS_DIR, LOG_DIR, TEMP_DIR,
                 HISTORY_DIR, PRESETS_DIR]:
    dir_path.mkdir(exist_ok=True, parents=True)

# ==================== æ—¥å¿—é…ç½® ====================
log_file = LOG_DIR / f'integrated_test_8093_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [%(levelname)s] - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ==================== å…¨å±€çŠ¶æ€ç®¡ç† ====================
class WorkflowState:
    def __init__(self):
        self.current_task = ""
        self.progress = 0
        self.logs = []
        self.status = "idle"  # idle, running, completed, error
        self.results = {}
        self.baseline_file = None
        self.target_file = None
        self.score_file = None
        self.marked_file = None
        self.upload_url = None
        self.start_time = None
        self.end_time = None
        self.execution_id = None
        self.advanced_settings = {}
        
    def add_log(self, message, level="INFO"):
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = {
            "timestamp": timestamp,  # æ”¹ä¸ºtimestampä»¥åŒ¹é…8089æœŸæœ›çš„æ ¼å¼
            "level": level,
            "message": message
        }
        self.logs.append(log_entry)
        logger.info(f"[{level}] {message}")
        
    def update_progress(self, task, progress):
        self.current_task = task
        self.progress = progress
        
    def reset(self):
        self.__init__()
        
    def save_to_history(self):
        """ä¿å­˜æ‰§è¡Œå†å²"""
        if self.execution_id:
            history_file = HISTORY_DIR / f"workflow_{self.execution_id}.json"
            history_data = {
                "id": self.execution_id,
                "start_time": self.start_time.isoformat() if self.start_time else None,
                "end_time": self.end_time.isoformat() if self.end_time else None,
                "status": self.status,
                "results": self.results,
                "logs": self.logs[-20:],  # åªä¿å­˜æœ€å20æ¡æ—¥å¿—
                "settings": self.advanced_settings
            }
            with open(history_file, 'w', encoding='utf-8') as f:
                json.dump(history_data, f, ensure_ascii=False, indent=2)

workflow_state = WorkflowState()

# ==================== å·¥ä½œæµé¢„è®¾ç®¡ç† ====================
class PresetManager:
    @staticmethod
    def save_preset(name, config):
        """ä¿å­˜é¢„è®¾é…ç½®"""
        preset_file = PRESETS_DIR / f"{name}.json"
        with open(preset_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
    
    @staticmethod
    def load_preset(name):
        """åŠ è½½é¢„è®¾é…ç½®"""
        preset_file = PRESETS_DIR / f"{name}.json"
        if preset_file.exists():
            with open(preset_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    @staticmethod
    def list_presets():
        """åˆ—å‡ºæ‰€æœ‰é¢„è®¾"""
        presets = []
        for preset_file in PRESETS_DIR.glob("*.json"):
            with open(preset_file, 'r', encoding='utf-8') as f:
                config = json.load(f)
                presets.append({
                    "name": preset_file.stem,
                    "description": config.get("description", "æ— æè¿°"),
                    "created": preset_file.stat().st_mtime
                })
        return sorted(presets, key=lambda x: x['created'], reverse=True)

# ==================== å¯¼å…¥ç”Ÿäº§æ¨¡å—ï¼ˆç¬¦åˆè§„èŒƒç‰ˆï¼‰ ====================
MODULES_STATUS = {}

# 1. æ—¶é—´ç®¡ç†å™¨ï¼ˆæ ¸å¿ƒæ¨¡å—ï¼Œç¬¦åˆè§„èŒƒï¼‰
try:
    from production.core_modules.week_time_manager import WeekTimeManager
    week_manager = WeekTimeManager()
    MODULES_STATUS['week_manager'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥å‘¨æ—¶é—´ç®¡ç†å™¨")
except ImportError as e:
    MODULES_STATUS['week_manager'] = False
    logger.warning(f"âš ï¸ æ— æ³•å¯¼å…¥å‘¨æ—¶é—´ç®¡ç†å™¨: {e}")
    week_manager = None

# 2. ä¸‹è½½æ¨¡å—ï¼ˆä½¿ç”¨ç¬¦åˆæ¶æ„è§„æ ¼çš„PlaywrightDownloaderï¼‰
try:
    from production.core_modules.playwright_downloader import PlaywrightDownloader
    # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™TencentDocAutoExporterçš„åˆ«å
    TencentDocAutoExporter = PlaywrightDownloader
    MODULES_STATUS['downloader'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥PlaywrightDownloaderï¼ˆç¬¦åˆæ¶æ„è§„æ ¼ï¼‰")
except ImportError:
    try:
        # å¤‡ç”¨ï¼šä½¿ç”¨åŸæœ‰çš„TencentDocAutoExporter
        from production.core_modules.tencent_export_automation import TencentDocAutoExporter
        MODULES_STATUS['downloader'] = True
        logger.info("âœ… æˆåŠŸå¯¼å…¥TencentDocAutoExporterï¼ˆå¤‡ç”¨ï¼‰")
    except ImportError as e:
        MODULES_STATUS['downloader'] = False
        logger.error(f"âŒ æ— æ³•å¯¼å…¥ä¸‹è½½æ¨¡å—: {e}")

# 3. æ¯”è¾ƒæ¨¡å—ï¼ˆä½¿ç”¨UnifiedCSVComparatorç¬¦åˆè§„èŒƒï¼‰
try:
    from unified_csv_comparator import UnifiedCSVComparator
    MODULES_STATUS['comparator'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥ç»Ÿä¸€CSVå¯¹æ¯”å™¨")
except ImportError as e:
    MODULES_STATUS['comparator'] = False
    logger.error(f"âŒ æ— æ³•å¯¼å…¥æ¯”è¾ƒæ¨¡å—: {e}")

# 4. åˆ—æ ‡å‡†åŒ–æ¨¡å—ï¼ˆä¼˜å…ˆä½¿ç”¨V3ç‰ˆæœ¬ï¼‰
try:
    from column_standardization_processor_v3 import ColumnStandardizationProcessorV3
    MODULES_STATUS['standardizer'] = True
    MODULES_STATUS['standardizer_v3'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥åˆ—æ ‡å‡†åŒ–V3æ¨¡å—")
except ImportError as e:
    MODULES_STATUS['standardizer_v3'] = False
    # å¦‚æœV3ä¸å­˜åœ¨ï¼Œå°è¯•æ—§ç‰ˆæœ¬
    try:
        from production.core_modules.column_standardization_prompt import ColumnStandardizationPrompt
        MODULES_STATUS['standardizer'] = True
        logger.warning("âš ï¸ ä½¿ç”¨æ—§ç‰ˆåˆ—æ ‡å‡†åŒ–æ¨¡å—")
    except ImportError:
        MODULES_STATUS['standardizer'] = False
        logger.error(f"âŒ æ— æ³•å¯¼å…¥åˆ—æ ‡å‡†åŒ–æ¨¡å—: {e}")

# 5. DeepSeekå®¢æˆ·ç«¯ï¼ˆç”¨äºAIå¢å¼ºï¼‰
try:
    from production.core_modules.deepseek_client import DeepSeekClient
    MODULES_STATUS['deepseek'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥DeepSeekå®¢æˆ·ç«¯")
except ImportError as e:
    MODULES_STATUS['deepseek'] = False
    logger.warning(f"âš ï¸ DeepSeekå®¢æˆ·ç«¯æœªåŠ è½½: {e}")

# 6. L2è¯­ä¹‰åˆ†ææ¨¡å—
try:
    from production.core_modules.l2_semantic_analysis_two_layer import L2SemanticAnalyzer
    MODULES_STATUS['l2_analyzer'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥L2è¯­ä¹‰åˆ†ææ¨¡å—")
except ImportError as e:
    MODULES_STATUS['l2_analyzer'] = False
    logger.error(f"âŒ æ— æ³•å¯¼å…¥L2è¯­ä¹‰åˆ†ææ¨¡å—: {e}")

# 5. æ™ºèƒ½æ ‡è®°æ¨¡å—
try:
    from intelligent_excel_marker import IntelligentExcelMarker
    from production.scoring_engine.integrated_scorer import IntegratedScorer
    MODULES_STATUS['marker'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥æ™ºèƒ½æ ‡è®°æ¨¡å—")
except ImportError as e:
    MODULES_STATUS['marker'] = False
    logger.error(f"âŒ æ— æ³•å¯¼å…¥æ™ºèƒ½æ ‡è®°æ¨¡å—: {e}")

# 6. Excelä¿®å¤æ¨¡å—
try:
    from fix_tencent_excel import fix_tencent_excel
    MODULES_STATUS['fixer'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥Excelä¿®å¤æ¨¡å—")
except ImportError as e:
    MODULES_STATUS['fixer'] = False
    logger.error(f"âŒ æ— æ³•å¯¼å…¥Excelä¿®å¤æ¨¡å—: {e}")

# 7. ä¸Šä¼ æ¨¡å—ï¼ˆä¼˜å…ˆä½¿ç”¨ç”Ÿäº§çº§v3 - 2025-09-20æ›´æ–°ï¼‰
try:
    # ç”Ÿäº§çº§v3æ¨¡å—ï¼š95%+é“¾æ¥å‡†ç¡®ç‡ï¼Œå¤šç­–ç•¥è¯†åˆ«ï¼ˆæ¨èï¼‰
    from production.core_modules.tencent_doc_upload_production_v3 import sync_upload_v3 as sync_upload_file
    MODULES_STATUS['uploader'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥ä¸Šä¼ æ¨¡å—(ç”Ÿäº§çº§v3ï¼Œæ¨è)")
except ImportError:
    try:
        # å¤‡ç”¨1ï¼šç»ˆæä¿®å¤ç‰ˆï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼Œä¸æ¨èï¼‰
        from tencent_doc_uploader_ultimate import sync_upload_file
        MODULES_STATUS['uploader'] = True
        logger.warning("âš ï¸ ä½¿ç”¨ä¸Šä¼ æ¨¡å—(ç»ˆæç‰ˆï¼Œå¯èƒ½è¿”å›é”™è¯¯é“¾æ¥)")
    except ImportError:
        try:
            # å¤‡ç”¨2ï¼šä¿®å¤ç‰ˆï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼Œä¸æ¨èï¼‰
            from tencent_doc_uploader_fixed import sync_upload_file
            MODULES_STATUS['uploader'] = True
            logger.warning("âš ï¸ ä½¿ç”¨ä¸Šä¼ æ¨¡å—(ä¿®å¤ç‰ˆï¼Œå¯èƒ½è¿”å›é”™è¯¯é“¾æ¥)")
        except ImportError:
            try:
                # å¤‡ç”¨3ï¼šåŸç‰ˆæœ¬ï¼ˆä¼šè¿”å›é”™è¯¯é“¾æ¥ï¼Œå¼ºçƒˆä¸æ¨èï¼‰
                from tencent_doc_uploader import sync_upload_file
                MODULES_STATUS['uploader'] = True
                logger.error("âŒ ä½¿ç”¨ä¸Šä¼ æ¨¡å—(åŸç‰ˆæœ¬ï¼Œä¼šè¿”å›é”™è¯¯é“¾æ¥!)")
            except ImportError as e:
                MODULES_STATUS['uploader'] = False
                logger.error(f"âŒ æ— æ³•å¯¼å…¥ä»»ä½•ä¸Šä¼ æ¨¡å—: {e}")

# 8. å‘¨æ—¶é—´ç®¡ç†å™¨
try:
    from production.core_modules.week_time_manager import WeekTimeManager
    MODULES_STATUS['week_manager'] = True
    logger.info("âœ… æˆåŠŸå¯¼å…¥å‘¨æ—¶é—´ç®¡ç†å™¨")
except ImportError as e:
    MODULES_STATUS['week_manager'] = False
    logger.error(f"âŒ æ— æ³•å¯¼å…¥å‘¨æ—¶é—´ç®¡ç†å™¨: {e}")

# ==================== æ™ºèƒ½åŸºçº¿ä¸‹è½½å’Œå­˜å‚¨å‡½æ•° ====================
def download_and_store_baseline(baseline_url: str, cookie: str, week_manager=None, workflow_state=None):
    """
    ä¸‹è½½åŸºçº¿æ–‡ä»¶å¹¶æŒ‰ç…§è§„èŒƒå­˜å‚¨åˆ°å½“å‘¨baselineç›®å½•
    
    Args:
        baseline_url: åŸºçº¿æ–‡æ¡£URL
        cookie: è®¤è¯cookie
        week_manager: å‘¨æ—¶é—´ç®¡ç†å™¨å®ä¾‹
    
    Returns:
        str: è§„èŒƒåŒ–åçš„åŸºçº¿æ–‡ä»¶è·¯å¾„
    """
    try:
        import shutil
        import re
        from urllib.parse import urlparse, parse_qs
        
        # è·å–å½“å‰å‘¨ä¿¡æ¯
        now = datetime.now()
        week_info = now.isocalendar()
        current_year = week_info[0]
        current_week = week_info[1]
        
        # ç¡®å®šåŸºçº¿åº”è¯¥å­˜å‚¨çš„å‘¨æ•°ï¼ˆæ ¹æ®æ—¶é—´ç®¡ç†è§„èŒƒï¼‰
        weekday = now.weekday()  # 0=å‘¨ä¸€
        hour = now.hour
        
        if weekday < 1 or (weekday == 1 and hour < 12):
            # å‘¨ä¸€å…¨å¤© OR å‘¨äºŒ12ç‚¹å‰ -> ä½¿ç”¨ä¸Šå‘¨
            target_week = current_week - 1
        else:
            # å‘¨äºŒ12ç‚¹åè‡³å‘¨æ—¥ -> ä½¿ç”¨æœ¬å‘¨
            target_week = current_week
        
        logger.info(f"åŸºçº¿æ–‡ä»¶å°†å­˜å‚¨åˆ°ç¬¬{target_week}å‘¨")
        if workflow_state:
            workflow_state.add_log(f"ğŸ“ åŸºçº¿æ–‡ä»¶å°†å­˜å‚¨åˆ°ç¬¬{target_week}å‘¨", "INFO")
        
        # åˆ›å»ºç›®æ ‡ç›®å½•
        baseline_dir = Path(f"/root/projects/tencent-doc-manager/csv_versions/{current_year}_W{target_week:02d}/baseline")
        baseline_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¸‹è½½æ–‡æ¡£
        if workflow_state:
            workflow_state.add_log("ğŸŒ åˆå§‹åŒ–æµè§ˆå™¨ä¸‹è½½å™¨...", "INFO")
        exporter = TencentDocAutoExporter()
        if workflow_state:
            workflow_state.add_log(f"ğŸ”— æ­£åœ¨æ‰“å¼€è…¾è®¯æ–‡æ¡£: {baseline_url}", "INFO")
            workflow_state.add_log("ğŸª è®¾ç½®Cookieè®¤è¯...", "INFO")
            workflow_state.add_log("â³ å¼€å§‹ä¸‹è½½ï¼Œè¯·è€å¿ƒç­‰å¾…ï¼ˆé€šå¸¸éœ€è¦30-60ç§’ï¼‰...", "INFO")
        # ä¸‹è½½æ–‡æ¡£ - æ ¹æ®ä¸‹è½½å™¨ç±»å‹é€‰æ‹©æ¥å£
        if hasattr(exporter, 'download'):
            # PlaywrightDownloaderæ¥å£ï¼ˆå¼‚æ­¥ï¼‰
            import asyncio
            result = asyncio.run(exporter.download(baseline_url, cookies=cookie, format='csv'))
        else:
            # TencentDocAutoExporteræ¥å£ï¼ˆåŒæ­¥ï¼‰
            result = exporter.export_document(baseline_url, cookies=cookie, format='csv')
        if workflow_state:
            workflow_state.add_log("âœ… ä¸‹è½½è¯·æ±‚å·²å®Œæˆ", "INFO")
        
        if not result or not result.get('success'):
            error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯') if result else 'ä¸‹è½½å™¨è¿”å›ç©ºç»“æœ'
            logger.error(f"åŸºçº¿æ–‡æ¡£ä¸‹è½½å¤±è´¥: {error_msg}")
            if workflow_state:
                workflow_state.add_log(f"âŒ ä¸‹è½½å¤±è´¥: {error_msg}", "ERROR")
                workflow_state.add_log("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆæˆ–ç½‘ç»œè¿æ¥", "WARNING")
            return None
        
        downloaded_file = result.get('file_path')
        if not downloaded_file or not os.path.exists(downloaded_file):
            logger.error("ä¸‹è½½çš„æ–‡ä»¶ä¸å­˜åœ¨")
            return None
        
        # ä»é…ç½®æ–‡ä»¶è·å–æ–‡æ¡£åç§°
        doc_name = "åŸºçº¿æ–‡æ¡£"
        doc_id = None  # åˆå§‹åŒ–doc_idå˜é‡

        # é¦–å…ˆä»URLæå–doc_idï¼ˆå‚è€ƒç›®æ ‡æ–‡æ¡£å‡½æ•°çš„æ­£ç¡®å®ç°ï¼‰
        try:
            from urllib.parse import urlparse
            parsed = urlparse(baseline_url)
            path_parts = parsed.path.split('/')
            if len(path_parts) > 2:
                # è…¾è®¯æ–‡æ¡£URLæ ¼å¼: https://docs.qq.com/sheet/XXXX
                doc_id = path_parts[-1]
                # å¤„ç†å¸¦å‚æ•°çš„æƒ…å†µï¼ˆå¦‚ ?tab=xxxï¼‰
                if '?' in doc_id:
                    doc_id = doc_id.split('?')[0]
                logger.info(f"ä»URLæå–çš„doc_id: {doc_id}")
        except Exception as e:
            logger.warning(f"æ— æ³•ä»URLæå–doc_id: {e}")

        try:
            # åŠ è½½æ–‡æ¡£é…ç½®
            import json
            config_file = '/root/projects/tencent-doc-manager/production/config/real_documents.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # æ ¹æ®URLæŸ¥æ‰¾æ–‡æ¡£å
            for doc in config.get('documents', []):
                if doc['url'] in baseline_url:
                    # ä½¿ç”¨ç®€åŒ–çš„æ–‡æ¡£åï¼ˆå»æ‰å‰ç¼€ï¼‰
                    full_name = doc['name']
                    # å»æ‰"å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-"å‰ç¼€
                    doc_name = full_name.replace('å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-', '').replace('æµ‹è¯•ç‰ˆæœ¬-', '')
                    logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡æ¡£å: {doc_name}")
                    break
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨ä»ä¸‹è½½æ–‡ä»¶åæå–çš„åç§°
                original_name = os.path.basename(downloaded_file)
                # ç§»é™¤æ—¶é—´æˆ³å’Œæ‰©å±•å
                doc_name_match = re.search(r'^(.+?)_\d{8}_\d{4}', original_name)
                if doc_name_match:
                    doc_name = doc_name_match.group(1)
                else:
                    # ä½¿ç”¨æ–‡ä»¶åçš„å‰éƒ¨åˆ†
                    doc_name = original_name.split('_')[0] if '_' in original_name else original_name.split('.')[0]
                logger.warning(f"æœªåœ¨é…ç½®ä¸­æ‰¾åˆ°æ–‡æ¡£ï¼Œä½¿ç”¨fallbackåç§°: {doc_name}")
        except Exception as e:
            logger.warning(f"æ— æ³•ä»é…ç½®è§£ææ–‡æ¡£å: {e}")

        # doc_idæ˜¯å¿…é¡»çš„ï¼Œå¦‚æœæ²¡æœ‰åˆ™æŠ¥é”™
        if not doc_id:
            logger.error("æ— æ³•ä»URLæå–doc_idï¼Œè¿™æ˜¯å¿…éœ€çš„")
            return None

        # æ¸…ç†doc_idä¸­å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦
        clean_doc_id = re.sub(r'[<>:"/\\|?*]', '', doc_id)

        # ç”Ÿæˆå”¯ä¸€è§„èŒƒæ–‡ä»¶å
        # æ ¼å¼: tencent_{doc_name}_{doc_id}_{YYYYMMDD_HHMM}_baseline_W{week}.csv
        timestamp = now.strftime("%Y%m%d_%H%M")
        normalized_name = f"tencent_{doc_name}_{clean_doc_id}_{timestamp}_baseline_W{target_week:02d}.csv"
        
        # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤å¯èƒ½çš„ç‰¹æ®Šå­—ç¬¦ï¼‰
        normalized_name = re.sub(r'[<>:"|?*]', '_', normalized_name)
        normalized_name = re.sub(r'_{2,}', '_', normalized_name)  # ç§»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
        
        # ç›®æ ‡æ–‡ä»¶è·¯å¾„
        target_path = baseline_dir / normalized_name
        
        # ç§»åŠ¨å¹¶é‡å‘½åæ–‡ä»¶
        shutil.move(downloaded_file, str(target_path))
        logger.info(f"åŸºçº¿æ–‡ä»¶å·²è§„èŒƒåŒ–å­˜å‚¨: {target_path}")
        
        return str(target_path)
        
    except Exception as e:
        logger.error(f"ä¸‹è½½å’Œå­˜å‚¨åŸºçº¿æ–‡ä»¶å¤±è´¥: {e}")
        return None

def download_and_store_target(target_url: str, cookie: str, week_manager=None, workflow_state=None):
    """
    ä¸‹è½½ç›®æ ‡æ–‡æ¡£å¹¶è§„èŒƒåŒ–å­˜å‚¨åˆ°å¯¹åº”çš„æ—¶é—´æ–‡ä»¶å¤¹ï¼ˆmidweek/weekendï¼‰

    Args:
        target_url: è…¾è®¯æ–‡æ¡£URL
        cookie: è®¤è¯cookie
        week_manager: å‘¨ç®¡ç†å™¨å®ä¾‹
        workflow_state: å·¥ä½œæµçŠ¶æ€å¯¹è±¡

    Returns:
        str: è§„èŒƒåŒ–åçš„æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    try:
        if not week_manager:
            logger.error("å‘¨ç®¡ç†å™¨æœªåˆå§‹åŒ–")
            return None

        # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
        exporter = TencentDocAutoExporter()

        if workflow_state:
            workflow_state.add_log("ğŸŒ å¼€å§‹ä¸‹è½½ç›®æ ‡æ–‡æ¡£...", "INFO")

        # ä¸‹è½½æ–‡æ¡£ - æ ¹æ®ä¸‹è½½å™¨ç±»å‹é€‰æ‹©æ¥å£
        if hasattr(exporter, 'download'):
            # PlaywrightDownloaderæ¥å£ï¼ˆå¼‚æ­¥ï¼‰
            import asyncio
            result = asyncio.run(exporter.download(target_url, cookies=cookie, format='csv'))
        else:
            # TencentDocAutoExporteræ¥å£ï¼ˆåŒæ­¥ï¼‰
            result = exporter.export_document(target_url, cookies=cookie, format='csv')

        if not result or not result.get('success'):
            logger.error(f"ç›®æ ‡æ–‡æ¡£ä¸‹è½½å¤±è´¥: {result.get('error') if result else 'æœªçŸ¥é”™è¯¯'}")
            return None

        downloaded_file = result.get('file_path')
        if not os.path.exists(downloaded_file):
            logger.error(f"ä¸‹è½½çš„æ–‡ä»¶ä¸å­˜åœ¨: {downloaded_file}")
            return None

        # ä»é…ç½®æ–‡ä»¶è·å–æ–‡æ¡£åï¼Œå¹¶æå–doc_id
        doc_name = 'target_doc'
        doc_id = None

        # ä»URLæå–doc_id
        try:
            from urllib.parse import urlparse
            parsed = urlparse(target_url)
            path_parts = parsed.path.split('/')
            if len(path_parts) > 2:
                # è…¾è®¯æ–‡æ¡£URLæ ¼å¼: https://docs.qq.com/sheet/XXXX
                doc_id = path_parts[-1]
                # å¤„ç†å¸¦å‚æ•°çš„æƒ…å†µï¼ˆå¦‚ ?tab=xxxï¼‰
                if '?' in doc_id:
                    doc_id = doc_id.split('?')[0]
                logger.info(f"ä»URLæå–çš„doc_id: {doc_id}")
        except Exception as e:
            logger.warning(f"æ— æ³•ä»URLæå–doc_id: {e}")

        try:
            # åŠ è½½æ–‡æ¡£é…ç½®
            import json
            config_file = '/root/projects/tencent-doc-manager/config/download_config.json'
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # æ ¹æ®URLæŸ¥æ‰¾æ–‡æ¡£åï¼ˆä½¿ç”¨download_config.jsonä»¥ä¿æŒä¸€è‡´æ€§ï¼‰
            for doc in config.get('document_links', []):
                if doc['url'] in target_url or target_url in doc['url']:
                    # ä½¿ç”¨ç®€åŒ–çš„æ–‡æ¡£åï¼ˆå»æ‰å‰ç¼€ï¼‰
                    full_name = doc['name']
                    # å»æ‰"å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-"å‰ç¼€
                    doc_name = full_name.replace('å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-', '').replace('æµ‹è¯•ç‰ˆæœ¬-', '')
                    logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡æ¡£å: {doc_name}")
                    break
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œfallbackåˆ°ä»URLæå–
                if len(path_parts) > 1:
                    doc_name = path_parts[-1] or path_parts[-2]
                logger.warning(f"æœªåœ¨é…ç½®ä¸­æ‰¾åˆ°æ–‡æ¡£ï¼Œä½¿ç”¨URLæå–çš„åç§°: {doc_name}")
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£åå¤±è´¥: {e}")
            pass

        # è·å–å½“å‰æ—¶é—´ä¿¡æ¯
        now = datetime.now()
        weekday = now.weekday()
        hour = now.hour

        # åˆ¤æ–­ç‰ˆæœ¬ç±»å‹ï¼ˆæ ¹æ®WeekTimeManagerçš„é€»è¾‘ï¼‰
        if weekday == 5 and hour >= 19:  # å‘¨å…­æ™šä¸Š7ç‚¹å
            version_type = "weekend"
        else:
            version_type = "midweek"

        if workflow_state:
            workflow_state.add_log(f"ğŸ“ ç›®æ ‡æ–‡æ¡£å°†å­˜å‚¨ä¸º{version_type}ç‰ˆæœ¬", "INFO")

        # è·å–å‘¨ä¿¡æ¯å’Œç›®å½•
        week_info = week_manager.get_current_week_info()
        current_week = week_info['week_number']
        week_dirs = week_manager.get_week_directory(week_info['year'], current_week)

        # è·å–ç›®æ ‡ç›®å½•
        target_dir = week_dirs / version_type
        target_dir.mkdir(parents=True, exist_ok=True)

        # doc_idæ˜¯å¿…é¡»çš„ï¼Œå¦‚æœæ²¡æœ‰åˆ™æŠ¥é”™
        if not doc_id:
            logger.error("æ— æ³•ä»URLæå–doc_idï¼Œè¿™æ˜¯å¿…éœ€çš„")
            if workflow_state:
                workflow_state.add_log("âŒ æ— æ³•ä»URLæå–doc_id", "ERROR")
            return None

        # ç”Ÿæˆè§„èŒƒåŒ–æ–‡ä»¶åï¼ˆåŒ…å«doc_idï¼‰
        file_extension = os.path.splitext(downloaded_file)[1].lstrip('.') or 'csv'
        target_filename = week_manager.generate_filename(
            doc_name=doc_name,
            file_time=now,
            version_type=version_type,
            week_number=current_week,
            file_extension=file_extension,
            doc_id=doc_id  # ä¼ é€’doc_idå‚æ•°
        )

        # ç›®æ ‡è·¯å¾„
        target_path = target_dir / target_filename

        # ç§»åŠ¨å¹¶é‡å‘½åæ–‡ä»¶
        shutil.move(downloaded_file, str(target_path))
        logger.info(f"ç›®æ ‡æ–‡ä»¶å·²è§„èŒƒåŒ–å­˜å‚¨: {target_path}")

        if workflow_state:
            workflow_state.add_log(f"âœ… ç›®æ ‡æ–‡æ¡£å·²å­˜å‚¨åˆ°{version_type}æ–‡ä»¶å¤¹: {target_filename}", "INFO")

        return str(target_path)

    except Exception as e:
        logger.error(f"ä¸‹è½½å’Œå­˜å‚¨ç›®æ ‡æ–‡ä»¶å¤±è´¥: {e}")
        if workflow_state:
            workflow_state.add_log(f"âŒ ç›®æ ‡æ–‡æ¡£å­˜å‚¨å¤±è´¥: {str(e)}", "ERROR")
        return None

# ==================== æ ¸å¿ƒå·¥ä½œæµå‡½æ•° ====================
def run_complete_workflow(baseline_url: str, target_url: str, cookie: str, advanced_settings: dict = None, skip_reset: bool = False):
    """
    æ‰§è¡Œå®Œæ•´çš„å·¥ä½œæµç¨‹ï¼ˆå¢å¼ºç‰ˆï¼‰

    Args:
        baseline_url: åŸºçº¿æ–‡æ¡£URL
        target_url: ç›®æ ‡æ–‡æ¡£URL
        cookie: è…¾è®¯æ–‡æ¡£cookie
        advanced_settings: é«˜çº§è®¾ç½®
        skip_reset: æ˜¯å¦è·³è¿‡çŠ¶æ€é‡ç½®ï¼ˆæ‰¹é‡å¤„ç†æ—¶ä½¿ç”¨ï¼‰
    """
    try:
        # æ‰¹é‡å¤„ç†æ—¶ä¸é‡ç½®çŠ¶æ€
        if not skip_reset:
            workflow_state.reset()
            workflow_state.status = "running"
            workflow_state.start_time = datetime.now()
            workflow_state.execution_id = datetime.now().strftime("%Y%m%d_%H%M%S")

        workflow_state.advanced_settings = advanced_settings or {}
        
        # ========== æ­¥éª¤1: è·å–åŸºçº¿æ–‡ä»¶ ==========
        workflow_state.update_progress("è·å–åŸºçº¿æ–‡æ¡£", 10)
        workflow_state.add_log("å¼€å§‹è·å–åŸºçº¿æ–‡æ¡£...")

        # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦åº”è¯¥ä¸‹è½½åŸºçº¿
        weekday = datetime.now().weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ
        hour = datetime.now().hour

        # åªæœ‰å‘¨äºŒ12ç‚¹ååˆ°å‘¨ä¸‰12ç‚¹å‰æ‰åº”è¯¥åˆ›å»ºæ–°åŸºçº¿
        should_download_baseline = (weekday == 1 and hour >= 12) or (weekday == 2 and hour < 12)

        # å¦‚æœç”¨æˆ·æ²¡æœ‰æ˜ç¡®æŒ‡å®šï¼Œä½¿ç”¨æ™ºèƒ½é»˜è®¤å€¼
        if 'force_download' not in advanced_settings:
            force_download = should_download_baseline
            workflow_state.add_log(f"ğŸ“Š åŸºçº¿ç­–ç•¥: {'åˆ›å»ºæ–°åŸºçº¿' if force_download else 'ä½¿ç”¨å·²æœ‰åŸºçº¿'} (è‡ªåŠ¨åˆ¤æ–­)", "INFO")
            workflow_state.add_log(f"ğŸ“… å½“å‰æ—¶é—´: å‘¨{weekday+1} {hour:02d}:00", "INFO")
        else:
            force_download = advanced_settings.get('force_download', False)
            workflow_state.add_log(f"ğŸ“Š åŸºçº¿ç­–ç•¥: {'åˆ›å»ºæ–°åŸºçº¿' if force_download else 'ä½¿ç”¨å·²æœ‰åŸºçº¿'} (æ‰‹åŠ¨æŒ‡å®š)", "INFO")

        # åŸºçº¿ä½¿ç”¨ç­–ç•¥ä¸ä¸‹è½½ç›¸å
        use_existing_baseline = not force_download

        baseline_file = None

        # å¦‚æœbaseline_urlä¸ºNoneæˆ–use_existing_baselineä¸ºTrueï¼Œå¿…é¡»ä½¿ç”¨ç°æœ‰åŸºçº¿
        if baseline_url is None or use_existing_baseline:
            workflow_state.add_log("ğŸ“‚ åˆ·æ–°æ¨¡å¼ï¼šä½¿ç”¨ç°æœ‰åŸºçº¿æ–‡ä»¶")
            if MODULES_STATUS.get('week_manager') and week_manager:
                try:
                    baseline_files, baseline_desc = week_manager.find_baseline_files()
                    if baseline_files:
                        # ä»ç›®æ ‡URLæå–doc_idä»¥åŒ¹é…æ­£ç¡®çš„åŸºçº¿
                        target_doc_id = None
                        if target_url:
                            # ä»URLæå–doc_id
                            target_doc_id = target_url.split('/')[-1].split('?')[0]
                            workflow_state.add_log(f"ğŸ“ ç›®æ ‡æ–‡æ¡£ID: {target_doc_id}")

                        # æ ¹æ®doc_idåŒ¹é…åŸºçº¿æ–‡ä»¶
                        matched_baseline = None
                        if target_doc_id:
                            for baseline in baseline_files:
                                basename = os.path.basename(baseline)
                                # ä½¿ç”¨doc_idåŒ¹é…
                                baseline_doc_id = extract_doc_id_from_filename(baseline)
                                if baseline_doc_id and baseline_doc_id == target_doc_id:
                                    matched_baseline = baseline
                                    workflow_state.add_log(f"âœ… åŒ¹é…åŸºçº¿: {basename} (doc_id: {baseline_doc_id})")
                                    break

                        if matched_baseline:
                            baseline_file = matched_baseline
                            workflow_state.baseline_file = baseline_file
                            workflow_state.add_log(f"âœ… æ‰¾åˆ°åŒ¹é…çš„åŸºçº¿æ–‡ä»¶: {os.path.basename(baseline_file)}")
                            workflow_state.add_log(f"ğŸ“Š åŸºçº¿æè¿°: {baseline_desc}")
                        else:
                            workflow_state.add_log(f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„åŸºçº¿æ–‡ä»¶ï¼", "ERROR")
                            workflow_state.add_log(f"ğŸ“Š ç›®æ ‡doc_id: {target_doc_id}", "ERROR")
                            workflow_state.add_log(f"ğŸ“Š å¯ç”¨åŸºçº¿: {', '.join([os.path.basename(f) for f in baseline_files])}", "ERROR")

                            # æ˜¾ç¤ºå¯ç”¨åŸºçº¿çš„doc_id
                            available_doc_ids = []
                            for f in baseline_files:
                                doc_id = extract_doc_id_from_filename(f)
                                if doc_id:
                                    available_doc_ids.append(f"{os.path.basename(f)} (doc_id: {doc_id})")
                            if available_doc_ids:
                                workflow_state.add_log(f"ğŸ“Š å¯ç”¨åŸºçº¿doc_ids: {', '.join(available_doc_ids)}", "ERROR")

                            raise Exception(f"æœªæ‰¾åˆ°ä¸doc_id '{target_doc_id}'åŒ¹é…çš„åŸºçº¿æ–‡ä»¶ï¼Œè¯·å…ˆä¸‹è½½å¯¹åº”çš„åŸºçº¿")
                    else:
                        workflow_state.add_log("âŒ æœªæ‰¾åˆ°åŸºçº¿æ–‡ä»¶ï¼Œè¯·å…ˆä¸‹è½½åŸºçº¿", "ERROR")
                        raise Exception("æœªæ‰¾åˆ°åŸºçº¿æ–‡ä»¶ï¼Œè¯·å…ˆä¸‹è½½åŸºçº¿")
                except Exception as e:
                    workflow_state.add_log(f"âŒ åŸºçº¿æ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {str(e)}", "ERROR")
                    raise
            else:
                workflow_state.add_log("âŒ å‘¨ç®¡ç†å™¨æœªåŠ è½½ï¼Œæ— æ³•æŸ¥æ‰¾åŸºçº¿", "ERROR")
                raise Exception("å‘¨ç®¡ç†å™¨æœªåŠ è½½ï¼Œæ— æ³•æŸ¥æ‰¾åŸºçº¿æ–‡ä»¶")

        # å¦‚æœæœ‰baseline_urlï¼Œæ ¹æ®force_downloadå†³å®šæ˜¯å¦ä¸‹è½½
        elif baseline_url:
            # å¦‚æœä¸å¼ºåˆ¶ä¸‹è½½ï¼Œä¼˜å…ˆå°è¯•ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
            if not force_download and MODULES_STATUS.get('week_manager') and week_manager:
                try:
                    baseline_files, baseline_desc = week_manager.find_baseline_files()
                    if baseline_files:
                        # ä»ç›®æ ‡URLæå–doc_idä»¥åŒ¹é…æ­£ç¡®çš„åŸºçº¿
                        target_doc_id = None
                        if target_url:
                            # ä»URLæå–doc_id
                            target_doc_id = target_url.split('/')[-1].split('?')[0]
                            workflow_state.add_log(f"ğŸ“ ç›®æ ‡æ–‡æ¡£ID: {target_doc_id}")

                        # æ ¹æ®doc_idåŒ¹é…åŸºçº¿æ–‡ä»¶
                        matched_baseline = None
                        if target_doc_id:
                            for baseline in baseline_files:
                                basename = os.path.basename(baseline)
                                # ä½¿ç”¨doc_idåŒ¹é…
                                baseline_doc_id = extract_doc_id_from_filename(baseline)
                                if baseline_doc_id and baseline_doc_id == target_doc_id:
                                    matched_baseline = baseline
                                    workflow_state.add_log(f"âœ… åŒ¹é…åŸºçº¿: {basename} (doc_id: {baseline_doc_id})")
                                    break

                        # ç®€åŒ–é€»è¾‘ï¼šæ‰¾åˆ°å°±ç”¨ï¼Œæ²¡æ‰¾åˆ°ç›´æ¥æŠ¥é”™
                        if matched_baseline:
                            baseline_file = matched_baseline
                            workflow_state.baseline_file = baseline_file
                            workflow_state.add_log(f"âœ… ä½¿ç”¨æœ¬åœ°åŸºçº¿æ–‡ä»¶: {os.path.basename(baseline_file)}")
                        else:
                            # æ²¡æœ‰åŒ¹é…çš„åŸºçº¿ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
                            error_msg = f"âŒ æœªæ‰¾åˆ°åŒ¹é…çš„åŸºçº¿æ–‡ä»¶ (doc_id: {target_doc_id})"
                            workflow_state.add_log(error_msg, "ERROR")

                            # åˆ—å‡ºå¯ç”¨çš„åŸºçº¿æ–‡ä»¶å¸®åŠ©è°ƒè¯•
                            available_files = [os.path.basename(f) for f in baseline_files]
                            if available_files:
                                workflow_state.add_log(f"å¯ç”¨åŸºçº¿æ–‡ä»¶: {', '.join(available_files)}", "INFO")

                            raise Exception(error_msg)
                except Exception as e:
                    workflow_state.add_log(f"âš ï¸ æœ¬åœ°æ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {str(e)}", "WARNING")
            elif force_download:
                workflow_state.add_log("ğŸ”„ å¼ºåˆ¶ä¸‹è½½æ¨¡å¼ï¼šè·³è¿‡æœ¬åœ°æ–‡ä»¶æ£€æŸ¥")

            # å¦‚æœæœ¬åœ°æ²¡æœ‰åŸºçº¿æ–‡ä»¶ï¼Œåˆ™ä¸‹è½½å¹¶è§„èŒƒåŒ–å­˜å‚¨
            if not baseline_file:
                if MODULES_STATUS.get('downloader'):
                    workflow_state.add_log("å¼€å§‹ä¸‹è½½åŸºçº¿æ–‡æ¡£å¹¶è§„èŒƒåŒ–å­˜å‚¨...")

                    # ä¸‹è½½åŸºçº¿æ–‡æ¡£åˆ°è§„èŒƒä½ç½®
                    baseline_file = download_and_store_baseline(
                        baseline_url=baseline_url,
                        cookie=cookie,
                        week_manager=week_manager,
                        workflow_state=workflow_state
                    )

                    if baseline_file:
                        workflow_state.baseline_file = baseline_file
                        workflow_state.add_log(f"âœ… åŸºçº¿æ–‡æ¡£ä¸‹è½½å¹¶è§„èŒƒåŒ–å­˜å‚¨æˆåŠŸ: {os.path.basename(baseline_file)}")
                    else:
                        raise Exception("åŸºçº¿æ–‡æ¡£ä¸‹è½½æˆ–å­˜å‚¨å¤±è´¥")
                else:
                    # ä¸å…è®¸é™çº§ï¼Œå¿…é¡»æœ‰ä¸‹è½½æ¨¡å—
                    workflow_state.add_log("âŒ ä¸‹è½½æ¨¡å—æœªåŠ è½½", "ERROR")
                    raise Exception("ä¸‹è½½æ¨¡å—æœªåŠ è½½ï¼Œæ— æ³•ç»§ç»­")
        
        # ========== æ­¥éª¤2: è·å–ç›®æ ‡æ–‡ä»¶ ==========
        workflow_state.update_progress("è·å–ç›®æ ‡æ–‡æ¡£", 20)
        workflow_state.add_log("å¼€å§‹è·å–ç›®æ ‡æ–‡æ¡£...")

        # åœ¨åˆ·æ–°æ¨¡å¼ä¸‹ï¼Œæ€»æ˜¯ä¸‹è½½æ–°çš„ç›®æ ‡æ–‡ä»¶
        target_file = None
        should_download_target = True  # é»˜è®¤æ€»æ˜¯ä¸‹è½½æ–°æ–‡ä»¶

        # ä»…åœ¨æ˜ç¡®è®¾ç½®ä¸ä¸‹è½½æ—¶æ‰ä½¿ç”¨æœ¬åœ°æ–‡ä»¶
        if advanced_settings and advanced_settings.get('use_cached_target', False):
            should_download_target = False
            if MODULES_STATUS.get('week_manager') and week_manager:
                try:
                    target_files = week_manager.find_target_files()
                    if target_files:
                        target_file = target_files[0]  # ä½¿ç”¨æœ€æ–°çš„ç›®æ ‡æ–‡ä»¶
                        workflow_state.target_file = target_file
                        workflow_state.add_log(f"ğŸ“ ä½¿ç”¨ç¼“å­˜ç›®æ ‡æ–‡ä»¶: {os.path.basename(target_file)}")
                except Exception as e:
                    workflow_state.add_log(f"âš ï¸ æœ¬åœ°æ–‡ä»¶æŸ¥æ‰¾å¤±è´¥: {str(e)}", "WARNING")
        else:
            workflow_state.add_log("ğŸ”„ åˆ·æ–°æ¨¡å¼ï¼šå°†ä¸‹è½½æœ€æ–°ç›®æ ‡æ–‡æ¡£")
        
        # å¦‚æœæœ¬åœ°æ²¡æœ‰ç›®æ ‡æ–‡ä»¶ï¼Œåˆ™ä¸‹è½½å¹¶è§„èŒƒåŒ–å­˜å‚¨
        if not target_file:
            if MODULES_STATUS.get('downloader'):
                workflow_state.add_log("å¼€å§‹ä¸‹è½½ç›®æ ‡æ–‡æ¡£å¹¶è§„èŒƒåŒ–å­˜å‚¨...")

                # ä½¿ç”¨æ–°çš„è§„èŒƒåŒ–å­˜å‚¨å‡½æ•°
                target_file = download_and_store_target(
                    target_url=target_url,
                    cookie=cookie,
                    week_manager=week_manager,
                    workflow_state=workflow_state
                )

                if target_file:
                    workflow_state.target_file = target_file
                    workflow_state.add_log(f"âœ… ç›®æ ‡æ–‡æ¡£ä¸‹è½½å¹¶è§„èŒƒåŒ–å­˜å‚¨æˆåŠŸ: {os.path.basename(target_file)}")
                else:
                    # è¾“å‡ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    workflow_state.add_log(f"âŒ ç›®æ ‡æ–‡æ¡£ä¸‹è½½æˆ–å­˜å‚¨å¤±è´¥", "ERROR")
                    workflow_state.add_log(f"ç›®æ ‡URL: {target_url}", "ERROR")
                    workflow_state.add_log("ğŸ’¡ æç¤º: è¯·æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆæˆ–ç½‘ç»œè¿æ¥", "WARNING")
                    raise Exception("ç›®æ ‡æ–‡æ¡£ä¸‹è½½æˆ–å­˜å‚¨å¤±è´¥")
            else:
                workflow_state.target_file = str(DOWNLOAD_DIR / "test_target.csv")
                workflow_state.add_log("âš ï¸ ä¸‹è½½æ¨¡å—æœªåŠ è½½ï¼Œä½¿ç”¨æµ‹è¯•æ–‡ä»¶", "WARNING")
        
        # ========== æ­¥éª¤2.5: æ–‡æ¡£åŒ¹é…é¢„éªŒè¯ ==========
        workflow_state.add_log("éªŒè¯æ–‡æ¡£åŒ¹é…æ€§...")

        # ä»æ–‡ä»¶åæå–æ–‡æ¡£åç§°è¿›è¡ŒåŒ¹é…éªŒè¯
        if workflow_state.baseline_file and workflow_state.target_file:
            baseline_doc_name = extract_doc_name_from_filename(workflow_state.baseline_file)
            target_doc_name = extract_doc_name_from_filename(workflow_state.target_file)

            if baseline_doc_name and target_doc_name:
                if baseline_doc_name != target_doc_name:
                    workflow_state.add_log(f"âš ï¸ è­¦å‘Šï¼šåŸºçº¿æ–‡æ¡£å’Œç›®æ ‡æ–‡æ¡£å¯èƒ½ä¸åŒ¹é…ï¼", "WARNING")
                    workflow_state.add_log(f"ğŸ“Š åŸºçº¿æ–‡æ¡£: {baseline_doc_name}", "WARNING")
                    workflow_state.add_log(f"ğŸ“Š ç›®æ ‡æ–‡æ¡£: {target_doc_name}", "WARNING")

                    # å¦‚æœæ–‡æ¡£ä¸åŒ¹é…ä¸”å˜æ›´æ•°é‡è¿‡å¤§ï¼Œåº”è¯¥æŠ¥é”™
                    # è¿™å°†åœ¨å¯¹æ¯”åéªŒè¯
                else:
                    workflow_state.add_log(f"âœ… æ–‡æ¡£åŒ¹é…éªŒè¯é€šè¿‡: {baseline_doc_name}")
            else:
                workflow_state.add_log("âš ï¸ æ— æ³•ä»æ–‡ä»¶åæå–æ–‡æ¡£åè¿›è¡ŒéªŒè¯", "WARNING")

        # ========== æ­¥éª¤3: CSVå¯¹æ¯”åˆ†æ ==========
        workflow_state.update_progress("æ‰§è¡ŒCSVå¯¹æ¯”åˆ†æ", 30)

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°åŸºçº¿æƒ…å†µ
        if hasattr(workflow_state, 'is_new_baseline') and workflow_state.is_new_baseline:
            workflow_state.add_log("ğŸ†• è¿™æ˜¯æ–°åŸºçº¿ï¼Œå°†ç›®æ ‡æ–‡æ¡£ä¿å­˜ä¸ºåŸºçº¿...")

            # å°†ç›®æ ‡æ–‡ä»¶å¤åˆ¶ä¸ºåŸºçº¿
            import shutil
            if workflow_state.target_file:
                # ä½¿ç”¨WeekTimeManageråŠ¨æ€è·å–å½“å‰å‘¨çš„åŸºçº¿ç›®å½•è·¯å¾„
                if MODULES_STATUS.get('week_manager') and week_manager:
                    current_year, current_week = week_manager.get_week_info()[0:2]
                    week_dir = week_manager.get_week_directory(current_year, current_week)
                    baseline_dir = week_dir / "baseline"
                else:
                    # é™çº§æ–¹æ¡ˆï¼šå¦‚æœweek_managerä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
                    current_year = datetime.datetime.now().year
                    current_week = datetime.datetime.now().isocalendar()[1]
                    baseline_dir = Path(f'/root/projects/tencent-doc-manager/csv_versions/{current_year}_W{current_week:02d}/baseline')

                baseline_dir.mkdir(parents=True, exist_ok=True)

                # ä»ç›®æ ‡æ–‡ä»¶åç”ŸæˆåŸºçº¿æ–‡ä»¶å
                target_name = Path(workflow_state.target_file).name
                baseline_name = target_name.replace('_midweek_', '_baseline_')
                baseline_path = baseline_dir / baseline_name

                # å¤åˆ¶æ–‡ä»¶
                shutil.copy2(workflow_state.target_file, baseline_path)
                workflow_state.baseline_file = str(baseline_path)
                workflow_state.add_log(f"âœ… åŸºçº¿æ–‡ä»¶å·²åˆ›å»º: {baseline_name}")

            # ç”Ÿæˆç©ºçš„å¯¹æ¯”ç»“æœï¼ˆæ‰€æœ‰ä¿®æ”¹ä¸º0ï¼‰
            comparison_result = {
                "statistics": {
                    "total_modifications": 0,
                    "added_rows": 0,
                    "deleted_rows": 0,
                    "modified_rows": 0
                },
                "modifications": [],
                "added": [],
                "deleted": [],
                "message": "æ–°åŸºçº¿åˆ›å»ºï¼Œæ— ä¿®æ”¹å†…å®¹"
            }
            workflow_state.add_log("âœ… å¯¹æ¯”åˆ†æå®Œæˆï¼Œå‘ç° 0 å¤„å˜æ›´ï¼ˆæ–°åŸºçº¿ï¼‰")

        else:
            workflow_state.add_log("å¼€å§‹å¯¹æ¯”åˆ†æ...")
            comparison_result = None
            if MODULES_STATUS.get('comparator'):
                # ä½¿ç”¨ç»Ÿä¸€CSVå¯¹æ¯”å™¨ï¼ˆæ ¹æ®è§„èŒƒè¦æ±‚ï¼‰
                unified_comparator = UnifiedCSVComparator()

                # ç›´æ¥å¯¹æ¯”CSVæ–‡ä»¶
                comparison_result = unified_comparator.compare(
                    workflow_state.baseline_file,
                    workflow_state.target_file
                )

                # è·å–å˜æ›´æ•°é‡
                num_changes = comparison_result.get('statistics', {}).get('total_modifications', 0)
                workflow_state.add_log(f"âœ… å¯¹æ¯”åˆ†æå®Œæˆï¼Œå‘ç° {num_changes} å¤„å˜æ›´")

        # ä¿å­˜å¯¹æ¯”ç»“æœï¼ˆæ–°åŸºçº¿å’Œå·²æœ‰åŸºçº¿éƒ½éœ€è¦ä¿å­˜ï¼‰
        if comparison_result:
            import json  # ç¡®ä¿jsonæ¨¡å—å·²å¯¼å…¥
            comparison_file = COMPARISON_RESULTS_DIR / f"comparison_{workflow_state.execution_id}.json"
            with open(comparison_file, 'w', encoding='utf-8') as f:
                json.dump(comparison_result, f, ensure_ascii=False, indent=2)

            # å˜æ›´æ•°é‡å¼‚å¸¸æ£€æµ‹ï¼ˆæŠ€æœ¯è§„èŒƒv1.6ï¼‰
            num_changes = comparison_result.get('statistics', {}).get('total_modifications', 0)
            if num_changes > 500:
                workflow_state.add_log(f"âš ï¸ è­¦å‘Šï¼šå˜æ›´æ•°é‡å¼‚å¸¸è¿‡å¤§({num_changes})ï¼", "WARNING")
                workflow_state.add_log("âš ï¸ è¿™é€šå¸¸è¡¨ç¤ºå¯¹æ¯”äº†ä¸åŒçš„æ–‡æ¡£ï¼Œè¯·éªŒè¯æ–‡æ¡£åŒ¹é…æ€§", "WARNING")

                # å†æ¬¡æ£€æŸ¥æ–‡æ¡£åç§°
                if workflow_state.baseline_file and workflow_state.target_file:
                    baseline_doc_name = extract_doc_name_from_filename(workflow_state.baseline_file)
                    target_doc_name = extract_doc_name_from_filename(workflow_state.target_file)
                    if baseline_doc_name != target_doc_name:
                        workflow_state.add_log(f"âŒ é”™è¯¯ï¼šåŸºçº¿({baseline_doc_name})ä¸ç›®æ ‡({target_doc_name})æ–‡æ¡£ä¸åŒ¹é…ï¼", "ERROR")
                        raise Exception(f"æ–‡æ¡£ä¸åŒ¹é…ï¼šåŸºçº¿æ˜¯'{baseline_doc_name}'ï¼Œç›®æ ‡æ˜¯'{target_doc_name}'ï¼Œè¯·ä½¿ç”¨ç›¸åŒæ–‡æ¡£çš„ä¸åŒç‰ˆæœ¬è¿›è¡Œå¯¹æ¯”")
        else:
            workflow_state.add_log("âš ï¸ æ¯”è¾ƒæ¨¡å—æœªåŠ è½½ï¼Œè·³è¿‡", "WARNING")
        
        # ========== æ­¥éª¤4: åˆ—æ ‡å‡†åŒ–ï¼ˆä½¿ç”¨V3ç‰ˆæœ¬ï¼‰ ==========
        workflow_state.update_progress("åˆ—æ ‡å‡†åŒ–å¤„ç†", 40)
        workflow_state.add_log("å¼€å§‹åˆ—æ ‡å‡†åŒ–...")
        
        standardized_result = None
        if MODULES_STATUS.get('standardizer') and comparison_result:
            try:
                # ä¼˜å…ˆä½¿ç”¨V3ç‰ˆæœ¬
                if MODULES_STATUS.get('standardizer_v3'):
                    # è·å–DeepSeek APIå¯†é’¥
                    api_key = os.getenv('DEEPSEEK_API_KEY')
                    if not api_key:
                        workflow_state.add_log("âš ï¸ DeepSeek APIå¯†é’¥æœªé…ç½®ï¼Œä½¿ç”¨ç®€åŒ–æ ‡å‡†åŒ–", "WARNING")
                        standardized_result = comparison_result  # ç›´æ¥ä½¿ç”¨åŸå§‹ç»“æœ
                    else:
                        processor = ColumnStandardizationProcessorV3(api_key)
                        # æå–ä¿®æ”¹åˆ—å¹¶è¿›è¡Œæ ‡å‡†åŒ–
                        if 'modified_columns' in comparison_result:
                            import asyncio
                            column_mapping = comparison_result.get('modified_columns', {})
                            # å¼‚æ­¥è°ƒç”¨æ ‡å‡†åŒ–
                            loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(loop)
                            standardized_mapping = loop.run_until_complete(
                                processor.standardize_column_names(column_mapping)
                            )
                            loop.close()
                            
                            # åº”ç”¨æ ‡å‡†åŒ–ç»“æœ
                            standardized_result = comparison_result.copy()
                            standardized_result['standardized_columns'] = standardized_mapping
                            workflow_state.add_log(f"âœ… åˆ—æ ‡å‡†åŒ–V3å®Œæˆï¼Œæ ‡å‡†åŒ–äº† {len(standardized_mapping)} ä¸ªåˆ—")
                        else:
                            standardized_result = comparison_result
                            workflow_state.add_log("âš ï¸ æ— ä¿®æ”¹åˆ—éœ€è¦æ ‡å‡†åŒ–", "WARNING")
                else:
                    # ä½¿ç”¨æ—§ç‰ˆæœ¬
                    from production.core_modules.column_standardization_prompt import ColumnStandardizationPrompt
                    standardizer = ColumnStandardizationPrompt()
                    
                    # æå–åˆ—åè¿›è¡Œæ ‡å‡†åŒ–
                    if workflow_state.baseline_file and workflow_state.target_file:
                        # è¯»å–æ–‡ä»¶è·å–åˆ—å
                        with open(workflow_state.baseline_file, 'r', encoding='utf-8') as f:
                            baseline_headers = csv.reader(f).__next__()
                        with open(workflow_state.target_file, 'r', encoding='utf-8') as f:
                            target_headers = csv.reader(f).__next__()
                        
                        # è°ƒç”¨æ ‡å‡†åŒ–ï¼ˆè¿™é‡Œå¯èƒ½éœ€è¦AIï¼Œä½†æˆ‘ä»¬ä½¿ç”¨è§„åˆ™åŸºç¡€æ–¹æ³•ï¼‰
                        standardized_result = {
                            'baseline_headers': baseline_headers,
                            'target_headers': target_headers,
                            'mapping': dict(zip(target_headers, baseline_headers[:len(target_headers)]))
                        }
                        workflow_state.add_log(f"âš ï¸ ä½¿ç”¨æ—§ç‰ˆåˆ—æ ‡å‡†åŒ–ï¼Œæ˜ å°„äº† {len(standardized_result['mapping'])} ä¸ªåˆ—", "WARNING")
            except Exception as e:
                workflow_state.add_log(f"âš ï¸ åˆ—æ ‡å‡†åŒ–å‡ºé”™: {str(e)}", "WARNING")
        else:
            workflow_state.add_log("âš ï¸ æ ‡å‡†åŒ–æ¨¡å—æœªåŠ è½½æˆ–æ— å¯¹æ¯”ç»“æœ", "WARNING")
        
        # ========== æ­¥éª¤5: L2è¯­ä¹‰åˆ†æ + L1L3è§„åˆ™æ‰“åˆ† ==========
        workflow_state.update_progress("è¯­ä¹‰åˆ†æå’Œæ‰“åˆ†", 50)
        workflow_state.add_log("å¼€å§‹L2è¯­ä¹‰åˆ†æå’ŒL1L3è§„åˆ™æ‰“åˆ†...")
        
        semantic_scores = None
        if MODULES_STATUS.get('l2_analyzer') and comparison_result:
            try:
                from production.core_modules.l2_semantic_analysis_two_layer import L2SemanticAnalyzer
                analyzer = L2SemanticAnalyzer()
                
                # å‡†å¤‡ä¿®æ”¹æ•°æ®æ ¼å¼ï¼ˆå…¼å®¹UnifiedCSVComparatorçš„è¾“å‡ºï¼‰
                modifications = []
                # UnifiedCSVComparatorä½¿ç”¨'modifications'è€Œä¸æ˜¯'changes'
                if comparison_result and 'modifications' in comparison_result:
                    for change in comparison_result['modifications']:
                        # ä»å•å…ƒæ ¼åœ°å€æå–è¡Œå·
                        cell = change.get('cell', 'A1')
                        row_num = int(''.join(filter(str.isdigit, cell))) if any(c.isdigit() for c in cell) else 0
                        
                        modifications.append({
                            'column_name': cell[0] if cell else '',
                            'old_value': change.get('old', ''),
                            'new_value': change.get('new', ''),
                            'row': row_num,
                            'cell': cell
                        })
                
                # æ‰§è¡Œè¯­ä¹‰åˆ†æï¼ˆä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•åï¼‰
                semantic_scores = analyzer.analyze_modifications(modifications)
                workflow_state.add_log(f"âœ… è¯­ä¹‰åˆ†æå®Œæˆï¼Œåˆ†æäº† {len(modifications)} å¤„å˜æ›´")
            except Exception as e:
                workflow_state.add_log(f"âŒ è¯­ä¹‰åˆ†æå¤±è´¥: {str(e)}", "ERROR")
                raise  # ä¸å…è®¸é™çº§ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
        
        # ========== æ­¥éª¤6: ç”Ÿæˆè¯¦ç»†æ‰“åˆ†JSON ==========
        workflow_state.update_progress("ç”Ÿæˆè¯¦ç»†æ‰“åˆ†", 60)
        workflow_state.add_log("ç”Ÿæˆè¯¦ç»†æ‰“åˆ†JSON...")

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°åŸºçº¿æƒ…å†µ
        if hasattr(workflow_state, 'is_new_baseline') and workflow_state.is_new_baseline:
            # ä¸ºæ–°åŸºçº¿ç”Ÿæˆç©ºçš„æ‰“åˆ†ç»“æœ
            import tempfile
            score_file_name = f"detailed_score_newbaseline_{workflow_state.execution_id}.json"
            score_file_path = str(SCORING_RESULTS_DIR / 'detailed' / score_file_name)

            # åˆ›å»ºç©ºçš„æ‰“åˆ†ç»“æœ
            empty_score = {
                "metadata": {
                    "table_name": f"newbaseline_{workflow_state.execution_id}",
                    "source_file": str(workflow_state.target_file),
                    "scoring_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "total_modifications": 0,
                    "scoring_version": "v1.0",
                    "is_new_baseline": True
                },
                "scores": [],
                "statistics": {
                    "total_cells": 0,
                    "modified_cells": 0,
                    "L1_count": 0,
                    "L2_count": 0,
                    "L3_count": 0
                }
            }

            # ä¿å­˜æ‰“åˆ†ç»“æœ
            Path(score_file_path).parent.mkdir(parents=True, exist_ok=True)
            with open(score_file_path, 'w', encoding='utf-8') as f:
                json.dump(empty_score, f, ensure_ascii=False, indent=2)

            workflow_state.score_file = score_file_path
            workflow_state.add_log(f"âœ… è¯¦ç»†æ‰“åˆ†ç”Ÿæˆå®Œæˆï¼ˆæ–°åŸºçº¿ï¼Œ0ä¿®æ”¹ï¼‰: {score_file_name}")

        elif MODULES_STATUS.get('marker') and comparison_result:
            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„IntegratedScorerï¼ˆå¿…é¡»ä½¿ç”¨AIï¼ŒL2å¼ºåˆ¶è¦æ±‚ï¼‰
                scorer = IntegratedScorer(use_ai=True, cache_enabled=False)
                
                # å°†å¯¹æ¯”ç»“æœä¿å­˜ä¸ºä¸´æ—¶JSONæ–‡ä»¶ä¾›scorerå¤„ç†
                import tempfile
                with tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False) as tmp:
                    json.dump(comparison_result, tmp)
                    tmp_input_file = tmp.name
                
                # ä½¿ç”¨IntegratedScorerå¤„ç†æ–‡ä»¶
                score_file_path = scorer.process_file(
                    input_file=tmp_input_file,
                    output_dir=str(SCORING_RESULTS_DIR)
                )
                
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                os.unlink(tmp_input_file)
                
                workflow_state.score_file = score_file_path
                workflow_state.add_log(f"âœ… è¯¦ç»†æ‰“åˆ†ç”Ÿæˆå®Œæˆ: {os.path.basename(score_file_path)}")
            except Exception as e:
                # ä¸å…è®¸é™çº§ï¼Œç›´æ¥æŠ›å‡ºå¼‚å¸¸
                workflow_state.add_log(f"âŒ æ‰“åˆ†ç”Ÿæˆå¤±è´¥: {str(e)}", "ERROR")
                raise
        
        # ========== æ­¥éª¤7: ä¸‹è½½ç›®æ ‡XLSX ==========
        workflow_state.update_progress("ä¸‹è½½Excelæ ¼å¼", 70)
        workflow_state.add_log("ä¸‹è½½ç›®æ ‡æ–‡æ¡£çš„Excelæ ¼å¼...")
        
        excel_file = None
        if MODULES_STATUS.get('downloader'):
            # ä¸ºExcelä¸‹è½½åˆ›å»ºæ–°çš„exporterå®ä¾‹
            exporter_excel = TencentDocAutoExporter()
            
            import asyncio
            if hasattr(exporter_excel, 'download'):
                # PlaywrightDownloaderæ¥å£
                excel_result = asyncio.run(exporter_excel.download(target_url, cookies=cookie, format='xlsx'))
            else:
                # TencentDocAutoExporteræ¥å£
                excel_result = asyncio.run(exporter_excel.export_document(target_url, cookies=cookie, format='xlsx'))
            if excel_result and excel_result.get('success'):
                excel_file = excel_result.get('file_path')
                workflow_state.add_log(f"âœ… Excelæ–‡æ¡£ä¸‹è½½æˆåŠŸ: {os.path.basename(excel_file)}")
            else:
                workflow_state.add_log("âš ï¸ Excelä¸‹è½½å¤±è´¥", "WARNING")
        
        # ========== æ­¥éª¤8: ä¿®å¤Excelæ ¼å¼ ==========
        if excel_file and MODULES_STATUS.get('fixer'):
            workflow_state.update_progress("ä¿®å¤Excelæ ¼å¼", 75)
            workflow_state.add_log("ä¿®å¤è…¾è®¯æ–‡æ¡£Excelæ ¼å¼é—®é¢˜...")
            
            fixed_file = fix_tencent_excel(excel_file)
            if fixed_file:
                excel_file = fixed_file
                workflow_state.add_log(f"âœ… Excelæ ¼å¼ä¿®å¤å®Œæˆ")
        
        # ========== æ­¥éª¤9: åº”ç”¨æ¡çº¹æ¶‚è‰² ==========
        if excel_file and MODULES_STATUS.get('marker') and workflow_state.score_file:
            workflow_state.update_progress("åº”ç”¨æ™ºèƒ½æ¶‚è‰²", 85)
            workflow_state.add_log("åº”ç”¨æ¡çº¹æ¶‚è‰²æ ‡è®°...")
            
            marker = IntelligentExcelMarker()
            marked_file = marker.apply_striped_coloring(
                excel_file,
                workflow_state.score_file
            )
            
            if marked_file:
                workflow_state.marked_file = marked_file
                workflow_state.add_log(f"âœ… æ¶‚è‰²æ ‡è®°å®Œæˆ: {os.path.basename(marked_file)}")
        
        # ========== æ­¥éª¤10: ä¸Šä¼ åˆ°è…¾è®¯æ–‡æ¡£ ==========
        if workflow_state.marked_file and MODULES_STATUS.get('uploader'):
            workflow_state.update_progress("ä¸Šä¼ è…¾è®¯æ–‡æ¡£", 90)
            workflow_state.add_log("ä¸Šä¼ å¤„ç†åçš„æ–‡æ¡£åˆ°è…¾è®¯æ–‡æ¡£...")

            # ä¿®æ­£ï¼šsync_upload_v3åªéœ€è¦3ä¸ªå‚æ•°(cookie_string, file_path, headless)
            # ç¬¬1ä¸ªå‚æ•°å¿…é¡»æ˜¯cookie_stringï¼Œç¬¬2ä¸ªæ˜¯file_path
            upload_result = sync_upload_file(
                cookie,  # ç¬¬1ä¸ªå‚æ•°ï¼šcookie_string
                workflow_state.marked_file,  # ç¬¬2ä¸ªå‚æ•°ï¼šfile_path
                True  # ç¬¬3ä¸ªå‚æ•°ï¼šheadlessæ¨¡å¼
            )

            if upload_result and upload_result.get('success'):
                workflow_state.upload_url = upload_result.get('url')
                workflow_state.add_log(f"âœ… æ–‡æ¡£ä¸Šä¼ æˆåŠŸ!")
                if workflow_state.upload_url:
                    workflow_state.add_log(f"ğŸ“ æ–‡æ¡£é“¾æ¥: {workflow_state.upload_url}")
            else:
                workflow_state.add_log("âš ï¸ æ–‡æ¡£ä¸Šä¼ å¤±è´¥", "WARNING")

        # ========== æ­¥éª¤11: ç”Ÿæˆç»¼åˆæ‰“åˆ† ==========
        # æ‰¹é‡å¤„ç†æ—¶è·³è¿‡å•æ–‡æ¡£çš„ç»¼åˆæ‰“åˆ†ï¼ˆç”±æ‰¹é‡å¤„ç†å‡½æ•°ç»Ÿä¸€ç”Ÿæˆï¼‰
        if not skip_reset:
            workflow_state.update_progress("ç”Ÿæˆç»¼åˆæ‰“åˆ†", 95)
            workflow_state.add_log("ğŸ”¥ ç”Ÿæˆç»¼åˆæ‰“åˆ†æ–‡ä»¶ï¼ˆç¬¦åˆè§„èŒƒ16çš„Step 7ï¼‰...")

            try:
                from production.core_modules.auto_comprehensive_generator import AutoComprehensiveGenerator

                # åˆ›å»ºç»¼åˆæ‰“åˆ†ç”Ÿæˆå™¨
                generator = AutoComprehensiveGenerator()

                # ä»æœ€æ–°çš„è¯¦ç»†æ‰“åˆ†ç”Ÿæˆç»¼åˆæ‰“åˆ†ï¼Œä¼ é€’ä¸Šä¼ çš„URL
                comprehensive_file = generator.generate_from_latest_results(
                    excel_url=workflow_state.upload_url
                )

                workflow_state.add_log(f"âœ… ç»¼åˆæ‰“åˆ†å·²ç”Ÿæˆ: {os.path.basename(comprehensive_file)}")
                workflow_state.comprehensive_file = comprehensive_file

                # è¯»å–ç»¼åˆæ‰“åˆ†æ–‡ä»¶ä»¥è·å–å…³é”®ä¿¡æ¯
                with open(comprehensive_file, 'r', encoding='utf-8') as f:
                    comprehensive_data = json.load(f)

                # è¾“å‡ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
                summary = comprehensive_data.get('summary', {})
                workflow_state.add_log(f"ğŸ“Š L1é«˜é£é™©ä¿®æ”¹: {summary.get('l1_modifications', 0)}å¤„")
                workflow_state.add_log(f"ğŸ“Š L2ä¸­é£é™©ä¿®æ”¹: {summary.get('l2_modifications', 0)}å¤„")
                workflow_state.add_log(f"ğŸ“Š L3ä½é£é™©ä¿®æ”¹: {summary.get('l3_modifications', 0)}å¤„")
                workflow_state.add_log(f"ğŸ“Š æ€»ä½“é£é™©è¯„åˆ†: {summary.get('overall_risk_score', 0)}")

                # è¾“å‡ºçƒ­åŠ›å›¾é¢œè‰²åˆ†å¸ƒ
                heatmap_data = comprehensive_data.get('heatmap_data', {})
                color_dist = heatmap_data.get('color_distribution', {})
                workflow_state.add_log(f"ğŸ¨ çƒ­åŠ›å›¾åˆ†å¸ƒ: çº¢è‰²{color_dist.get('red_0.9', 0)}æ ¼, "
                                      f"æ©™è‰²{color_dist.get('orange_0.6', 0)}æ ¼, "
                                      f"ç»¿è‰²{color_dist.get('green_0.3', 0)}æ ¼, "
                                      f"è“è‰²{color_dist.get('blue_0.05', 0)}æ ¼")

            except ImportError as e:
                workflow_state.add_log(f"âš ï¸ æ— æ³•å¯¼å…¥ç»¼åˆæ‰“åˆ†ç”Ÿæˆå™¨: {e}", "WARNING")
                workflow_state.add_log("ğŸ’¡ ç»¼åˆæ‰“åˆ†æ˜¯å¯é€‰æ­¥éª¤ï¼Œç»§ç»­æ‰§è¡Œ...", "INFO")
            except Exception as e:
                workflow_state.add_log(f"âš ï¸ ç»¼åˆæ‰“åˆ†ç”Ÿæˆå¤±è´¥: {e}", "WARNING")
                workflow_state.add_log("ğŸ’¡ ç»¼åˆæ‰“åˆ†æ˜¯è¡¥å……æ­¥éª¤ï¼Œä¸å½±å“ä¸»æµç¨‹", "INFO")
        else:
            workflow_state.add_log("ğŸ“‹ æ‰¹é‡å¤„ç†æ¨¡å¼ï¼šè·³è¿‡å•æ–‡æ¡£ç»¼åˆæ‰“åˆ†ï¼Œå°†åœ¨æœ€åç»Ÿä¸€ç”Ÿæˆ")

        # ========== å®Œæˆ ==========
        # æ‰¹é‡å¤„ç†æ—¶ä¸è®¾ç½®å®ŒæˆçŠ¶æ€ï¼ˆç”±æ‰¹é‡å¤„ç†å‡½æ•°ç®¡ç†ï¼‰
        if not skip_reset:
            workflow_state.update_progress("å¤„ç†å®Œæˆ", 100)
            workflow_state.status = "completed"
            workflow_state.end_time = datetime.now()
            workflow_state.add_log("ğŸ‰ æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆ!", "SUCCESS")
        else:
            workflow_state.add_log(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ", "SUCCESS")
        
        # ä¿å­˜ç»“æœ
        workflow_state.results = {
            "baseline_file": workflow_state.baseline_file,
            "target_file": workflow_state.target_file,
            "score_file": workflow_state.score_file,
            "marked_file": workflow_state.marked_file,
            "upload_url": workflow_state.upload_url,
            "comprehensive_file": getattr(workflow_state, 'comprehensive_file', None),
            "execution_time": str(workflow_state.end_time - workflow_state.start_time) if workflow_state.end_time and workflow_state.start_time else None
        }
        
        # ä¿å­˜å†å²è®°å½•
        workflow_state.save_to_history()
        
    except Exception as e:
        workflow_state.status = "error"
        workflow_state.end_time = datetime.now()
        workflow_state.add_log(f"âŒ æ‰§è¡Œå‡ºé”™: {str(e)}", "ERROR")
        workflow_state.save_to_history()
        logger.error(f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)

def run_batch_workflow(document_pairs: list, cookie: str, advanced_settings: dict = None):
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡æ¡£å¯¹ï¼Œç”Ÿæˆå¤šæ–‡æ¡£ç»¼åˆæ‰“åˆ†

    Args:
        document_pairs: æ–‡æ¡£å¯¹åˆ—è¡¨ï¼Œæ ¼å¼:
            [
                {"name": "å‡ºå›½é”€å”®è®¡åˆ’è¡¨", "baseline_url": "...", "target_url": "..."},
                {"name": "å›å›½é”€å”®è®¡åˆ’è¡¨", "baseline_url": "...", "target_url": "..."},
                {"name": "å°çº¢ä¹¦éƒ¨é—¨", "baseline_url": "...", "target_url": "..."}
            ]
        cookie: Cookieå­—ç¬¦ä¸²
        advanced_settings: é«˜çº§è®¾ç½®
    """
    try:
        # æ³¨æ„ï¼šçŠ¶æ€å·²ç»åœ¨start_batch_workflowä¸­è®¾ç½®ï¼Œè¿™é‡Œä¸é‡å¤è®¾ç½®
        # åªæ›´æ–°å¿…è¦çš„å­—æ®µ
        workflow_state.advanced_settings = advanced_settings or {}

        total_pairs = len(document_pairs)
        workflow_state.add_log(f"ğŸš€ å¼€å§‹æ‰¹é‡å¤„ç† {total_pairs} ä¸ªæ–‡æ¡£å¯¹", "INFO")

        # å­˜å‚¨æ‰€æœ‰æ–‡æ¡£çš„å¤„ç†ç»“æœ
        all_results = []
        all_score_files = []
        excel_urls = {}

        # å¤„ç†æ¯ä¸ªæ–‡æ¡£å¯¹
        for idx, doc_pair in enumerate(document_pairs, 1):
            doc_name = doc_pair.get('name', f'æ–‡æ¡£{idx}')
            baseline_url = doc_pair.get('baseline_url')
            target_url = doc_pair.get('target_url')

            workflow_state.update_progress(
                f"å¤„ç†æ–‡æ¡£ {idx}/{total_pairs}: {doc_name}",
                int(idx * 80 / total_pairs)  # å‰80%ç”¨äºå¤„ç†å„æ–‡æ¡£
            )

            workflow_state.add_log(f"ğŸ“„ å¼€å§‹å¤„ç†: {doc_name}", "INFO")

            try:
                # è°ƒç”¨å•æ–‡æ¡£å¤„ç†æµç¨‹ï¼ˆä½†ä¸ç”Ÿæˆç»¼åˆæ‰“åˆ†ï¼‰
                # æš‚å­˜å½“å‰çŠ¶æ€
                current_logs = workflow_state.logs[:]
                current_progress = workflow_state.progress

                # æ‰§è¡Œå•æ–‡æ¡£å·¥ä½œæµï¼ˆç¬¬ä¸€ä¸ªæ–‡æ¡£å·²ç»é‡ç½®è¿‡çŠ¶æ€äº†ï¼Œåç»­æ–‡æ¡£è·³è¿‡é‡ç½®ï¼‰
                run_complete_workflow(baseline_url, target_url, cookie, advanced_settings, skip_reset=True)

                # æ”¶é›†ç»“æœ
                if workflow_state.score_file:
                    all_score_files.append(workflow_state.score_file)
                    workflow_state.add_log(f"âœ… {doc_name} è¯¦ç»†æ‰“åˆ†å·²ç”Ÿæˆ: {workflow_state.score_file}", "SUCCESS")

                if workflow_state.upload_url:
                    excel_urls[doc_name] = workflow_state.upload_url
                    workflow_state.add_log(f"ğŸ“Š {doc_name} Excelå·²ä¸Šä¼ : {workflow_state.upload_url}", "SUCCESS")

                all_results.append({
                    'name': doc_name,
                    'score_file': workflow_state.score_file,
                    'marked_file': workflow_state.marked_file,
                    'upload_url': workflow_state.upload_url
                })

            except Exception as e:
                workflow_state.add_log(f"âŒ å¤„ç† {doc_name} å¤±è´¥: {str(e)}", "ERROR")
                workflow_state.status = "error"
                workflow_state.end_time = datetime.now()
                # æŒ‰ç…§ç”¨æˆ·è¦æ±‚ï¼šå”¯ä¸€æ–¹æ¡ˆä¸é€šç›´æ¥æŠ›å‡ºå¼‚å¸¸æŠ¥é”™
                raise Exception(f"æ–‡æ¡£å¤„ç†å¤±è´¥ - {doc_name}: {str(e)}")

        # ========== æ‰¹é‡ç»¼åˆæ‰“åˆ†ç”Ÿæˆ ==========
        workflow_state.update_progress("ç”Ÿæˆå¤šæ–‡æ¡£ç»¼åˆæ‰“åˆ†", 90)
        workflow_state.add_log("ğŸ“Š å¼€å§‹ç”Ÿæˆå¤šæ–‡æ¡£ç»¼åˆæ‰“åˆ†...", "INFO")

        try:
            # å¯¼å…¥æ‰¹é‡ç»¼åˆæ‰“åˆ†ç”Ÿæˆå™¨
            from production.core_modules.auto_comprehensive_generator import AutoComprehensiveGenerator

            generator = AutoComprehensiveGenerator()

            # ä½¿ç”¨æ–°çš„æ‰¹é‡å¤„ç†æ–¹æ³•ï¼Œä¼ å…¥æœŸæœ›çš„æ–‡æ¡£æ•°é‡
            expected_doc_count = len(document_pairs)  # ä½¿ç”¨é…ç½®çš„æ–‡æ¡£æ•°
            comprehensive_file = generator.generate_from_all_detailed_results(
                excel_urls,
                expected_count=expected_doc_count
            )
            workflow_state.add_log(f"   ä½¿ç”¨é…ç½®çš„æ–‡æ¡£æ•° {expected_doc_count} è¿›è¡Œæ‰¹é‡å¤„ç†", "INFO")

            workflow_state.comprehensive_file = comprehensive_file
            workflow_state.add_log(f"âœ… å¤šæ–‡æ¡£ç»¼åˆæ‰“åˆ†å·²ç”Ÿæˆ: {comprehensive_file}", "SUCCESS")
            workflow_state.add_log(f"   åŒ…å« {len(all_results)} ä¸ªè¡¨æ ¼çš„èšåˆæ•°æ®", "INFO")

            # æ·»åŠ åˆ°ç»“æœ
            workflow_state.results['batch_comprehensive_file'] = comprehensive_file
            workflow_state.results['processed_documents'] = all_results

        except ImportError as e:
            workflow_state.add_log(f"âš ï¸ æ— æ³•å¯¼å…¥æ‰¹é‡ç»¼åˆæ‰“åˆ†ç”Ÿæˆå™¨: {e}", "WARNING")
        except Exception as e:
            workflow_state.add_log(f"âš ï¸ æ‰¹é‡ç»¼åˆæ‰“åˆ†ç”Ÿæˆå¤±è´¥: {e}", "WARNING")

        # ========== å®Œæˆ ==========
        # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡æ¡£éƒ½æˆåŠŸå¤„ç†
        if len(all_results) == total_pairs:
            workflow_state.update_progress("æ‰¹é‡å¤„ç†å®Œæˆ", 100)
            workflow_state.status = "completed"
            workflow_state.end_time = datetime.now()
            workflow_state.add_log(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç† {len(all_results)} ä¸ªæ–‡æ¡£", "SUCCESS")
        else:
            # éƒ¨åˆ†å¤±è´¥çš„æƒ…å†µï¼ˆå®é™…ä¸Šä¸ä¼šåˆ°è¾¾è¿™é‡Œï¼Œå› ä¸ºå¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸ï¼‰
            workflow_state.status = "error"
            workflow_state.end_time = datetime.now()
            workflow_state.add_log(f"âŒ æ‰¹é‡å¤„ç†æœªå®Œæˆ: ä»…æˆåŠŸ {len(all_results)}/{total_pairs} ä¸ªæ–‡æ¡£", "ERROR")
            raise Exception(f"æ‰¹é‡å¤„ç†å¤±è´¥: ä»…æˆåŠŸå¤„ç† {len(all_results)}/{total_pairs} ä¸ªæ–‡æ¡£")

        # ä¿å­˜æ‰¹é‡å¤„ç†ç»“æœ
        workflow_state.results = {
            "batch_mode": True,
            "total_documents": total_pairs,
            "successful_documents": len(all_results),
            "documents": all_results,
            "comprehensive_file": getattr(workflow_state, 'comprehensive_file', None),
            "excel_urls": excel_urls,
            "execution_time": str(workflow_state.end_time - workflow_state.start_time) if workflow_state.end_time and workflow_state.start_time else None
        }

        # ä¿å­˜å†å²è®°å½•
        workflow_state.save_to_history()

        return workflow_state.execution_id

    except Exception as e:
        workflow_state.status = "error"
        workflow_state.end_time = datetime.now()
        workflow_state.add_log(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}", "ERROR")
        workflow_state.save_to_history()
        logger.error(f"æ‰¹é‡å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return None

# ==================== Flaskè·¯ç”± ====================
@app.route('/')
def index():
    # ç»ˆæç¼“å­˜ç ´åæ–¹æ¡ˆï¼šä½¿ç”¨å”¯ä¸€ç±»åå’ŒJavaScriptå¼ºåˆ¶æ›´æ–°
    from flask import make_response
    import time
    import random

    # ç”Ÿæˆå”¯ä¸€çš„ç‰ˆæœ¬æ ‡è¯†
    version = f"{int(time.time())}_{random.randint(1000, 9999)}"

    # åŠ¨æ€æ›¿æ¢HTMLä¸­çš„ç±»åå’Œæ ·å¼
    versioned_html = HTML_TEMPLATE

    # æ·»åŠ JavaScriptå¼ºåˆ¶åˆ·æ–°æ ·å¼
    js_injection = f'''
    <script>
        // å¼ºåˆ¶æ›´æ–°æ ·å¼ - ç‰ˆæœ¬ {version}
        document.addEventListener('DOMContentLoaded', function() {{
            // ç›´æ¥é€šè¿‡JavaScriptè®¾ç½®æ ·å¼ï¼Œç»•è¿‡æ‰€æœ‰ç¼“å­˜
            const logContainers = document.querySelectorAll('.log-container');
            logContainers.forEach(container => {{
                container.style.height = '800px';
                container.style.maxHeight = '800px';
                container.style.overflowY = 'auto';
                container.style.overflowX = 'hidden';
            }});

            // æ·»åŠ ç‰ˆæœ¬ä¿¡æ¯åˆ°æ§åˆ¶å°
            console.log('ğŸ“‹ ç›‘æ§ç•Œé¢CSSå·²æ›´æ–° - ç‰ˆæœ¬:', '{version}');
            console.log('ğŸ“ æ—¥å¿—å®¹å™¨é«˜åº¦: 800px');

            // æ¸…é™¤localStorageç¼“å­˜
            if (localStorage.getItem('css_version') !== '{version}') {{
                localStorage.setItem('css_version', '{version}');
                console.log('ğŸ”„ ç¼“å­˜å·²æ¸…é™¤');
            }}
        }});
    </script>
    '''

    # åœ¨</head>æ ‡ç­¾å‰æ’å…¥JavaScript
    versioned_html = versioned_html.replace('</head>', js_injection + '\n    </head>')

    response = make_response(render_template_string(versioned_html))

    # æœ€æ¿€è¿›çš„ç¼“å­˜æ§åˆ¶
    response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate, private, max-age=0'
    response.headers['Pragma'] = 'no-cache'
    response.headers['Expires'] = '-1'
    response.headers['X-CSS-Version'] = version
    response.headers['ETag'] = f'"{version}"'
    response.headers['Last-Modified'] = time.strftime('%a, %d %b %Y %H:%M:%S GMT')

    return response

@app.route('/api/modules')
def get_modules():
    """è·å–æ¨¡å—åŠ è½½çŠ¶æ€"""
    return jsonify(MODULES_STATUS)

@app.route('/api/status')
def get_status():
    """è·å–å½“å‰å·¥ä½œæµçŠ¶æ€ - å¢å¼ºç‰ˆè‡ªåŠ¨é‡ç½®æœºåˆ¶"""
    # å¤šé‡æ£€æŸ¥æœºåˆ¶ï¼Œç¡®ä¿ä¸ä¼šè¿”å›è™šå‡æˆåŠŸ

    # å¦‚æœçŠ¶æ€æ˜¯runningï¼Œç›´æ¥è¿”å›ï¼Œä¸åšä»»ä½•æ£€æµ‹
    if workflow_state.status == "running":
        return jsonify({
            "status": workflow_state.status,
            "progress": workflow_state.progress,
            "current_task": workflow_state.current_task,
            "logs": workflow_state.logs,
            "results": workflow_state.results,
            "is_running": True
        })

    # 1. æ£€æŸ¥æ˜¯å¦æœ‰é™ˆæ—§çš„å®Œæˆ/é”™è¯¯çŠ¶æ€
    if workflow_state.status in ["completed", "error"]:
        # æ£€æŸ¥å¤šä¸ªè™šå‡æˆåŠŸçš„ç‰¹å¾
        is_fake = False

        # ç‰¹å¾1: æ‰€æœ‰æ—¶é—´æˆ³ç›¸åŒï¼ˆå¢åŠ é•¿åº¦æ£€æŸ¥ï¼‰
        if workflow_state.logs and len(workflow_state.logs) > 3:
            timestamps = []
            for log in workflow_state.logs:
                if isinstance(log, dict) and 'timestamp' in log:
                    timestamps.append(log['timestamp'])

            if timestamps and len(set(timestamps)) == 1 and len(timestamps) > 5:
                print(f"âš ï¸ æ£€æµ‹åˆ°è™šå‡æ—¥å¿—ç‰¹å¾1ï¼šæ‰€æœ‰æ—¶é—´æˆ³ç›¸åŒ ({timestamps[0]})")
                is_fake = True

        # ç‰¹å¾2: å®ŒæˆçŠ¶æ€ä½†æ²¡æœ‰ç»“æœ
        if workflow_state.status == "completed" and not workflow_state.results:
            print(f"âš ï¸ æ£€æµ‹åˆ°è™šå‡æ—¥å¿—ç‰¹å¾2ï¼šå®ŒæˆçŠ¶æ€ä½†æ— ç»“æœ")
            is_fake = True

        # ç‰¹å¾3: å®Œæˆæ—¶é—´ä¸å¼€å§‹æ—¶é—´ç›¸åŒæˆ–éå¸¸æ¥è¿‘ï¼ˆå°äº1ç§’ï¼‰
        if workflow_state.start_time and workflow_state.end_time:
            time_diff = (workflow_state.end_time - workflow_state.start_time).total_seconds()
            if time_diff < 1:
                print(f"âš ï¸ æ£€æµ‹åˆ°è™šå‡æ—¥å¿—ç‰¹å¾3ï¼šæ‰§è¡Œæ—¶é—´è¿‡çŸ­ ({time_diff}ç§’)")
                is_fake = True

        # ç‰¹å¾4: æ—¥å¿—æ•°é‡å¼‚å¸¸å°‘ï¼ˆæ­£å¸¸åº”è¯¥æœ‰å¤šæ¡å¤„ç†æ—¥å¿—ï¼‰
        if workflow_state.status == "completed" and len(workflow_state.logs) < 5:
            print(f"âš ï¸ æ£€æµ‹åˆ°è™šå‡æ—¥å¿—ç‰¹å¾4ï¼šæ—¥å¿—è¿‡å°‘ ({len(workflow_state.logs)}æ¡)")
            is_fake = True

        # å¦‚æœæ£€æµ‹åˆ°è™šå‡æˆåŠŸï¼Œè‡ªåŠ¨é‡ç½®
        if is_fake:
            print("ğŸ”„ è‡ªåŠ¨é‡ç½®è™šå‡å·¥ä½œæµçŠ¶æ€")
            workflow_state.reset()

    return jsonify({
        "status": workflow_state.status,
        "progress": workflow_state.progress,
        "current_task": workflow_state.current_task,
        "logs": workflow_state.logs,  # è¿”å›æ‰€æœ‰æ—¥å¿—ï¼ˆä¸å†æˆªæ–­ï¼‰
        "results": workflow_state.results
    })

@app.route('/api/reset-status', methods=['POST'])
def reset_status():
    """æ‰‹åŠ¨é‡ç½®å·¥ä½œæµçŠ¶æ€"""
    # æ£€æŸ¥æ˜¯å¦æœ‰æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµ
    if workflow_state.status == "running":
        return jsonify({"error": "ä¸èƒ½é‡ç½®æ­£åœ¨è¿è¡Œçš„å·¥ä½œæµ"}), 400

    # æ‰§è¡Œé‡ç½®
    workflow_state.reset()
    print("âœ… æ‰‹åŠ¨é‡ç½®å·¥ä½œæµçŠ¶æ€æˆåŠŸ")

    return jsonify({
        "message": "å·¥ä½œæµçŠ¶æ€å·²é‡ç½®",
        "status": workflow_state.status,
        "logs": workflow_state.logs
    })

@app.route('/api/save-cookie', methods=['POST'])
def save_cookie():
    """ä¿å­˜Cookieåˆ°é…ç½®æ–‡ä»¶"""
    try:
        data = request.json
        cookie_string = data.get('cookie')
        
        if not cookie_string:
            return jsonify({"error": "Cookieä¸èƒ½ä¸ºç©º"}), 400
        
        # Cookieé…ç½®æ–‡ä»¶è·¯å¾„
        cookie_file = Path("/root/projects/tencent-doc-manager/config/cookies.json")
        
        # è§£æCookieå­—ç¬¦ä¸²
        cookie_list = []
        for cookie_part in cookie_string.split('; '):
            if '=' in cookie_part:
                name, value = cookie_part.split('=', 1)
                cookie_list.append({
                    "name": name.strip(),
                    "value": value.strip()
                })
        
        # æ„å»ºCookieé…ç½®
        cookie_config = {
            "cookies": cookie_list,
            "cookie_string": cookie_string,
            "current_cookies": cookie_string,
            "last_updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        cookie_file.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open(cookie_file, 'w', encoding='utf-8') as f:
            json.dump(cookie_config, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… Cookieå·²ä¿å­˜åˆ°é…ç½®æ–‡ä»¶: {cookie_file}")
        return jsonify({
            "success": True,
            "message": f"Cookieå·²æˆåŠŸä¿å­˜åˆ°é…ç½®æ–‡ä»¶",
            "cookie_count": len(cookie_list),
            "last_updated": cookie_config["last_updated"]
        })
        
    except Exception as e:
        logger.error(f"ä¿å­˜Cookieå¤±è´¥: {e}")
        return jsonify({"error": f"ä¿å­˜Cookieå¤±è´¥: {str(e)}"}), 500

@app.route('/api/load-cookie', methods=['GET'])
def load_cookie():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½Cookie"""
    try:
        cookie_file = Path("/root/projects/tencent-doc-manager/config/cookies.json")
        
        if not cookie_file.exists():
            return jsonify({"error": "Cookieé…ç½®æ–‡ä»¶ä¸å­˜åœ¨"}), 404
        
        with open(cookie_file, 'r', encoding='utf-8') as f:
            cookie_config = json.load(f)
        
        return jsonify({
            "success": True,
            "cookie": cookie_config.get("cookie_string", ""),
            "last_updated": cookie_config.get("last_updated", ""),
            "cookie_count": len(cookie_config.get("cookies", []))
        })
        
    except Exception as e:
        logger.error(f"åŠ è½½Cookieå¤±è´¥: {e}")
        return jsonify({"error": f"åŠ è½½Cookieå¤±è´¥: {str(e)}"}), 500

@app.route('/api/start', methods=['POST'])
def start_workflow():
    """å¯åŠ¨å·¥ä½œæµ"""
    if workflow_state.status == "running":
        return jsonify({"error": "å·¥ä½œæµæ­£åœ¨è¿è¡Œä¸­"}), 400
    
    data = request.json
    baseline_url = data.get('baseline_url')
    target_url = data.get('target_url')
    cookie = data.get('cookie')
    advanced_settings = data.get('advanced_settings', {})
    
    # åˆ·æ–°æ¨¡å¼ï¼šbaseline_urlå¯ä»¥ä¸ºNoneï¼Œä½†target_urlå’Œcookieå¿…é¡»æä¾›
    if not target_url or not cookie:
        return jsonify({"error": "ç¼ºå°‘å¿…è¦å‚æ•°: target_urlå’Œcookie"}), 400
    
    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œå·¥ä½œæµ
    thread = threading.Thread(
        target=run_complete_workflow,
        args=(baseline_url, target_url, cookie, advanced_settings)
    )
    thread.daemon = True
    thread.start()
    
    return jsonify({"message": "å·¥ä½œæµå·²å¯åŠ¨", "execution_id": workflow_state.execution_id})

@app.route('/api/start-batch', methods=['POST'])
def start_batch_workflow():
    """å¯åŠ¨æ‰¹é‡å·¥ä½œæµå¤„ç†å¤šä¸ªæ–‡æ¡£"""
    if workflow_state.status == "running":
        return jsonify({"error": "å·¥ä½œæµæ­£åœ¨è¿è¡Œä¸­"}), 400

    # é‡ç½®å·¥ä½œæµçŠ¶æ€ï¼Œæ¸…é™¤ä»»ä½•æ—§çš„æ—¥å¿—å’Œç»“æœ
    workflow_state.reset()
    print("âœ… å·²é‡ç½®å·¥ä½œæµçŠ¶æ€ï¼Œæ¸…é™¤æ—§çš„æ—¥å¿—å’Œç»“æœ")

    # ç«‹å³è®¾ç½®ä¸ºè¿è¡ŒçŠ¶æ€ï¼Œé˜²æ­¢å‰ç«¯è·å–åˆ°ç©ºé—²çŠ¶æ€
    workflow_state.status = "running"
    workflow_state.start_time = datetime.now()
    workflow_state.execution_id = datetime.now().strftime("%Y%m%d_%H%M%S_batch")
    workflow_state.add_log("ğŸš€ æ­£åœ¨å¯åŠ¨æ‰¹é‡å¤„ç†å·¥ä½œæµ...", "INFO")
    workflow_state.current_task = "åˆå§‹åŒ–æ‰¹é‡å¤„ç†"
    workflow_state.progress = 1  # è®¾ç½®æœ€å°è¿›åº¦ï¼Œè¡¨ç¤ºå·²å¼€å§‹

    data = request.json
    cookie = data.get('cookie')
    advanced_settings = data.get('advanced_settings', {})

    # ä»é…ç½®æ–‡ä»¶è¯»å–æ–‡æ¡£é…ç½®
    import sys
    sys.path.insert(0, '/root/projects/tencent-doc-manager')

    # ç›´æ¥è¯»å–é…ç½®æ–‡ä»¶ - ä½¿ç”¨ä¸8089ç›¸åŒçš„é…ç½®æº
    import json
    # ä¼˜å…ˆä½¿ç”¨download_config.jsonï¼Œç¡®ä¿ä¸8089 UIä¸€è‡´
    config_file = Path("/root/projects/tencent-doc-manager/config/download_config.json")
    REAL_DOCUMENTS = {'documents': []}

    if config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            download_config = json.load(f)
            # è½¬æ¢download_configæ ¼å¼åˆ°REAL_DOCUMENTSæ ¼å¼
            documents = []
            for link in download_config.get('document_links', []):
                if link.get('enabled', False):  # åªå¤„ç†å¯ç”¨çš„é“¾æ¥
                    documents.append({
                        'name': link['name'],
                        'url': link['url'],
                        'doc_id': link['url'].split('/')[-1] if '/' in link['url'] else link['url'],
                        'csv_pattern': f"tencent_{link['name']}_*.csv",
                        'description': f"æ¥è‡ªUIé…ç½®: {link['name']}"
                    })
            REAL_DOCUMENTS = {'documents': documents}
            print(f"âœ… ä»download_config.jsonåŠ è½½ {len(documents)} ä¸ªå¯ç”¨çš„æ–‡æ¡£")
    else:
        print("âš ï¸ æœªæ‰¾åˆ°download_config.jsonï¼Œä½¿ç”¨ç©ºé…ç½®")

    # æ„å»ºæ–‡æ¡£å¯¹åˆ—è¡¨
    document_pairs = []
    for doc in REAL_DOCUMENTS['documents']:
        # æ¯ä¸ªæ–‡æ¡£ä½¿ç”¨ç›¸åŒçš„URLä½œä¸ºbaselineå’Œtargetï¼ˆåˆ·æ–°æ¨¡å¼ï¼‰
        doc_pair = {
            'name': doc['name'],
            'baseline_url': doc['url'],  # å¯ä»¥æ”¹ä¸ºNoneä½¿ç”¨ç¼“å­˜çš„baseline
            'target_url': doc['url']
        }
        document_pairs.append(doc_pair)

    if not document_pairs:
        return jsonify({"error": "æ²¡æœ‰é…ç½®æ–‡æ¡£"}), 400

    if not cookie:
        # å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–cookie
        try:
            cookie_file = Path("/root/projects/tencent-doc-manager/config/cookies.json")
            if cookie_file.exists():
                with open(cookie_file, 'r', encoding='utf-8') as f:
                    cookie_config = json.load(f)
                    cookie = cookie_config.get('current_cookies', '') or cookie_config.get('cookie_string', '')
        except Exception:
            pass

        if not cookie:
            return jsonify({"error": "ç¼ºå°‘Cookieå‚æ•°"}), 400

    # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæ‰¹é‡å·¥ä½œæµ
    thread = threading.Thread(
        target=run_batch_workflow,
        args=(document_pairs, cookie, advanced_settings)
    )
    thread.daemon = True
    thread.start()

    return jsonify({
        "message": f"æ‰¹é‡å·¥ä½œæµå·²å¯åŠ¨ï¼Œå°†å¤„ç† {len(document_pairs)} ä¸ªæ–‡æ¡£",
        "documents": [doc['name'] for doc in document_pairs]
    })

@app.route('/api/files/<path:category>')
def list_files(category):
    """åˆ—å‡ºç‰¹å®šç±»åˆ«çš„æ–‡ä»¶"""
    file_dirs = {
        'downloads': DOWNLOAD_DIR,
        'csv_versions': CSV_VERSIONS_DIR,
        'comparisons': COMPARISON_RESULTS_DIR,
        'scores': SCORING_RESULTS_DIR,
        'excel_outputs': EXCEL_OUTPUTS_DIR
    }
    
    if category not in file_dirs:
        return jsonify({"error": "æ— æ•ˆçš„æ–‡ä»¶ç±»åˆ«"}), 400
    
    target_dir = file_dirs[category]
    files = []
    
    for file_path in sorted(target_dir.glob('*'), key=lambda x: x.stat().st_mtime, reverse=True)[:20]:
        if file_path.is_file():
            files.append({
                'name': file_path.name,
                'size': file_path.stat().st_size,
                'modified': datetime.fromtimestamp(file_path.stat().st_mtime).isoformat(),
                'path': str(file_path)
            })
    
    return jsonify(files)

@app.route('/api/presets')
def list_presets():
    """åˆ—å‡ºæ‰€æœ‰é¢„è®¾"""
    return jsonify(PresetManager.list_presets())

@app.route('/api/presets/<name>')
def get_preset(name):
    """è·å–ç‰¹å®šé¢„è®¾"""
    preset = PresetManager.load_preset(name)
    if preset:
        return jsonify(preset)
    return jsonify({"error": "é¢„è®¾ä¸å­˜åœ¨"}), 404

@app.route('/api/presets', methods=['POST'])
def save_preset():
    """ä¿å­˜é¢„è®¾"""
    data = request.json
    name = data.get('name')
    config = data.get('config')
    
    if not name or not config:
        return jsonify({"error": "ç¼ºå°‘é¢„è®¾åç§°æˆ–é…ç½®"}), 400
    
    PresetManager.save_preset(name, config)
    return jsonify({"message": "é¢„è®¾ä¿å­˜æˆåŠŸ"})

@app.route('/api/history')
def list_history():
    """åˆ—å‡ºæ‰§è¡Œå†å²"""
    history_files = sorted(HISTORY_DIR.glob('*.json'), key=lambda x: x.stat().st_mtime, reverse=True)[:20]
    history = []
    
    for history_file in history_files:
        with open(history_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            history.append({
                'id': data['id'],
                'start_time': data['start_time'],
                'end_time': data['end_time'],
                'status': data['status'],
                'results': data.get('results', {})
            })
    
    return jsonify(history)

@app.route('/api/download/<path:file_path>')
def download_file(file_path):
    """ä¸‹è½½æ–‡ä»¶"""
    file_path = Path(file_path)
    if file_path.exists() and file_path.is_file():
        return send_file(str(file_path), as_attachment=True)
    return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

# ==================== HTMLæ¨¡æ¿ï¼ˆå¢å¼ºç‰ˆï¼‰ ====================
HTML_TEMPLATE = '''
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è…¾è®¯æ–‡æ¡£æ™ºèƒ½å¤„ç†ç³»ç»Ÿ - å®Œæ•´é›†æˆæµ‹è¯•ï¼ˆå¢å¼ºç‰ˆï¼‰</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Noto Sans SC', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1600px;
            margin: 0 auto;
        }
        
        .header {
            background: white;
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        .header h1 {
            color: #333;
            margin-bottom: 10px;
            text-align: center;
        }
        
        .header p {
            color: #666;
            text-align: center;
        }
        
        .version-badge {
            display: inline-block;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 12px;
            margin-left: 10px;
        }
        
        .main-content {
            display: grid;
            grid-template-columns: 400px 1fr 400px;
            gap: 30px;
        }
        
        .panel {
            background: white;
            border-radius: 20px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        .tabs {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
            border-bottom: 2px solid #e0e0e0;
        }
        
        .tab {
            padding: 10px 20px;
            cursor: pointer;
            border: none;
            background: none;
            color: #666;
            font-weight: 500;
            transition: all 0.3s;
        }
        
        .tab.active {
            color: #667eea;
            border-bottom: 3px solid #667eea;
            margin-bottom: -2px;
        }
        
        .tab-content {
            display: none;
        }
        
        .tab-content.active {
            display: block;
        }
        
        .form-group {
            margin-bottom: 20px;
        }
        
        .form-group label {
            display: block;
            margin-bottom: 8px;
            color: #333;
            font-weight: 500;
        }
        
        .form-group input, 
        .form-group textarea,
        .form-group select {
            width: 100%;
            padding: 12px;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            font-size: 14px;
            transition: border-color 0.3s;
        }
        
        .form-group input:focus, 
        .form-group textarea:focus,
        .form-group select:focus {
            outline: none;
            border-color: #667eea;
        }
        
        .btn {
            width: 100%;
            padding: 15px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            border-radius: 10px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: transform 0.2s;
        }
        
        .btn:hover {
            transform: translateY(-2px);
        }
        
        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .btn-secondary {
            background: #f5f5f5;
            color: #333;
        }
        
        .progress-bar {
            height: 40px;
            background: #f0f0f0;
            border-radius: 20px;
            margin: 20px 0;
            overflow: hidden;
        }
        
        .progress-fill {
            height: 100%;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: 600;
            transition: width 0.5s ease;
        }
        
        .modules-status {
            display: grid;
            grid-template-columns: repeat(4, 1fr);
            gap: 10px;
            margin-top: 20px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
        }
        
        .module-item {
            padding: 8px;
            border-radius: 8px;
            font-size: 12px;
            text-align: center;
        }
        
        .module-loaded {
            background: #E8F5E9;
            color: #2E7D32;
        }
        
        .module-failed {
            background: #FFEBEE;
            color: #C62828;
        }
        
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
        }
        
        .status-idle { background: #9E9E9E; }
        .status-running { 
            background: #4CAF50;
            animation: pulse 1.5s infinite;
        }
        .status-completed { background: #2196F3; }
        .status-error { background: #F44336; }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .log-container {
            height: 800px !important;  /* ç»ˆæé«˜åº¦è®¾ç½® - 800px */
            max-height: 800px !important;
            min-height: 800px !important;  /* æ·»åŠ æœ€å°é«˜åº¦ç¡®ä¿ */
            overflow-y: auto;
            overflow-x: hidden;
            /* æ·»åŠ æ›´å¤šæ ·å¼ç¡®ä¿ç”Ÿæ•ˆ */
            display: block !important;
            position: relative !important;
            background: #f8f8f8;
            border-radius: 10px;
            padding: 15px;
            font-family: 'Monaco', 'Menlo', monospace;
            font-size: 12px;
        }
        
        .log-entry {
            margin-bottom: 8px;
            padding: 8px;
            border-radius: 5px;
            background: white;
        }
        
        .log-INFO { border-left: 3px solid #4CAF50; }
        .log-WARNING { 
            border-left: 3px solid #FF9800;
            background: #FFF3E0;
        }
        .log-ERROR { 
            border-left: 3px solid #F44336;
            background: #FFEBEE;
        }
        .log-SUCCESS {
            border-left: 3px solid #2196F3;
            background: #E3F2FD;
            font-weight: bold;
        }
        
        .results-panel {
            margin-top: 20px;
            padding-top: 20px;
            border-top: 1px solid #e0e0e0;
        }
        
        .result-item {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 10px;
            background: #f8f8f8;
            border-radius: 8px;
            margin-bottom: 10px;
        }
        
        .result-item a {
            color: #667eea;
            text-decoration: none;
        }
        
        .file-browser {
            max-height: 300px;
            overflow-y: auto;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            padding: 10px;
        }
        
        .file-item {
            padding: 8px;
            cursor: pointer;
            border-radius: 5px;
            transition: background 0.2s;
        }
        
        .file-item:hover {
            background: #f0f0f0;
        }
        
        .file-item.selected {
            background: #E3F2FD;
            border: 1px solid #2196F3;
        }
        
        .history-item {
            padding: 15px;
            background: #f8f8f8;
            border-radius: 10px;
            margin-bottom: 10px;
            cursor: pointer;
            transition: all 0.3s;
        }
        
        .history-item:hover {
            background: #e0e0e0;
            transform: translateX(5px);
        }
        
        .preset-item {
            padding: 12px;
            background: #f8f8f8;
            border-radius: 8px;
            margin-bottom: 10px;
            cursor: pointer;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        
        .preset-item:hover {
            background: #e0e0e0;
        }
        
        .advanced-settings {
            background: #f8f8f8;
            border-radius: 10px;
            padding: 15px;
            margin-top: 20px;
        }
        
        .setting-row {
            display: flex;
            align-items: center;
            margin-bottom: 10px;
        }
        
        .setting-row label {
            flex: 1;
            margin-bottom: 0;
        }
        
        .setting-row input[type="checkbox"] {
            width: auto;
            margin-left: 10px;
        }
        
        .quick-actions {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 10px;
            margin-bottom: 20px;
        }
        
        .quick-action-btn {
            padding: 10px;
            background: #f5f5f5;
            border: 2px solid #e0e0e0;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.3s;
            text-align: center;
        }
        
        .quick-action-btn:hover {
            background: #e0e0e0;
            border-color: #667eea;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(2, 1fr);
            gap: 15px;
            margin-bottom: 20px;
        }
        
        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            text-align: center;
        }
        
        .stat-value {
            font-size: 24px;
            font-weight: bold;
            margin-bottom: 5px;
        }
        
        .stat-label {
            font-size: 12px;
            opacity: 0.9;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸš€ è…¾è®¯æ–‡æ¡£æ™ºèƒ½å¤„ç†ç³»ç»Ÿ <span class="version-badge">v5.0 å¢å¼ºç‰ˆ</span></h1>
            <div style="background: #f0f8ff; border-left: 4px solid #1890ff; padding: 12px; margin: 20px 0; border-radius: 4px;">
                <strong>ğŸ“Œ ä½¿ç”¨è¯´æ˜ï¼š</strong><br>
                <ul style="margin: 8px 0 0 0; padding-left: 20px;">
                    <li><strong>åŸºçº¿æ–‡æ¡£</strong>ï¼šé€‰æ‹©ä¸Šå‘¨æˆ–æ›´æ—©çš„ç‰ˆæœ¬ä½œä¸ºå¯¹æ¯”åŸºå‡†</li>
                    <li><strong>ç›®æ ‡æ–‡æ¡£</strong>ï¼šé€‰æ‹©å½“å‰æœ€æ–°ç‰ˆæœ¬è¿›è¡Œå˜æ›´æ£€æµ‹</li>
                    <li><strong>é‡è¦</strong>ï¼šä¸¤ä¸ªURLå¿…é¡»ä¸åŒï¼Œå¦åˆ™æ— æ³•æ£€æµ‹åˆ°å˜æ›´</li>
                </ul>
            </div>
            <p>å®Œæ•´é›†æˆæµ‹è¯• - ä»ä¸‹è½½åˆ°ä¸Šä¼ çš„å…¨è‡ªåŠ¨åŒ–æµç¨‹</p>
        </div>
        
        <div class="main-content">
            <!-- å·¦ä¾§é¢æ¿ï¼šè¾“å…¥é…ç½® -->
            <div class="panel">
                <h2>ğŸ“¥ è¾“å…¥é…ç½®</h2>
                
                <div class="tabs">
                    <button class="tab active" onclick="switchTab('basic')">åŸºç¡€é…ç½®</button>
                    <button class="tab" onclick="switchTab('advanced')">é«˜çº§é€‰é¡¹</button>
                    <button class="tab" onclick="switchTab('presets')">é¢„è®¾æ¨¡æ¿</button>
                </div>
                
                <!-- åŸºç¡€é…ç½® -->
                <div id="basic-tab" class="tab-content active">
                    <div class="form-group">
                        <label>åŸºçº¿æ–‡æ¡£é“¾æ¥ <span style="color: #666; font-size: 12px;">(ä¸Šå‘¨æˆ–æ›´æ—©ç‰ˆæœ¬)</span></label>
                        <input type="text" id="baselineUrl" placeholder="https://docs.qq.com/sheet/xxx (æ—§ç‰ˆæœ¬)">
                        <button class="btn-secondary" style="margin-top: 5px; padding: 5px;" onclick="browseFiles('baseline')">
                            é€‰æ‹©å·²ä¸‹è½½æ–‡ä»¶
                        </button>
                    </div>
                    
                    <div class="form-group">
                        <label>ç›®æ ‡æ–‡æ¡£é“¾æ¥ <span style="color: #666; font-size: 12px;">(å½“å‰æœ€æ–°ç‰ˆæœ¬)</span></label>
                        <input type="text" id="targetUrl" placeholder="https://docs.qq.com/sheet/xxx (æ–°ç‰ˆæœ¬)">
                        <button class="btn-secondary" style="margin-top: 5px; padding: 5px;" onclick="browseFiles('target')">
                            é€‰æ‹©å·²ä¸‹è½½æ–‡ä»¶
                        </button>
                    </div>
                    
                    <div class="form-group">
                        <label>Cookieï¼ˆç”¨äºä¸‹è½½å’Œä¸Šä¼ ï¼‰</label>
                        <textarea id="cookie" rows="4" placeholder="è¾“å…¥å®Œæ•´çš„Cookieå­—ç¬¦ä¸²"></textarea>
                        <div style="margin-top: 5px;">
                            <button class="btn-secondary" style="padding: 5px; margin-right: 10px; background: #28a745;" onclick="saveCookieToServer()">
                                ğŸ’¾ ä¿å­˜Cookieåˆ°æœåŠ¡å™¨
                            </button>
                            <button class="btn-secondary" style="padding: 5px; margin-right: 10px; background: #17a2b8;" onclick="loadCookieFromServer()">
                                ğŸ“¥ ä»æœåŠ¡å™¨åŠ è½½Cookie
                            </button>
                            <button class="btn-secondary" style="padding: 5px; margin-right: 10px;" onclick="loadSavedCookie()">
                                åŠ è½½æœ¬åœ°Cookie
                            </button>
                            <button class="btn-secondary" style="padding: 5px; background: #ff6b6b;" onclick="clearSavedData()">
                                æ¸…é™¤ä¿å­˜çš„æ•°æ®
                            </button>
                        </div>
                    </div>
                    
                    <button class="btn" id="startBtn" onclick="startWorkflow()">
                        å¼€å§‹æ‰§è¡Œå®Œæ•´æµç¨‹
                    </button>
                </div>
                
                <!-- é«˜çº§é€‰é¡¹ -->
                <div id="advanced-tab" class="tab-content">
                    <div class="advanced-settings">
                        <div class="setting-row">
                            <label>ä¸Šä¼ æ–¹å¼</label>
                            <select id="uploadOption">
                                <option value="new">åˆ›å»ºæ–°æ–‡æ¡£</option>
                                <option value="replace">æ›¿æ¢ç°æœ‰æ–‡æ¡£</option>
                            </select>
                        </div>
                        
                        <div class="setting-row">
                            <label>ç›®æ ‡æ–‡æ¡£URLï¼ˆæ›¿æ¢æ¨¡å¼ï¼‰</label>
                            <input type="text" id="uploadTargetUrl" placeholder="ç•™ç©ºåˆ™åˆ›å»ºæ–°æ–‡æ¡£">
                        </div>
                        
                        <div class="setting-row">
                            <label>å¯ç”¨è¯¦ç»†æ—¥å¿—</label>
                            <input type="checkbox" id="verboseLogging">
                        </div>
                        
                        <div class="setting-row">
                            <label>å¼ºåˆ¶ä¸‹è½½æ–°æ–‡ä»¶ï¼ˆä¸ä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼‰</label>
                            <input type="checkbox" id="forceDownload" checked>
                        </div>
                        
                        <div class="setting-row">
                            <label>ä¿å­˜æ‰§è¡Œé…ç½®ä¸ºé¢„è®¾</label>
                            <input type="checkbox" id="saveAsPreset">
                        </div>
                        
                        <div class="form-group" id="presetNameGroup" style="display: none;">
                            <label>é¢„è®¾åç§°</label>
                            <input type="text" id="presetName" placeholder="è¾“å…¥é¢„è®¾åç§°">
                        </div>
                    </div>
                </div>
                
                <!-- é¢„è®¾æ¨¡æ¿ -->
                <div id="presets-tab" class="tab-content">
                    <div class="quick-actions">
                        <div class="quick-action-btn" onclick="loadPreset('weekly_check')">
                            ğŸ“… å‘¨åº¦æ£€æŸ¥
                        </div>
                        <div class="quick-action-btn" onclick="loadPreset('emergency_check')">
                            ğŸš¨ ç´§æ€¥æ£€æŸ¥
                        </div>
                        <div class="quick-action-btn" onclick="loadPreset('full_analysis')">
                            ğŸ“Š å®Œæ•´åˆ†æ
                        </div>
                        <div class="quick-action-btn" onclick="loadPreset('quick_test')">
                            âš¡ å¿«é€Ÿæµ‹è¯•
                        </div>
                    </div>
                    
                    <div id="presetsList"></div>
                </div>
                
                <div class="progress-bar">
                    <div class="progress-fill" id="progressBar" style="width: 0%">
                        0%
                    </div>
                </div>
                
                <div class="modules-status" id="modulesStatus"></div>
            </div>
            
            <!-- ä¸­é—´é¢æ¿ï¼šæ‰§è¡ŒçŠ¶æ€å’Œæ—¥å¿— -->
            <div class="panel">
                <h2>ğŸ“Š æ‰§è¡ŒçŠ¶æ€</h2>
                
                <div style="margin-bottom: 15px;">
                    <span class="status-indicator status-idle" id="statusIndicator"></span>
                    <span id="statusText">ç­‰å¾…å¼€å§‹</span>
                    <span style="float: right;" id="currentTask"></span>
                </div>
                
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="stat-value" id="changedCells">0</div>
                        <div class="stat-label">å˜æ›´å•å…ƒæ ¼</div>
                    </div>
                    <div class="stat-card" style="background: linear-gradient(135deg, #FF6B6B, #FF8E53);">
                        <div class="stat-value" id="riskScore">0</div>
                        <div class="stat-label">é£é™©åˆ†æ•°</div>
                    </div>
                    <div class="stat-card" style="background: linear-gradient(135deg, #4ECDC4, #44A08D);">
                        <div class="stat-value" id="executionTime">00:00</div>
                        <div class="stat-label">æ‰§è¡Œæ—¶é—´</div>
                    </div>
                    <div class="stat-card" style="background: linear-gradient(135deg, #FA709A, #FEE140);">
                        <div class="stat-value" id="successRate">0%</div>
                        <div class="stat-label">æˆåŠŸç‡</div>
                    </div>
                </div>
                
                <div class="log-container" id="logContainer"></div>
                
                <div class="results-panel" id="resultsPanel">
                    <h3>å¤„ç†ç»“æœ</h3>
                    <div id="resultsContent"></div>
                </div>
            </div>
            
            <!-- å³ä¾§é¢æ¿ï¼šå†å²è®°å½•å’Œæ–‡ä»¶ç®¡ç† -->
            <div class="panel">
                <h2>ğŸ“š å†å²ä¸æ–‡ä»¶</h2>
                
                <div class="tabs">
                    <button class="tab active" onclick="switchRightTab('history')">æ‰§è¡Œå†å²</button>
                    <button class="tab" onclick="switchRightTab('files')">æ–‡ä»¶ç®¡ç†</button>
                </div>
                
                <!-- æ‰§è¡Œå†å² -->
                <div id="history-tab" class="tab-content active">
                    <div id="historyList"></div>
                </div>
                
                <!-- æ–‡ä»¶ç®¡ç† -->
                <div id="files-tab" class="tab-content">
                    <div class="form-group">
                        <label>æ–‡ä»¶ç±»åˆ«</label>
                        <select id="fileCategory" onchange="loadFiles()">
                            <option value="downloads">ä¸‹è½½æ–‡ä»¶</option>
                            <option value="csv_versions">CSVç‰ˆæœ¬</option>
                            <option value="comparisons">å¯¹æ¯”ç»“æœ</option>
                            <option value="scores">æ‰“åˆ†æ–‡ä»¶</option>
                            <option value="excel_outputs">Excelè¾“å‡º</option>
                        </select>
                    </div>
                    
                    <div class="file-browser" id="fileBrowser"></div>
                </div>
            </div>
        </div>
    </div>
    
    <!-- æ–‡ä»¶é€‰æ‹©å¯¹è¯æ¡† -->
    <div id="fileDialog" style="display: none; position: fixed; top: 0; left: 0; right: 0; bottom: 0; background: rgba(0,0,0,0.5); z-index: 1000;">
        <div style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); background: white; padding: 30px; border-radius: 20px; width: 600px; max-height: 500px;">
            <h3>é€‰æ‹©æ–‡ä»¶</h3>
            <div class="file-browser" id="dialogFileBrowser" style="height: 300px; margin: 20px 0;"></div>
            <div style="text-align: right;">
                <button class="btn-secondary" style="width: auto; padding: 10px 20px; margin-right: 10px;" onclick="closeFileDialog()">å–æ¶ˆ</button>
                <button class="btn" style="width: auto; padding: 10px 20px;" onclick="selectFile()">é€‰æ‹©</button>
            </div>
        </div>
    </div>
    
    <script>
        let isRunning = false;
        let statusInterval = null;
        let selectedFile = null;
        let fileDialogTarget = null;
        let executionStartTime = null;
        let timeInterval = null;
        
        // é¡µé¢åŠ è½½æ—¶åˆå§‹åŒ–
        window.onload = function() {
            loadModules();
            loadHistory();
            loadPresets();
            
            // è‡ªåŠ¨åŠ è½½ä¿å­˜çš„URLå’ŒCookie
            loadSavedInputs();
            
            // ç›‘å¬é«˜çº§è®¾ç½®å˜åŒ–
            document.getElementById('saveAsPreset').addEventListener('change', function(e) {
                document.getElementById('presetNameGroup').style.display = e.target.checked ? 'block' : 'none';
            });
            
            // ç›‘å¬URLè¾“å…¥å˜åŒ–ï¼Œè‡ªåŠ¨ä¿å­˜
            document.getElementById('baselineUrl').addEventListener('change', function() {
                if (this.value) {
                    localStorage.setItem('tencent_baseline_url', this.value);
                }
            });
            
            document.getElementById('targetUrl').addEventListener('change', function() {
                if (this.value) {
                    localStorage.setItem('tencent_target_url', this.value);
                }
            });
        }
        
        // åŠ è½½ä¿å­˜çš„è¾“å…¥å€¼
        function loadSavedInputs() {
            // åŠ è½½ä¿å­˜çš„URL
            const savedBaselineUrl = localStorage.getItem('tencent_baseline_url');
            const savedTargetUrl = localStorage.getItem('tencent_target_url');
            const savedCookie = localStorage.getItem('tencent_doc_cookie');
            
            if (savedBaselineUrl) {
                document.getElementById('baselineUrl').value = savedBaselineUrl;
            }
            
            if (savedTargetUrl) {
                document.getElementById('targetUrl').value = savedTargetUrl;
            }
            
            if (savedCookie) {
                document.getElementById('cookie').value = savedCookie;
            }
            
            // å¦‚æœæœ‰ä¿å­˜çš„å€¼ï¼Œæ˜¾ç¤ºæç¤º
            if (savedBaselineUrl || savedTargetUrl || savedCookie) {
                console.log('å·²è‡ªåŠ¨åŠ è½½ä¸Šæ¬¡ä¿å­˜çš„è¾“å…¥');
            }
        }
        
        function loadModules() {
            fetch('/api/modules')
                .then(r => r.json())
                .then(data => {
                    displayModules(data);
                });
        }
        
        function displayModules(modules) {
            const container = document.getElementById('modulesStatus');
            container.innerHTML = '<h4 style="grid-column: 1/-1; margin-bottom: 10px;">æ¨¡å—åŠ è½½çŠ¶æ€</h4>';
            
            const moduleNames = {
                'downloader': 'ä¸‹è½½æ¨¡å—',
                'comparator': 'æ¯”è¾ƒæ¨¡å—',
                'standardizer': 'æ ‡å‡†åŒ–',
                'l2_analyzer': 'L2åˆ†æ',
                'marker': 'æ™ºèƒ½æ ‡è®°',
                'fixer': 'Excelä¿®å¤',
                'uploader': 'ä¸Šä¼ æ¨¡å—',
                'week_manager': 'æ—¶é—´ç®¡ç†'
            };
            
            let loadedCount = 0;
            let totalCount = 0;
            
            for (let [key, loaded] of Object.entries(modules)) {
                totalCount++;
                if (loaded) loadedCount++;
                
                const div = document.createElement('div');
                div.className = 'module-item ' + (loaded ? 'module-loaded' : 'module-failed');
                div.innerHTML = (loaded ? '[OK] ' : '[X] ') + (moduleNames[key] || key);
                container.appendChild(div);
            }
            
            // æ›´æ–°æˆåŠŸç‡
            document.getElementById('successRate').textContent = Math.round(loadedCount / totalCount * 100) + '%';
        }
        
        function switchTab(tabName) {
            // éšè—æ‰€æœ‰æ ‡ç­¾å†…å®¹
            document.querySelectorAll('.tab-content').forEach(tab => {
                tab.classList.remove('active');
            });
            
            // ç§»é™¤æ‰€æœ‰æ ‡ç­¾çš„activeç±»
            document.querySelectorAll('.tab').forEach(tab => {
                tab.classList.remove('active');
            });
            
            // æ˜¾ç¤ºé€‰ä¸­çš„æ ‡ç­¾
            document.getElementById(tabName + '-tab').classList.add('active');
            event.target.classList.add('active');
        }
        
        function switchRightTab(tabName) {
            // å³ä¾§é¢æ¿çš„æ ‡ç­¾åˆ‡æ¢
            const rightPanel = event.target.closest('.panel');
            rightPanel.querySelectorAll('.tab-content').forEach(tab => {
                tab.classList.remove('active');
            });
            
            rightPanel.querySelectorAll('.tab').forEach(tab => {
                tab.classList.remove('active');
            });
            
            rightPanel.querySelector('#' + tabName + '-tab').classList.add('active');
            event.target.classList.add('active');
            
            if (tabName === 'files') {
                loadFiles();
            }
        }
        
        function startWorkflow() {
            if (isRunning) {
                alert('å·¥ä½œæµæ­£åœ¨è¿è¡Œä¸­ï¼Œè¯·ç­‰å¾…å®Œæˆ');
                return;
            }
            
            const baselineUrl = document.getElementById('baselineUrl').value;
            const targetUrl = document.getElementById('targetUrl').value;
            const cookie = document.getElementById('cookie').value;
            
            if (!baselineUrl || !targetUrl || !cookie) {
                alert('è¯·å¡«å†™æ‰€æœ‰å¿…è¦å­—æ®µ');
                return;
            }
            
            // éªŒè¯URLä¸èƒ½ç›¸åŒ
            if (baselineUrl === targetUrl) {
                alert('é”™è¯¯ï¼šåŸºçº¿æ–‡æ¡£å’Œç›®æ ‡æ–‡æ¡£ä¸èƒ½ç›¸åŒï¼\\n\\n' +
                      'åŸºçº¿æ–‡æ¡£ï¼šåº”é€‰æ‹©ä¸Šå‘¨æˆ–æ›´æ—©ç‰ˆæœ¬\\n' +
                      'ç›®æ ‡æ–‡æ¡£ï¼šåº”é€‰æ‹©å½“å‰æœ€æ–°ç‰ˆæœ¬\\n\\n' +
                      'è¯·ä½¿ç”¨ä¸åŒçš„æ–‡æ¡£URLè¿›è¡Œå¯¹æ¯”ã€‚');
                return;
            }
            
            // æ”¶é›†é«˜çº§è®¾ç½®
            const advancedSettings = {
                upload_option: document.getElementById('uploadOption').value,
                upload_target_url: document.getElementById('uploadTargetUrl').value,
                verbose_logging: document.getElementById('verboseLogging').checked,
                force_download: document.getElementById('forceDownload').checked
            };
            
            // å¦‚æœéœ€è¦ä¿å­˜ä¸ºé¢„è®¾
            if (document.getElementById('saveAsPreset').checked) {
                const presetName = document.getElementById('presetName').value;
                if (presetName) {
                    savePreset(presetName, {
                        baseline_url: baselineUrl,
                        target_url: targetUrl,
                        advanced_settings: advancedSettings,
                        description: 'ç”¨æˆ·è‡ªå®šä¹‰é¢„è®¾'
                    });
                }
            }
            
            isRunning = true;
            document.getElementById('startBtn').disabled = true;
            document.getElementById('logContainer').innerHTML = '';
            document.getElementById('resultsContent').innerHTML = '';
            
            // å¼€å§‹è®¡æ—¶
            executionStartTime = Date.now();
            timeInterval = setInterval(updateExecutionTime, 1000);
            
            fetch('/api/start', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({
                    baseline_url: baselineUrl,
                    target_url: targetUrl,
                    cookie: cookie,
                    advanced_settings: advancedSettings
                })
            })
            .then(r => r.json())
            .then(data => {
                if (data.error) {
                    alert(data.error);
                    resetUI();
                } else {
                    // å¼€å§‹è½®è¯¢çŠ¶æ€
                    statusInterval = setInterval(updateStatus, 1000);
                }
            });
        }
        
        function updateStatus() {
            fetch('/api/status')
                .then(r => r.json())
                .then(data => {
                    // æ›´æ–°è¿›åº¦æ¡
                    document.getElementById('progressBar').style.width = data.progress + '%';
                    document.getElementById('progressBar').textContent = data.progress + '%';
                    
                    // æ›´æ–°çŠ¶æ€æŒ‡ç¤ºå™¨
                    const indicator = document.getElementById('statusIndicator');
                    indicator.className = 'status-indicator status-' + data.status;
                    
                    // æ›´æ–°çŠ¶æ€æ–‡æœ¬
                    const statusTexts = {
                        'idle': 'ç­‰å¾…å¼€å§‹',
                        'running': 'æ­£åœ¨æ‰§è¡Œ',
                        'completed': 'æ‰§è¡Œå®Œæˆ',
                        'error': 'æ‰§è¡Œå‡ºé”™'
                    };
                    document.getElementById('statusText').textContent = statusTexts[data.status] || data.status;
                    
                    // æ›´æ–°å½“å‰ä»»åŠ¡
                    document.getElementById('currentTask').textContent = data.current_task || '';
                    
                    // æ›´æ–°æ—¥å¿—ï¼ˆæ”¹ä¸ºç´¯ç§¯æ˜¾ç¤ºæ‰€æœ‰æ—¥å¿—ï¼‰
                    if (data.logs && data.logs.length > 0) {
                        const container = document.getElementById('logContainer');
                        const currentLogCount = container.children.length;

                        // å¦‚æœæ—¥å¿—æ•°é‡å‡å°‘äº†ï¼ˆæ–°çš„å·¥ä½œæµå¼€å§‹ï¼‰ï¼Œæ¸…ç©ºå®¹å™¨
                        if (data.logs.length < currentLogCount) {
                            container.innerHTML = '';
                        }

                        // åªæ·»åŠ æ–°çš„æ—¥å¿—æ¡ç›®
                        for (let i = currentLogCount; i < data.logs.length; i++) {
                            const log = data.logs[i];
                            const div = document.createElement('div');
                            div.className = 'log-entry log-' + log.level;
                            div.innerHTML = `<span style="color: #666;">[${log.time}]</span> ${log.message}`;
                            container.appendChild(div);
                        }

                        // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
                        container.scrollTop = container.scrollHeight;
                    }
                    
                    // æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                    if (data.results && data.results.statistics) {
                        const stats = data.results.statistics;
                        document.getElementById('changedCells').textContent = stats.changed_cells || 0;
                        document.getElementById('riskScore').textContent = stats.risk_score || 0;
                    }
                    
                    // å¦‚æœå®Œæˆæˆ–å‡ºé”™ï¼Œåœæ­¢è½®è¯¢
                    if (data.status === 'completed' || data.status === 'error') {
                        clearInterval(statusInterval);
                        clearInterval(timeInterval);
                        isRunning = false;
                        document.getElementById('startBtn').disabled = false;
                        
                        // æ˜¾ç¤ºç»“æœ
                        if (data.results) {
                            displayResults(data.results);
                        }
                        
                        // åˆ·æ–°å†å²è®°å½•
                        loadHistory();
                    }
                });
        }
        
        function updateExecutionTime() {
            if (executionStartTime) {
                const elapsed = Math.floor((Date.now() - executionStartTime) / 1000);
                const minutes = Math.floor(elapsed / 60);
                const seconds = elapsed % 60;
                document.getElementById('executionTime').textContent = 
                    `${minutes.toString().padStart(2, '0')}:${seconds.toString().padStart(2, '0')}`;
            }
        }
        
        function displayResults(results) {
            const container = document.getElementById('resultsContent');
            container.innerHTML = '';
            
            const files = [
                {label: 'åŸºçº¿æ–‡ä»¶', key: 'baseline_file'},
                {label: 'ç›®æ ‡æ–‡ä»¶', key: 'target_file'},
                {label: 'æ‰“åˆ†æ–‡ä»¶', key: 'score_file'},
                {label: 'æ ‡è®°æ–‡ä»¶', key: 'marked_file'}
            ];
            
            files.forEach(file => {
                if (results[file.key]) {
                    const div = document.createElement('div');
                    div.className = 'result-item';
                    const filename = results[file.key].split('/').pop();
                    div.innerHTML = `
                        <span>${file.label}: ${filename}</span>
                        <a href="/api/download/${results[file.key]}" download>ä¸‹è½½</a>
                    `;
                    container.appendChild(div);
                }
            });
            
            if (results.upload_url) {
                const div = document.createElement('div');
                div.className = 'result-item';
                div.innerHTML = `
                    <span>ä¸Šä¼ é“¾æ¥:</span>
                    <a href="${results.upload_url}" target="_blank">æ‰“å¼€æ–‡æ¡£</a>
                `;
                container.appendChild(div);
            }
        }
        
        function resetUI() {
            isRunning = false;
            document.getElementById('startBtn').disabled = false;
            clearInterval(statusInterval);
            clearInterval(timeInterval);
        }
        
        function browseFiles(target) {
            fileDialogTarget = target;
            document.getElementById('fileDialog').style.display = 'block';
            loadDialogFiles();
        }
        
        function loadDialogFiles() {
            fetch('/api/files/downloads')
                .then(r => r.json())
                .then(files => {
                    const browser = document.getElementById('dialogFileBrowser');
                    browser.innerHTML = '';
                    
                    files.forEach(file => {
                        const div = document.createElement('div');
                        div.className = 'file-item';
                        div.onclick = () => {
                            document.querySelectorAll('.file-item').forEach(item => {
                                item.classList.remove('selected');
                            });
                            div.classList.add('selected');
                            selectedFile = file;
                        };
                        
                        const size = (file.size / 1024).toFixed(2) + ' KB';
                        const date = new Date(file.modified).toLocaleDateString();
                        
                        div.innerHTML = `
                            <div style="font-weight: 500;">${file.name}</div>
                            <div style="font-size: 12px; color: #666;">${size} | ${date}</div>
                        `;
                        
                        browser.appendChild(div);
                    });
                });
        }
        
        function selectFile() {
            if (selectedFile) {
                if (fileDialogTarget === 'baseline') {
                    document.getElementById('baselineUrl').value = selectedFile.path;
                } else if (fileDialogTarget === 'target') {
                    document.getElementById('targetUrl').value = selectedFile.path;
                }
            }
            closeFileDialog();
        }
        
        function closeFileDialog() {
            document.getElementById('fileDialog').style.display = 'none';
            selectedFile = null;
            fileDialogTarget = null;
        }
        
        function loadFiles() {
            const category = document.getElementById('fileCategory').value;
            fetch('/api/files/' + category)
                .then(r => r.json())
                .then(files => {
                    const browser = document.getElementById('fileBrowser');
                    browser.innerHTML = '';
                    
                    files.forEach(file => {
                        const div = document.createElement('div');
                        div.className = 'file-item';
                        
                        const size = (file.size / 1024).toFixed(2) + ' KB';
                        const date = new Date(file.modified).toLocaleDateString();
                        
                        div.innerHTML = `
                            <div style="display: flex; justify-content: space-between; align-items: center;">
                                <div>
                                    <div style="font-weight: 500;">${file.name}</div>
                                    <div style="font-size: 12px; color: #666;">${size} | ${date}</div>
                                </div>
                                <a href="/api/download/${file.path}" download style="color: #667eea;">ä¸‹è½½</a>
                            </div>
                        `;
                        
                        browser.appendChild(div);
                    });
                });
        }
        
        function loadHistory() {
            fetch('/api/history')
                .then(r => r.json())
                .then(history => {
                    const container = document.getElementById('historyList');
                    container.innerHTML = '';
                    
                    if (history.length === 0) {
                        container.innerHTML = '<div style="text-align: center; color: #999; padding: 20px;">æš‚æ— æ‰§è¡Œå†å²</div>';
                        return;
                    }
                    
                    history.forEach(item => {
                        const div = document.createElement('div');
                        div.className = 'history-item';
                        
                        const startTime = item.start_time ? new Date(item.start_time).toLocaleString() : 'æœªçŸ¥';
                        const statusIcon = {
                            'completed': '[å®Œæˆ]',
                            'error': '[é”™è¯¯]',
                            'running': '[è¿è¡Œä¸­]'
                        }[item.status] || 'â“';
                        
                        div.innerHTML = `
                            <div style="display: flex; justify-content: space-between; margin-bottom: 5px;">
                                <strong>${statusIcon} ${item.id}</strong>
                                <span style="color: #666; font-size: 12px;">${item.status}</span>
                            </div>
                            <div style="font-size: 12px; color: #666;">${startTime}</div>
                        `;
                        
                        div.onclick = () => loadHistoryDetails(item.id);
                        container.appendChild(div);
                    });
                });
        }
        
        function loadHistoryDetails(id) {
            // å¯ä»¥å±•å¼€æ˜¾ç¤ºå†å²è¯¦æƒ…
            console.log('Loading history:', id);
        }
        
        function loadPresets() {
            fetch('/api/presets')
                .then(r => r.json())
                .then(presets => {
                    const container = document.getElementById('presetsList');
                    container.innerHTML = '<h4 style="margin-bottom: 10px;">è‡ªå®šä¹‰é¢„è®¾</h4>';
                    
                    if (presets.length === 0) {
                        container.innerHTML += '<div style="text-align: center; color: #999; padding: 20px;">æš‚æ— è‡ªå®šä¹‰é¢„è®¾</div>';
                        return;
                    }
                    
                    presets.forEach(preset => {
                        const div = document.createElement('div');
                        div.className = 'preset-item';
                        div.innerHTML = `
                            <div>
                                <div style="font-weight: 500;">${preset.name}</div>
                                <div style="font-size: 12px; color: #666;">${preset.description}</div>
                            </div>
                            <button class="btn-secondary" style="width: auto; padding: 5px 15px;" onclick="applyPreset('${preset.name}')">åº”ç”¨</button>
                        `;
                        container.appendChild(div);
                    });
                });
        }
        
        function loadPreset(presetType) {
            // é¢„å®šä¹‰çš„å¿«é€Ÿé¢„è®¾
            const presets = {
                'weekly_check': {
                    baseline_url: 'https://docs.qq.com/sheet/baseline_week',
                    target_url: 'https://docs.qq.com/sheet/target_week',
                    advanced_settings: {
                        upload_option: 'new'
                    }
                },
                'emergency_check': {
                    baseline_url: '',
                    target_url: '',
                    advanced_settings: {
                        upload_option: 'replace',
                        verbose_logging: true
                    }
                },
                'full_analysis': {
                    baseline_url: '',
                    target_url: '',
                    advanced_settings: {
                        upload_option: 'new',
                        verbose_logging: true
                    }
                },
                'quick_test': {
                    baseline_url: '',
                    target_url: '',
                    advanced_settings: {
                        upload_option: 'new'
                    }
                }
            };
            
            const preset = presets[presetType];
            if (preset) {
                if (preset.baseline_url) document.getElementById('baselineUrl').value = preset.baseline_url;
                if (preset.target_url) document.getElementById('targetUrl').value = preset.target_url;
                if (preset.advanced_settings) {
                    document.getElementById('uploadOption').value = preset.advanced_settings.upload_option || 'new';
                    document.getElementById('uploadTargetUrl').value = preset.advanced_settings.upload_target_url || '';
                    document.getElementById('verboseLogging').checked = preset.advanced_settings.verbose_logging || false;
                }
                
                // åˆ‡æ¢åˆ°åŸºç¡€é…ç½®æ ‡ç­¾
                document.querySelectorAll('.tab').forEach(tab => tab.classList.remove('active'));
                document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
                document.querySelector('.tab').classList.add('active');
                document.getElementById('basic-tab').classList.add('active');
            }
        }
        
        function applyPreset(name) {
            fetch('/api/presets/' + name)
                .then(r => r.json())
                .then(preset => {
                    if (preset.baseline_url) document.getElementById('baselineUrl').value = preset.baseline_url;
                    if (preset.target_url) document.getElementById('targetUrl').value = preset.target_url;
                    if (preset.cookie) document.getElementById('cookie').value = preset.cookie;
                    if (preset.advanced_settings) {
                        document.getElementById('uploadOption').value = preset.advanced_settings.upload_option || 'new';
                        document.getElementById('uploadTargetUrl').value = preset.advanced_settings.upload_target_url || '';
                        document.getElementById('verboseLogging').checked = preset.advanced_settings.verbose_logging || false;
                    }
                    
                    // åˆ‡æ¢åˆ°åŸºç¡€é…ç½®æ ‡ç­¾
                    document.querySelectorAll('.tab').forEach(tab => tab.classList.remove('active'));
                    document.querySelectorAll('.tab-content').forEach(content => content.classList.remove('active'));
                    document.querySelector('.tab').classList.add('active');
                    document.getElementById('basic-tab').classList.add('active');
                });
        }
        
        function savePreset(name, config) {
            fetch('/api/presets', {
                method: 'POST',
                headers: {'Content-Type': 'application/json'},
                body: JSON.stringify({
                    name: name,
                    config: config
                })
            })
            .then(r => r.json())
            .then(data => {
                if (data.message) {
                    loadPresets();
                }
            });
        }
        
        function saveCookieToServer() {
            const cookie = document.getElementById('cookie').value.trim();
            
            if (!cookie) {
                alert('è¯·å…ˆè¾“å…¥Cookie');
                return;
            }
            
            fetch('/api/save-cookie', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ cookie: cookie })
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    alert(`âœ… Cookieå·²æˆåŠŸä¿å­˜åˆ°æœåŠ¡å™¨ï¼\nä¿å­˜äº† ${data.cookie_count} ä¸ªCookieå­—æ®µ\næ›´æ–°æ—¶é—´: ${data.last_updated}`);
                    // åŒæ—¶ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
                    localStorage.setItem('tencent_doc_cookie', cookie);
                } else {
                    alert('âŒ ä¿å­˜å¤±è´¥: ' + (data.error || 'æœªçŸ¥é”™è¯¯'));
                }
            })
            .catch(error => {
                alert('âŒ ä¿å­˜Cookieæ—¶å‡ºé”™: ' + error);
            });
        }
        
        function loadCookieFromServer() {
            fetch('/api/load-cookie')
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    document.getElementById('cookie').value = data.cookie;
                    // åŒæ—¶ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
                    localStorage.setItem('tencent_doc_cookie', data.cookie);
                    alert(`âœ… CookieåŠ è½½æˆåŠŸï¼\nåŒ…å« ${data.cookie_count} ä¸ªCookieå­—æ®µ\næœ€åæ›´æ–°: ${data.last_updated}`);
                } else {
                    alert('âŒ åŠ è½½å¤±è´¥: ' + (data.error || 'æœªæ‰¾åˆ°Cookieé…ç½®æ–‡ä»¶'));
                }
            })
            .catch(error => {
                alert('âŒ åŠ è½½Cookieæ—¶å‡ºé”™: ' + error);
            });
        }
        
        function loadSavedCookie() {
            // å°è¯•ä»æœ¬åœ°å­˜å‚¨åŠ è½½Cookie
            const savedCookie = localStorage.getItem('tencent_doc_cookie');
            if (savedCookie) {
                document.getElementById('cookie').value = savedCookie;
                alert('CookieåŠ è½½æˆåŠŸï¼ˆä»æµè§ˆå™¨æœ¬åœ°å­˜å‚¨ï¼‰');
            } else {
                alert('æ²¡æœ‰ä¿å­˜çš„Cookie');
            }
        }
        
        function clearSavedData() {
            if (confirm('ç¡®å®šè¦æ¸…é™¤æ‰€æœ‰ä¿å­˜çš„URLå’ŒCookieå—ï¼Ÿ')) {
                // æ¸…é™¤localStorageä¸­çš„æ‰€æœ‰ç›¸å…³æ•°æ®
                localStorage.removeItem('tencent_baseline_url');
                localStorage.removeItem('tencent_target_url');
                localStorage.removeItem('tencent_doc_cookie');
                
                // æ¸…ç©ºè¾“å…¥æ¡†
                document.getElementById('baselineUrl').value = '';
                document.getElementById('targetUrl').value = '';
                document.getElementById('cookie').value = '';
                
                alert('å·²æ¸…é™¤æ‰€æœ‰ä¿å­˜çš„æ•°æ®');
            }
        }
        
        // ä¿å­˜Cookieåˆ°æœ¬åœ°å­˜å‚¨
        document.getElementById('cookie').addEventListener('change', function() {
            if (this.value) {
                localStorage.setItem('tencent_doc_cookie', this.value);
            }
        });
    </script>
</body>
</html>
'''

# ==================== ä¸»ç¨‹åºå…¥å£ ====================
if __name__ == '__main__':
    logger.info("="*60)
    logger.info("è…¾è®¯æ–‡æ¡£æ™ºèƒ½å¤„ç†ç³»ç»Ÿ - å®Œæ•´é›†æˆæµ‹è¯•ï¼ˆå¢å¼ºç‰ˆï¼‰")
    logger.info(f"è®¿é—®: http://localhost:8093")
    logger.info("="*60)
    
    # å°è¯•å¤šä¸ªç«¯å£
    ports = [8093, 8094, 8095, 8096, 8097, 8098, 8099, 8100, 8101, 8102]
    
    for port in ports:
        try:
            app.run(host='0.0.0.0', port=port, debug=False)
            break
        except OSError as e:
            if "Address already in use" in str(e):
                logger.warning(f"ç«¯å£ {port} å·²è¢«å ç”¨ï¼Œå°è¯•ä¸‹ä¸€ä¸ª...")
                continue
            else:
                raise
    else:
        logger.error("æ‰€æœ‰ç«¯å£éƒ½è¢«å ç”¨ï¼Œæ— æ³•å¯åŠ¨æœåŠ¡")