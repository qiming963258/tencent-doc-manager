#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœåŠ¡å™¨ç«¯å…¨è‡ªåŠ¨åŒ–æ–¹æ¡ˆ
æ— éœ€ç”¨æˆ·ä»‹å…¥ï¼Œ24/7åœ¨æœåŠ¡å™¨è¿è¡Œ
ä½¿ç”¨æ— å¤´æµè§ˆå™¨ + CookieæŒä¹…åŒ–
"""

import os
import time
import json
import asyncio
import schedule
import logging
from datetime import datetime
from typing import List, Dict
from playwright.async_api import async_playwright
import pandas as pd

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ServerSideAutomation:
    """
    æœåŠ¡å™¨ç«¯å…¨è‡ªåŠ¨åŒ–ä¸‹è½½å’Œå¤„ç†ç³»ç»Ÿ
    æ ¸å¿ƒï¼šä½¿ç”¨æ— å¤´æµè§ˆå™¨ + Cookieè‡ªåŠ¨åˆ·æ–°
    """
    
    def __init__(self):
        self.config_file = "/root/projects/tencent-doc-manager/automation_config.json"
        self.cookie_file = "/root/projects/tencent-doc-manager/config/cookies_new.json"
        self.download_dir = "/root/projects/tencent-doc-manager/auto_downloads"
        self.upload_dir = "/root/projects/tencent-doc-manager/processed"
        
        os.makedirs(self.download_dir, exist_ok=True)
        os.makedirs(self.upload_dir, exist_ok=True)
        
        # åŠ è½½é…ç½®
        self.config = self.load_config()
        self.browser = None
        self.context = None
        
    def load_config(self) -> Dict:
        """åŠ è½½è‡ªåŠ¨åŒ–é…ç½®"""
        default_config = {
            "documents": [
                {
                    "id": "DWEVjZndkR2xVSWJN",
                    "name": "æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨",
                    "schedule": "*/30 * * * *",  # æ¯30åˆ†é’Ÿ
                    "format": "xlsx"
                },
                {
                    "id": "DRFppYm15RGZ2WExN",
                    "name": "æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨",
                    "schedule": "0 */2 * * *",  # æ¯2å°æ—¶
                    "format": "csv"
                }
            ],
            "upload": {
                "enabled": True,
                "target": "tencent_docs",  # æˆ– "local", "ftp", "s3"
                "auto_rename": True
            },
            "notification": {
                "enabled": True,
                "webhook": ""  # é’‰é’‰/ä¼ä¸šå¾®ä¿¡webhook
            }
        }
        
        if os.path.exists(self.config_file):
            with open(self.config_file, 'r') as f:
                return json.load(f)
        else:
            # åˆ›å»ºé»˜è®¤é…ç½®
            with open(self.config_file, 'w') as f:
                json.dump(default_config, f, indent=2, ensure_ascii=False)
            return default_config
            
    async def init_browser(self):
        """åˆå§‹åŒ–æ— å¤´æµè§ˆå™¨"""
        playwright = await async_playwright().start()
        
        # ä½¿ç”¨æœåŠ¡å™¨ç«¯ä¸“ç”¨çš„æµè§ˆå™¨é…ç½®
        self.browser = await playwright.chromium.launch(
            headless=True,  # æœåŠ¡å™¨ç«¯å¿…é¡»æ— å¤´æ¨¡å¼
            args=[
                '--no-sandbox',  # æœåŠ¡å™¨ç¯å¢ƒéœ€è¦
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-accelerated-2d-canvas',
                '--no-gpu',
                '--disable-blink-features=AutomationControlled',
                '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            ]
        )
        
        # åˆ›å»ºæŒä¹…åŒ–ä¸Šä¸‹æ–‡
        self.context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            locale='zh-CN',
            timezone_id='Asia/Shanghai'
        )
        
        # åŠ è½½Cookie
        await self.load_and_set_cookies()
        
        logger.info("âœ… æ— å¤´æµè§ˆå™¨åˆå§‹åŒ–æˆåŠŸ")
        
    async def load_and_set_cookies(self):
        """åŠ è½½å¹¶è®¾ç½®Cookie"""
        try:
            with open(self.cookie_file, 'r') as f:
                cookie_data = json.load(f)
                cookie_str = cookie_data['current_cookies']
                
            # å…ˆè®¿é—®è…¾è®¯æ–‡æ¡£ä¸»é¡µ
            page = await self.context.new_page()
            await page.goto("https://docs.qq.com")
            
            # è§£æå¹¶è®¾ç½®Cookie
            cookies = []
            for item in cookie_str.split('; '):
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies.append({
                        'name': key,
                        'value': value,
                        'domain': '.qq.com',
                        'path': '/'
                    })
            
            await self.context.add_cookies(cookies)
            await page.close()
            
            logger.info(f"âœ… å·²è®¾ç½® {len(cookies)} ä¸ªCookie")
            
        except Exception as e:
            logger.error(f"CookieåŠ è½½å¤±è´¥: {e}")
            
    async def download_document(self, doc_info: Dict) -> str:
        """
        ä¸‹è½½å•ä¸ªæ–‡æ¡£
        è¿”å›ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„
        """
        doc_id = doc_info['id']
        doc_name = doc_info['name']
        format_type = doc_info.get('format', 'xlsx')
        
        logger.info(f"å¼€å§‹ä¸‹è½½: {doc_name} ({doc_id})")
        
        try:
            page = await self.context.new_page()
            
            # è®¿é—®æ–‡æ¡£
            doc_url = f"https://docs.qq.com/sheet/{doc_id}"
            await page.goto(doc_url, wait_until='networkidle')
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            await page.wait_for_timeout(3000)
            
            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            if "ç™»å½•" in await page.content():
                logger.warning("Cookieå·²è¿‡æœŸï¼Œéœ€è¦åˆ·æ–°")
                return None
                
            # æ–¹æ¡ˆ1ï¼šç›´æ¥æ„é€ ä¸‹è½½URLï¼ˆæœ€ç¨³å®šï¼‰
            timestamp = int(time.time() * 1000)
            download_url = f"https://docs.qq.com/dop-api/opendoc?id={doc_id}&type=export_{format_type}&download=1&t={timestamp}"
            
            # è·å–ä¸‹è½½å†…å®¹
            response = await page.goto(download_url)
            
            if response.status == 200:
                content = await response.body()
                
                # ä¿å­˜æ–‡ä»¶
                timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{doc_name}_{timestamp_str}.{format_type}"
                filepath = os.path.join(self.download_dir, filename)
                
                with open(filepath, 'wb') as f:
                    f.write(content)
                    
                logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {filepath}")
                await page.close()
                return filepath
                
            else:
                logger.error(f"ä¸‹è½½å¤±è´¥: HTTP {response.status}")
                await page.close()
                return None
                
        except Exception as e:
            logger.error(f"ä¸‹è½½å‡ºé”™: {e}")
            if page:
                await page.close()
            return None
            
    async def analyze_document(self, filepath: str) -> Dict:
        """
        åˆ†ææ–‡æ¡£å†…å®¹
        æ£€æµ‹å˜åŒ–ã€æå–å…³é”®ä¿¡æ¯
        """
        logger.info(f"åˆ†ææ–‡æ¡£: {filepath}")
        
        try:
            if filepath.endswith('.xlsx'):
                df = pd.read_excel(filepath)
            elif filepath.endswith('.csv'):
                df = pd.read_csv(filepath)
            else:
                return {}
                
            analysis = {
                'rows': len(df),
                'columns': len(df.columns),
                'columns_list': df.columns.tolist(),
                'has_changes': False,  # TODO: ä¸å†å²ç‰ˆæœ¬å¯¹æ¯”
                'summary': f"è¡¨æ ¼åŒ…å« {len(df)} è¡Œ {len(df.columns)} åˆ—"
            }
            
            # TODO: è¿™é‡Œå¯ä»¥åŠ å…¥æ›´å¤æ‚çš„åˆ†æé€»è¾‘
            # - ä¸ä¸Šä¸€ç‰ˆæœ¬å¯¹æ¯”
            # - AIè¯­ä¹‰åˆ†æ
            # - é£é™©è¯„ä¼°
            
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥: {e}")
            return {}
            
    async def upload_to_target(self, filepath: str, analysis: Dict) -> bool:
        """
        ä¸Šä¼ åˆ°ç›®æ ‡ä½ç½®
        å¯ä»¥æ˜¯è…¾è®¯æ–‡æ¡£ã€æœ¬åœ°æœåŠ¡å™¨ã€äº‘å­˜å‚¨ç­‰
        """
        if not self.config['upload']['enabled']:
            return True
            
        target = self.config['upload']['target']
        
        if target == 'local':
            # ç§»åŠ¨åˆ°processedç›®å½•
            import shutil
            filename = os.path.basename(filepath)
            dest = os.path.join(self.upload_dir, filename)
            shutil.move(filepath, dest)
            logger.info(f"âœ… æ–‡ä»¶å·²ç§»åŠ¨åˆ°: {dest}")
            return True
            
        elif target == 'tencent_docs':
            # ä¸Šä¼ å›è…¾è®¯æ–‡æ¡£ï¼ˆåˆ›å»ºæ–°æ–‡æ¡£æˆ–æ›´æ–°ç°æœ‰ï¼‰
            # TODO: å®ç°è…¾è®¯æ–‡æ¡£ä¸Šä¼ API
            logger.info("ä¸Šä¼ åˆ°è…¾è®¯æ–‡æ¡£ï¼ˆå¾…å®ç°ï¼‰")
            return True
            
        elif target == 's3':
            # ä¸Šä¼ åˆ°S3
            # TODO: å®ç°S3ä¸Šä¼ 
            pass
            
        return False
        
    async def send_notification(self, message: str):
        """å‘é€é€šçŸ¥"""
        if not self.config['notification']['enabled']:
            return
            
        webhook = self.config['notification']['webhook']
        if webhook:
            # TODO: å‘é€é’‰é’‰/ä¼ä¸šå¾®ä¿¡é€šçŸ¥
            logger.info(f"é€šçŸ¥: {message}")
            
    async def process_document(self, doc_info: Dict):
        """
        å¤„ç†å•ä¸ªæ–‡æ¡£çš„å®Œæ•´æµç¨‹
        ä¸‹è½½ -> åˆ†æ -> ä¸Šä¼  -> é€šçŸ¥
        """
        try:
            # 1. ä¸‹è½½
            filepath = await self.download_document(doc_info)
            if not filepath:
                await self.send_notification(f"âŒ ä¸‹è½½å¤±è´¥: {doc_info['name']}")
                return
                
            # 2. åˆ†æ
            analysis = await self.analyze_document(filepath)
            
            # 3. ä¸Šä¼ 
            uploaded = await self.upload_to_target(filepath, analysis)
            
            # 4. é€šçŸ¥
            if analysis.get('has_changes'):
                await self.send_notification(
                    f"ğŸ“Š æ–‡æ¡£æ›´æ–°: {doc_info['name']}\n"
                    f"åˆ†æç»“æœ: {analysis['summary']}"
                )
                
            logger.info(f"âœ… å®Œæˆå¤„ç†: {doc_info['name']}")
            
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥: {e}")
            await self.send_notification(f"âŒ å¤„ç†å¤±è´¥: {doc_info['name']}")
            
    async def run_batch(self):
        """æ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡æ¡£"""
        logger.info("="*60)
        logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† - {datetime.now()}")
        logger.info("="*60)
        
        if not self.browser:
            await self.init_browser()
            
        for doc in self.config['documents']:
            await self.process_document(doc)
            # é¿å…é¢‘ç‡è¿‡é«˜
            await asyncio.sleep(5)
            
        logger.info("æ‰¹é‡å¤„ç†å®Œæˆ")
        
    async def keep_alive(self):
        """ä¿æŒCookieæ´»æ€§"""
        while True:
            try:
                # æ¯20åˆ†é’Ÿè®¿é—®ä¸€æ¬¡ä¿æŒä¼šè¯
                page = await self.context.new_page()
                await page.goto("https://docs.qq.com")
                await page.wait_for_timeout(2000)
                
                # æ£€æŸ¥ç™»å½•çŠ¶æ€
                if "ç™»å½•" not in await page.content():
                    logger.info("âœ… Cookieä»ç„¶æœ‰æ•ˆ")
                else:
                    logger.warning("âš ï¸ Cookieå·²å¤±æ•ˆï¼Œéœ€è¦æ›´æ–°")
                    # TODO: å®ç°è‡ªåŠ¨åˆ·æ–°Cookieæœºåˆ¶
                    
                await page.close()
                
            except Exception as e:
                logger.error(f"ä¿æ´»å¤±è´¥: {e}")
                
            # ç­‰å¾…20åˆ†é’Ÿ
            await asyncio.sleep(1200)

class AutomationScheduler:
    """
    å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    ä½¿ç”¨cronè¡¨è¾¾å¼ç²¾ç¡®æ§åˆ¶
    """
    
    def __init__(self, automation: ServerSideAutomation):
        self.automation = automation
        self.loop = asyncio.new_event_loop()
        
    def run_async_task(self, coro):
        """åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥ä»»åŠ¡"""
        asyncio.set_event_loop(self.loop)
        self.loop.run_until_complete(coro)
        
    def setup_schedules(self):
        """è®¾ç½®å®šæ—¶ä»»åŠ¡"""
        # æ¯å°æ—¶æ‰§è¡Œä¸€æ¬¡æ‰¹é‡å¤„ç†
        schedule.every().hour.do(
            self.run_async_task, 
            self.automation.run_batch()
        )
        
        # æ¯å¤©å‡Œæ™¨2ç‚¹æ‰§è¡Œå®Œæ•´å¤‡ä»½
        schedule.every().day.at("02:00").do(
            self.run_async_task,
            self.automation.run_batch()
        )
        
        logger.info("âœ… å®šæ—¶ä»»åŠ¡å·²è®¾ç½®")
        
    def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        logger.info("å¯åŠ¨è‡ªåŠ¨åŒ–è°ƒåº¦å™¨...")
        
        # é¦–æ¬¡è¿è¡Œ
        self.run_async_task(self.automation.run_batch())
        
        # å¯åŠ¨ä¿æ´»åç¨‹
        asyncio.create_task(self.automation.keep_alive())
        
        # å®šæ—¶ä»»åŠ¡å¾ªç¯
        while True:
            schedule.run_pending()
            time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡

async def main():
    """ä¸»å‡½æ•°"""
    print("="*60)
    print("è…¾è®¯æ–‡æ¡£æœåŠ¡å™¨ç«¯å…¨è‡ªåŠ¨åŒ–ç³»ç»Ÿ")
    print("æ— éœ€ç”¨æˆ·ä»‹å…¥ï¼Œ24/7è‡ªåŠ¨è¿è¡Œ")
    print("="*60)
    
    automation = ServerSideAutomation()
    
    print("\nåŠŸèƒ½ç‰¹ç‚¹:")
    print("âœ… æœåŠ¡å™¨ç«¯æ— å¤´æµè§ˆå™¨")
    print("âœ… Cookieè‡ªåŠ¨ä¿æ´»")
    print("âœ… å®šæ—¶è‡ªåŠ¨ä¸‹è½½")
    print("âœ… å†…å®¹å˜åŒ–åˆ†æ")
    print("âœ… è‡ªåŠ¨ä¸Šä¼ å¤„ç†")
    print("âœ… å¼‚å¸¸é€šçŸ¥å‘Šè­¦")
    
    print("\né…ç½®æ–‡ä»¶:", automation.config_file)
    print("ä¸‹è½½ç›®å½•:", automation.download_dir)
    print("å¤„ç†ç›®å½•:", automation.upload_dir)
    
    # åˆå§‹åŒ–æµè§ˆå™¨
    await automation.init_browser()
    
    # è¿è¡Œä¸€æ¬¡æµ‹è¯•
    print("\næ‰§è¡Œæµ‹è¯•è¿è¡Œ...")
    await automation.run_batch()
    
    print("\nâœ… æµ‹è¯•æˆåŠŸï¼ç³»ç»Ÿå°†æŒ‰é…ç½®å®šæ—¶è¿è¡Œ")
    print("å¯ä»¥ä½¿ç”¨ systemd æˆ– supervisor ç®¡ç†æ­¤æœåŠ¡")

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œ
    asyncio.run(main())
    
    # æˆ–è€…ä½œä¸ºå®ˆæŠ¤è¿›ç¨‹è¿è¡Œ
    # scheduler = AutomationScheduler(ServerSideAutomation())
    # scheduler.setup_schedules()
    # scheduler.start()