#!/usr/bin/env python3
"""
ç»¼åˆé›†æˆæ‰“åˆ†å¼•æ“ - è¯¦ç»†æ‰“åˆ†æ¨¡å—
å®ç°L1/L2/L3å·®å¼‚åŒ–æ‰“åˆ†ç­–ç•¥
"""

import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from collections import defaultdict
import hashlib
import time

# æ·»åŠ ä¸Šçº§ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥L2è¯­ä¹‰åˆ†ææ¨¡å—
from core_modules.l2_semantic_analysis_two_layer import L2SemanticAnalyzer
# å¯¼å…¥è·¯å¾„ç®¡ç†å™¨
from core_modules.path_manager import path_manager
from core_modules.deepseek_client import get_deepseek_client

# L1/L2/L3åˆ—å®šä¹‰
L1_COLUMNS = [
    "æ¥æº",
    "ä»»åŠ¡å‘èµ·æ—¶é—´", 
    "ç›®æ ‡å¯¹é½",
    "å…³é”®KRå¯¹é½",
    "é‡è¦ç¨‹åº¦",
    "é¢„è®¡å®Œæˆæ—¶é—´",
    "å®Œæˆè¿›åº¦"
]

L2_COLUMNS = [
    "é¡¹ç›®ç±»å‹",
    "å…·ä½“è®¡åˆ’å†…å®¹",
    "é‚“æ€»æŒ‡å¯¼ç™»è®°ï¼ˆæ—¥æ›´æ–°ï¼‰",
    "è´Ÿè´£äºº",
    "ååŠ©äºº",
    "ç›‘ç£äºº",
    "å½¢æˆè®¡åˆ’æ¸…å•"
]

L3_COLUMNS = [
    "åºå·",
    "å¤ç›˜æ—¶é—´",
    "å¯¹ä¸Šæ±‡æŠ¥",
    "åº”ç”¨æƒ…å†µ",
    "è¿›åº¦åˆ†ææ€»ç»“"
]

# åˆ—æƒé‡é…ç½®
COLUMN_WEIGHTS = {
    "é‡è¦ç¨‹åº¦": 1.4,
    "ä»»åŠ¡å‘èµ·æ—¶é—´": 1.3,
    "è´Ÿè´£äºº": 1.2,
    "é¢„è®¡å®Œæˆæ—¶é—´": 1.2,
    "é‚“æ€»æŒ‡å¯¼ç™»è®°ï¼ˆæ—¥æ›´æ–°ï¼‰": 1.15,
    "å®Œæˆè¿›åº¦": 1.1
}

# AIå†³ç­–åˆ°è°ƒæ•´ç³»æ•°çš„æ˜ å°„
AI_DECISION_FACTORS = {
    'APPROVE': 0.6,
    'CONDITIONAL': 0.8,
    'REVIEW': 1.2,
    'REJECT': 1.5,
    'UNSURE': 1.0
}


class IntegratedScorer:
    """ç»¼åˆæ‰“åˆ†å¼•æ“"""
    
    def __init__(self, use_ai=True, cache_enabled=True):
        """
        åˆå§‹åŒ–æ‰“åˆ†å¼•æ“
        
        Args:
            use_ai: æ˜¯å¦ä½¿ç”¨AIåˆ†æï¼ˆL2åˆ—ï¼‰
            cache_enabled: æ˜¯å¦å¯ç”¨ç¼“å­˜
        """
        self.use_ai = use_ai
        self.cache_enabled = cache_enabled
        self.cache = {} if cache_enabled else None
        self.l2_analyzer = None
        
        if self.use_ai:
            # åˆå§‹åŒ–L2åˆ†æå™¨ï¼ˆä½¿ç”¨çœŸå®APIï¼‰
            try:
                # è·å–DeepSeekå®¢æˆ·ç«¯
                deepseek_client = get_deepseek_client()
                self.l2_analyzer = L2SemanticAnalyzer(api_client=deepseek_client)
                print("L2è¯­ä¹‰åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸï¼ˆçœŸå®APIæ¨¡å¼ï¼‰")
            except Exception as e:
                # ä¸å…è®¸é™çº§ï¼ŒL2å¿…é¡»ä½¿ç”¨AI
                raise Exception(f"L2è¯­ä¹‰åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œæ— æ³•ç»§ç»­: {e}")
    
    def get_column_level(self, column_name: str) -> str:
        """è·å–åˆ—çš„é£é™©ç­‰çº§"""
        if column_name in L1_COLUMNS:
            return "L1"
        elif column_name in L2_COLUMNS:
            return "L2"
        elif column_name in L3_COLUMNS:
            return "L3"
        else:
            # æœªåˆ†ç±»çš„åˆ—é»˜è®¤ä¸ºL3
            return "L3"
    
    def get_base_score(self, column_level: str) -> float:
        """è·å–åŸºç¡€é£é™©åˆ†
        
        æ³¨æ„ï¼šL1å’ŒL2çš„å®é™…æœ€ä½åˆ†æ•°åœ¨process_l1_modificationå’Œ
        process_l2_modificationä¸­æœ‰ç‰¹æ®Šä¿éšœæœºåˆ¶
        """
        scores = {
            "L1": 0.8,  # L1ä»»ä½•å˜æ›´æœ€ä½0.8ï¼ˆçº¢è‰²è­¦å‘Šï¼‰
            "L2": 0.5,  # L2ä»»ä½•å˜æ›´æœ€ä½0.6ï¼ˆæ©™è‰²è­¦å‘Šï¼‰
            "L3": 0.2   # L3ä¿æŒåŸæœ‰é€»è¾‘
        }
        return scores.get(column_level, 0.2)
    
    def calculate_change_factor(self, old_value: str, new_value: str) -> float:
        """
        è®¡ç®—å˜æ›´ç³»æ•°
        
        Returns:
            0.0-1.3ä¹‹é—´çš„ç³»æ•°
        """
        # å¤„ç†ç©ºå€¼
        old_value = str(old_value).strip() if old_value else ""
        new_value = str(new_value).strip() if new_value else ""
        
        # æ— å˜åŒ–
        if old_value == new_value:
            return 0.0
        
        # ä»ç©ºåˆ°æœ‰
        if not old_value and new_value:
            return 1.0
        
        # ä»æœ‰åˆ°ç©ºï¼ˆé£é™©æ›´é«˜ï¼‰
        if old_value and not new_value:
            return 1.3
        
        # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if len(old_value) < 10 and len(new_value) < 10:
            # çŸ­æ–‡æœ¬å®Œå…¨ä¸åŒ
            return 1.0
        else:
            # é•¿æ–‡æœ¬ï¼Œæ ¹æ®é•¿åº¦å˜åŒ–ä¼°ç®—
            len_change = abs(len(new_value) - len(old_value)) / max(len(old_value), 1)
            if len_change > 0.5:
                return 1.1  # å¤§å¹…å˜åŒ–
            elif len_change > 0.2:
                return 0.8  # ä¸­ç­‰å˜åŒ–
            else:
                return 0.5  # å°å¹…å˜åŒ–
    
    def get_column_weight(self, column_name: str) -> float:
        """è·å–åˆ—çš„é‡è¦æ€§æƒé‡"""
        return COLUMN_WEIGHTS.get(column_name, 1.0)
    
    def apply_confidence_weight(self, score: float, confidence: int) -> float:
        """æ ¹æ®AIç½®ä¿¡åº¦è°ƒæ•´åˆ†æ•°"""
        if confidence >= 90:
            return score
        elif confidence >= 70:
            return score * 0.9 + 0.1
        elif confidence >= 50:
            return score * 0.7 + 0.15
        else:
            return 0.5  # ä½ç½®ä¿¡åº¦ä½¿ç”¨ä¸­é—´å€¼
    
    def process_l1_modification(self, mod: Dict) -> Dict:
        """å¤„ç†L1åˆ—ä¿®æ”¹ï¼ˆçº¯è§„åˆ™ï¼‰"""
        base_score = 0.8
        change_factor = self.calculate_change_factor(
            mod.get('old_value', ''),
            mod.get('new_value', '')
        )
        importance_weight = self.get_column_weight(mod['column_name'])
        
        # L1ä¸ä½¿ç”¨AI
        ai_adjustment = 1.0
        confidence_weight = 1.0
        
        # L1åˆ—ç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿ä»»ä½•å˜æ›´éƒ½è§¦å‘çº¢è‰²è­¦å‘Š
        # å¦‚æœæœ‰å˜æ›´ï¼ˆchange_factor > 0ï¼‰ï¼Œæœ€ä½åˆ†æ•°ä¸º0.8
        if change_factor > 0:
            # åŸºç¡€åˆ†0.8ï¼Œç¡®ä¿å§‹ç»ˆ>=0.8ä»¥è§¦å‘çº¢è‰²è­¦å‘Š
            final_score = max(0.8, min(base_score * change_factor * importance_weight, 1.0))
        else:
            # æ— å˜æ›´æ—¶åˆ†æ•°ä¸º0
            final_score = 0.0
        
        return {
            'base_score': base_score,
            'change_factor': change_factor,
            'importance_weight': importance_weight,
            'ai_adjustment': ai_adjustment,
            'confidence_weight': confidence_weight,
            'final_score': final_score,
            'ai_used': False,
            'ai_reason': 'L1_column_rule_based'
        }
    
    def process_l2_modification(self, mod: Dict) -> Dict:
        """
        å¤„ç†L2åˆ—ä¿®æ”¹ï¼ˆAI+è§„åˆ™æ··åˆï¼‰
        
        é‡è¦ï¼šä¸å…è®¸é™çº§ï¼ŒL2å¿…é¡»ä½¿ç”¨AIåˆ†æ
        """
        base_score = 0.5
        change_factor = self.calculate_change_factor(
            mod.get('old_value', ''),
            mod.get('new_value', '')
        )
        importance_weight = self.get_column_weight(mod['column_name'])
        
        # L2å¿…é¡»ä½¿ç”¨AIåˆ†æï¼Œä¸å…è®¸é™çº§
        if not self.use_ai or not self.l2_analyzer:
            raise Exception("L2åˆ—å¿…é¡»ä½¿ç”¨AIåˆ†æï¼Œä½†AIæœåŠ¡æœªåˆå§‹åŒ–")
        
        # è°ƒç”¨L2åˆ†æå™¨ï¼ˆå¿…é¡»æˆåŠŸï¼‰
        try:
            analysis_result = self.l2_analyzer.analyze_single_modification(mod)
        except Exception as e:
            # ä¸å…è®¸é™çº§ï¼Œå¿…é¡»æŠ¥é”™
            raise Exception(f"L2 AIè¯­ä¹‰åˆ†æè°ƒç”¨å¤±è´¥: {e}")
        
        if not analysis_result:
            raise Exception("L2 AIåˆ†æè¿”å›ç©ºç»“æœ")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if analysis_result.get('error'):
            raise Exception(f"L2 AIåˆ†æé”™è¯¯: {analysis_result['error']}")
        
        # æå–AIå†³ç­–
        final_decision = analysis_result.get('final_decision', 'UNSURE')
        
        # è·å–ç½®ä¿¡åº¦
        if analysis_result.get('layer2_result'):
            confidence = analysis_result['layer2_result'].get('confidence', 70)
        elif analysis_result.get('layer1_result'):
            confidence = analysis_result['layer1_result'].get('confidence', 50)
        else:
            confidence = 50
        
        # AIå†³ç­–æ˜ å°„åˆ°è°ƒæ•´ç³»æ•°
        ai_adjustment = AI_DECISION_FACTORS.get(final_decision, 1.0)
        
        # ç½®ä¿¡åº¦åŠ æƒ
        if confidence >= 90:
            confidence_weight = 1.0
        elif confidence >= 70:
            confidence_weight = 0.9
        elif confidence >= 50:
            confidence_weight = 0.8
        else:
            confidence_weight = 0.7
        
        # è®¡ç®—æœ€ç»ˆåˆ†æ•°
        # L2åˆ—ç‰¹æ®Šå¤„ç†ï¼šç¡®ä¿ä»»ä½•å˜æ›´æœ€ä½æ©™è‰²è­¦å‘Šï¼ˆ>=0.6ï¼‰
        if change_factor > 0:
            # æœ‰å˜æ›´æ—¶ï¼Œæœ€ä½åˆ†æ•°ä¸º0.6ä»¥ç¡®ä¿æ©™è‰²è­¦å‘Š
            raw_score = base_score * change_factor * importance_weight * ai_adjustment * confidence_weight
            final_score = max(0.6, min(raw_score, 1.0))
        else:
            # æ— å˜æ›´æ—¶åˆ†æ•°ä¸º0
            final_score = 0.0
        
        return {
            'base_score': base_score,
            'change_factor': change_factor,
            'importance_weight': importance_weight,
            'ai_adjustment': ai_adjustment,
            'confidence_weight': confidence_weight,
            'final_score': final_score,
            'ai_used': True,
            'ai_analysis': analysis_result,
            'ai_decision': final_decision,
            'ai_confidence': confidence,
            'layer1_result': analysis_result.get('layer1_result'),
            'layer2_result': analysis_result.get('layer2_result')
        }
    
    def process_l3_modification(self, mod: Dict) -> Dict:
        """å¤„ç†L3åˆ—ä¿®æ”¹ï¼ˆçº¯è§„åˆ™ï¼‰"""
        base_score = 0.2
        change_factor = self.calculate_change_factor(
            mod.get('old_value', ''),
            mod.get('new_value', '')
        )
        importance_weight = self.get_column_weight(mod['column_name'])
        
        # L3ä¸ä½¿ç”¨AI
        ai_adjustment = 1.0
        confidence_weight = 1.0
        
        final_score = min(base_score * change_factor * importance_weight, 1.0)
        
        return {
            'base_score': base_score,
            'change_factor': change_factor,
            'importance_weight': importance_weight,
            'ai_adjustment': ai_adjustment,
            'confidence_weight': confidence_weight,
            'final_score': final_score,
            'ai_used': False,
            'ai_reason': 'L3_column_rule_based'
        }
    
    def get_risk_level(self, score: float) -> Tuple[str, str, str]:
        """
        è·å–é£é™©ç­‰çº§
        
        Returns:
            (risk_level, color, icon)
        """
        if score >= 0.8:
            return ("EXTREME_HIGH", "red", "ğŸ”´")
        elif score >= 0.6:
            return ("HIGH", "orange", "ğŸŸ ")
        elif score >= 0.4:
            return ("MEDIUM", "yellow", "ğŸŸ¡")
        elif score >= 0.2:
            return ("LOW", "green", "ğŸŸ¢")
        else:
            return ("EXTREME_LOW", "blue", "ğŸ”µ")
    
    def get_action_required(self, risk_level: str) -> Tuple[str, int]:
        """
        è·å–æ‰€éœ€æ“ä½œå’Œä¼˜å…ˆçº§
        
        Returns:
            (action, priority)
        """
        actions = {
            "EXTREME_HIGH": ("immediate_review", 1),
            "HIGH": ("manual_review", 2),
            "MEDIUM": ("periodic_check", 3),
            "LOW": ("log_only", 4),
            "EXTREME_LOW": ("none", 5)
        }
        return actions.get(risk_level, ("none", 5))
    
    def score_modification(self, mod: Dict, mod_id: str) -> Dict:
        """
        å¯¹å•ä¸ªä¿®æ”¹è¿›è¡Œæ‰“åˆ†
        
        Args:
            mod: ä¿®æ”¹æ•°æ®
            mod_id: ä¿®æ”¹ID
            
        Returns:
            å®Œæ•´çš„æ‰“åˆ†ç»“æœ
        """
        # è·å–åˆ—çº§åˆ«
        column_name = mod.get('column_name', '')
        column_level = self.get_column_level(column_name)
        
        # æ ¹æ®åˆ—çº§åˆ«é€‰æ‹©å¤„ç†æ–¹æ³•
        if column_level == "L1":
            scoring_details = self.process_l1_modification(mod)
        elif column_level == "L2":
            scoring_details = self.process_l2_modification(mod)
        else:  # L3
            scoring_details = self.process_l3_modification(mod)
        
        # è·å–é£é™©è¯„ä¼°
        final_score = scoring_details['final_score']
        risk_level, risk_color, risk_icon = self.get_risk_level(final_score)
        action_required, priority = self.get_action_required(risk_level)
        
        # æ„å»ºå®Œæ•´ç»“æœ
        result = {
            'modification_id': mod_id,
            'cell': mod.get('cell', ''),
            'column_name': column_name,
            'column_level': column_level,
            'old_value': mod.get('old_value', ''),
            'new_value': mod.get('new_value', ''),
            'scoring_details': {
                'base_score': scoring_details['base_score'],
                'change_factor': scoring_details['change_factor'],
                'importance_weight': scoring_details['importance_weight'],
                'ai_adjustment': scoring_details['ai_adjustment'],
                'confidence_weight': scoring_details['confidence_weight'],
                'final_score': final_score
            },
            'ai_analysis': {
                'ai_used': scoring_details.get('ai_used', False)
            },
            'risk_assessment': {
                'risk_level': risk_level,
                'risk_color': risk_color,
                'risk_icon': risk_icon,
                'action_required': action_required,
                'priority': priority
            }
        }
        
        # æ·»åŠ AIåˆ†æè¯¦æƒ…ï¼ˆå¦‚æœæœ‰ï¼‰
        if scoring_details.get('ai_used'):
            result['ai_analysis'].update({
                'ai_decision': scoring_details.get('ai_decision'),
                'ai_confidence': scoring_details.get('ai_confidence'),
                'layer1_result': scoring_details.get('ai_analysis', {}).get('layer1_result'),
                'layer2_result': scoring_details.get('ai_analysis', {}).get('layer2_result')
            })
        else:
            result['ai_analysis']['reason'] = scoring_details.get('ai_reason', 'N/A')
        
        return result
    
    def process_file(self, input_file: str, output_dir: str = None) -> str:
        """
        å¤„ç†ç®€åŒ–å¯¹æ¯”æ–‡ä»¶ï¼Œç”Ÿæˆè¯¦ç»†æ‰“åˆ†
        
        Args:
            input_file: è¾“å…¥çš„ç®€åŒ–å¯¹æ¯”JSONæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # è¯»å–è¾“å…¥æ–‡ä»¶
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æå–ä¿®æ”¹åˆ—è¡¨
        modifications = data.get('modifications', [])
        if not modifications:
            raise ValueError("è¾“å…¥æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°modificationsæ•°æ®")
        
        # è·å–è¡¨å
        table_name = data.get('table_name', 
                              os.path.basename(input_file).replace('.json', ''))
        
        # æ‰“åˆ†ç»“æœ
        scores = []
        risk_distribution = defaultdict(int)
        ai_usage = {
            'total_ai_calls': 0,
            'layer1_passes': 0,
            'layer2_analyses': 0
        }
        
        # å¤„ç†æ¯ä¸ªä¿®æ”¹
        for i, mod in enumerate(modifications):
            mod_id = f"M{i+1:03d}"
            
            # æ•°æ®æ ¼å¼å…¼å®¹æ€§å¤„ç†ï¼šå°†'old'/'new'è½¬æ¢ä¸º'old_value'/'new_value'
            if 'old' in mod and 'old_value' not in mod:
                mod['old_value'] = mod['old']
            if 'new' in mod and 'new_value' not in mod:
                mod['new_value'] = mod['new']
            
            # å¤„ç†'column'åˆ°'column_name'çš„å…¼å®¹æ€§
            if 'column' in mod and 'column_name' not in mod:
                mod['column_name'] = mod['column']
            
            # å¤„ç†'cell'å­—æ®µ - å¦‚æœæ²¡æœ‰cellï¼ŒåŸºäºrowç”Ÿæˆä¸€ä¸ªé»˜è®¤å€¼
            if 'cell' not in mod:
                row = mod.get('row', i+1)
                mod['cell'] = f"A{row}"
            
            # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
            if 'old_value' not in mod:
                mod['old_value'] = ''
            if 'new_value' not in mod:
                mod['new_value'] = ''
            if 'column_name' not in mod:
                mod['column_name'] = 'unknown'
            
            # æ‰“åˆ†
            score_result = self.score_modification(mod, mod_id)
            scores.append(score_result)
            
            # ç»Ÿè®¡
            risk_distribution[score_result['risk_assessment']['risk_level']] += 1
            if score_result['ai_analysis']['ai_used']:
                ai_usage['total_ai_calls'] += 1
                if score_result['ai_analysis'].get('layer2_result'):
                    ai_usage['layer2_analyses'] += 1
                else:
                    ai_usage['layer1_passes'] += 1
        
        # è®¡ç®—æ±‡æ€»
        total_score = sum(s['scoring_details']['final_score'] for s in scores)
        avg_score = total_score / len(scores) if scores else 0
        
        # æ„å»ºè¾“å‡º
        output = {
            'metadata': {
                'table_name': table_name,
                'source_file': input_file,
                'scoring_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_modifications': len(modifications),
                'scoring_version': 'v1.0'
            },
            'scores': scores,
            'summary': {
                'total_score': round(total_score, 3),
                'average_score': round(avg_score, 3),
                'risk_distribution': dict(risk_distribution),
                'ai_usage': ai_usage
            }
        }
        
        # ä¿å­˜ç»“æœ
        if not output_dir:
            # ä½¿ç”¨ç»Ÿä¸€è·¯å¾„ç®¡ç†å™¨è·å–æ­£ç¡®è·¯å¾„
            output_dir = str(path_manager.get_scoring_results_path(detailed=True))
        
        os.makedirs(output_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_file = os.path.join(
            output_dir,
            f"detailed_score_{table_name}_{timestamp}.json"
        )
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output, f, ensure_ascii=False, indent=2)
        
        print(f"è¯¦ç»†æ‰“åˆ†å®Œæˆ: {output_file}")
        return output_file


def main():
    """ä¸»å‡½æ•°ï¼ˆæµ‹è¯•ç”¨ï¼‰"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç»¼åˆæ‰“åˆ†å¼•æ“ - è¯¦ç»†æ‰“åˆ†')
    parser.add_argument('--input', required=True, help='è¾“å…¥çš„ç®€åŒ–å¯¹æ¯”JSONæ–‡ä»¶')
    parser.add_argument('--output-dir', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--no-ai', action='store_true', help='ç¦ç”¨AIåˆ†æ')
    parser.add_argument('--no-cache', action='store_true', help='ç¦ç”¨ç¼“å­˜')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ‰“åˆ†å™¨
    scorer = IntegratedScorer(
        use_ai=not args.no_ai,
        cache_enabled=not args.no_cache
    )
    
    # å¤„ç†æ–‡ä»¶
    try:
        output_file = scorer.process_file(args.input, args.output_dir)
        print(f"æˆåŠŸç”Ÿæˆè¯¦ç»†æ‰“åˆ†æ–‡ä»¶: {output_file}")
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()