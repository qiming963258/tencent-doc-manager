#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Stage 3 å®Œæ•´ç³»ç»Ÿ - CSVå¯¹æ¯”å’Œå®‰å…¨è¯„åˆ†ä¼˜åŒ–ç»Ÿä¸€ç®¡ç†å™¨
æ•´åˆç”Ÿäº§çº§å¯¹æ¯”å™¨ + Claude API + å®‰å…¨è¯„åˆ† + é£é™©ç®¡ç†
"""

import sys
import os
sys.path.append('/root/projects/tencent-doc-manager/production/core_modules')

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
from production_csv_comparator import ProductionCSVComparator, SecurityConfig
from cookie_manager import get_cookie_manager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CSVSecurityManager:
    """
    CSVå¯¹æ¯”å’Œå®‰å…¨è¯„åˆ†ç»Ÿä¸€ç®¡ç†å™¨
    æä¾›ç«¯åˆ°ç«¯çš„CSVå¤„ç†å’Œå®‰å…¨ä¿éšœ
    """
    
    def __init__(self, base_dir: str = None):
        """åˆå§‹åŒ–ç®¡ç†å™¨"""
        self.base_dir = base_dir or "/root/projects/tencent-doc-manager"
        self.results_dir = os.path.join(self.base_dir, "csv_security_results")
        self.archive_dir = os.path.join(self.base_dir, "csv_security_archive")
        
        # åˆ›å»ºç›®å½•
        for directory in [self.results_dir, self.archive_dir]:
            os.makedirs(directory, exist_ok=True)
        
        # åˆå§‹åŒ–å­ç³»ç»Ÿ
        security_config = SecurityConfig(
            max_file_size=100 * 1024 * 1024,  # 100MB
            max_rows=500000,
            max_columns=1000,
            require_checksum=True,
            enable_audit_log=True
        )
        
        self.csv_comparator = ProductionCSVComparator(security_config)
        self.cookie_manager = get_cookie_manager()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.session_stats = {
            'session_start': datetime.now().isoformat(),
            'comparisons_total': 0,
            'comparisons_success': 0,
            'comparisons_failed': 0,
            'security_violations_detected': 0,
            'high_risk_changes': 0,
            'medium_risk_changes': 0,
            'low_risk_changes': 0
        }
        
        logger.info("âœ… CSVå®‰å…¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def comprehensive_csv_analysis(self, file1_path: str, file2_path: str, 
                                       analysis_name: str = None) -> Dict:
        """
        ç»¼åˆCSVåˆ†æ
        
        Args:
            file1_path: åŸºå‡†æ–‡ä»¶
            file2_path: å½“å‰æ–‡ä»¶
            analysis_name: åˆ†æåç§°
            
        Returns:
            dict: ç»¼åˆåˆ†æç»“æœ
        """
        self.session_stats['comparisons_total'] += 1
        
        try:
            logger.info(f"ğŸ“Š å¼€å§‹ç»¼åˆCSVåˆ†æ: {Path(file1_path).name} vs {Path(file2_path).name}")
            
            # ç”Ÿæˆåˆ†æåç§°
            if not analysis_name:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                analysis_name = f"csv_analysis_{timestamp}"
            
            # Step 1: åŸºç¡€å¯¹æ¯”åˆ†æ
            logger.info("ğŸ” æ‰§è¡ŒåŸºç¡€å¯¹æ¯”åˆ†æ...")
            output_file = os.path.join(self.results_dir, f"{analysis_name}_comparison.json")
            
            comparison_result = await self.csv_comparator.compare_csv_files(
                file1_path, file2_path, output_file
            )
            
            if not comparison_result.success:
                self.session_stats['comparisons_failed'] += 1
                return {
                    'success': False,
                    'error': 'åŸºç¡€å¯¹æ¯”å¤±è´¥',
                    'analysis_name': analysis_name
                }
            
            # Step 2: å®‰å…¨é£é™©è¯„ä¼°
            logger.info("ğŸ›¡ï¸ æ‰§è¡Œå®‰å…¨é£é™©è¯„ä¼°...")
            security_assessment = await self._conduct_security_assessment(
                comparison_result, analysis_name
            )
            
            # Step 3: æ™ºèƒ½å»ºè®®ç”Ÿæˆ
            logger.info("ğŸ¤– ç”Ÿæˆæ™ºèƒ½å®‰å…¨å»ºè®®...")
            recommendations = await self._generate_security_recommendations(
                comparison_result, security_assessment
            )
            
            # Step 4: æ›´æ–°ç»Ÿè®¡
            self._update_session_stats(comparison_result)
            
            # Step 5: æ„å»ºç»¼åˆç»“æœ
            comprehensive_result = {
                'success': True,
                'analysis_name': analysis_name,
                'analysis_time': datetime.now().isoformat(),
                'files_analyzed': {
                    'baseline': Path(file1_path).name,
                    'current': Path(file2_path).name,
                    'baseline_checksum': comparison_result.file_checksums.get('file1', 'unknown'),
                    'current_checksum': comparison_result.file_checksums.get('file2', 'unknown')
                },
                'comparison_summary': {
                    'total_differences': comparison_result.total_differences,
                    'security_score': comparison_result.security_score,
                    'risk_level': comparison_result.risk_level,
                    'processing_time': comparison_result.processing_time
                },
                'security_assessment': security_assessment,
                'intelligent_recommendations': recommendations,
                'detailed_results': {
                    'differences': comparison_result.differences,
                    'metadata': comparison_result.metadata
                },
                'session_stats': self.session_stats.copy()
            }
            
            # Step 6: ä¿å­˜ç»¼åˆç»“æœ
            comprehensive_file = os.path.join(self.results_dir, f"{analysis_name}_comprehensive.json")
            with open(comprehensive_file, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_result, f, ensure_ascii=False, indent=2)
            
            # Step 7: å½’æ¡£å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if security_assessment.get('requires_archival', False):
                await self._archive_analysis_results(analysis_name)
            
            self.session_stats['comparisons_success'] += 1
            
            logger.info(f"âœ… ç»¼åˆåˆ†æå®Œæˆ: {comparison_result.total_differences}ä¸ªå·®å¼‚, å®‰å…¨è¯„åˆ†: {comparison_result.security_score:.1f}")
            
            return comprehensive_result
            
        except Exception as e:
            self.session_stats['comparisons_failed'] += 1
            logger.error(f"âŒ ç»¼åˆåˆ†æå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'analysis_name': analysis_name or 'unknown',
                'session_stats': self.session_stats.copy()
            }
    
    async def _conduct_security_assessment(self, comparison_result, analysis_name: str) -> Dict:
        """æ‰§è¡Œå®‰å…¨é£é™©è¯„ä¼°"""
        try:
            assessment = {
                'timestamp': datetime.now().isoformat(),
                'overall_risk_grade': 'UNKNOWN',
                'critical_findings': [],
                'security_metrics': {},
                'compliance_status': {},
                'requires_archival': False,
                'requires_approval': False
            }
            
            # åŸºäºå¯¹æ¯”ç»“æœçš„é£é™©è¯„ä¼°
            risk_analysis = comparison_result.metadata.get('risk_analysis', {})
            security_violations = risk_analysis.get('security_violations', [])
            
            # è®¡ç®—é£é™©ç­‰çº§
            if comparison_result.security_score < 30:
                assessment['overall_risk_grade'] = 'CRITICAL'
                assessment['requires_approval'] = True
                assessment['requires_archival'] = True
            elif comparison_result.security_score < 60:
                assessment['overall_risk_grade'] = 'HIGH' 
                assessment['requires_approval'] = True
            elif comparison_result.security_score < 80:
                assessment['overall_risk_grade'] = 'MEDIUM'
            else:
                assessment['overall_risk_grade'] = 'LOW'
            
            # å…³é”®å‘ç°
            if security_violations:
                assessment['critical_findings'].extend(security_violations)
            
            if comparison_result.total_differences > 50:
                assessment['critical_findings'].append(f"å¤§é‡å˜æ›´æ£€æµ‹: {comparison_result.total_differences}ä¸ªå·®å¼‚")
            
            # å®‰å…¨æŒ‡æ ‡
            assessment['security_metrics'] = {
                'security_score': comparison_result.security_score,
                'total_differences': comparison_result.total_differences,
                'max_risk_score': risk_analysis.get('max_risk_score', 0),
                'security_violations_count': len(security_violations),
                'processing_time': comparison_result.processing_time
            }
            
            # åˆè§„çŠ¶æ€
            assessment['compliance_status'] = {
                'data_integrity': comparison_result.security_score > 70,
                'audit_trail': True,  # å› ä¸ºæœ‰å®¡è®¡æ—¥å¿—
                'access_control': True,  # å› ä¸ºæœ‰Cookieç®¡ç†
                'encryption': True,  # å› ä¸ºæœ‰æ–‡ä»¶æ ¡éªŒå’Œ
                'backup_required': assessment['overall_risk_grade'] in ['CRITICAL', 'HIGH']
            }
            
            return assessment
            
        except Exception as e:
            logger.error(f"å®‰å…¨è¯„ä¼°å¤±è´¥: {e}")
            return {
                'error': str(e),
                'overall_risk_grade': 'ERROR',
                'timestamp': datetime.now().isoformat()
            }
    
    async def _generate_security_recommendations(self, comparison_result, security_assessment: Dict) -> List[Dict]:
        """ç”Ÿæˆæ™ºèƒ½å®‰å…¨å»ºè®®"""
        try:
            recommendations = []
            
            # åŸºäºé£é™©ç­‰çº§çš„å»ºè®®
            risk_grade = security_assessment.get('overall_risk_grade', 'UNKNOWN')
            
            if risk_grade == 'CRITICAL':
                recommendations.extend([
                    {
                        'priority': 'URGENT',
                        'category': 'immediate_action',
                        'title': 'ç«‹å³æš‚åœå˜æ›´æ‰§è¡Œ',
                        'description': 'æ£€æµ‹åˆ°å…³é”®å®‰å…¨é£é™©ï¼Œå»ºè®®ç«‹å³æš‚åœæ‰€æœ‰å˜æ›´æ“ä½œ',
                        'action': 'halt_changes'
                    },
                    {
                        'priority': 'HIGH',
                        'category': 'security_review',
                        'title': 'å¯åŠ¨å®‰å…¨å®¡æŸ¥æµç¨‹',
                        'description': 'éœ€è¦é«˜çº§ç®¡ç†å±‚æˆ–å®‰å…¨å›¢é˜Ÿè¿›è¡Œäººå·¥å®¡æŸ¥',
                        'action': 'manual_review'
                    }
                ])
            
            elif risk_grade == 'HIGH':
                recommendations.extend([
                    {
                        'priority': 'HIGH',
                        'category': 'approval_required',
                        'title': 'éœ€è¦ç®¡ç†å±‚æ‰¹å‡†',
                        'description': 'å˜æ›´æ¶‰åŠé«˜é£é™©å­—æ®µï¼Œéœ€è¦è·å¾—ç›¸åº”ç®¡ç†å±‚æ‰¹å‡†',
                        'action': 'require_approval'
                    }
                ])
            
            # åŸºäºå…·ä½“é—®é¢˜çš„å»ºè®®
            if comparison_result.total_differences > 50:
                recommendations.append({
                    'priority': 'MEDIUM',
                    'category': 'change_volume',
                    'title': 'å¤§é‡å˜æ›´ä¼˜åŒ–',
                    'description': f'æ£€æµ‹åˆ°{comparison_result.total_differences}ä¸ªå˜æ›´ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†',
                    'action': 'batch_processing'
                })
            
            # åŸºäºå®‰å…¨è¿è§„çš„å»ºè®®
            security_violations = comparison_result.metadata.get('risk_analysis', {}).get('security_violations', [])
            if security_violations:
                recommendations.append({
                    'priority': 'HIGH',
                    'category': 'security_violation',
                    'title': 'å¤„ç†å®‰å…¨è¿è§„',
                    'description': f'æ£€æµ‹åˆ°{len(security_violations)}é¡¹å®‰å…¨è¿è§„ï¼Œéœ€è¦é€ä¸€å¤„ç†',
                    'action': 'fix_violations',
                    'details': security_violations[:3]  # åªæ˜¾ç¤ºå‰3ä¸ª
                })
            
            # åŸºäºåˆè§„æ€§çš„å»ºè®®
            compliance = security_assessment.get('compliance_status', {})
            if not compliance.get('data_integrity', True):
                recommendations.append({
                    'priority': 'MEDIUM',
                    'category': 'compliance',
                    'title': 'åŠ å¼ºæ•°æ®å®Œæ•´æ€§æ ¡éªŒ',
                    'description': 'å»ºè®®å¢åŠ é¢å¤–çš„æ•°æ®å®Œæ•´æ€§æ ¡éªŒæªæ–½',
                    'action': 'enhance_integrity'
                })
            
            # é€šç”¨å»ºè®®
            if comparison_result.security_score < 90:
                recommendations.append({
                    'priority': 'LOW',
                    'category': 'best_practice',
                    'title': 'å®šæœŸå®‰å…¨æ£€æŸ¥',
                    'description': 'å»ºè®®å»ºç«‹å®šæœŸçš„æ•°æ®å®‰å…¨æ£€æŸ¥æœºåˆ¶',
                    'action': 'regular_audit'
                })
            
            return recommendations
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå»ºè®®å¤±è´¥: {e}")
            return [{
                'priority': 'ERROR',
                'category': 'system_error',
                'title': 'å»ºè®®ç”Ÿæˆå¤±è´¥',
                'description': f'ç³»ç»Ÿé”™è¯¯: {str(e)}',
                'action': 'check_system'
            }]
    
    def _update_session_stats(self, comparison_result):
        """æ›´æ–°ä¼šè¯ç»Ÿè®¡"""
        try:
            # æ›´æ–°å®‰å…¨è¿è§„ç»Ÿè®¡
            risk_analysis = comparison_result.metadata.get('risk_analysis', {})
            violations = risk_analysis.get('security_violations', [])
            self.session_stats['security_violations_detected'] += len(violations)
            
            # æ›´æ–°é£é™©ç­‰çº§ç»Ÿè®¡
            if 'L1' in comparison_result.risk_level:
                self.session_stats['high_risk_changes'] += comparison_result.total_differences
            elif 'L2' in comparison_result.risk_level:
                self.session_stats['medium_risk_changes'] += comparison_result.total_differences
            else:
                self.session_stats['low_risk_changes'] += comparison_result.total_differences
                
        except Exception as e:
            logger.error(f"æ›´æ–°ç»Ÿè®¡å¤±è´¥: {e}")
    
    async def _archive_analysis_results(self, analysis_name: str):
        """å½’æ¡£åˆ†æç»“æœ"""
        try:
            logger.info(f"ğŸ“ å½’æ¡£åˆ†æç»“æœ: {analysis_name}")
            
            # åˆ›å»ºå½’æ¡£ç›®å½•
            archive_subdir = os.path.join(self.archive_dir, analysis_name)
            os.makedirs(archive_subdir, exist_ok=True)
            
            # ç§»åŠ¨ç»“æœæ–‡ä»¶åˆ°å½’æ¡£ç›®å½•
            for file_pattern in [f"{analysis_name}_*.json"]:
                import glob
                for file_path in glob.glob(os.path.join(self.results_dir, file_pattern)):
                    archive_path = os.path.join(archive_subdir, os.path.basename(file_path))
                    os.rename(file_path, archive_path)
                    logger.info(f"ğŸ“¦ å·²å½’æ¡£: {os.path.basename(file_path)}")
            
        except Exception as e:
            logger.error(f"å½’æ¡£å¤±è´¥: {e}")
    
    async def get_comprehensive_status(self) -> Dict:
        """è·å–ç»¼åˆç³»ç»ŸçŠ¶æ€"""
        try:
            # è·å–å„å­ç³»ç»ŸçŠ¶æ€
            cookie_health = await self.cookie_manager.get_health_status()
            security_report = self.csv_comparator.get_security_report()
            
            # è®¡ç®—æˆåŠŸç‡
            total_comps = self.session_stats['comparisons_total']
            success_rate = (self.session_stats['comparisons_success'] / max(total_comps, 1)) * 100
            
            # ç³»ç»Ÿç­‰çº§è¯„ä¼°
            if success_rate >= 95 and cookie_health.get('healthy', False):
                system_grade = "ğŸ… A+ (ä¼ä¸šçº§å®‰å…¨)"
            elif success_rate >= 90:
                system_grade = "âœ… A (ç”Ÿäº§çº§ç¨³å®š)"
            elif success_rate >= 80:
                system_grade = "ğŸŸ¢ B+ (è‰¯å¥½è¿è¡Œ)"
            elif success_rate >= 70:
                system_grade = "ğŸŸ¡ B (åŸºæœ¬å¯ç”¨)"
            else:
                system_grade = "ğŸ”´ C (éœ€è¦ä¼˜åŒ–)"
            
            return {
                'system_grade': system_grade,
                'success_rate': f"{success_rate:.1f}%",
                'session_stats': self.session_stats,
                'security_subsystem': security_report,
                'cookie_subsystem': cookie_health,
                'directories': {
                    'results_dir': self.results_dir,
                    'archive_dir': self.archive_dir
                },
                'capabilities': [
                    'intelligent_csv_comparison',
                    'security_risk_assessment', 
                    'automated_recommendations',
                    'audit_logging',
                    'checksum_validation',
                    'sensitive_content_detection',
                    'compliance_monitoring'
                ]
            }
            
        except Exception as e:
            logger.error(f"è·å–çŠ¶æ€å¤±è´¥: {e}")
            return {'error': str(e)}


# å‘½ä»¤è¡Œæ¥å£
async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='CSVå¯¹æ¯”å’Œå®‰å…¨è¯„åˆ†ç»Ÿä¸€ç®¡ç†å™¨')
    parser.add_argument('file1', nargs='?', help='åŸºå‡†CSVæ–‡ä»¶')
    parser.add_argument('file2', nargs='?', help='å½“å‰CSVæ–‡ä»¶')
    parser.add_argument('-n', '--name', help='åˆ†æåç§°')
    parser.add_argument('--status', action='store_true', help='æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€')
    
    args = parser.parse_args()
    
    manager = CSVSecurityManager()
    
    try:
        if args.status or (not args.file1 and not args.file2):
            print("ğŸ“Š CSVå®‰å…¨ç®¡ç†å™¨çŠ¶æ€:")
            status = await manager.get_comprehensive_status()
            
            print(f"   ç³»ç»Ÿç­‰çº§: {status.get('system_grade', 'Unknown')}")
            print(f"   æˆåŠŸç‡: {status.get('success_rate', '0.0%')}")
            
            stats = status.get('session_stats', {})
            print(f"   ä¼šè¯ç»Ÿè®¡:")
            print(f"     æ€»åˆ†ææ¬¡æ•°: {stats.get('comparisons_total', 0)}")
            print(f"     æˆåŠŸ: {stats.get('comparisons_success', 0)}")
            print(f"     å¤±è´¥: {stats.get('comparisons_failed', 0)}")
            print(f"     å®‰å…¨è¿è§„: {stats.get('security_violations_detected', 0)}")
            
            capabilities = status.get('capabilities', [])
            if capabilities:
                print(f"   ç³»ç»Ÿèƒ½åŠ› ({len(capabilities)}é¡¹):")
                for cap in capabilities[:5]:  # æ˜¾ç¤ºå‰5é¡¹
                    print(f"     âœ“ {cap}")
            print()
        
        if args.file1 and args.file2:
            print(f"ğŸ” å¼€å§‹ç»¼åˆCSVå®‰å…¨åˆ†æ:")
            print(f"   åŸºå‡†æ–‡ä»¶: {Path(args.file1).name}")
            print(f"   å½“å‰æ–‡ä»¶: {Path(args.file2).name}")
            if args.name:
                print(f"   åˆ†æåç§°: {args.name}")
            
            result = await manager.comprehensive_csv_analysis(args.file1, args.file2, args.name)
            
            if result['success']:
                print(f"\nâœ… ç»¼åˆåˆ†æå®Œæˆ!")
                
                summary = result.get('comparison_summary', {})
                print(f"   å·®å¼‚æ•°é‡: {summary.get('total_differences', 0)}")
                print(f"   å®‰å…¨è¯„åˆ†: {summary.get('security_score', 0):.1f}/100")
                print(f"   é£é™©ç­‰çº§: {summary.get('risk_level', 'Unknown')}")
                print(f"   å¤„ç†æ—¶é—´: {summary.get('processing_time', 0):.2f}ç§’")
                
                # å®‰å…¨è¯„ä¼°ç»“æœ
                security = result.get('security_assessment', {})
                print(f"   æ•´ä½“é£é™©: {security.get('overall_risk_grade', 'Unknown')}")
                
                critical_findings = security.get('critical_findings', [])
                if critical_findings:
                    print(f"   å…³é”®å‘ç°: {len(critical_findings)}é¡¹")
                    for finding in critical_findings[:2]:
                        print(f"     â€¢ {finding}")
                
                # æ™ºèƒ½å»ºè®®
                recommendations = result.get('intelligent_recommendations', [])
                if recommendations:
                    high_priority = [r for r in recommendations if r.get('priority') == 'HIGH']
                    if high_priority:
                        print(f"   é«˜ä¼˜å…ˆçº§å»ºè®®:")
                        for rec in high_priority[:2]:
                            print(f"     â€¢ {rec.get('title', 'Unknown')}")
                
                print(f"   åˆ†æç»“æœ: {result.get('analysis_name', 'unknown')}_comprehensive.json")
            else:
                print(f"\nâŒ åˆ†æå¤±è´¥: {result.get('error')}")
        
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())