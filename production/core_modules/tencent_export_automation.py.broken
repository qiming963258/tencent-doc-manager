#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è…¾è®¯æ–‡æ¡£è‡ªåŠ¨å¯¼å‡ºå·¥å…· - ä¸“æ³¨äºè‡ªåŠ¨åŒ–ä¸‹è½½
ç›´æ¥æ¨¡æ‹Ÿç”¨æˆ·ç‚¹å‡»å¯¼å‡ºæŒ‰é’®ï¼Œä¸‹è½½å®˜æ–¹ç”Ÿæˆçš„æ–‡ä»¶
"""

import asyncio
import os
import time
import argparse
from pathlib import Path
from playwright.async_api import async_playwright
try:
    from csv_version_manager import CSVVersionManager
except ImportError:
    from production.core_modules.csv_version_manager import CSVVersionManager


class TencentDocAutoExporter:
    """è…¾è®¯æ–‡æ¡£è‡ªåŠ¨å¯¼å‡ºå·¥å…· - ä¸“æ³¨ä¸‹è½½è‡ªåŠ¨åŒ–"""
    
    def __init__(self, download_dir=None):
        """åˆå§‹åŒ–å¯¼å‡ºå·¥å…· - å¼ºåˆ¶ä½¿ç”¨è§„èŒƒå‘½å"""
        self.browser = None
        self.page = None
        self.download_dir = download_dir or os.path.join(os.getcwd(), "downloads")
        
        # å§‹ç»ˆå¯ç”¨ç‰ˆæœ¬ç®¡ç†å™¨ - ä¸å†ä½œä¸ºå¯é€‰é¡¹
        try:
            from csv_version_manager import CSVVersionManager
            self.version_manager = CSVVersionManager()
        except ImportError:
            from production.core_modules.csv_version_manager import CSVVersionManager
            self.version_manager = CSVVersionManager()
        
    async def start_browser(self, headless=False):
        """å¯åŠ¨æµè§ˆå™¨ - ç›´æ¥åˆ›å»ºæ–°å®ä¾‹"""
        # ç›´æ¥ä½¿ç”¨å¸¸è§„æ–¹å¼ï¼Œåˆ é™¤å•ä¾‹æ¨¡å¼
        self.playwright = await async_playwright().start()
        self.using_singleton = False
        
        # åˆ›å»ºä¸‹è½½ç›®å½•
        os.makedirs(self.download_dir, exist_ok=True)
        
        # ğŸ†• 2025å¢å¼ºï¼š30+åæ£€æµ‹å‚æ•°
        launch_args = [
            '--disable-blink-features=AutomationControlled',
            '--disable-dev-shm-usage',
            '--disable-web-security',
            '--no-sandbox',
            '--disable-setuid-sandbox',
            '--disable-infobars',
            '--window-size=1920,1080',
            '--start-maximized',
            '--disable-extensions',
            '--disable-default-apps',
            '--disable-features=IsolateOrigins,site-per-process',
            '--enable-features=NetworkService,NetworkServiceInProcess',
            '--disable-features=VizDisplayCompositor',
            '--disable-features=TranslateUI',
            '--disable-features=BlinkGenPropertyTrees',
            '--disable-ipc-flooding-protection',
            '--disable-background-timer-throttling',
            '--disable-renderer-backgrounding',
            '--disable-features=OptimizationGuideModelDownloading,OptimizationHintsFetching,OptimizationTargetPrediction,OptimizationHints',
            '--disable-backgrounding-occluded-windows',
            '--disable-features=BackForwardCache',
            '--disable-features=GlobalMediaControls,GlobalMediaControlsModernUI',
            '--disable-features=InterestFeedContentSuggestions',
            '--disable-component-extensions-with-background-pages',
            '--disable-features=CalculateNativeWinOcclusion',
            '--disable-features=OptimizationGuideModelDownloading',
            '--metrics-recording-only',
            '--no-first-run',
            '--mute-audio',
            '--no-default-browser-check',
            '--no-pings'
        ]
        
        # å¯åŠ¨æµè§ˆå™¨ï¼Œè®¾ç½®ä¸‹è½½ç›®å½•å’Œåæ£€æµ‹å‚æ•°
        self.browser = await self.playwright.chromium.launch(
            headless=True,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',  # å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨/tmp
                '--disable-gpu',
                '--disable-extensions',
                '--disable-images',  # ä¸åŠ è½½å›¾ç‰‡
                '--disable-background-networking',
                '--disable-background-timer-throttling',
                '--disable-renderer-backgrounding',
                '--disable-features=site-per-process',  # å‡å°‘è¿›ç¨‹
                '--renderer-process-limit=1',  # é™åˆ¶æ¸²æŸ“è¿›ç¨‹æ•°
                '--memory-model=low',  # ä½å†…å­˜æ¨¡å¼
                '--max_old_space_size=512'  # é™åˆ¶å †å¤§å°
            ]
        )
        
        # åˆ›å»ºé¡µé¢ä¸Šä¸‹æ–‡ï¼Œè®¾ç½®ä¸‹è½½è¡Œä¸ºå’Œå¢å¼ºé…ç½®
        context = await self.browser.new_context(
            accept_downloads=True,
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='zh-CN',
            timezone_id='Asia/Shanghai',
            permissions=['clipboard-read', 'clipboard-write', 'notifications'],
            extra_http_headers={
                'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            },
            ignore_https_errors=True,
            java_script_enabled=True,
            bypass_csp=True,
            device_scale_factor=1,
            has_touch=False,
            is_mobile=False
        )
        
        self.page = await context.new_page()
        
        # ç›‘å¬ä¸‹è½½äº‹ä»¶
        self.downloaded_files = []
        self.page.on("download", self._handle_download)
    
    async def _handle_download(self, download):
        """å¤„ç†ä¸‹è½½äº‹ä»¶ - å¼ºåˆ¶ä½¿ç”¨è§„èŒƒæ–‡ä»¶å‘½åå’Œç›®å½•ç»“æ„"""
        filename = download.suggested_filename
        
        # æå–æ–‡ä»¶æ‰©å±•å
        import re
        ext_match = re.search(r'\.(csv|xlsx|xls|xlsm)$', filename, flags=re.IGNORECASE)
        file_extension = ext_match.group(1).lower() if ext_match else 'csv'
        
        # å¼ºåˆ¶ä½¿ç”¨è§„èŒƒæ–‡ä»¶å‘½å - åˆ é™¤æ‰€æœ‰é™çº§é€»è¾‘
        from file_version_manager import FileVersionManager
        from datetime import datetime
        file_manager = FileVersionManager()
        
        # ç¡®ä¿æœ‰URLä¿¡æ¯
        if not hasattr(self, 'current_url'):
            self.current_url = ""  # é˜²å¾¡æ€§ç¼–ç¨‹
        
        # è‡ªåŠ¨åˆ¤æ–­ç‰ˆæœ¬ç±»å‹ï¼ˆæ ¹æ®å½“å‰æ—¶é—´å’Œä¸‹è½½ç±»å‹ï¼‰
        def determine_version_type():
            now = datetime.now()
            weekday = now.weekday()  # 0=å‘¨ä¸€, 1=å‘¨äºŒ...
            hour = now.hour
            
            # ä¸¥æ ¼è§„åˆ™ï¼šåªæœ‰å‘¨äºŒ12ç‚¹çš„è‡ªåŠ¨ä¸‹è½½æ‰èƒ½æ˜¯baseline
            # æ‰€æœ‰æ‰‹åŠ¨æµ‹è¯•ã€ä¸´æ—¶ä¸‹è½½éƒ½å½’ç±»åˆ°midweek
            if weekday == 1 and hour >= 12 and hour <= 13:
                # å‘¨äºŒ12-13ç‚¹æœŸé—´çš„ä¸‹è½½å½’ç±»ä¸ºbaseline
                # æ³¨ï¼šå¯èƒ½éœ€è¦æ ¹æ®ä¸‹è½½ç”¨é€”è¿›ä¸€æ­¥åˆ¤æ–­
                return 'baseline'  # ä¿®å¤ï¼šå…è®¸åˆ›å»ºbaselineæ–‡ä»¶
            # å‘¨å…­æ™šä¸Š7ç‚¹ â†’ weekendï¼ˆå‘¨æœ«ç‰ˆï¼‰
            elif weekday == 5 and hour >= 19 and hour <= 20:
                return 'weekend'
            else:
                # æ‰€æœ‰å…¶ä»–æ—¶é—´çš„æ‰‹åŠ¨ä¸‹è½½éƒ½å½’ç±»åˆ°midweek
                return 'midweek'  # é»˜è®¤ä½¿ç”¨midweekä½œä¸ºä¸´æ—¶/æµ‹è¯•æ–‡ä»¶
        
        version_type = determine_version_type()
        print(f"ğŸ” è‡ªåŠ¨åˆ¤æ–­ç‰ˆæœ¬ç±»å‹: {version_type} (å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')})")
        
        # å…ˆä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åä¸‹è½½ï¼ˆé˜²æ­¢å¹¶è¡Œå†²çªï¼‰
        temp_filename = file_manager.get_temp_filename(self.current_url)
        temp_filepath = os.path.join(self.download_dir, temp_filename)
        
        print(f"ğŸ“¥ ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶åä¸‹è½½: {temp_filename}")
        await download.save_as(str(temp_filepath))
        
        # ä¸‹è½½å®Œæˆåï¼Œç”Ÿæˆè§„èŒƒæ–‡ä»¶åå¹¶ç§»åŠ¨åˆ°è§„èŒƒç›®å½•
        standard_filename = file_manager.get_standard_filename(
            self.current_url, 
            filename, 
            version_type=version_type,  # ä½¿ç”¨è‡ªåŠ¨åˆ¤æ–­çš„ç‰ˆæœ¬ç±»å‹
            file_extension=file_extension  # ä¼ é€’å®é™…æ–‡ä»¶æ‰©å±•å
        )
        
        # è·å–è§„èŒƒä¿å­˜ç›®å½•
        save_dir = file_manager.get_save_directory(version_type=version_type)
        final_filepath = save_dir / standard_filename
        
        # ğŸ”’ åŸºçº¿æ–‡ä»¶å¤¹å•æ–‡ä»¶è§„åˆ™ï¼šç¡®ä¿åŸºçº¿æ–‡ä»¶å¤¹åªæœ‰ä¸€ä¸ªæ–‡ä»¶
        if version_type == 'baseline':
            # æ¸…ç†åŸºçº¿æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰ç°æœ‰æ–‡ä»¶
            import glob
            # æ”¯æŒå¤šç§æ‰©å±•å
            existing_files = []
            for ext in ['*.csv', '*.xlsx', '*.xls', '*.xlsm']:
                existing_files.extend(glob.glob(str(save_dir / ext)))
            if existing_files:
                print(f"âš ï¸ åŸºçº¿æ–‡ä»¶å¤¹å•æ–‡ä»¶è§„åˆ™ç”Ÿæ•ˆï¼šæ¸…ç† {len(existing_files)} ä¸ªæ—§æ–‡ä»¶")
                for old_file in existing_files:
                    try:
                        os.remove(old_file)
                        print(f"   âœ… å·²åˆ é™¤: {os.path.basename(old_file)}")
                    except Exception as e:
                        print(f"   âŒ åˆ é™¤å¤±è´¥: {os.path.basename(old_file)} - {e}")
                print(f"ğŸ”’ åŸºçº¿æ–‡ä»¶å¤¹å·²æ¸…ç†ï¼Œç¡®ä¿åªä¿å­˜æœ€æ–°åŸºçº¿æ–‡ä»¶")
        
        # ç§»åŠ¨æ–‡ä»¶åˆ°è§„èŒƒä½ç½®
        import shutil
        shutil.move(str(temp_filepath), str(final_filepath))
        
        print(f"ğŸ¯ è§„èŒƒæ–‡ä»¶å‘½å: {standard_filename}")
        print(f"ğŸ“ è§„èŒƒä¿å­˜ç›®å½•: {save_dir}")
        
        filepath = final_filepath
        
        self.downloaded_files.append(str(filepath))
        print(f"ä¸‹è½½å®Œæˆ: {filepath}")
    
    async def login_with_cookies(self, cookies):
        """ä½¿ç”¨cookiesç™»å½•"""
        if cookies:
            cookie_list = []
            for cookie_str in cookies.split(';'):
                if '=' in cookie_str:
                    name, value = cookie_str.strip().split('=', 1)
                    # ä¸ºå¤šä¸ªdomainæ·»åŠ cookies
                    domains = ['docs.qq.com', '.docs.qq.com', 'qq.com', '.qq.com']
                    for domain in domains:
                        cookie_list.append({
                            'name': name,
                            'value': value,
                            'domain': domain,
                            'path': '/',
                            'httpOnly': False,
                            'secure': True,
                            'sameSite': 'None'
                        })
            try:
                await self.page.context.add_cookies(cookie_list)
                print(f"å·²æ·»åŠ  {len(cookie_list)} ä¸ªcookiesï¼ˆå¤šåŸŸåï¼‰")
            except Exception as e:
                print(f"æ·»åŠ cookiesæ—¶å‡ºé”™: {e}")
                # é™çº§åˆ°ç®€å•ç‰ˆæœ¬
                simple_cookies = []
                for cookie_str in cookies.split(';'):
                    if '=' in cookie_str:
                        name, value = cookie_str.strip().split('=', 1)
                        simple_cookies.append({
                            'name': name,
                            'value': value,
                            'domain': '.qq.com',
                            'path': '/'
                        })
                await self.page.context.add_cookies(simple_cookies)
                print(f"å·²æ·»åŠ ç®€åŒ–cookies: {len(simple_cookies)} ä¸ª")
    
    def _analyze_document_url(self, doc_url):
        """
        é˜¶æ®µ4å¢å¼ºåŠŸèƒ½ï¼šæ™ºèƒ½URLè§£æå’Œæ–‡æ¡£ç±»å‹è¯†åˆ«
        
        Args:
            doc_url: æ–‡æ¡£URL
            
        Returns:
            dict: URLåˆ†æç»“æœå’Œæ¨èç­–ç•¥
        """
        import re
        
        analysis = {
            "url": doc_url,
            "url_type": "unknown",
            "document_id": None,
            "is_specific_document": False,
            "recommended_methods": [],
            "expected_challenges": [],
            "adaptive_config": {}
        }
        
        try:
            print(f"ğŸ” å¼€å§‹æ™ºèƒ½URLåˆ†æ: {doc_url}")
            
            # 1. åŸºç¡€URLç±»å‹è¯†åˆ«
            if "docs.qq.com/desktop" in doc_url.lower() and len(doc_url.replace("https://docs.qq.com/desktop", "").strip("/?")) == 0:
                analysis["url_type"] = "desktop_general"
                analysis["is_specific_document"] = False
                analysis["expected_challenges"].append("éœ€è¦ä»åˆ—è¡¨ä¸­é€‰æ‹©æ–‡æ¡£")
                analysis["recommended_methods"] = ["_try_right_click_export", "_try_keyboard_shortcut_export", "_try_menu_export"]
                analysis["adaptive_config"]["require_document_selection"] = True
                
            elif "docs.qq.com/sheet/" in doc_url.lower():
                # å…·ä½“è¡¨æ ¼æ–‡æ¡£
                sheet_match = re.search(r'/sheet/([A-Za-z0-9]+)', doc_url)
                if sheet_match:
                    analysis["document_id"] = sheet_match.group(1)
                    analysis["url_type"] = "specific_sheet"
                    analysis["is_specific_document"] = True
                    analysis["recommended_methods"] = ["_try_menu_export", "_try_toolbar_export", "_try_keyboard_shortcut_export"]
                    analysis["adaptive_config"]["direct_export_available"] = True
                    
            elif "docs.qq.com/doc/" in doc_url.lower():
                # å…·ä½“æ–‡æ¡£
                doc_match = re.search(r'/doc/([A-Za-z0-9]+)', doc_url)
                if doc_match:
                    analysis["document_id"] = doc_match.group(1)
                    analysis["url_type"] = "specific_document"
                    analysis["is_specific_document"] = True
                    analysis["recommended_methods"] = ["_try_menu_export", "_try_toolbar_export"]
                    analysis["adaptive_config"]["direct_export_available"] = True
                    
            elif "docs.qq.com/slide/" in doc_url.lower():
                # å¹»ç¯ç‰‡æ–‡æ¡£
                slide_match = re.search(r'/slide/([A-Za-z0-9]+)', doc_url)
                if slide_match:
                    analysis["document_id"] = slide_match.group(1)
                    analysis["url_type"] = "specific_slide"
                    analysis["is_specific_document"] = True
                    analysis["recommended_methods"] = ["_try_menu_export", "_try_toolbar_export"]
                    analysis["expected_challenges"].append("å¹»ç¯ç‰‡å¯¼å‡ºæ ¼å¼å¯èƒ½å—é™")
                    
            elif "pad.qq.com" in doc_url.lower():
                # æ™ºèƒ½è¡¨æ ¼æˆ–å…¶ä»–padåŸŸå
                analysis["url_type"] = "pad_domain"
                analysis["is_specific_document"] = True
                analysis["recommended_methods"] = ["_try_menu_export", "_try_right_click_export"]
                analysis["adaptive_config"]["alternative_domain"] = True
                
            else:
                # æœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨å…¨æ–¹ä½æ–¹æ³•
                analysis["url_type"] = "unknown"
                analysis["recommended_methods"] = ["_try_menu_export", "_try_toolbar_export", "_try_keyboard_shortcut_export", "_try_right_click_export"]
                analysis["expected_challenges"].append("æœªçŸ¥URLæ ¼å¼ï¼Œä½¿ç”¨å…¨æ–¹ä½å°è¯•")
                
            # 2. URLå‚æ•°åˆ†æ
            if "?tab=" in doc_url:
                analysis["adaptive_config"]["has_tab_parameter"] = True
                analysis["expected_challenges"].append("å¤šæ ‡ç­¾é¡µæ–‡æ¡£ï¼Œéœ€è¦ç¡®è®¤å½“å‰æ ‡ç­¾")
                
            if "#" in doc_url:
                analysis["adaptive_config"]["has_anchor"] = True
                
            # 3. ç‰¹æ®Šæƒ…å†µæ£€æµ‹
            if "readonly" in doc_url.lower():
                analysis["expected_challenges"].append("åªè¯»æ–‡æ¡£ï¼Œå¯¼å‡ºåŠŸèƒ½å¯èƒ½å—é™")
                analysis["adaptive_config"]["readonly_mode"] = True
                
            print(f"ğŸ“Š URLåˆ†æå®Œæˆ:")
            print(f"   ç±»å‹: {analysis['url_type']}")
            print(f"   æ–‡æ¡£ID: {analysis.get('document_id', 'N/A')}")
            print(f"   æ¨èæ–¹æ³•: {len(analysis['recommended_methods'])}ä¸ª")
            print(f"   é¢„æœŸæŒ‘æˆ˜: {len(analysis['expected_challenges'])}ä¸ª")
            
            return analysis
            
        except Exception as e:
            print(f"âš ï¸ URLåˆ†æå¼‚å¸¸: {e}")
            # è¿”å›å®‰å…¨çš„é»˜è®¤åˆ†æç»“æœ
            analysis["url_type"] = "fallback"
            analysis["recommended_methods"] = ["_try_menu_export", "_try_toolbar_export", "_try_keyboard_shortcut_export", "_try_right_click_export"]
            return analysis

    async def export_document(self, doc_url, export_format="excel", **kwargs):
        """
        å¯¼å‡ºæ–‡æ¡£çš„ä¸»æ–¹æ³•ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
        æ¥å—é¢å¤–å‚æ•°å¦‚cookiesç­‰
        """
        # ç¡®ä¿æµè§ˆå™¨å·²å¯åŠ¨
        if not self.browser or not self.page:
            print("ğŸŒ å¯åŠ¨æµè§ˆå™¨...")
            await self.start_browser(headless=True)

        # å¦‚æœä¼ å…¥äº†cookieså‚æ•°ï¼Œè®¾ç½®cookies
        if 'cookies' in kwargs:
            cookie = kwargs['cookies']
            if cookie:
                print("ğŸª è®¾ç½®Cookie...")
                await self.login_with_cookies(cookie)

        # è°ƒç”¨è‡ªåŠ¨å¯¼å‡ºæ–¹æ³•
        return await self.auto_export_document(doc_url, export_format)

    async def auto_export_document(self, doc_url, export_format="excel"):
        """
        ç®€åŒ–ç‰ˆï¼šç›´æ¥ä¸‹è½½æ–‡æ¡£ï¼ˆç§»é™¤æ‰€æœ‰é™çº§æ–¹æ³•ï¼‰
        """
        print(f"ğŸš€ å¼€å§‹æ–‡æ¡£ä¸‹è½½: {doc_url}")

        try:
            # è®¾ç½®å½“å‰URLä¾›_handle_downloadä½¿ç”¨
            self.current_url = doc_url

            # ç›´æ¥è®¿é—®é¡µé¢
            print("ğŸ“‹ åŠ è½½é¡µé¢...")
            await self.page.goto(doc_url, wait_until='domcontentloaded', timeout=30000)
            print("âœ… é¡µé¢åŠ è½½å®Œæˆ")

            # ç­‰å¾…é¡µé¢æ¸²æŸ“
            await self.page.wait_for_timeout(5000)

            # ç­‰å¾…ç½‘ç»œç©ºé—²
            try:
                await self.page.wait_for_load_state('networkidle', timeout=10000)
                print("ğŸŒ ç½‘ç»œè¯·æ±‚å®Œæˆ")
            except:
                print("âš ï¸ ç½‘ç»œç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­...")

            # ç­‰å¾…ä¸‹è½½å®Œæˆ
            print("ğŸ“¥ ç­‰å¾…ä¸‹è½½...")
            await self._wait_for_download(timeout=30)

            if self.downloaded_files:
                print(f"ğŸ‰ æˆåŠŸä¸‹è½½æ–‡ä»¶: {self.downloaded_files}")
                return self.downloaded_files
            else:
                print("âš ï¸ æœªæ£€æµ‹åˆ°ä¸‹è½½æ–‡ä»¶ï¼Œå¯èƒ½é¡µé¢æ­£åœ¨è‡ªåŠ¨ä¸‹è½½")
                # å†ç­‰å¾…ä¸€æ®µæ—¶é—´
                await self.page.wait_for_timeout(10000)
                if self.downloaded_files:
                    print(f"âœ… å»¶è¿Ÿä¸‹è½½æˆåŠŸ: {self.downloaded_files}")
                    return self.downloaded_files
                else:
                    raise Exception("æœªæ£€æµ‹åˆ°ä¸‹è½½çš„æ–‡ä»¶")

        except Exception as e:
            print(f"âŒ æ–‡æ¡£ä¸‹è½½å¤±è´¥: {e}")
            return None
    

    async def _detect_desktop_page_status(self):
        """æ£€æµ‹æ¡Œé¢é¡µé¢çŠ¶æ€"""
        print("ğŸ“‹ æ£€æµ‹æ¡Œé¢é¡µé¢çŠ¶æ€...")
        
        # æ£€æµ‹æ–‡æ¡£åˆ—è¡¨æ˜¯å¦åŠ è½½å®Œæˆ
        document_list_selectors = [
            '[class*="doc-list"]',
            '[class*="file-list"]', 
            '[class*="document-item"]',
            '.desktop-content'
        ]
        
        list_found = False
        for selector in document_list_selectors:
            elements = await self.page.query_selector_all(selector)
            if elements:
                print(f"âœ… æ£€æµ‹åˆ°æ–‡æ¡£åˆ—è¡¨: {selector} ({len(elements)}ä¸ªå…ƒç´ )")
                list_found = True
                break
        
        if not list_found:
            print("âš ï¸ æœªæ£€æµ‹åˆ°æ˜ç¡®çš„æ–‡æ¡£åˆ—è¡¨ï¼Œä½†ç»§ç»­è¿›è¡Œ...")
    
    async def _detect_specific_document_status(self, url_analysis):
        """æ£€æµ‹å…·ä½“æ–‡æ¡£é¡µé¢çŠ¶æ€"""
        print(f"ğŸ“„ æ£€æµ‹å…·ä½“æ–‡æ¡£çŠ¶æ€ (ç±»å‹: {url_analysis['url_type']})...")
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        readonly_btn = await self.page.query_selector('.readonly-button')
        menu_btn = await self.page.query_selector('.titlebar-icon-more')
        has_edit_access = await self.page.query_selector('[class*="edit"]')
        
        current_url = self.page.url
        print(f"ğŸ“Š é¡µé¢çŠ¶æ€æ£€æµ‹ç»“æœ:")
        print(f"   å½“å‰URL: {current_url[:100]}...")
        print(f"   åªè¯»æŒ‰é’®: {'å­˜åœ¨' if readonly_btn else 'ä¸å­˜åœ¨'}")
        print(f"   èœå•æŒ‰é’®: {'å­˜åœ¨' if menu_btn else 'ä¸å­˜åœ¨'}")
        print(f"   ç¼–è¾‘å…ƒç´ : {'å­˜åœ¨' if has_edit_access else 'ä¸å­˜åœ¨'}")
        
        # æ ¹æ®URLåˆ†æç»“æœè°ƒæ•´çŠ¶æ€åˆ¤æ–­
        if url_analysis.get("adaptive_config", {}).get("readonly_mode"):
            print("ğŸ“– åªè¯»æ¨¡å¼æ–‡æ¡£ï¼Œè°ƒæ•´å¯¼å‡ºç­–ç•¥")
        
        if menu_btn:
            print("âœ… æ£€æµ‹åˆ°å¯¼å‡ºèœå•ï¼Œç”¨æˆ·å·²ç™»å½•ï¼Œç»§ç»­å¯¼å‡ºæµç¨‹...")
        elif readonly_btn:
            print("â„¹ï¸ æ–‡æ¡£ä¸ºåªè¯»æ¨¡å¼ï¼Œä½†å¯èƒ½ä»å¯å¯¼å‡º")
        else:
            print("âš ï¸ æœªæ£€æµ‹åˆ°æ˜ç¡®çš„ç™»å½•/èœå•å…ƒç´ ï¼Œå°†å°è¯•ç»§ç»­...")

    async def cleanup(self):
        """æ¸…ç†èµ„æº - å¢å¼ºç‰ˆï¼Œç¡®ä¿è¿›ç¨‹è¢«ç»ˆæ­¢"""
        cleanup_errors = []

        # 1. å°è¯•æ­£å¸¸å…³é—­é¡µé¢
        if self.page:
            try:
                await self.page.close()
                self.page = None
            except Exception as e:
                cleanup_errors.append(f"é¡µé¢å…³é—­å¤±è´¥: {e}")

        # 2. å¦‚æœä½¿ç”¨å•ä¾‹æ¨¡å¼ï¼Œä¸å…³é—­æµè§ˆå™¨ï¼ˆä¿æŒå¤ç”¨ï¼‰
        if hasattr(self, 'using_singleton') and self.using_singleton:
            print("â™»ï¸ ä¿æŒå•ä¾‹æµè§ˆå™¨å®ä¾‹ï¼ˆä¾›ä¸‹æ¬¡å¤ç”¨ï¼‰")
            return
        
        # 3. å°è¯•æ­£å¸¸å…³é—­æµè§ˆå™¨ï¼ˆéå•ä¾‹æ¨¡å¼ï¼‰
        if self.browser:
            try:
                await self.browser.close()
                self.browser = None
            except Exception as e:
                cleanup_errors.append(f"æµè§ˆå™¨å…³é—­å¤±è´¥: {e}")
        
        # 3. åœæ­¢playwright
        if hasattr(self, 'playwright'):
            try:
                await self.playwright.stop()
                self.playwright = None
            except Exception as e:
                cleanup_errors.append(f"Playwrightåœæ­¢å¤±è´¥: {e}")
        
        # 4. å¦‚æœæœ‰é”™è¯¯ï¼Œä½¿ç”¨å¼ºåˆ¶æ¸…ç†
        if cleanup_errors:
            print(f"âš ï¸ æ¸…ç†è¿‡ç¨‹é‡åˆ°é”™è¯¯: {cleanup_errors}")
            try:
                # å¯¼å…¥è¿›ç¨‹ç®¡ç†å™¨è¿›è¡Œå¼ºåˆ¶æ¸…ç†
                import sys
                import os
                sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
                from browser_process_manager import BrowserProcessManager
                BrowserProcessManager.kill_all_browser_processes()
                print("âœ… å·²å¼ºåˆ¶ç»ˆæ­¢æ‰€æœ‰æµè§ˆå™¨è¿›ç¨‹")
            except Exception as e:
                print(f"âŒ å¼ºåˆ¶æ¸…ç†å¤±è´¥: {e}")
        
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            import glob
            import shutil
            for pattern in ['/tmp/playwright*', '/tmp/chromium*']:
                for path in glob.glob(pattern)[:5]:  # åªæ¸…ç†æœ€è¿‘çš„5ä¸ª
                    try:
                        if os.path.isdir(path):
                            shutil.rmtree(path)
                    except:
                        pass
        except:
            pass


async def main():
    parser = argparse.ArgumentParser(description='è…¾è®¯æ–‡æ¡£è‡ªåŠ¨å¯¼å‡ºå·¥å…·')
    parser.add_argument('url', help='è…¾è®¯æ–‡æ¡£URL')
    parser.add_argument('-c', '--cookies', help='ç™»å½•Cookie')
    parser.add_argument('-f', '--format', default='excel', choices=['excel', 'xlsx', 'csv'], help='å¯¼å‡ºæ ¼å¼')
    parser.add_argument('-d', '--download-dir', help='ä¸‹è½½ç›®å½•')
    parser.add_argument('--visible', action='store_true', help='æ˜¾ç¤ºæµè§ˆå™¨çª—å£')
    
    args = parser.parse_args()
    
    exporter = TencentDocAutoExporter(
        download_dir=args.download_dir
    )
    
    try:
        await exporter.start_browser(headless=not args.visible)
        
        if args.cookies:
            await exporter.login_with_cookies(args.cookies)
        
        result = await exporter.auto_export_document(args.url, args.format)
        
        if result:
            print(f"[æˆåŠŸ] è‡ªåŠ¨å¯¼å‡ºå®Œæˆï¼Œæ–‡ä»¶ä¿å­˜åœ¨: {result}")
            
            # ç‰ˆæœ¬ç®¡ç†å¤„ç†
            if exporter.enable_version_management and exporter.version_manager:
                print("æ­£åœ¨è¿›è¡Œç‰ˆæœ¬ç®¡ç†å¤„ç†...")
                
                for file_path in result:
                    # ä»æ–‡ä»¶åæå–è¡¨æ ¼åç§°
                    file_name = Path(file_path).stem
                    version_result = exporter.version_manager.add_new_version(file_path, file_name)
                    
                    if version_result["success"]:
                        print(f"âœ… {version_result['message']}")
                        if version_result.get("archived_files"):
                            print(f"ğŸ“ å·²å½’æ¡£æ—§ç‰ˆæœ¬: {', '.join(version_result['archived_files'])}")
                        
                        # å‡†å¤‡å¯¹æ¯”æ–‡ä»¶
                        table_name = version_result["table_name"]
                        comparison_result = exporter.version_manager.prepare_comparison(table_name)
                        if comparison_result["success"]:
                            print(f"ğŸ“Š å¯¹æ¯”æ–‡ä»¶å·²å‡†å¤‡: {comparison_result['message']}")
                            print(f"ğŸ“„ å½“å‰ç‰ˆæœ¬: {Path(comparison_result['current_file']).name}")
                            print(f"ğŸ“„ å¯¹æ¯”ç‰ˆæœ¬: {Path(comparison_result['previous_file']).name}")
                        else:
                            print(f"âš ï¸  {comparison_result.get('message', 'æ— æ³•å‡†å¤‡å¯¹æ¯”æ–‡ä»¶')}")
                    else:
                        action = version_result.get("action", "unknown")
                        if action == "duplicate_content":
                            print(f"â„¹ï¸  æ–‡ä»¶å†…å®¹æœªå˜åŒ–ï¼Œä¸ {version_result.get('duplicate_file', 'ç°æœ‰æ–‡ä»¶')} ç›¸åŒ")
                        else:
                            print(f"âš ï¸  ç‰ˆæœ¬ç®¡ç†å¤„ç†å¤±è´¥: {version_result.get('error', version_result.get('message', 'æœªçŸ¥é”™è¯¯'))}")
        else:
            print("[å¤±è´¥] è‡ªåŠ¨å¯¼å‡ºå¤±è´¥")
            
    except Exception as e:
        print(f"ç¨‹åºå‡ºé”™: {e}")
    finally:
        await exporter.cleanup()


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"ç¨‹åºå‡ºé”™: {e}")