#!/usr/bin/env python3
"""
æ•°æ®æ ¼å¼é€‚é…å™¨ - è½¬æ¢ç”Ÿæˆçš„æ‰“åˆ†æ–‡ä»¶ä¸ºç¬¦åˆ10-ç»¼åˆæ‰“åˆ†ç»å¯¹è§„èŒƒçš„æ ¼å¼
ç”¨äºä¿®å¤å½“å‰è¾“å‡ºä¸UIè¦æ±‚ä¹‹é—´çš„æ•°æ®æ ¼å¼å·®å¼‚
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any

class DataFormatAdapter:
    """æ•°æ®æ ¼å¼é€‚é…å™¨ï¼Œç¡®ä¿è¾“å‡ºç¬¦åˆè§„èŒƒ"""

    def __init__(self):
        """åˆå§‹åŒ–é€‚é…å™¨"""
        self.standard_columns = [
            "åºå·", "é¡¹ç›®ç±»å‹", "æ¥æº", "ä»»åŠ¡å‘èµ·æ—¶é—´", "ç›®æ ‡å¯¹é½",
            "å…³é”®KRå¯¹é½", "å…·ä½“è®¡åˆ’å†…å®¹", "é‚“æ€»æŒ‡å¯¼ç™»è®°", "è´Ÿè´£äºº",
            "ååŠ©äºº", "ç›‘ç£äºº", "é‡è¦ç¨‹åº¦", "é¢„è®¡å®Œæˆæ—¶é—´", "å®Œæˆè¿›åº¦",
            "å®Œæˆé“¾æ¥", "ç»ç†åˆ†æå¤ç›˜", "æœ€æ–°å¤ç›˜æ—¶é—´", "å¯¹ä¸Šæ±‡æŠ¥", "åº”ç”¨æƒ…å†µ"
        ]

    def transform_to_standard_format(self, input_data: Dict) -> Dict:
        """
        å°†å½“å‰æ ¼å¼è½¬æ¢ä¸ºç¬¦åˆ10-ç»¼åˆæ‰“åˆ†ç»å¯¹è§„èŒƒçš„æ ¼å¼

        å‚æ•°:
            input_data: å½“å‰ç”Ÿæˆçš„ç»¼åˆæ‰“åˆ†æ•°æ®

        è¿”å›:
            ç¬¦åˆè§„èŒƒçš„ç»¼åˆæ‰“åˆ†æ•°æ®
        """
        print("ğŸ”„ å¼€å§‹æ•°æ®æ ¼å¼è½¬æ¢...")

        # æå–åŸºç¡€ä¿¡æ¯
        table_names = input_data.get('table_names', [])
        table_scores = input_data.get('table_scores', [])

        # æ„å»ºç¬¦åˆè§„èŒƒçš„è¾“å‡ºæ ¼å¼
        output_data = {
            # å…ƒæ•°æ®éƒ¨åˆ†
            "metadata": {
                "version": "2.0",
                "timestamp": datetime.now().isoformat(),
                "week": input_data.get('week_number', 'W38'),
                "generator": "data_format_adapter",
                "total_params": 0,  # ç¨åè®¡ç®—
                "processing_time": 0.0,
                "data_source": "csv_comparison"
            },

            # æ‘˜è¦éƒ¨åˆ†
            "summary": {
                "total_tables": len(table_names),
                "total_columns": len(self.standard_columns),
                "total_modifications": input_data.get('total_modifications', 0),
                "overall_risk_score": 0.0,  # ç¨åè®¡ç®—
                "processing_status": "complete"
            },

            # è¡¨ååˆ—è¡¨ï¼ˆUIå‚æ•°1ï¼šè¡¨åä½œä¸ºè¡Œåï¼‰
            "table_names": table_names,

            # åˆ—ååˆ—è¡¨ï¼ˆUIå‚æ•°2ï¼šåˆ—åï¼‰
            "column_names": self.standard_columns,

            # çƒ­åŠ›å›¾çŸ©é˜µæ•°æ®ï¼ˆUIå‚æ•°4ï¼šæ ¼å­çš„åˆ—ä¿®æ”¹å€¼ï¼‰
            "heatmap_data": {
                "matrix": [],
                "description": f"{len(table_names)}Ã—19çŸ©é˜µï¼Œå€¼åŸŸ[0.05-1.0]"
            },

            # è¯¦ç»†è¡¨æ ¼æ•°æ®
            "table_details": [],

            # UIæ•°æ®ï¼ˆç”¨äºå‰ç«¯æ¸²æŸ“ï¼‰
            "ui_data": input_data.get('ui_data', [])
        }

        # æ„å»ºçƒ­åŠ›å›¾çŸ©é˜µå’Œè¡¨æ ¼è¯¦æƒ…
        for i, table_score in enumerate(table_scores):
            table_name = table_score.get('table_name', f'è¡¨æ ¼_{i+1}')
            column_scores = table_score.get('column_scores', {})

            # æ„å»ºå•è¡Œçƒ­åŠ›å›¾æ•°æ®
            row_data = []
            column_details = []

            for col_name in self.standard_columns:
                if col_name in column_scores:
                    col_data = column_scores[col_name]
                    score = col_data.get('avg_score', 0.05)
                    modified_rows = col_data.get('modified_rows', [])
                    modification_count = col_data.get('modification_count', 0)
                else:
                    score = 0.05
                    modified_rows = []
                    modification_count = 0

                row_data.append(round(score, 2))

                # æ„å»ºåˆ—è¯¦æƒ…ï¼ˆUIå‚æ•°5,8ï¼šä¿®æ”¹è¡Œæ•°å’Œä½ç½®ï¼‰
                column_details.append({
                    "column_name": col_name,
                    "column_index": self.standard_columns.index(col_name),
                    "modification_count": modification_count,
                    "modified_rows": modified_rows,
                    "score": round(score, 2)
                })

            output_data['heatmap_data']['matrix'].append(row_data)

            # æ„å»ºè¡¨æ ¼è¯¦æƒ…ï¼ˆUIå‚æ•°6,7,9ï¼šæ€»ä¿®æ”¹æ•°ã€æ€»è¡Œæ•°ã€URLï¼‰
            table_detail = {
                "table_id": f"table_{i+1:03d}",
                "table_name": table_name,
                "table_index": i,
                "total_rows": self._extract_total_rows(table_score),
                "total_modifications": table_score.get('total_modifications', 0),
                "overall_risk_score": table_score.get('overall_risk_score', 0.05),
                "excel_url": table_score.get('table_url', ''),
                "column_details": column_details
            }

            output_data['table_details'].append(table_detail)

        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_params = sum(
            td['total_rows'] * len(self.standard_columns)
            for td in output_data['table_details']
        )
        output_data['metadata']['total_params'] = total_params

        # è®¡ç®—å¹³å‡é£é™©åˆ†æ•°
        if output_data['table_details']:
            avg_risk = sum(
                td['overall_risk_score']
                for td in output_data['table_details']
            ) / len(output_data['table_details'])
            output_data['summary']['overall_risk_score'] = round(avg_risk, 3)

        # æ·»åŠ hover_dataï¼ˆç”¨äºæ‚¬æµ®æç¤ºï¼‰
        output_data['hover_data'] = {
            "data": self._build_hover_data(output_data['table_details'])
        }

        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        output_data['statistics'] = self._calculate_statistics(output_data)

        print(f"âœ… æ•°æ®æ ¼å¼è½¬æ¢å®Œæˆ")
        print(f"   - è¡¨æ ¼æ•°é‡: {len(table_names)}")
        print(f"   - æ€»å‚æ•°æ•°: {total_params}")
        print(f"   - çŸ©é˜µç»´åº¦: {len(table_names)}Ã—19")

        return output_data

    def _extract_total_rows(self, table_score: Dict) -> int:
        """
        æå–è¡¨æ ¼æ€»è¡Œæ•°
        å¦‚æœæ²¡æœ‰æ˜ç¡®çš„total_rowså­—æ®µï¼Œå°è¯•ä»å…¶ä»–åœ°æ–¹æ¨æ–­
        """
        # ç›´æ¥æŸ¥æ‰¾total_rowså­—æ®µ
        if 'total_rows' in table_score:
            return table_score['total_rows']

        # å°è¯•ä»ä¿®æ”¹è¡Œä¸­æ¨æ–­ï¼ˆå–æœ€å¤§è¡Œå·ï¼‰
        max_row = 0
        column_scores = table_score.get('column_scores', {})
        for col_data in column_scores.values():
            modified_rows = col_data.get('modified_rows', [])
            if modified_rows:
                max_row = max(max_row, max(modified_rows))

        # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå‡è®¾æ€»è¡Œæ•°è‡³å°‘æ˜¯æœ€å¤§è¡Œå·çš„1.5å€
        if max_row > 0:
            return int(max_row * 1.5)

        # é»˜è®¤å€¼
        return 100

    def _build_hover_data(self, table_details: List[Dict]) -> List[Dict]:
        """æ„å»ºæ‚¬æµ®æç¤ºæ•°æ®"""
        hover_data = []

        for table in table_details:
            hover_item = {
                "table_index": table['table_index'],
                "table_name": table['table_name'],
                "total_modifications": table['total_modifications'],
                "column_details": [
                    {
                        "column_name": cd['column_name'],
                        "modification_count": cd['modification_count'],
                        "modified_rows": cd['modified_rows'][:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
                    }
                    for cd in table['column_details']
                ]
            }
            hover_data.append(hover_item)

        return hover_data

    def _calculate_statistics(self, data: Dict) -> Dict:
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        heatmap_matrix = data['heatmap_data']['matrix']

        # ç»Ÿè®¡ä¸åŒé£é™©ç­‰çº§çš„æ•°é‡
        high_risk_count = 0
        medium_risk_count = 0
        low_risk_count = 0

        for row in heatmap_matrix:
            for value in row:
                if value >= 0.7:
                    high_risk_count += 1
                elif value >= 0.3:
                    medium_risk_count += 1
                elif value > 0.05:
                    low_risk_count += 1

        # ç»Ÿè®¡æœ‰ä¿®æ”¹çš„è¡¨æ ¼æ•°
        tables_with_modifications = sum(
            1 for td in data['table_details']
            if td['total_modifications'] > 0
        )

        return {
            "total_modifications": data['summary']['total_modifications'],
            "average_modifications_per_table": (
                data['summary']['total_modifications'] /
                max(1, data['summary']['total_tables'])
            ),
            "high_risk_count": high_risk_count,
            "medium_risk_count": medium_risk_count,
            "low_risk_count": low_risk_count,
            "tables_with_modifications": tables_with_modifications
        }

    def validate_output(self, data: Dict) -> bool:
        """
        éªŒè¯è¾“å‡ºæ•°æ®æ˜¯å¦ç¬¦åˆè§„èŒƒè¦æ±‚çš„9ç±»å‚æ•°
        """
        required_fields = [
            'table_names',  # UIå‚æ•°1
            'column_names',  # UIå‚æ•°2
            'heatmap_data',  # UIå‚æ•°4
            'table_details'  # åŒ…å«UIå‚æ•°5-9
        ]

        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        for field in required_fields:
            if field not in data:
                print(f"âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
                return False

        # æ£€æŸ¥çƒ­åŠ›å›¾çŸ©é˜µ
        if 'matrix' not in data['heatmap_data']:
            print("âŒ ç¼ºå°‘çƒ­åŠ›å›¾çŸ©é˜µæ•°æ®")
            return False

        # æ£€æŸ¥çŸ©é˜µç»´åº¦
        matrix = data['heatmap_data']['matrix']
        expected_rows = len(data['table_names'])
        expected_cols = len(data['column_names'])

        if len(matrix) != expected_rows:
            print(f"âŒ çŸ©é˜µè¡Œæ•°ä¸åŒ¹é…: æœŸæœ›{expected_rows}, å®é™…{len(matrix)}")
            return False

        for row in matrix:
            if len(row) != expected_cols:
                print(f"âŒ çŸ©é˜µåˆ—æ•°ä¸åŒ¹é…: æœŸæœ›{expected_cols}, å®é™…{len(row)}")
                return False

        # æ£€æŸ¥è¡¨æ ¼è¯¦æƒ…
        for table in data['table_details']:
            required_table_fields = [
                'table_name',
                'total_rows',
                'total_modifications',
                'column_details',
                'excel_url'
            ]

            for field in required_table_fields:
                if field not in table:
                    print(f"âŒ è¡¨æ ¼ç¼ºå°‘å­—æ®µ: {field}")
                    return False

        print("âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡ï¼ŒåŒ…å«æ‰€æœ‰9ç±»å¿…éœ€å‚æ•°")
        return True


def convert_comprehensive_score_file(input_file: str, output_file: str = None):
    """
    è½¬æ¢ç»¼åˆæ‰“åˆ†æ–‡ä»¶æ ¼å¼

    å‚æ•°:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤åœ¨åŒç›®å½•ä¸‹ç”Ÿæˆ_standardç‰ˆæœ¬ï¼‰
    """
    adapter = DataFormatAdapter()

    # è¯»å–è¾“å…¥æ–‡ä»¶
    with open(input_file, 'r', encoding='utf-8') as f:
        input_data = json.load(f)

    # è½¬æ¢æ ¼å¼
    output_data = adapter.transform_to_standard_format(input_data)

    # éªŒè¯è¾“å‡º
    if not adapter.validate_output(output_data):
        print("âš ï¸ è¾“å‡ºæ•°æ®éªŒè¯å¤±è´¥ï¼Œä½†ä»ä¼šä¿å­˜æ–‡ä»¶")

    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    if output_file is None:
        base_name = os.path.splitext(input_file)[0]
        output_file = f"{base_name}_standard.json"

    # ä¿å­˜è¾“å‡ºæ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“ æ ‡å‡†æ ¼å¼æ–‡ä»¶å·²ä¿å­˜: {output_file}")
    return output_file


if __name__ == "__main__":
    # æµ‹è¯•è½¬æ¢æœ€æ–°çš„ç»¼åˆæ‰“åˆ†æ–‡ä»¶
    import glob

    scoring_dir = '/root/projects/tencent-doc-manager/scoring_results/comprehensive'
    pattern = os.path.join(scoring_dir, 'comprehensive_score_W38_*.json')
    files = glob.glob(pattern)

    if files:
        # æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶
        latest_file = max(files, key=os.path.getmtime)
        print(f"ğŸ“‚ è½¬æ¢æ–‡ä»¶: {os.path.basename(latest_file)}")

        # æ‰§è¡Œè½¬æ¢
        output_file = convert_comprehensive_score_file(latest_file)

        print("\nğŸ¯ è½¬æ¢å®Œæˆï¼")