#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆCSVå¯¹æ¯”å™¨ - æ”¯æŒæ‰€æœ‰åˆ—çš„å¯¹æ¯”ï¼Œä¸é™äºæ ‡å‡†åˆ—
"""

import csv
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnhancedCSVComparator:
    """
    å¢å¼ºç‰ˆCSVå¯¹æ¯”å™¨
    - å¯¹æ¯”æ‰€æœ‰åˆ—ï¼Œä¸ä»…é™äºæ ‡å‡†åˆ—
    - ä¿ç•™åŸæœ‰çš„é£é™©è¯„åˆ†æœºåˆ¶
    - æ”¯æŒå¯¹è§’çº¿æ¨¡å¼æ£€æµ‹
    """

    def __init__(self):
        # æ ‡å‡†åˆ—é…ç½®ï¼ˆç”¨äºé£é™©è¯„åˆ†ï¼Œä½†ä¸é™åˆ¶å¯¹æ¯”èŒƒå›´ï¼‰
        self.standard_columns = {
            "åºå·": "L3",
            "é¡¹ç›®ç®¡ç†ID": "L3",
            "é¡¹ç›®ç±»å‹": "L2",
            "æ¥æº": "L1",
            "ä»»åŠ¡å‘èµ·æ—¶é—´": "L1",
            "ç›®æ ‡å¯¹é½": "L1",
            "å…³é”®KRå¯¹é½": "L1",
            "å…·ä½“è®¡åˆ’å†…å®¹": "L2",
            "é‚“æ€»æŒ‡å¯¼ç™»è®°": "L2",
            "è´Ÿè´£äºº": "L2",
            "ååŠ©äºº": "L2",
            "ç›‘ç£äºº": "L2",
            "é‡è¦ç¨‹åº¦": "L1",
            "é¢„è®¡å®Œæˆæ—¶é—´": "L1",
            "å®Œæˆè¿›åº¦": "L1",
            "å®Œæˆé“¾æ¥": "L2",
            "ç»ç†åˆ†æå¤ç›˜": "L3",
            "æœ€æ–°å¤ç›˜æ—¶é—´": "L3",
            "å¯¹ä¸Šæ±‡æŠ¥": "L3",
            "åº”ç”¨æƒ…å†µ": "L3"
        }

        # åˆ—å·åˆ°åç§°çš„æ˜ å°„
        self.column_letter_mapping = {
            0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E',
            5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J',
            10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O',
            15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T'
        }

    def _load_csv(self, file_path: str) -> List[List[str]]:
        """åŠ è½½CSVæ–‡ä»¶"""
        encodings = ['utf-8-sig', 'utf-8', 'gbk', 'gb2312']

        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    reader = csv.reader(f)
                    data = list(reader)
                    logger.info(f"âœ… æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æ–‡ä»¶")
                    return data
            except (UnicodeDecodeError, UnicodeError):
                continue

        raise ValueError(f"æ— æ³•åŠ è½½æ–‡ä»¶: {file_path}")

    def _get_column_name(self, headers: List[str], col_idx: int) -> str:
        """è·å–åˆ—åï¼ˆä¼˜å…ˆä½¿ç”¨æ ‡é¢˜è¡Œï¼Œå¦åˆ™ä½¿ç”¨åˆ—å­—æ¯ï¼‰"""
        if col_idx < len(headers) and headers[col_idx].strip():
            return headers[col_idx].strip()
        else:
            return f"åˆ—{self.column_letter_mapping.get(col_idx, col_idx+1)}"

    def compare_all_columns(self, file1_path: str, file2_path: str) -> Dict:
        """
        å¯¹æ¯”æ‰€æœ‰åˆ—çš„ä¿®æ”¹ï¼Œä¸é™äºæ ‡å‡†åˆ—

        è¿”å›:
            åŒ…å«æ‰€æœ‰å·®å¼‚çš„å­—å…¸ï¼ŒåŒ…æ‹¬å¯¹è§’çº¿æ¨¡å¼æ£€æµ‹
        """
        try:
            logger.info(f"ğŸ” å¼€å§‹å¢å¼ºç‰ˆCSVå¯¹æ¯”")
            logger.info(f"  åŸºå‡†æ–‡ä»¶: {Path(file1_path).name}")
            logger.info(f"  å½“å‰æ–‡ä»¶: {Path(file2_path).name}")

            # åŠ è½½æ–‡ä»¶
            data1 = self._load_csv(file1_path)
            data2 = self._load_csv(file2_path)

            if not data1 or not data2:
                raise ValueError("æ–‡ä»¶æ•°æ®ä¸ºç©º")

            # è·å–æ ‡é¢˜è¡Œï¼ˆå‡è®¾ç¬¬ä¸€è¡Œæ˜¯æ ‡é¢˜ï¼‰
            headers1 = data1[0] if data1 else []
            headers2 = data2[0] if data2 else []

            # å‡†å¤‡å·®å¼‚åˆ—è¡¨
            differences = []
            diagonal_pattern = []  # å¯¹è§’çº¿æ¨¡å¼æ£€æµ‹
            column_modifications = {}  # æ¯åˆ—çš„ä¿®æ”¹ç»Ÿè®¡

            # ç¡®å®šå¯¹æ¯”èŒƒå›´
            max_cols = max(len(headers1), len(headers2))
            max_rows = min(len(data1), len(data2))

            logger.info(f"  å¯¹æ¯”èŒƒå›´: {max_rows}è¡Œ Ã— {max_cols}åˆ—")

            # é€è¡Œé€åˆ—å¯¹æ¯”ï¼ˆä»ç¬¬äºŒè¡Œå¼€å§‹ï¼Œè·³è¿‡æ ‡é¢˜ï¼‰
            for row_idx in range(1, max_rows):
                row1 = data1[row_idx] if row_idx < len(data1) else []
                row2 = data2[row_idx] if row_idx < len(data2) else []

                # å¯¹æ¯”æ¯ä¸€åˆ—
                for col_idx in range(max_cols):
                    val1 = row1[col_idx] if col_idx < len(row1) else ""
                    val2 = row2[col_idx] if col_idx < len(row2) else ""

                    # æ¸…ç†å€¼
                    val1 = str(val1).strip()
                    val2 = str(val2).strip()

                    # æ£€æµ‹å·®å¼‚
                    if val1 != val2:
                        col_name = self._get_column_name(headers1, col_idx)
                        col_letter = self.column_letter_mapping.get(col_idx, str(col_idx+1))

                        # è®°å½•å·®å¼‚
                        diff = {
                            "åºå·": len(differences) + 1,
                            "è¡Œå·": row_idx + 1,  # Excelè¡Œå·ï¼ˆä»1å¼€å§‹ï¼‰
                            "åˆ—å·": col_idx + 1,  # Excelåˆ—å·ï¼ˆä»1å¼€å§‹ï¼‰
                            "åˆ—å­—æ¯": col_letter,
                            "åˆ—å": col_name,
                            "åŸå€¼": val1,
                            "æ–°å€¼": val2,
                            "ä½ç½®": f"{col_letter}{row_idx+1}",
                            "é£é™©ç­‰çº§": self.standard_columns.get(col_name, "L3")
                        }
                        differences.append(diff)

                        # ç»Ÿè®¡åˆ—ä¿®æ”¹
                        if col_name not in column_modifications:
                            column_modifications[col_name] = []
                        column_modifications[col_name].append(row_idx + 1)

                        # æ£€æµ‹å¯¹è§’çº¿æ¨¡å¼
                        if col_idx == row_idx - 3:  # B4, C5, D6...çš„æ¨¡å¼
                            diagonal_pattern.append(diff)

            # åˆ†æç»“æœ
            logger.info(f"âœ… å¯¹æ¯”å®Œæˆ:")
            logger.info(f"  æ€»å·®å¼‚æ•°: {len(differences)}")
            logger.info(f"  ä¿®æ”¹çš„åˆ—æ•°: {len(column_modifications)}")
            logger.info(f"  å¯¹è§’çº¿æ¨¡å¼: {len(diagonal_pattern)}ä¸ª")

            # å¦‚æœæ£€æµ‹åˆ°å¯¹è§’çº¿æ¨¡å¼ï¼Œè®°å½•è¯¦æƒ…
            if diagonal_pattern:
                logger.info("  ğŸ“ æ£€æµ‹åˆ°å¯¹è§’çº¿ä¿®æ”¹æ¨¡å¼:")
                for d in diagonal_pattern[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                    logger.info(f"    {d['ä½ç½®']}: {d['åˆ—å']}")
                if len(diagonal_pattern) > 5:
                    logger.info(f"    ... è¿˜æœ‰{len(diagonal_pattern)-5}ä¸ª")

            # æ„å»ºç»“æœ
            result = {
                "success": True,
                "total_differences": len(differences),
                "differences": differences,
                "column_modifications": column_modifications,
                "diagonal_pattern": {
                    "detected": len(diagonal_pattern) > 0,
                    "count": len(diagonal_pattern),
                    "pattern": diagonal_pattern
                },
                "metadata": {
                    "file1_rows": len(data1),
                    "file1_cols": len(headers1),
                    "file2_rows": len(data2),
                    "file2_cols": len(headers2),
                    "compared_rows": max_rows - 1,
                    "compared_cols": max_cols,
                    "timestamp": datetime.now().isoformat()
                }
            }

            return result

        except Exception as e:
            logger.error(f"âŒ å¢å¼ºç‰ˆCSVå¯¹æ¯”å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "total_differences": 0,
                "differences": []
            }

    def save_comparison_result(self, result: Dict, output_path: str):
        """ä¿å­˜å¯¹æ¯”ç»“æœ"""
        try:
            os.makedirs(os.path.dirname(output_path), exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)

            logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")

        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥: {e}")


def test_diagonal_pattern():
    """æµ‹è¯•å¯¹è§’çº¿æ¨¡å¼æ£€æµ‹"""
    comparator = EnhancedCSVComparator()

    # æŸ¥æ‰¾æœ€æ–°çš„CSVæ–‡ä»¶
    csv_dir = Path('/root/projects/tencent-doc-manager/csv_versions/2025_W38')
    baseline_dir = csv_dir / 'baseline'
    midweek_dir = csv_dir / 'midweek'

    # æŸ¥æ‰¾æ–‡ä»¶
    baseline_files = list(baseline_dir.glob('*å‡ºå›½*.csv')) if baseline_dir.exists() else []
    midweek_files = list(midweek_dir.glob('*å‡ºå›½*.csv')) if midweek_dir.exists() else []

    if not baseline_files or not midweek_files:
        logger.error("æ‰¾ä¸åˆ°æµ‹è¯•æ–‡ä»¶")
        return

    # æ‰§è¡Œå¯¹æ¯”
    result = comparator.compare_all_columns(
        str(baseline_files[0]),
        str(midweek_files[0])
    )

    # ä¿å­˜ç»“æœ
    output_path = '/root/projects/tencent-doc-manager/comparison_results/enhanced_comparison_result.json'
    comparator.save_comparison_result(result, output_path)

    return result


if __name__ == "__main__":
    # æ‰§è¡Œæµ‹è¯•
    result = test_diagonal_pattern()

    if result and result['success']:
        print(f"\nğŸ“Š å¢å¼ºç‰ˆå¯¹æ¯”ç»“æœæ€»ç»“:")
        print(f"  æ€»ä¿®æ”¹æ•°: {result['total_differences']}")
        print(f"  å¯¹è§’çº¿æ¨¡å¼: {result['diagonal_pattern']['detected']}")

        if result['diagonal_pattern']['detected']:
            print(f"  å¯¹è§’çº¿ä¿®æ”¹æ•°: {result['diagonal_pattern']['count']}")