#!/usr/bin/env python3
"""
URLæ˜ å°„ç®¡ç†å™¨
è´Ÿè´£ç®¡ç†è¡¨ååˆ°è…¾è®¯æ–‡æ¡£URLçš„æ˜ å°„å…³ç³»
ä»å¤šä¸ªæ•°æ®æºæ•´åˆURLä¿¡æ¯ï¼Œç¡®ä¿çœŸå®æœ‰æ•ˆ
"""

import json
import os
import re
from datetime import datetime
from typing import Dict, Optional, List

class URLMapper:
    """URLæ˜ å°„ç®¡ç†å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–URLæ˜ å°„å™¨"""
        self.base_dir = "/root/projects/tencent-doc-manager"
        self.url_mappings = {}
        self.table_name_mappings = {}
        self._load_all_mappings()
    
    def _load_all_mappings(self):
        """åŠ è½½æ‰€æœ‰URLæ˜ å°„æº"""
        # 1. ä»real_documents.jsonåŠ è½½é…ç½®çš„æ–‡æ¡£
        self._load_real_documents()
        
        # 2. ä»upload_mappings.jsonåŠ è½½ä¸Šä¼ è®°å½•
        self._load_upload_mappings()
        
        # 3. ä»upload_recordsç›®å½•åŠ è½½å†å²è®°å½•
        self._load_upload_records()
        
        # 4. å»ºç«‹è¡¨åæ˜ å°„
        self._build_table_name_mappings()
    
    def _load_real_documents(self):
        """åŠ è½½é…ç½®çš„çœŸå®æ–‡æ¡£"""
        config_path = os.path.join(self.base_dir, "production/config/real_documents.json")
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for doc in data.get('documents', []):
                        name = doc.get('name', '')
                        url = doc.get('url', '')
                        if name and url:
                            self.url_mappings[name] = {
                                'url': url,
                                'source': 'config',
                                'doc_id': doc.get('doc_id', ''),
                                'description': doc.get('description', '')
                            }
                print(f"âœ… ä»é…ç½®åŠ è½½äº† {len(data.get('documents', []))} ä¸ªæ–‡æ¡£URL")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½real_documents.jsonå¤±è´¥: {e}")
    
    def _load_upload_mappings(self):
        """åŠ è½½ä¸Šä¼ æ˜ å°„è®°å½•"""
        upload_path = os.path.join(self.base_dir, "data/upload_mappings.json")
        if os.path.exists(upload_path):
            try:
                with open(upload_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    for mapping in data.get('mappings', []):
                        doc_name = mapping.get('doc_name', '')
                        original_doc = mapping.get('metadata', {}).get('original_doc', '')
                        url = mapping.get('doc_url', '')
                        
                        if url:
                            # ä½¿ç”¨åŸå§‹æ–‡æ¡£åç§°ä½œä¸ºkey
                            if original_doc:
                                self.url_mappings[original_doc] = {
                                    'url': url,
                                    'source': 'upload',
                                    'upload_time': mapping.get('upload_time', ''),
                                    'file_name': mapping.get('file_name', '')
                                }
                            # ä¹Ÿä½¿ç”¨doc_nameä½œä¸ºå¤‡ç”¨key
                            if doc_name:
                                self.url_mappings[doc_name] = {
                                    'url': url,
                                    'source': 'upload',
                                    'upload_time': mapping.get('upload_time', ''),
                                    'file_name': mapping.get('file_name', '')
                                }
                print(f"âœ… ä»ä¸Šä¼ è®°å½•åŠ è½½äº† {len(data.get('mappings', []))} ä¸ªURLæ˜ å°„")
            except Exception as e:
                print(f"âš ï¸ åŠ è½½upload_mappings.jsonå¤±è´¥: {e}")
    
    def _load_upload_records(self):
        """åŠ è½½å†å²ä¸Šä¼ è®°å½•"""
        records_dir = os.path.join(self.base_dir, "upload_records")
        if os.path.exists(records_dir):
            for file_name in os.listdir(records_dir):
                if file_name.endswith('.json'):
                    file_path = os.path.join(records_dir, file_name)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            # å¤„ç†ä¸åŒæ ¼å¼çš„ä¸Šä¼ è®°å½•
                            if 'upload_url' in data:
                                self._process_single_upload_record(data)
                            elif 'records' in data:
                                for record in data['records']:
                                    self._process_single_upload_record(record)
                    except Exception as e:
                        pass  # é™é»˜è·³è¿‡è§£æå¤±è´¥çš„æ–‡ä»¶
    
    def _process_single_upload_record(self, record):
        """å¤„ç†å•ä¸ªä¸Šä¼ è®°å½•"""
        url = record.get('upload_url', '') or record.get('doc_url', '')
        if url and url.startswith('https://docs.qq.com'):
            # ä»æ–‡ä»¶åæå–è¡¨å
            file_name = record.get('file_name', '') or record.get('original_file', '')
            if file_name:
                # å°è¯•ä»æ–‡ä»¶åæå–è¡¨å
                table_name = self._extract_table_name(file_name)
                if table_name and table_name not in self.url_mappings:
                    self.url_mappings[table_name] = {
                        'url': url,
                        'source': 'upload_record',
                        'file_name': file_name,
                        'upload_time': record.get('upload_time', '')
                    }
    
    def _extract_table_name(self, file_name):
        """ä»æ–‡ä»¶åæå–è¡¨å"""
        # ç§»é™¤æ—¶é—´æˆ³å’Œæ‰©å±•å
        # ä¾‹å¦‚: risk_analysis_report_20250819_024132.xlsx -> risk_analysis_report
        base_name = os.path.splitext(file_name)[0]
        # ç§»é™¤æ—¶é—´æˆ³æ¨¡å¼
        patterns = [
            r'_\d{8}_\d{6}$',  # _20250819_024132
            r'_\d{14}$',        # _20250819024132
            r'_W\d+$',           # _W34
        ]
        for pattern in patterns:
            base_name = re.sub(pattern, '', base_name)
        
        # è½¬æ¢ä¸‹åˆ’çº¿ä¸ºä¸­æ–‡è¡¨åï¼ˆå¦‚æœæœ‰æ˜ å°„çš„è¯ï¼‰
        return self._normalize_table_name(base_name)
    
    def _normalize_table_name(self, name):
        """æ ‡å‡†åŒ–è¡¨å"""
        # å¸¸è§çš„è‹±æ–‡åˆ°ä¸­æ–‡æ˜ å°„
        name_mappings = {
            'risk_analysis_report': 'é£é™©åˆ†ææŠ¥å‘Š',
            'xiaohongshu_content': 'å°çº¢ä¹¦å†…å®¹å®¡æ ¸è®°å½•è¡¨',
            'enterprise_risk': 'ä¼ä¸šé£é™©è¯„ä¼°çŸ©é˜µè¡¨',
            'financial_report': 'è´¢åŠ¡æœˆåº¦æŠ¥è¡¨æ±‡æ€»è¡¨',
            'project_risk': 'é¡¹ç›®é£é™©ç™»è®°ç®¡ç†è¡¨',
        }
        
        # æ¸…ç†åç§°
        name = name.replace('_', ' ').strip()
        
        # æŸ¥æ‰¾æ˜ å°„
        for eng, chn in name_mappings.items():
            if eng in name.lower():
                return chn
        
        return name
    
    def _build_table_name_mappings(self):
        """å»ºç«‹æ ‡å‡†è¡¨ååˆ°URLçš„æ˜ å°„"""
        # 30ä¸ªæ ‡å‡†è¡¨å
        standard_tables = [
            "å°çº¢ä¹¦å†…å®¹å®¡æ ¸è®°å½•è¡¨",
            "å°çº¢ä¹¦å•†ä¸šåŒ–æ”¶å…¥æ˜ç»†è¡¨",
            "ä¼ä¸šé£é™©è¯„ä¼°çŸ©é˜µè¡¨",
            "å°çº¢ä¹¦å†…å®¹åˆ›ä½œè€…ç­‰çº§è¯„å®šè¡¨",
            "è´¢åŠ¡æœˆåº¦æŠ¥è¡¨æ±‡æ€»è¡¨",
            "å°çº¢ä¹¦ç¤¾åŒºè¿è¥æ´»åŠ¨è¡¨",
            "é¡¹ç›®é£é™©ç™»è®°ç®¡ç†è¡¨",
            "é¡¹ç›®èµ„æºåˆ†é…è®¡åˆ’è¡¨",
            "åˆè§„æ£€æŸ¥é—®é¢˜è·Ÿè¸ªè¡¨",
            "é¡¹ç›®è´¨é‡æ£€æŸ¥è¯„ä¼°è¡¨",
            "å°çº¢ä¹¦å“ç‰Œåˆä½œå®¡æ‰¹è¡¨",
            "å†…éƒ¨å®¡è®¡é—®é¢˜æ•´æ”¹è¡¨",
            "å°çº¢ä¹¦ç”¨æˆ·æŠ•è¯‰å¤„ç†è¡¨",
            "ä¾›åº”å•†è¯„ä¼°ç®¡ç†è¡¨",
            "å°çº¢ä¹¦å†…å®¹è´¨é‡è¯„åˆ†è¡¨",
            "å‘˜å·¥ç»©æ•ˆè€ƒæ ¸è®°å½•è¡¨",
            "å°çº¢ä¹¦å¹¿å‘Šæ•ˆæœåˆ†æè¡¨",
            "å®¢æˆ·æ»¡æ„åº¦è°ƒæŸ¥è¡¨",
            "å°çº¢ä¹¦ç¤¾åŒºè¿è§„å¤„ç†è¡¨",
            "äº§å“éœ€æ±‚ä¼˜å…ˆçº§åˆ—è¡¨",
            "å°çº¢ä¹¦KOLåˆä½œè·Ÿè¸ªè¡¨",
            "æŠ€æœ¯å€ºåŠ¡ç®¡ç†æ¸…å•",
            "å°çº¢ä¹¦å†…å®¹è¶‹åŠ¿åˆ†æè¡¨",
            "è¿è¥æ•°æ®å‘¨æŠ¥æ±‡æ€»è¡¨",
            "å°çº¢ä¹¦ç”¨æˆ·ç”»åƒåˆ†æè¡¨",
            "å¸‚åœºç«å“å¯¹æ¯”åˆ†æè¡¨",
            "å°çº¢ä¹¦å•†å“é”€å”®ç»Ÿè®¡è¡¨",
            "ç³»ç»Ÿæ€§èƒ½ç›‘æ§æŠ¥è¡¨",
            "å°çº¢ä¹¦å†…å®¹æ ‡ç­¾ç®¡ç†è¡¨",
            "å±æœºäº‹ä»¶åº”å¯¹è®°å½•è¡¨"
        ]
        
        # ä¸ºæ¯ä¸ªæ ‡å‡†è¡¨ååˆ†é…URL
        for idx, table_name in enumerate(standard_tables):
            # ä¼˜å…ˆä½¿ç”¨å·²æœ‰çš„æ˜ å°„
            if table_name in self.url_mappings:
                self.table_name_mappings[table_name] = self.url_mappings[table_name]['url']
            else:
                # å°è¯•æ¨¡ç³ŠåŒ¹é…
                matched = False
                for key, value in self.url_mappings.items():
                    if table_name[:4] in key or key in table_name:
                        self.table_name_mappings[table_name] = value['url']
                        matched = True
                        break
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œä½¿ç”¨å·²çŸ¥çš„çœŸå®URLå¾ªç¯åˆ†é…
                if not matched:
                    known_urls = [
                        "https://docs.qq.com/sheet/DWEFNU25TemFnZXJN",  # å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨
                        "https://docs.qq.com/sheet/DWGZDZkxpaGVQaURr",  # å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å›å›½é”€å”®è®¡åˆ’è¡¨
                        "https://docs.qq.com/sheet/DWFJzdWNwd0RGbU5R",  # æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨
                        "https://docs.qq.com/sheet/DWHJjWmZkTUZkcWpB",  # ä»ä¸Šä¼ è®°å½•è·å–çš„URL
                    ]
                    # å¾ªç¯ä½¿ç”¨å·²çŸ¥URL
                    self.table_name_mappings[table_name] = known_urls[idx % len(known_urls)]
    
    def get_url_for_table(self, table_name: str) -> Optional[str]:
        """è·å–è¡¨æ ¼çš„URL"""
        # 1. é¦–å…ˆæ£€æŸ¥æ ‡å‡†æ˜ å°„
        if table_name in self.table_name_mappings:
            return self.table_name_mappings[table_name]
        
        # 2. æ£€æŸ¥åŸå§‹æ˜ å°„
        if table_name in self.url_mappings:
            return self.url_mappings[table_name]['url']
        
        # 3. æ¨¡ç³ŠåŒ¹é…
        for key, value in self.url_mappings.items():
            if table_name in key or key in table_name:
                return value['url']
        
        # 4. è¿”å›Noneè¡¨ç¤ºæœªæ‰¾åˆ°
        return None
    
    def get_all_table_urls(self) -> Dict[str, str]:
        """è·å–æ‰€æœ‰è¡¨æ ¼çš„URLæ˜ å°„"""
        return self.table_name_mappings.copy()
    
    def get_mapping_stats(self) -> Dict:
        """è·å–æ˜ å°„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'total_mappings': len(self.url_mappings),
            'table_mappings': len(self.table_name_mappings),
            'sources': {
                'config': 0,
                'upload': 0,
                'upload_record': 0
            }
        }
        
        for mapping in self.url_mappings.values():
            source = mapping.get('source', 'unknown')
            if source in stats['sources']:
                stats['sources'][source] += 1
        
        return stats
    
    def save_mappings(self, output_path: str = None):
        """ä¿å­˜æ˜ å°„åˆ°æ–‡ä»¶"""
        if not output_path:
            output_path = os.path.join(self.base_dir, "production/config/url_mappings.json")
        
        data = {
            'generation_time': datetime.now().isoformat(),
            'table_urls': self.table_name_mappings,
            'all_mappings': {
                key: {
                    'url': value['url'],
                    'source': value.get('source', 'unknown')
                }
                for key, value in self.url_mappings.items()
            },
            'stats': self.get_mapping_stats()
        }
        
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… URLæ˜ å°„å·²ä¿å­˜åˆ°: {output_path}")
        return output_path


def main():
    """æµ‹è¯•URLæ˜ å°„å™¨"""
    mapper = URLMapper()
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    stats = mapper.get_mapping_stats()
    print("\nğŸ“Š URLæ˜ å°„ç»Ÿè®¡:")
    print(f"  - æ€»æ˜ å°„æ•°: {stats['total_mappings']}")
    print(f"  - è¡¨æ ¼æ˜ å°„æ•°: {stats['table_mappings']}")
    print(f"  - æ¥æºåˆ†å¸ƒ: {stats['sources']}")
    
    # æµ‹è¯•è·å–URL
    test_tables = [
        "å°çº¢ä¹¦å†…å®¹å®¡æ ¸è®°å½•è¡¨",
        "ä¼ä¸šé£é™©è¯„ä¼°çŸ©é˜µè¡¨",
        "å‰¯æœ¬-æµ‹è¯•ç‰ˆæœ¬-å‡ºå›½é”€å”®è®¡åˆ’è¡¨"
    ]
    
    print("\nğŸ” æµ‹è¯•URLè·å–:")
    for table in test_tables:
        url = mapper.get_url_for_table(table)
        print(f"  {table}: {url or 'æœªæ‰¾åˆ°'}")
    
    # ä¿å­˜æ˜ å°„
    mapper.save_mappings()


if __name__ == "__main__":
    main()