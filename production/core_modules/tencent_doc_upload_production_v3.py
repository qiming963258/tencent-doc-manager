#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è…¾è®¯æ–‡æ¡£ç”Ÿäº§çº§ä¸Šä¼ æ¨¡å— v3
ç»ˆæè§£å†³æ–¹æ¡ˆï¼šå¤šç­–ç•¥ç»„åˆç¡®ä¿è·å–æ­£ç¡®çš„æ–‡æ¡£é“¾æ¥
"""

import asyncio
import json
import logging
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from playwright.async_api import async_playwright, Browser, BrowserContext, Page, Response

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class TencentDocProductionUploaderV3:
    """
    è…¾è®¯æ–‡æ¡£ç”Ÿäº§çº§ä¸Šä¼ å™¨ v3
    å¤šç­–ç•¥ç»„åˆï¼šç½‘ç»œç›‘å¬ + DOMç›‘æ§ + æ—¶é—´æˆ³åŒ¹é…
    """
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.playwright = None
        self.initial_doc_links = set()
        self.upload_response_url = None  # å­˜å‚¨ä¸Šä¼ APIè¿”å›çš„URL
        self.upload_start_time = None
        self.storage_space_info = None  # å­˜å‚¨ç©ºé—´ä¿¡æ¯
        self.api_response_data = None  # å®Œæ•´çš„APIå“åº”æ•°æ®
        
    async def __aenter__(self):
        await self.start()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.cleanup()
        
    async def start(self) -> bool:
        """å¯åŠ¨æµè§ˆå™¨"""
        try:
            self.playwright = await async_playwright().start()
            
            self.browser = await self.playwright.chromium.launch(
                headless=self.headless,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-dev-shm-usage',
                    '--disable-web-security',
                    '--disable-features=IsolateOrigins,site-per-process',
                    '--start-maximized'
                ]
            )
            
            self.context = await self.browser.new_context(
                accept_downloads=True,
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                locale='zh-CN'
            )
            
            self.page = await self.context.new_page()
            self.page.set_default_timeout(30000)
            
            # è®¾ç½®ç½‘ç»œå“åº”ç›‘å¬å™¨
            self.page.on("response", self.handle_response)
            
            logger.info("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            return False
    
    async def handle_response(self, response: Response):
        """ç›‘å¬ç½‘ç»œå“åº”ï¼Œæ•è·ä¸Šä¼ APIçš„è¿”å›"""
        try:
            url = response.url
            status = response.status
            
            # ç›‘å¬å¯èƒ½çš„ä¸Šä¼ APIç«¯ç‚¹
            upload_patterns = [
                '/api/drive/v2/files/upload',
                '/api/docs/import',
                '/api/file/upload',
                '/sheet/create',
                '/doc/create',
                'import',
                'upload'
            ]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¼ ç›¸å…³çš„è¯·æ±‚
            if any(pattern in url for pattern in upload_patterns):
                if status == 200:
                    try:
                        # å°è¯•è·å–å“åº”å†…å®¹
                        body = await response.body()
                        text = body.decode('utf-8', errors='ignore')
                        
                        # è®°å½•å…³é”®å“åº”
                        logger.info(f"ğŸ“¡ æ•è·ä¸Šä¼ å“åº”: {url[:100]}...")
                        
                        # å°è¯•è§£æJSON
                        try:
                            data = json.loads(text)
                            # ä¿å­˜å®Œæ•´çš„APIå“åº”
                            self.api_response_data = data

                            # æ£€æŸ¥æ˜¯å¦æ˜¯å¤±è´¥çš„å“åº”ï¼ˆurlå’Œdoc_idä¸ºç©ºï¼‰
                            if 'url' in data and 'doc_id' in data:
                                if not data['url'] and not data['doc_id']:
                                    logger.error(f"âŒ APIè¿”å›ç©ºçš„URLå’Œdoc_idï¼Œä¸Šä¼ å¯èƒ½å¤±è´¥: {data}")
                                    self.upload_response_url = None
                                    return

                            # æŸ¥æ‰¾å¯èƒ½åŒ…å«æ–‡æ¡£URLçš„å­—æ®µ
                            possible_url_fields = ['url', 'fileUrl', 'docUrl', 'shareUrl', 'doc_url', 'file_url', 'link', 'href']
                            for field in possible_url_fields:
                                if field in data:
                                    potential_url = data[field]
                                    if potential_url and ('docs.qq.com' in str(potential_url) or '/sheet/' in str(potential_url)):
                                        self.upload_response_url = potential_url
                                        logger.info(f"ğŸ¯ ä»APIå“åº”è·å–æ–‡æ¡£URL: {potential_url}")
                                        break

                            # æŸ¥æ‰¾æ–‡æ¡£ID
                            if 'doc_id' in data or 'fileId' in data or 'docId' in data:
                                doc_id = data.get('doc_id') or data.get('fileId') or data.get('docId')
                                if doc_id:
                                    # æ„å»ºæ–‡æ¡£URL
                                    self.upload_response_url = f"https://docs.qq.com/sheet/{doc_id}"
                                    logger.info(f"ğŸ¯ ä»APIå“åº”è·å–æ–‡æ¡£ID: {doc_id}")
                                    
                        except json.JSONDecodeError:
                            # ä¸æ˜¯JSONå“åº”ï¼Œå°è¯•æ­£åˆ™æå–URL
                            url_pattern = r'(https?://docs\.qq\.com/[^\s"\'"]+)'
                            matches = re.findall(url_pattern, text)
                            if matches:
                                self.upload_response_url = matches[0]
                                logger.info(f"ğŸ¯ ä»å“åº”æ–‡æœ¬æå–URL: {self.upload_response_url}")
                                
                    except Exception as e:
                        logger.debug(f"è§£æå“åº”å¤±è´¥: {e}")
                        
        except Exception as e:
            logger.debug(f"å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
    
    def parse_cookie_string(self, cookie_string: str) -> list:
        """è§£æCookieå­—ç¬¦ä¸²"""
        cookies = []
        
        for cookie_pair in cookie_string.split('; '):
            if '=' in cookie_pair:
                name, value = cookie_pair.strip().split('=', 1)
                cookies.append({
                    'name': name.strip(),
                    'value': value.strip(),
                    'domain': '.docs.qq.com',
                    'path': '/'
                })
        
        return cookies
    
    async def login_with_cookies(self, cookie_string: str) -> bool:
        """ä½¿ç”¨Cookieç™»å½•è…¾è®¯æ–‡æ¡£"""
        try:
            logger.info("ğŸ” å¼€å§‹Cookieç™»å½•...")
            
            cookies = self.parse_cookie_string(cookie_string)
            await self.context.add_cookies(cookies)
            logger.info(f"âœ… å·²æ·»åŠ  {len(cookies)} ä¸ªCookies")
            
            await self.page.goto(
                'https://docs.qq.com/desktop/',
                wait_until='domcontentloaded',
                timeout=30000
            )
            
            await self.page.wait_for_timeout(5000)
            
            # è®°å½•åˆå§‹é¡µé¢ä¸Šçš„æ–‡æ¡£é“¾æ¥
            await self.record_initial_doc_links()
            
            is_logged_in = await self.verify_login_status()
            
            if is_logged_in:
                logger.info("âœ… ç™»å½•æˆåŠŸï¼")
                # æ£€æŸ¥å­˜å‚¨ç©ºé—´
                await self.check_storage_space()
                return True
            else:
                logger.warning("âš ï¸ ç™»å½•å¤±è´¥ï¼Œå¯èƒ½Cookieå·²è¿‡æœŸ")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ç™»å½•å¼‚å¸¸: {e}")
            return False
    
    async def record_initial_doc_links(self):
        """è®°å½•é¡µé¢åˆå§‹çš„æ–‡æ¡£é“¾æ¥å’Œæ—¶é—´æˆ³"""
        try:
            # è®°å½•æ‰€æœ‰åˆå§‹æ–‡æ¡£
            self.initial_docs = {}
            
            # è·å–æ‰€æœ‰æ–‡æ¡£å¡ç‰‡æˆ–åˆ—è¡¨é¡¹
            doc_elements = await self.page.query_selector_all('.doc-item, .file-item, [class*="document"], [class*="file-list"] li, .desktop-file-item')
            
            for elem in doc_elements:
                try:
                    # å°è¯•è·å–é“¾æ¥
                    link_elem = await elem.query_selector('a[href*="/sheet/"], a[href*="/doc/"]')
                    if link_elem:
                        href = await link_elem.get_attribute('href')
                        # è·å–æ–‡æ¡£åç§°
                        name_elem = await elem.query_selector('[class*="name"], [class*="title"], .file-name')
                        name = await name_elem.text_content() if name_elem else ""
                        
                        # è·å–æ—¶é—´ä¿¡æ¯
                        time_elem = await elem.query_selector('[class*="time"], [class*="date"], .modified-time')
                        time_text = await time_elem.text_content() if time_elem else ""
                        
                        self.initial_docs[href] = {
                            'name': name.strip(),
                            'time': time_text.strip()
                        }
                except Exception:
                    # å¿½ç•¥å•ä¸ªå…ƒç´ å¤„ç†å¤±è´¥
                    continue
                        
            self.initial_doc_links = set(self.initial_docs.keys())
            logger.info(f"ğŸ“ è®°å½•äº† {len(self.initial_doc_links)} ä¸ªåˆå§‹æ–‡æ¡£")
            
        except Exception as e:
            logger.warning(f"è®°å½•åˆå§‹æ–‡æ¡£å¤±è´¥: {e}")
    
    async def verify_login_status(self) -> bool:
        """éªŒè¯ç™»å½•çŠ¶æ€"""
        try:
            login_btn = await self.page.query_selector('button:has-text("ç™»å½•")')
            has_login_btn = login_btn is not None
            
            import_btn = await self.page.query_selector('button.desktop-import-button-pc')
            has_import_btn = import_btn is not None
            
            user_info = await self.page.query_selector('[class*="avatar"], [class*="user"]')
            has_user_info = user_info is not None
            
            logger.info(f"ğŸ” çŠ¶æ€: ç™»å½•æŒ‰é’®={has_login_btn}, å¯¼å…¥æŒ‰é’®={has_import_btn}, ç”¨æˆ·ä¿¡æ¯={has_user_info}")
            
            return not has_login_btn and (has_import_btn or has_user_info)
            
        except Exception as e:
            logger.error(f"âŒ çŠ¶æ€éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def upload_file(self, file_path: str) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°è…¾è®¯æ–‡æ¡£"""
        result = {
            'success': False,
            'url': None,
            'message': '',
            'doc_name': None,
            'storage_info': None,
            'api_response': None
        }
        
        try:
            file_path = Path(file_path).resolve()
            if not file_path.exists():
                result['message'] = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                return result

            # è®°å½•å­˜å‚¨ç©ºé—´ä¿¡æ¯ä½†ä¸é˜»æ­¢ä¸Šä¼ 
            if self.storage_space_info:
                usage = self.storage_space_info.get('usage_percent', 0)
                if usage >= 95:
                    logger.warning(f"âš ï¸ å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡è¾ƒé«˜: {usage:.2f}% å·²ä½¿ç”¨ï¼Œä½†ç»§ç»­å°è¯•ä¸Šä¼ ")
                    result['storage_warning'] = f"å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡: {usage:.2f}%"
                else:
                    logger.info(f"âœ… å­˜å‚¨ç©ºé—´å……è¶³: {usage:.2f}% å·²ä½¿ç”¨")

            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ : {file_path.name}")

            # è®°å½•ä¸Šä¼ å¼€å§‹æ—¶é—´
            self.upload_start_time = datetime.now()
            
            # æ¸…ç©ºä¹‹å‰çš„ä¸Šä¼ å“åº”
            self.upload_response_url = None
            self.api_response_data = None
            
            # ç‚¹å‡»å¯¼å…¥æŒ‰é’®
            import_btn = await self.click_import_button()
            if not import_btn:
                result['message'] = "æœªæ‰¾åˆ°å¯¼å…¥æŒ‰é’®"
                return result
            
            # å¤„ç†æ–‡ä»¶é€‰æ‹©
            await self.handle_file_selection(str(file_path))
            
            # ç¡®è®¤ä¸Šä¼ 
            await self.confirm_upload_dialog()
            
            # ç­‰å¾…ä¸Šä¼ å®Œæˆå¹¶è·å–URLï¼ˆä½¿ç”¨å¤šç­–ç•¥ï¼‰
            success, url = await self.wait_for_upload_complete_v3(file_path.name)
            
            if success and url:
                # éªŒè¯URLæ˜¯å¦çœŸå®æœ‰æ•ˆ
                if await self.validate_upload_url(url, file_path.name):
                    result['success'] = True
                    result['url'] = url
                    result['message'] = "ä¸Šä¼ æˆåŠŸ"
                    result['doc_name'] = file_path.stem
                    logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {result['url']}")
                else:
                    result['success'] = False
                    result['message'] = "ä¸Šä¼ è¿”å›çš„URLæ— æ•ˆæˆ–æ˜¯å·²å­˜åœ¨çš„æ–‡æ¡£"
                    logger.error(f"âŒ è™šå‡æˆåŠŸ: URL {url} ä¸æ˜¯æ–°ä¸Šä¼ çš„æ–‡æ¡£")
            else:
                result['message'] = "ä¸Šä¼ å¤±è´¥æˆ–æœªèƒ½è·å–æ–‡æ¡£é“¾æ¥"
                logger.warning("âš ï¸ æœªèƒ½ç¡®è®¤ä¸Šä¼ çŠ¶æ€")

            # æ·»åŠ APIå“åº”ä¿¡æ¯
            result['api_response'] = self.api_response_data
            result['storage_info'] = self.storage_space_info
                
        except Exception as e:
            result['message'] = f"ä¸Šä¼ å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ ä¸Šä¼ å¼‚å¸¸: {e}")
            
        return result
    
    async def click_import_button(self) -> bool:
        """ç‚¹å‡»å¯¼å…¥æŒ‰é’®"""
        import_selectors = [
            'button.desktop-import-button-pc',
            'nav button:has(i.desktop-icon-import)',
            'button:has-text("å¯¼å…¥")',
        ]
        
        for selector in import_selectors:
            try:
                btn = await self.page.wait_for_selector(selector, timeout=3000)
                if btn:
                    await btn.click()
                    logger.info(f"âœ… ç‚¹å‡»å¯¼å…¥æŒ‰é’®: {selector}")
                    return True
            except:
                continue
                
        logger.error("âŒ æœªæ‰¾åˆ°å¯¼å…¥æŒ‰é’®")
        return False
    
    async def handle_file_selection(self, file_path: str):
        """å¤„ç†æ–‡ä»¶é€‰æ‹©"""
        await self.page.wait_for_timeout(1000)
        
        file_inputs = await self.page.query_selector_all('input[type="file"]')
        
        if file_inputs:
            await file_inputs[-1].set_input_files(file_path)
            logger.info(f"âœ… é€šè¿‡inputé€‰æ‹©æ–‡ä»¶: {file_path}")
        else:
            logger.info("ä½¿ç”¨filechooseré€‰æ‹©æ–‡ä»¶")
            async with self.page.expect_file_chooser() as fc_info:
                await self.click_import_button()
            
            file_chooser = await fc_info.value
            await file_chooser.set_files(file_path)
            logger.info(f"âœ… é€šè¿‡filechooseré€‰æ‹©æ–‡ä»¶: {file_path}")
    
    async def confirm_upload_dialog(self):
        """ç¡®è®¤ä¸Šä¼ å¯¹è¯æ¡†"""
        try:
            await self.page.wait_for_timeout(2000)
            
            confirm_selectors = [
                'button.dui-button-type-primary:has-text("ç¡®å®š")',
                '.import-kit-import-file-footer button.dui-button-type-primary',
                'button.dui-button-type-primary .dui-button-container:has-text("ç¡®å®š")'
            ]
            
            for selector in confirm_selectors:
                try:
                    btn = await self.page.wait_for_selector(selector, timeout=2000)
                    if btn:
                        await btn.click()
                        logger.info("âœ… ç‚¹å‡»ç¡®å®šæŒ‰é’®")
                        return
                except:
                    continue
            
            await self.page.keyboard.press('Enter')
            logger.info("âœ… ä½¿ç”¨Enteré”®ç¡®è®¤")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç¡®è®¤å¯¹è¯æ¡†å¤„ç†: {e}")
    
    async def wait_for_upload_complete_v3(self, filename: str, timeout: int = 60) -> Tuple[bool, Optional[str]]:
        """
        ç­‰å¾…ä¸Šä¼ å®Œæˆ v3 - å¤šç­–ç•¥ç»„åˆ

        ç­–ç•¥ä¼˜å…ˆçº§ï¼š
        1. APIå“åº”URLï¼ˆæœ€å‡†ç¡®ï¼‰
        2. Toastæ¶ˆæ¯ä¸­çš„URL
        3. URLè·³è½¬
        4. ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
        5. æ—¶é—´æˆ³æœ€æ–°çš„æ–‡æ¡£ï¼ˆä»…åœ¨å•æ–‡æ¡£ä¸Šä¼ æ—¶ä½¿ç”¨ï¼‰
        """
        logger.info(f"â³ ç­‰å¾…ä¸Šä¼ å®Œæˆ: {filename}")

        # è®°å½•å¼€å§‹æ—¶çš„æ–‡æ¡£é“¾æ¥æ•°é‡
        initial_links_count = len(self.initial_doc_links)
        
        for i in range(timeout // 5):
            await self.page.wait_for_timeout(5000)
            
            # ç­–ç•¥1: æ£€æŸ¥æ˜¯å¦å·²ä»APIå“åº”è·å–URL
            if self.upload_response_url:
                logger.info(f"âœ… ä½¿ç”¨APIå“åº”URL: {self.upload_response_url}")
                return True, self.upload_response_url
            
            # ç­–ç•¥2: æ£€æŸ¥Toastæ¶ˆæ¯
            toast_url = await self.check_toast_message()
            if toast_url:
                logger.info(f"âœ… ä»Toastæ¶ˆæ¯è·å–URL: {toast_url}")
                return True, toast_url
            
            # ç­–ç•¥3: æ£€æŸ¥URLè·³è½¬
            current_url = self.page.url
            if '/sheet/' in current_url or '/doc/' in current_url or '/slide/' in current_url:
                logger.info(f"âœ… URLå·²è·³è½¬: {current_url}")
                return True, current_url
            
            # ç­–ç•¥4: æ£€æµ‹å¯¼å…¥å¯¹è¯æ¡†å…³é—­
            import_dialog = await self.page.query_selector('.import-kit-import-file')
            if not import_dialog and i > 2:
                logger.info("âœ… å¯¼å…¥å¯¹è¯æ¡†å·²å…³é—­")
                
                # ç­–ç•¥5: ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
                matched_url = await self.find_document_by_name(filename)
                if matched_url:
                    logger.info(f"âœ… é€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°æ–‡æ¡£: {matched_url}")
                    return True, matched_url
                
                # ç­–ç•¥6: æŸ¥æ‰¾æœ€æ–°åˆ›å»ºçš„æ–‡æ¡£
                newest_url = await self.find_newest_document()
                if newest_url:
                    logger.info(f"âœ… æ‰¾åˆ°æœ€æ–°æ–‡æ¡£ï¼ˆå¯èƒ½æ˜¯ä¸Šä¼ çš„ï¼‰: {newest_url}")
                    return True, newest_url
                
                # ç­–ç•¥7: æŸ¥æ‰¾æ–°å¢çš„é“¾æ¥ï¼ˆæ”¹è¿›ï¼šä¼˜å…ˆåŒ¹é…æ–‡ä»¶åï¼‰
                new_links = await self.find_new_links()
                if new_links:
                    # å°è¯•é€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°æœ€ç›¸å…³çš„é“¾æ¥
                    matched_url = await self.match_url_by_filename(new_links, filename)
                    if matched_url:
                        logger.info(f"âœ… é€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°é“¾æ¥: {matched_url}")
                        return True, matched_url

                    # å¦‚æœåªæœ‰ä¸€ä¸ªæ–°é“¾æ¥ï¼Œè¿”å›å®ƒ
                    if len(new_links) == 1:
                        logger.info(f"âœ… æ‰¾åˆ°å•ä¸ªæ–°å¢é“¾æ¥: {new_links[0]}")
                        return True, new_links[0]

                    # å¤šä¸ªæ–°é“¾æ¥ä½†æ— æ³•åŒ¹é…æ–‡ä»¶åæ—¶ï¼Œè®°å½•è­¦å‘Š
                    logger.warning(f"âš ï¸ æ‰¾åˆ°{len(new_links)}ä¸ªæ–°é“¾æ¥ä½†æ— æ³•ç¡®å®šå“ªä¸ªå±äº{filename}")
                    # è¿”å›æœ€æ–°çš„é“¾æ¥ä½œä¸ºåå¤‡é€‰é¡¹
                    latest_url = new_links[-1]
                    logger.info(f"âœ… è¿”å›æœ€æ–°é“¾æ¥ï¼ˆå¯èƒ½ä¸å‡†ç¡®ï¼‰: {latest_url}")
                    return True, latest_url
            
            # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯
            error_msgs = await self.page.query_selector_all('.dui-message-error, [class*="error"]')
            if error_msgs:
                for msg in error_msgs:
                    text = await msg.text_content()
                    if text and ('å¤±è´¥' in text or 'é”™è¯¯' in text):
                        logger.error(f"âŒ æ£€æµ‹åˆ°é”™è¯¯: {text}")
                        return False, None
            
            if i % 3 == 0:
                logger.info(f"â³ å·²ç­‰å¾… {(i+1)*5} ç§’...")
        
        logger.warning("âš ï¸ ä¸Šä¼ è¶…æ—¶")
        return False, None

    async def check_storage_space(self) -> dict:
        """æ£€æŸ¥å­˜å‚¨ç©ºé—´"""
        try:
            # æŸ¥æ‰¾å­˜å‚¨ç©ºé—´å…ƒç´ 
            storage_elem = await self.page.query_selector('.desktop-storage-panel')
            if storage_elem:
                storage_text = await storage_elem.inner_text()
                logger.info(f"ğŸ“Š å­˜å‚¨ç©ºé—´ä¿¡æ¯: {storage_text}")

                # è·å–ä½¿ç”¨ç‡
                storage_bar = await self.page.query_selector('.desktop-storage-bar')
                if storage_bar:
                    style = await storage_bar.get_attribute('style')
                    if style and '--size:' in style:
                        size = style.split('--size:')[1].split('%')[0].strip()
                        usage = float(size)

                        # æ£€æŸ¥æ˜¯å¦æœ‰criticalç±»
                        classes = await storage_bar.get_attribute('class')
                        is_critical = 'critical' in classes if classes else False

                        self.storage_space_info = {
                            'usage_percent': usage,
                            'is_critical': is_critical,
                            'has_space': True,  # ä¸å†åŸºäº95%åˆ¤æ–­ï¼Œå§‹ç»ˆå…è®¸å°è¯•ä¸Šä¼ 
                            'text': storage_text
                        }

                        if usage >= 95:
                            logger.warning(f"âš ï¸ å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡è¾ƒé«˜: {usage:.2f}% å·²ä½¿ç”¨")
                        elif usage >= 90:
                            logger.info(f"ğŸ“Š å­˜å‚¨ç©ºé—´ä½¿ç”¨ç‡: {usage:.2f}% å·²ä½¿ç”¨")
                        else:
                            logger.info(f"âœ… å­˜å‚¨ç©ºé—´å……è¶³: {usage:.2f}% å·²ä½¿ç”¨")

                        return self.storage_space_info

        except Exception as e:
            logger.error(f"æ£€æŸ¥å­˜å‚¨ç©ºé—´å¤±è´¥: {e}")

        return {'usage_percent': -1, 'is_critical': False, 'has_space': True}

    async def check_toast_message(self) -> Optional[str]:
        """æ£€æŸ¥Toastæ¶ˆæ¯ä¸­çš„URL"""
        try:
            # æŸ¥æ‰¾Toastæ¶ˆæ¯
            toast_selectors = [
                '.dui-toast', '.toast-message', '[class*="toast"]',
                '.dui-message', '[class*="message"]', '.notification'
            ]
            
            for selector in toast_selectors:
                toasts = await self.page.query_selector_all(selector)
                for toast in toasts:
                    text = await toast.text_content()
                    if text and ('æˆåŠŸ' in text or 'å®Œæˆ' in text):
                        # å°è¯•ä»æ–‡æœ¬ä¸­æå–URL
                        url_pattern = r'(https?://docs\.qq\.com/[^\s]+)'
                        matches = re.findall(url_pattern, text)
                        if matches:
                            return matches[0]
            
            return None
        except:
            return None
    
    async def find_document_by_name(self, filename: str) -> Optional[str]:
        """é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾æ–‡æ¡£"""
        try:
            # å»æ‰æ–‡ä»¶æ‰©å±•å
            name_without_ext = filename.rsplit('.', 1)[0]
            
            # å¯èƒ½çš„æ–‡ä»¶åå˜ä½“
            name_variants = [
                filename,
                name_without_ext,
                name_without_ext.replace('_', ' '),
                name_without_ext.replace('-', ' '),
                # å»æ‰å¯èƒ½çš„æ—¶é—´æˆ³
                re.sub(r'_\d{8}_\d{6}', '', name_without_ext),
                re.sub(r'_\d{14}', '', name_without_ext),
            ]
            
            # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£å…ƒç´ 
            doc_elements = await self.page.query_selector_all('a[href*="/sheet/"], a[href*="/doc/"]')
            
            for elem in doc_elements:
                elem_text = await elem.text_content()
                elem_title = await elem.get_attribute('title')
                elem_href = await elem.get_attribute('href')
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°é“¾æ¥
                if elem_href in self.initial_doc_links:
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶ååŒ¹é…
                for variant in name_variants:
                    if variant and (
                        (elem_text and variant in elem_text) or
                        (elem_title and variant in elem_title)
                    ):
                        url = f"https://docs.qq.com{elem_href}" if elem_href.startswith('/') else elem_href
                        return url
            
            return None
        except Exception as e:
            logger.debug(f"æŸ¥æ‰¾æ–‡æ¡£å¤±è´¥: {e}")
            return None
    
    async def find_newest_document(self) -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°çš„æ–‡æ¡£ï¼ˆåŸºäºæ—¶é—´æ ‡è®°ï¼‰"""
        try:
            # æŸ¥æ‰¾å¸¦æœ‰"åˆšåˆš"ã€"ç§’å‰"ã€"1åˆ†é’Ÿå‰"ç­‰æ—¶é—´æ ‡è®°çš„æ–‡æ¡£
            time_indicators = [
                'åˆšåˆš', 'ç§’å‰', '1åˆ†é’Ÿå‰', 'just now', 
                'åˆšæ‰', 'åˆšä¸Šä¼ ', 'æ–°å»º'
            ]
            
            for indicator in time_indicators:
                time_elems = await self.page.query_selector_all(f'*:has-text("{indicator}")')
                for elem in time_elems:
                    # å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„é“¾æ¥
                    parent = elem
                    for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾5å±‚
                        parent = await parent.evaluate_handle('(el) => el.parentElement')
                        if not parent:
                            break
                        
                        link = await parent.query_selector('a[href*="/sheet/"], a[href*="/doc/"]')
                        if link:
                            href = await link.get_attribute('href')
                            if href and href not in self.initial_doc_links:
                                url = f"https://docs.qq.com{href}" if href.startswith('/') else href
                                return url
            
            return None
        except:
            return None
    
    async def find_new_links(self) -> List[str]:
        """æŸ¥æ‰¾æ‰€æœ‰æ–°å¢çš„æ–‡æ¡£é“¾æ¥"""
        try:
            new_links = []
            all_links = await self.page.query_selector_all('a[href*="/sheet/"], a[href*="/doc/"]')
            
            for link in all_links:
                href = await link.get_attribute('href')
                if href and href not in self.initial_doc_links:
                    url = f"https://docs.qq.com{href}" if href.startswith('/') else href
                    new_links.append(url)
            
            return new_links
        except:
            return []
    
    async def match_url_by_filename(self, urls: List[str], filename: str) -> Optional[str]:
        """é€šè¿‡æ–‡ä»¶ååŒ¹é…URL - ä¼˜åŒ–ç‰ˆæœ¬ä½¿ç”¨doc_idç²¾ç¡®åŒ¹é…"""
        try:
            # æå–doc_idä»æ–‡ä»¶åï¼ˆæ ¼å¼: tencent_æ–‡æ¡£å_doc_id_æ—¶é—´æˆ³_ç‰ˆæœ¬_å‘¨æ•°.æ‰©å±•åï¼‰
            # ç¤ºä¾‹: tencent_å°çº¢ä¹¦éƒ¨é—¨_DWEVjZndkR2xVSWJN_20250925_0105_midweek_W39.csv
            doc_id_pattern = r'tencent_[^_]+_([A-Za-z0-9]+)_\d{8}_\d{4}_[^_]+_W\d+\.'
            match = re.search(doc_id_pattern, filename)

            if match:
                doc_id = match.group(1)
                print(f"ğŸ“‹ ä»æ–‡ä»¶åæå–åˆ°doc_id: {doc_id}")

                # ç›´æ¥åœ¨URLä¸­æŸ¥æ‰¾åŒ…å«è¯¥doc_idçš„URL
                for url in urls:
                    if doc_id in url:
                        print(f"âœ… æ‰¾åˆ°åŒ¹é…çš„URL: {url}")
                        return url

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°doc_idï¼Œåˆ™ä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆï¼šå…³é”®è¯åŒ¹é…
            print("âš ï¸ æ–‡ä»¶åä¸­æœªæ‰¾åˆ°doc_idï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…")

            # å»æ‰æ–‡ä»¶æ‰©å±•åå’Œå¯èƒ½çš„æ—¶é—´æˆ³
            base_name = filename.rsplit('.', 1)[0]
            base_name = re.sub(r'_\d{8}_\d{4}', '', base_name)
            base_name = re.sub(r'_marked.*', '', base_name)

            # æå–å…³é”®è¯
            keywords = []
            if 'å‡ºå›½' in base_name or 'DWEFNU25TemFnZXJN' in filename:
                keywords.append('å‡ºå›½')
            if 'å°çº¢ä¹¦' in base_name or 'DWEVjZndkR2xVSWJN' in filename:
                keywords.append('å°çº¢ä¹¦')
            if 'å›å›½' in base_name or 'DWGZDZkxpaGVQaURr' in filename:
                keywords.append('å›å›½')

            # åŸºäºURLçš„doc_idå¿«é€ŸåŒ¹é…ï¼ˆä¸éœ€è¦è®¿é—®é¡µé¢ï¼‰
            url_doc_id_map = {
                'DWEFNU25TemFnZXJN': 'å‡ºå›½',
                'DWEVjZndkR2xVSWJN': 'å°çº¢ä¹¦',
                'DWGZDZkxpaGVQaURr': 'å›å›½'
            }

            for url in urls:
                # æ£€æŸ¥URLæ˜¯å¦åŒ…å«å·²çŸ¥çš„doc_id
                for doc_id, keyword in url_doc_id_map.items():
                    if doc_id in url and keyword in keywords:
                        print(f"âœ… é€šè¿‡å…³é”®è¯åŒ¹é…æ‰¾åˆ°URL: {url}")
                        return url

            return None
        except Exception as e:
            logger.debug(f"æ–‡ä»¶ååŒ¹é…å¤±è´¥: {e}")
            return None

    async def validate_upload_url(self, url: str, filename: str) -> bool:
        """éªŒè¯ä¸Šä¼ çš„URLæ˜¯å¦çœŸå®æœ‰æ•ˆ"""
        try:
            # å¦‚æœURLåœ¨åˆå§‹æ–‡æ¡£åˆ—è¡¨ä¸­ï¼Œè¯´æ˜æ˜¯å·²å­˜åœ¨çš„æ–‡æ¡£
            if url in self.initial_doc_links:
                logger.error(f"âŒ URL {url} æ˜¯å·²å­˜åœ¨çš„æ–‡æ¡£ï¼Œä¸æ˜¯æ–°ä¸Šä¼ çš„")
                return False

            # å¦‚æœæœ‰APIå“åº”æ•°æ®ï¼Œæ£€æŸ¥urlå’Œdoc_id
            if self.api_response_data:
                if 'url' in self.api_response_data and not self.api_response_data['url']:
                    logger.error("âŒ APIå“åº”çš„URLä¸ºç©º")
                    return False
                if 'doc_id' in self.api_response_data and not self.api_response_data['doc_id']:
                    logger.error("âŒ APIå“åº”çš„doc_idä¸ºç©º")
                    return False

            # å¦‚æœä¸Šä¼ æ—¶é—´å¤ªä¹…ï¼Œå¯èƒ½æ˜¯çŒœæµ‹çš„ç»“æœ
            if self.upload_start_time:
                elapsed = (datetime.now() - self.upload_start_time).total_seconds()
                if elapsed > 60:
                    logger.warning(f"âš ï¸ ä¸Šä¼ è€—æ—¶è¿‡é•¿ ({elapsed:.1f}ç§’)ï¼Œç»“æœå¯èƒ½ä¸å¯é ")

            return True

        except Exception as e:
            logger.error(f"éªŒè¯URLå¤±è´¥: {e}")
            return False

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        logger.info("ğŸ”š èµ„æºå·²æ¸…ç†")


# ============= ä¾¿æ·å‡½æ•° =============

async def quick_upload_v3(cookie_string: str, file_path: str, headless: bool = True) -> Dict[str, Any]:
    """å¿«é€Ÿä¸Šä¼ æ–‡ä»¶ v3"""
    async with TencentDocProductionUploaderV3(headless=headless) as uploader:
        login_success = await uploader.login_with_cookies(cookie_string)
        if not login_success:
            return {
                'success': False,
                'message': 'ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥Cookie'
            }
        
        result = await uploader.upload_file(file_path)
        return result


def sync_upload_v3(cookie_string: str, file_path: str, headless: bool = True) -> Dict[str, Any]:
    """åŒæ­¥ç‰ˆæœ¬çš„ä¸Šä¼ å‡½æ•° v3"""
    return asyncio.run(quick_upload_v3(cookie_string, file_path, headless))


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python tencent_doc_upload_production_v3.py <æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    config_path = Path('/root/projects/tencent-doc-manager/config.json')
    if config_path.exists():
        with open(config_path, 'r') as f:
            config = json.load(f)
            cookie = config.get('cookie', '')
    else:
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        sys.exit(1)
    
    file_to_upload = sys.argv[1]
    result = sync_upload_v3(cookie, file_to_upload, headless=True)
    
    print(json.dumps(result, ensure_ascii=False, indent=2))