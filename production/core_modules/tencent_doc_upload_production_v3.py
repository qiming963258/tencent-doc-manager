#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è…¾è®¯æ–‡æ¡£ç”Ÿäº§çº§ä¸Šä¼ æ¨¡å— v3
ç»ˆæè§£å†³æ–¹æ¡ˆï¼šå¤šç­–ç•¥ç»„åˆç¡®ä¿è·å–æ­£ç¡®çš„æ–‡æ¡£é“¾æ¥
"""

import asyncio
import json
import logging
import re
from pathlib import Path
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime
from playwright.async_api import async_playwright, Browser, BrowserContext, Page, Response

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class TencentDocProductionUploaderV3:
    """
    è…¾è®¯æ–‡æ¡£ç”Ÿäº§çº§ä¸Šä¼ å™¨ v3
    å¤šç­–ç•¥ç»„åˆï¼šç½‘ç»œç›‘å¬ + DOMç›‘æ§ + æ—¶é—´æˆ³åŒ¹é…
    """
    
    def __init__(self, headless: bool = True):
        self.headless = headless
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.playwright = None
        self.initial_doc_links = set()
        self.upload_response_url = None  # å­˜å‚¨ä¸Šä¼ APIè¿”å›çš„URL
        self.upload_start_time = None
        
    async def __aenter__(self):
        await self.start()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.cleanup()
        
    async def start(self) -> bool:
        """å¯åŠ¨æµè§ˆå™¨"""
        try:
            self.playwright = await async_playwright().start()
            
            self.browser = await self.playwright.chromium.launch(
                headless=self.headless,
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-blink-features=AutomationControlled',
                    '--disable-dev-shm-usage',
                    '--disable-web-security',
                    '--disable-features=IsolateOrigins,site-per-process',
                    '--start-maximized'
                ]
            )
            
            self.context = await self.browser.new_context(
                accept_downloads=True,
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                locale='zh-CN'
            )
            
            self.page = await self.context.new_page()
            self.page.set_default_timeout(30000)
            
            # è®¾ç½®ç½‘ç»œå“åº”ç›‘å¬å™¨
            self.page.on("response", self.handle_response)
            
            logger.info("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
            return False
    
    async def handle_response(self, response: Response):
        """ç›‘å¬ç½‘ç»œå“åº”ï¼Œæ•è·ä¸Šä¼ APIçš„è¿”å›"""
        try:
            url = response.url
            status = response.status
            
            # ç›‘å¬å¯èƒ½çš„ä¸Šä¼ APIç«¯ç‚¹
            upload_patterns = [
                '/api/drive/v2/files/upload',
                '/api/docs/import',
                '/api/file/upload',
                '/sheet/create',
                '/doc/create',
                'import',
                'upload'
            ]
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸Šä¼ ç›¸å…³çš„è¯·æ±‚
            if any(pattern in url for pattern in upload_patterns):
                if status == 200:
                    try:
                        # å°è¯•è·å–å“åº”å†…å®¹
                        body = await response.body()
                        text = body.decode('utf-8', errors='ignore')
                        
                        # è®°å½•å…³é”®å“åº”
                        logger.info(f"ğŸ“¡ æ•è·ä¸Šä¼ å“åº”: {url[:100]}...")
                        
                        # å°è¯•è§£æJSON
                        try:
                            data = json.loads(text)
                            # æŸ¥æ‰¾å¯èƒ½åŒ…å«æ–‡æ¡£URLçš„å­—æ®µ
                            possible_url_fields = ['url', 'fileUrl', 'docUrl', 'shareUrl', 'doc_url', 'file_url', 'link', 'href']
                            for field in possible_url_fields:
                                if field in data:
                                    potential_url = data[field]
                                    if potential_url and ('docs.qq.com' in str(potential_url) or '/sheet/' in str(potential_url)):
                                        self.upload_response_url = potential_url
                                        logger.info(f"ğŸ¯ ä»APIå“åº”è·å–æ–‡æ¡£URL: {potential_url}")
                                        break
                            
                            # æŸ¥æ‰¾æ–‡æ¡£ID
                            if 'doc_id' in data or 'fileId' in data or 'docId' in data:
                                doc_id = data.get('doc_id') or data.get('fileId') or data.get('docId')
                                if doc_id:
                                    # æ„å»ºæ–‡æ¡£URL
                                    self.upload_response_url = f"https://docs.qq.com/sheet/{doc_id}"
                                    logger.info(f"ğŸ¯ ä»APIå“åº”è·å–æ–‡æ¡£ID: {doc_id}")
                                    
                        except json.JSONDecodeError:
                            # ä¸æ˜¯JSONå“åº”ï¼Œå°è¯•æ­£åˆ™æå–URL
                            url_pattern = r'(https?://docs\.qq\.com/[^\s"\'"]+)'
                            matches = re.findall(url_pattern, text)
                            if matches:
                                self.upload_response_url = matches[0]
                                logger.info(f"ğŸ¯ ä»å“åº”æ–‡æœ¬æå–URL: {self.upload_response_url}")
                                
                    except Exception as e:
                        logger.debug(f"è§£æå“åº”å¤±è´¥: {e}")
                        
        except Exception as e:
            logger.debug(f"å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
    
    def parse_cookie_string(self, cookie_string: str) -> list:
        """è§£æCookieå­—ç¬¦ä¸²"""
        cookies = []
        
        for cookie_pair in cookie_string.split('; '):
            if '=' in cookie_pair:
                name, value = cookie_pair.strip().split('=', 1)
                cookies.append({
                    'name': name.strip(),
                    'value': value.strip(),
                    'domain': '.docs.qq.com',
                    'path': '/'
                })
        
        return cookies
    
    async def login_with_cookies(self, cookie_string: str) -> bool:
        """ä½¿ç”¨Cookieç™»å½•è…¾è®¯æ–‡æ¡£"""
        try:
            logger.info("ğŸ” å¼€å§‹Cookieç™»å½•...")
            
            cookies = self.parse_cookie_string(cookie_string)
            await self.context.add_cookies(cookies)
            logger.info(f"âœ… å·²æ·»åŠ  {len(cookies)} ä¸ªCookies")
            
            await self.page.goto(
                'https://docs.qq.com/desktop/',
                wait_until='domcontentloaded',
                timeout=30000
            )
            
            await self.page.wait_for_timeout(5000)
            
            # è®°å½•åˆå§‹é¡µé¢ä¸Šçš„æ–‡æ¡£é“¾æ¥
            await self.record_initial_doc_links()
            
            is_logged_in = await self.verify_login_status()
            
            if is_logged_in:
                logger.info("âœ… ç™»å½•æˆåŠŸï¼")
                return True
            else:
                logger.warning("âš ï¸ ç™»å½•å¤±è´¥ï¼Œå¯èƒ½Cookieå·²è¿‡æœŸ")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ç™»å½•å¼‚å¸¸: {e}")
            return False
    
    async def record_initial_doc_links(self):
        """è®°å½•é¡µé¢åˆå§‹çš„æ–‡æ¡£é“¾æ¥å’Œæ—¶é—´æˆ³"""
        try:
            # è®°å½•æ‰€æœ‰åˆå§‹æ–‡æ¡£
            self.initial_docs = {}
            
            # è·å–æ‰€æœ‰æ–‡æ¡£å¡ç‰‡æˆ–åˆ—è¡¨é¡¹
            doc_elements = await self.page.query_selector_all('.doc-item, .file-item, [class*="document"], [class*="file-list"] li, .desktop-file-item')
            
            for elem in doc_elements:
                try:
                    # å°è¯•è·å–é“¾æ¥
                    link_elem = await elem.query_selector('a[href*="/sheet/"], a[href*="/doc/"]')
                    if link_elem:
                        href = await link_elem.get_attribute('href')
                        # è·å–æ–‡æ¡£åç§°
                        name_elem = await elem.query_selector('[class*="name"], [class*="title"], .file-name')
                        name = await name_elem.text_content() if name_elem else ""
                        
                        # è·å–æ—¶é—´ä¿¡æ¯
                        time_elem = await elem.query_selector('[class*="time"], [class*="date"], .modified-time')
                        time_text = await time_elem.text_content() if time_elem else ""
                        
                        self.initial_docs[href] = {
                            'name': name.strip(),
                            'time': time_text.strip()
                        }
                except Exception:
                    # å¿½ç•¥å•ä¸ªå…ƒç´ å¤„ç†å¤±è´¥
                    continue
                        
            self.initial_doc_links = set(self.initial_docs.keys())
            logger.info(f"ğŸ“ è®°å½•äº† {len(self.initial_doc_links)} ä¸ªåˆå§‹æ–‡æ¡£")
            
        except Exception as e:
            logger.warning(f"è®°å½•åˆå§‹æ–‡æ¡£å¤±è´¥: {e}")
    
    async def verify_login_status(self) -> bool:
        """éªŒè¯ç™»å½•çŠ¶æ€"""
        try:
            login_btn = await self.page.query_selector('button:has-text("ç™»å½•")')
            has_login_btn = login_btn is not None
            
            import_btn = await self.page.query_selector('button.desktop-import-button-pc')
            has_import_btn = import_btn is not None
            
            user_info = await self.page.query_selector('[class*="avatar"], [class*="user"]')
            has_user_info = user_info is not None
            
            logger.info(f"ğŸ” çŠ¶æ€: ç™»å½•æŒ‰é’®={has_login_btn}, å¯¼å…¥æŒ‰é’®={has_import_btn}, ç”¨æˆ·ä¿¡æ¯={has_user_info}")
            
            return not has_login_btn and (has_import_btn or has_user_info)
            
        except Exception as e:
            logger.error(f"âŒ çŠ¶æ€éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def upload_file(self, file_path: str) -> Dict[str, Any]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°è…¾è®¯æ–‡æ¡£"""
        result = {
            'success': False,
            'url': None,
            'message': '',
            'doc_name': None
        }
        
        try:
            file_path = Path(file_path).resolve()
            if not file_path.exists():
                result['message'] = f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                return result
            
            logger.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ : {file_path.name}")
            
            # è®°å½•ä¸Šä¼ å¼€å§‹æ—¶é—´
            self.upload_start_time = datetime.now()
            
            # æ¸…ç©ºä¹‹å‰çš„ä¸Šä¼ å“åº”URL
            self.upload_response_url = None
            
            # ç‚¹å‡»å¯¼å…¥æŒ‰é’®
            import_btn = await self.click_import_button()
            if not import_btn:
                result['message'] = "æœªæ‰¾åˆ°å¯¼å…¥æŒ‰é’®"
                return result
            
            # å¤„ç†æ–‡ä»¶é€‰æ‹©
            await self.handle_file_selection(str(file_path))
            
            # ç¡®è®¤ä¸Šä¼ 
            await self.confirm_upload_dialog()
            
            # ç­‰å¾…ä¸Šä¼ å®Œæˆå¹¶è·å–URLï¼ˆä½¿ç”¨å¤šç­–ç•¥ï¼‰
            success, url = await self.wait_for_upload_complete_v3(file_path.name)
            
            if success:
                result['success'] = True
                result['url'] = url if url else "https://docs.qq.com/desktop/"
                result['message'] = "ä¸Šä¼ æˆåŠŸ"
                result['doc_name'] = file_path.stem
                logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {result['url']}")
            else:
                result['message'] = "ä¸Šä¼ å¤±è´¥æˆ–æœªèƒ½è·å–æ–‡æ¡£é“¾æ¥"
                logger.warning("âš ï¸ æœªèƒ½ç¡®è®¤ä¸Šä¼ çŠ¶æ€")
                
        except Exception as e:
            result['message'] = f"ä¸Šä¼ å¼‚å¸¸: {str(e)}"
            logger.error(f"âŒ ä¸Šä¼ å¼‚å¸¸: {e}")
            
        return result
    
    async def click_import_button(self) -> bool:
        """ç‚¹å‡»å¯¼å…¥æŒ‰é’®"""
        import_selectors = [
            'button.desktop-import-button-pc',
            'nav button:has(i.desktop-icon-import)',
            'button:has-text("å¯¼å…¥")',
        ]
        
        for selector in import_selectors:
            try:
                btn = await self.page.wait_for_selector(selector, timeout=3000)
                if btn:
                    await btn.click()
                    logger.info(f"âœ… ç‚¹å‡»å¯¼å…¥æŒ‰é’®: {selector}")
                    return True
            except:
                continue
                
        logger.error("âŒ æœªæ‰¾åˆ°å¯¼å…¥æŒ‰é’®")
        return False
    
    async def handle_file_selection(self, file_path: str):
        """å¤„ç†æ–‡ä»¶é€‰æ‹©"""
        await self.page.wait_for_timeout(1000)
        
        file_inputs = await self.page.query_selector_all('input[type="file"]')
        
        if file_inputs:
            await file_inputs[-1].set_input_files(file_path)
            logger.info(f"âœ… é€šè¿‡inputé€‰æ‹©æ–‡ä»¶: {file_path}")
        else:
            logger.info("ä½¿ç”¨filechooseré€‰æ‹©æ–‡ä»¶")
            async with self.page.expect_file_chooser() as fc_info:
                await self.click_import_button()
            
            file_chooser = await fc_info.value
            await file_chooser.set_files(file_path)
            logger.info(f"âœ… é€šè¿‡filechooseré€‰æ‹©æ–‡ä»¶: {file_path}")
    
    async def confirm_upload_dialog(self):
        """ç¡®è®¤ä¸Šä¼ å¯¹è¯æ¡†"""
        try:
            await self.page.wait_for_timeout(2000)
            
            confirm_selectors = [
                'button.dui-button-type-primary:has-text("ç¡®å®š")',
                '.import-kit-import-file-footer button.dui-button-type-primary',
                'button.dui-button-type-primary .dui-button-container:has-text("ç¡®å®š")'
            ]
            
            for selector in confirm_selectors:
                try:
                    btn = await self.page.wait_for_selector(selector, timeout=2000)
                    if btn:
                        await btn.click()
                        logger.info("âœ… ç‚¹å‡»ç¡®å®šæŒ‰é’®")
                        return
                except:
                    continue
            
            await self.page.keyboard.press('Enter')
            logger.info("âœ… ä½¿ç”¨Enteré”®ç¡®è®¤")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ç¡®è®¤å¯¹è¯æ¡†å¤„ç†: {e}")
    
    async def wait_for_upload_complete_v3(self, filename: str, timeout: int = 60) -> Tuple[bool, Optional[str]]:
        """
        ç­‰å¾…ä¸Šä¼ å®Œæˆ v3 - å¤šç­–ç•¥ç»„åˆ
        
        ç­–ç•¥ä¼˜å…ˆçº§ï¼š
        1. APIå“åº”URLï¼ˆæœ€å‡†ç¡®ï¼‰
        2. Toastæ¶ˆæ¯ä¸­çš„URL
        3. æ–°å¢æ–‡æ¡£åŒ¹é…æ–‡ä»¶å
        4. æ—¶é—´æˆ³æœ€æ–°çš„æ–‡æ¡£
        """
        logger.info("â³ ç­‰å¾…ä¸Šä¼ å®Œæˆ...")
        
        for i in range(timeout // 5):
            await self.page.wait_for_timeout(5000)
            
            # ç­–ç•¥1: æ£€æŸ¥æ˜¯å¦å·²ä»APIå“åº”è·å–URL
            if self.upload_response_url:
                logger.info(f"âœ… ä½¿ç”¨APIå“åº”URL: {self.upload_response_url}")
                return True, self.upload_response_url
            
            # ç­–ç•¥2: æ£€æŸ¥Toastæ¶ˆæ¯
            toast_url = await self.check_toast_message()
            if toast_url:
                logger.info(f"âœ… ä»Toastæ¶ˆæ¯è·å–URL: {toast_url}")
                return True, toast_url
            
            # ç­–ç•¥3: æ£€æŸ¥URLè·³è½¬
            current_url = self.page.url
            if '/sheet/' in current_url or '/doc/' in current_url or '/slide/' in current_url:
                logger.info(f"âœ… URLå·²è·³è½¬: {current_url}")
                return True, current_url
            
            # ç­–ç•¥4: æ£€æµ‹å¯¼å…¥å¯¹è¯æ¡†å…³é—­
            import_dialog = await self.page.query_selector('.import-kit-import-file')
            if not import_dialog and i > 2:
                logger.info("âœ… å¯¼å…¥å¯¹è¯æ¡†å·²å…³é—­")
                
                # ç­–ç•¥5: ç²¾ç¡®æ–‡ä»¶ååŒ¹é…
                matched_url = await self.find_document_by_name(filename)
                if matched_url:
                    logger.info(f"âœ… é€šè¿‡æ–‡ä»¶ååŒ¹é…æ‰¾åˆ°æ–‡æ¡£: {matched_url}")
                    return True, matched_url
                
                # ç­–ç•¥6: æŸ¥æ‰¾æœ€æ–°åˆ›å»ºçš„æ–‡æ¡£
                newest_url = await self.find_newest_document()
                if newest_url:
                    logger.info(f"âœ… æ‰¾åˆ°æœ€æ–°æ–‡æ¡£ï¼ˆå¯èƒ½æ˜¯ä¸Šä¼ çš„ï¼‰: {newest_url}")
                    return True, newest_url
                
                # ç­–ç•¥7: æŸ¥æ‰¾æ–°å¢çš„é“¾æ¥
                new_links = await self.find_new_links()
                if new_links:
                    # è¿”å›æœ€åä¸€ä¸ªæ–°é“¾æ¥
                    latest_url = new_links[-1]
                    logger.info(f"âœ… æ‰¾åˆ°æ–°å¢é“¾æ¥: {latest_url}")
                    return True, latest_url
            
            # æ£€æŸ¥é”™è¯¯æ¶ˆæ¯
            error_msgs = await self.page.query_selector_all('.dui-message-error, [class*="error"]')
            if error_msgs:
                for msg in error_msgs:
                    text = await msg.text_content()
                    if text and ('å¤±è´¥' in text or 'é”™è¯¯' in text):
                        logger.error(f"âŒ æ£€æµ‹åˆ°é”™è¯¯: {text}")
                        return False, None
            
            if i % 3 == 0:
                logger.info(f"â³ å·²ç­‰å¾… {(i+1)*5} ç§’...")
        
        logger.warning("âš ï¸ ä¸Šä¼ è¶…æ—¶")
        return False, None
    
    async def check_toast_message(self) -> Optional[str]:
        """æ£€æŸ¥Toastæ¶ˆæ¯ä¸­çš„URL"""
        try:
            # æŸ¥æ‰¾Toastæ¶ˆæ¯
            toast_selectors = [
                '.dui-toast', '.toast-message', '[class*="toast"]',
                '.dui-message', '[class*="message"]', '.notification'
            ]
            
            for selector in toast_selectors:
                toasts = await self.page.query_selector_all(selector)
                for toast in toasts:
                    text = await toast.text_content()
                    if text and ('æˆåŠŸ' in text or 'å®Œæˆ' in text):
                        # å°è¯•ä»æ–‡æœ¬ä¸­æå–URL
                        url_pattern = r'(https?://docs\.qq\.com/[^\s]+)'
                        matches = re.findall(url_pattern, text)
                        if matches:
                            return matches[0]
            
            return None
        except:
            return None
    
    async def find_document_by_name(self, filename: str) -> Optional[str]:
        """é€šè¿‡æ–‡ä»¶åæŸ¥æ‰¾æ–‡æ¡£"""
        try:
            # å»æ‰æ–‡ä»¶æ‰©å±•å
            name_without_ext = filename.rsplit('.', 1)[0]
            
            # å¯èƒ½çš„æ–‡ä»¶åå˜ä½“
            name_variants = [
                filename,
                name_without_ext,
                name_without_ext.replace('_', ' '),
                name_without_ext.replace('-', ' '),
                # å»æ‰å¯èƒ½çš„æ—¶é—´æˆ³
                re.sub(r'_\d{8}_\d{6}', '', name_without_ext),
                re.sub(r'_\d{14}', '', name_without_ext),
            ]
            
            # æŸ¥æ‰¾æ‰€æœ‰æ–‡æ¡£å…ƒç´ 
            doc_elements = await self.page.query_selector_all('a[href*="/sheet/"], a[href*="/doc/"]')
            
            for elem in doc_elements:
                elem_text = await elem.text_content()
                elem_title = await elem.get_attribute('title')
                elem_href = await elem.get_attribute('href')
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°é“¾æ¥
                if elem_href in self.initial_doc_links:
                    continue
                
                # æ£€æŸ¥æ–‡ä»¶ååŒ¹é…
                for variant in name_variants:
                    if variant and (
                        (elem_text and variant in elem_text) or
                        (elem_title and variant in elem_title)
                    ):
                        url = f"https://docs.qq.com{elem_href}" if elem_href.startswith('/') else elem_href
                        return url
            
            return None
        except Exception as e:
            logger.debug(f"æŸ¥æ‰¾æ–‡æ¡£å¤±è´¥: {e}")
            return None
    
    async def find_newest_document(self) -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°çš„æ–‡æ¡£ï¼ˆåŸºäºæ—¶é—´æ ‡è®°ï¼‰"""
        try:
            # æŸ¥æ‰¾å¸¦æœ‰"åˆšåˆš"ã€"ç§’å‰"ã€"1åˆ†é’Ÿå‰"ç­‰æ—¶é—´æ ‡è®°çš„æ–‡æ¡£
            time_indicators = [
                'åˆšåˆš', 'ç§’å‰', '1åˆ†é’Ÿå‰', 'just now', 
                'åˆšæ‰', 'åˆšä¸Šä¼ ', 'æ–°å»º'
            ]
            
            for indicator in time_indicators:
                time_elems = await self.page.query_selector_all(f'*:has-text("{indicator}")')
                for elem in time_elems:
                    # å‘ä¸ŠæŸ¥æ‰¾æœ€è¿‘çš„é“¾æ¥
                    parent = elem
                    for _ in range(5):  # æœ€å¤šå‘ä¸ŠæŸ¥æ‰¾5å±‚
                        parent = await parent.evaluate_handle('(el) => el.parentElement')
                        if not parent:
                            break
                        
                        link = await parent.query_selector('a[href*="/sheet/"], a[href*="/doc/"]')
                        if link:
                            href = await link.get_attribute('href')
                            if href and href not in self.initial_doc_links:
                                url = f"https://docs.qq.com{href}" if href.startswith('/') else href
                                return url
            
            return None
        except:
            return None
    
    async def find_new_links(self) -> List[str]:
        """æŸ¥æ‰¾æ‰€æœ‰æ–°å¢çš„æ–‡æ¡£é“¾æ¥"""
        try:
            new_links = []
            all_links = await self.page.query_selector_all('a[href*="/sheet/"], a[href*="/doc/"]')
            
            for link in all_links:
                href = await link.get_attribute('href')
                if href and href not in self.initial_doc_links:
                    url = f"https://docs.qq.com{href}" if href.startswith('/') else href
                    new_links.append(url)
            
            return new_links
        except:
            return []
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.browser:
            await self.browser.close()
        if self.playwright:
            await self.playwright.stop()
        logger.info("ğŸ”š èµ„æºå·²æ¸…ç†")


# ============= ä¾¿æ·å‡½æ•° =============

async def quick_upload_v3(cookie_string: str, file_path: str, headless: bool = True) -> Dict[str, Any]:
    """å¿«é€Ÿä¸Šä¼ æ–‡ä»¶ v3"""
    async with TencentDocProductionUploaderV3(headless=headless) as uploader:
        login_success = await uploader.login_with_cookies(cookie_string)
        if not login_success:
            return {
                'success': False,
                'message': 'ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥Cookie'
            }
        
        result = await uploader.upload_file(file_path)
        return result


def sync_upload_v3(cookie_string: str, file_path: str, headless: bool = True) -> Dict[str, Any]:
    """åŒæ­¥ç‰ˆæœ¬çš„ä¸Šä¼ å‡½æ•° v3"""
    return asyncio.run(quick_upload_v3(cookie_string, file_path, headless))


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python tencent_doc_upload_production_v3.py <æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    config_path = Path('/root/projects/tencent-doc-manager/config.json')
    if config_path.exists():
        with open(config_path, 'r') as f:
            config = json.load(f)
            cookie = config.get('cookie', '')
    else:
        print("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨")
        sys.exit(1)
    
    file_to_upload = sys.argv[1]
    result = sync_upload_v3(cookie, file_to_upload, headless=True)
    
    print(json.dumps(result, ensure_ascii=False, indent=2))