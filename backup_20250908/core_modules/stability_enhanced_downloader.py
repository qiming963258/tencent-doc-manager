#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”Ÿäº§çº§ä¸‹è½½ç¨³å®šæ€§å¢å¼ºå™¨ - Stage 2 å®Œæ•´ç‰ˆ
æ•´åˆCookieç®¡ç†å™¨ + ç°æœ‰ä¸‹è½½ç³»ç»Ÿ + ç¨³å®šæ€§ä¼˜åŒ–
"""

import sys
import os
sys.path.append('/root/projects/tencent-doc-manager/production/core_modules')
sys.path.append('/root/projects/tencent-doc-manager/æµ‹è¯•ç‰ˆæœ¬-æ€§èƒ½ä¼˜åŒ–å¼€å‘-20250811-001430')

import asyncio
import logging
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional, List
from cookie_manager import get_cookie_manager
from production_downloader import ProductionTencentDownloader

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StabilityEnhancedDownloader:
    """
    ç¨³å®šæ€§å¢å¼ºçš„ä¸‹è½½ç³»ç»Ÿ
    ç»“åˆCookieç®¡ç†å™¨ + ç”Ÿäº§çº§ä¸‹è½½å™¨ + ç°æœ‰ç³»ç»Ÿ
    """
    
    def __init__(self, download_dir: str = None):
        """åˆå§‹åŒ–å¢å¼ºä¸‹è½½å™¨"""
        self.download_dir = download_dir or "/root/projects/tencent-doc-manager/downloads"
        self.cookie_manager = get_cookie_manager()
        
        # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
        os.makedirs(self.download_dir, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'attempts': 0,
            'successes': 0,
            'failures': 0,
            'cookie_refreshes': 0,
            'session_start': datetime.now().isoformat()
        }
        
        # ç¨³å®šæ€§é…ç½®
        self.max_retries = 3
        self.timeout_extend_factor = 1.5  # æ‰©å±•è¶…æ—¶å€æ•°
        
    async def download_with_stability(self, url: str, format_type: str = 'csv', 
                                     cookies: str = None) -> Dict:
        """
        ç¨³å®šæ€§å¢å¼ºçš„ä¸‹è½½æ¥å£
        
        Args:
            url: è…¾è®¯æ–‡æ¡£URL
            format_type: å¯¼å‡ºæ ¼å¼ ('csv', 'excel', 'xlsx')
            cookies: å¯é€‰çš„æ–°Cookie
            
        Returns:
            dict: ä¸‹è½½ç»“æœ
        """
        self.stats['attempts'] += 1
        
        try:
            logger.info(f"ğŸš€ ç¨³å®šæ€§å¢å¼ºä¸‹è½½å¯åŠ¨: {url}")
            
            # Step 1: Cookieç®¡ç†ä¸éªŒè¯
            effective_cookies = await self._ensure_valid_cookies(cookies)
            if not effective_cookies:
                self.stats['failures'] += 1
                return {
                    'success': False,
                    'error': 'Cookieè·å–å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œè®¤è¯',
                    'cookie_status': 'failed'
                }
            
            # Step 2: ä½¿ç”¨ç”Ÿäº§çº§ä¸‹è½½å™¨æ‰§è¡Œä¸‹è½½
            downloader = ProductionTencentDownloader(self.download_dir)
            
            try:
                # å¯åŠ¨æµè§ˆå™¨ï¼ˆå¢å¼ºé…ç½®ï¼‰
                await downloader.start_browser(headless=True)
                
                # è®¾ç½®Cookie
                login_success = await downloader.login_with_cookies(effective_cookies)
                if not login_success:
                    logger.warning("âš ï¸ åˆå§‹Cookieè®¾ç½®å¤±è´¥ï¼Œå°è¯•åˆ·æ–°Cookie...")
                    # åˆ·æ–°Cookieå¹¶é‡è¯•
                    fresh_cookies = await self.cookie_manager.get_valid_cookies()
                    if fresh_cookies:
                        login_success = await downloader.login_with_cookies(fresh_cookies)
                        effective_cookies = fresh_cookies
                        self.stats['cookie_refreshes'] += 1
                
                if not login_success:
                    raise Exception("Cookieè®¤è¯å¤±è´¥ï¼Œæ— æ³•ç™»å½•")
                
                # æ‰§è¡Œä¸‹è½½ï¼ˆå¸¦ç¨³å®šæ€§å¢å¼ºï¼‰
                success, message, files = await downloader.download_document(
                    url, format_type
                )
                
                if success and files:
                    self.stats['successes'] += 1
                    result = {
                        'success': True,
                        'message': message,
                        'files': files,
                        'file_count': len(files),
                        'primary_file': files[0] if files else None,
                        'cookie_status': 'valid',
                        'download_method': 'production_downloader',
                        'stats': self.stats.copy()
                    }
                    
                    logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {len(files)} ä¸ªæ–‡ä»¶")
                    await self._record_success(url, result)
                    return result
                else:
                    # ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
                    logger.warning("âš ï¸ ç”Ÿäº§ä¸‹è½½å™¨å¤±è´¥ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
                    return await self._fallback_download(url, format_type, effective_cookies)
                    
            finally:
                # ç¡®ä¿æ¸…ç†èµ„æº
                try:
                    await downloader.cleanup()
                except:
                    pass
                    
        except Exception as e:
            self.stats['failures'] += 1
            logger.error(f"âŒ ç¨³å®šæ€§å¢å¼ºä¸‹è½½å¤±è´¥: {e}")
            
            # è®°å½•å¤±è´¥
            await self._record_failure(url, str(e))
            
            return {
                'success': False,
                'error': str(e),
                'cookie_status': 'unknown',
                'stats': self.stats.copy()
            }
    
    async def _ensure_valid_cookies(self, provided_cookies: str = None) -> Optional[str]:
        """ç¡®ä¿è·å–æœ‰æ•ˆCookie"""
        try:
            # å¦‚æœæä¾›äº†æ–°Cookieï¼Œæ›´æ–°åˆ°ç®¡ç†å™¨
            if provided_cookies:
                logger.info("ğŸ”„ æ›´æ–°æä¾›çš„Cookieåˆ°ç®¡ç†å™¨...")
                success = await self.cookie_manager.update_primary_cookie(provided_cookies)
                if success:
                    logger.info("âœ… æ–°Cookieå·²ä¿å­˜")
                    return provided_cookies
                else:
                    logger.warning("âš ï¸ æä¾›çš„Cookieæ— æ•ˆ")
            
            # ä»ç®¡ç†å™¨è·å–æœ‰æ•ˆCookie
            logger.info("ğŸ“‹ ä»Cookieç®¡ç†å™¨è·å–æœ‰æ•ˆCookie...")
            valid_cookies = await self.cookie_manager.get_valid_cookies()
            
            if valid_cookies:
                logger.info("âœ… å·²è·å–æœ‰æ•ˆCookie")
                return valid_cookies
            else:
                logger.error("âŒ æ— æ³•ä»ç®¡ç†å™¨è·å–æœ‰æ•ˆCookie")
                return None
                
        except Exception as e:
            logger.error(f"Cookieç¡®ä¿è¿‡ç¨‹å¤±è´¥: {e}")
            return None
    
    async def _fallback_download(self, url: str, format_type: str, cookies: str) -> Dict:
        """å¤‡ç”¨ä¸‹è½½æ–¹æ³•"""
        try:
            logger.info("ğŸ”„ å¯åŠ¨å¤‡ç”¨ä¸‹è½½æ–¹æ³•...")
            
            # ä½¿ç”¨ç°æœ‰çš„ä¸‹è½½è‡ªåŠ¨åŒ–ç³»ç»Ÿ
            from tencent_export_automation import TencentDocAutoExporter
            
            exporter = TencentDocAutoExporter(
                download_dir=self.download_dir
                # ç‰ˆæœ¬ç®¡ç†ç°åœ¨æ˜¯å¼ºåˆ¶å¯ç”¨çš„ï¼Œä¸å†éœ€è¦å‚æ•°
            )
            
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£
            result = exporter.export_document(
                url=url,
                cookies=cookies,
                format=format_type,
                download_dir=self.download_dir
            )
            
            if result.get('success'):
                self.stats['successes'] += 1
                enhanced_result = {
                    'success': True,
                    'message': 'å¤‡ç”¨æ–¹æ³•ä¸‹è½½æˆåŠŸ',
                    'files': result.get('files', []),
                    'file_count': len(result.get('files', [])),
                    'primary_file': result.get('file_path'),
                    'cookie_status': 'valid',
                    'download_method': 'fallback_automation',
                    'stats': self.stats.copy(),
                    'original_result': result
                }
                
                logger.info("âœ… å¤‡ç”¨æ–¹æ³•ä¸‹è½½æˆåŠŸ")
                await self._record_success(url, enhanced_result)
                return enhanced_result
            else:
                self.stats['failures'] += 1
                logger.error(f"âŒ å¤‡ç”¨æ–¹æ³•ä¹Ÿå¤±è´¥: {result.get('error')}")
                await self._record_failure(url, f"å¤‡ç”¨æ–¹æ³•å¤±è´¥: {result.get('error')}")
                return {
                    'success': False,
                    'error': f"æ‰€æœ‰ä¸‹è½½æ–¹æ³•éƒ½å¤±è´¥: {result.get('error')}",
                    'download_method': 'fallback_failed',
                    'stats': self.stats.copy()
                }
            
        except Exception as e:
            self.stats['failures'] += 1
            logger.error(f"å¤‡ç”¨ä¸‹è½½æ–¹æ³•å¼‚å¸¸: {e}")
            await self._record_failure(url, f"å¤‡ç”¨æ–¹æ³•å¼‚å¸¸: {str(e)}")
            return {
                'success': False,
                'error': f"å¤‡ç”¨ä¸‹è½½æ–¹æ³•å¼‚å¸¸: {str(e)}",
                'download_method': 'fallback_error',
                'stats': self.stats.copy()
            }
    
    async def _record_success(self, url: str, result: Dict):
        """è®°å½•æˆåŠŸçš„ä¸‹è½½"""
        try:
            record = {
                'timestamp': datetime.now().isoformat(),
                'url': url,
                'result': 'success',
                'files': result.get('files', []),
                'method': result.get('download_method', 'unknown'),
                'stats': self.stats.copy()
            }
            
            # ä¿å­˜è®°å½•
            record_file = os.path.join(
                self.download_dir, 
                f"download_success_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(record, f, ensure_ascii=False, indent=2)
                
            logger.info(f"ğŸ“ æˆåŠŸè®°å½•å·²ä¿å­˜: {record_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æˆåŠŸè®°å½•å¤±è´¥: {e}")
    
    async def _record_failure(self, url: str, error_msg: str):
        """è®°å½•å¤±è´¥çš„ä¸‹è½½"""
        try:
            record = {
                'timestamp': datetime.now().isoformat(),
                'url': url,
                'result': 'failure',
                'error': error_msg,
                'stats': self.stats.copy()
            }
            
            # ä¿å­˜è®°å½•
            record_file = os.path.join(
                self.download_dir, 
                f"download_failure_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            )
            
            with open(record_file, 'w', encoding='utf-8') as f:
                json.dump(record, f, ensure_ascii=False, indent=2)
                
            logger.info(f"ğŸ“ å¤±è´¥è®°å½•å·²ä¿å­˜: {record_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥è®°å½•å¤±è´¥: {e}")
    
    async def get_stability_report(self) -> Dict:
        """è·å–ç¨³å®šæ€§æŠ¥å‘Š"""
        try:
            cookie_health = await self.cookie_manager.get_health_status()
            
            success_rate = (self.stats['successes'] / max(self.stats['attempts'], 1)) * 100
            
            report = {
                'overall_success_rate': f"{success_rate:.1f}%",
                'session_stats': self.stats,
                'cookie_health': cookie_health,
                'download_directory': self.download_dir,
                'stability_grade': self._calculate_stability_grade(success_rate),
                'recommendations': self._get_stability_recommendations(success_rate, cookie_health)
            }
            
            return report
            
        except Exception as e:
            logger.error(f"è·å–ç¨³å®šæ€§æŠ¥å‘Šå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def _calculate_stability_grade(self, success_rate: float) -> str:
        """è®¡ç®—ç¨³å®šæ€§ç­‰çº§"""
        if success_rate >= 95:
            return "A+ (ä¼ä¸šçº§)"
        elif success_rate >= 90:
            return "A (ç”Ÿäº§çº§)"
        elif success_rate >= 80:
            return "B+ (è‰¯å¥½)"
        elif success_rate >= 70:
            return "B (å¯ç”¨)"
        elif success_rate >= 50:
            return "C (ä¸ç¨³å®š)"
        else:
            return "D (å¤±è´¥)"
    
    def _get_stability_recommendations(self, success_rate: float, cookie_health: Dict) -> List[str]:
        """è·å–ç¨³å®šæ€§å»ºè®®"""
        recommendations = []
        
        if success_rate < 90:
            recommendations.append("å»ºè®®å¢åŠ ç½‘ç»œé‡è¯•æœºåˆ¶")
            recommendations.append("å»ºè®®å»¶é•¿é¡µé¢åŠ è½½è¶…æ—¶æ—¶é—´")
        
        if not cookie_health.get('healthy', False):
            recommendations.append("éœ€è¦æ›´æ–°Cookieè®¤è¯ä¿¡æ¯")
            recommendations.append("å»ºè®®æ·»åŠ å¤‡ç”¨Cookie")
        
        if cookie_health.get('backup_cookies_count', 0) == 0:
            recommendations.append("å»ºè®®æ·»åŠ å¤‡ç”¨Cookieä»¥æé«˜å¯ç”¨æ€§")
        
        if self.stats['cookie_refreshes'] > 3:
            recommendations.append("Cookieåˆ·æ–°é¢‘ç¹ï¼Œå»ºè®®æ£€æŸ¥Cookieæœ‰æ•ˆæœŸ")
        
        if not recommendations:
            recommendations.append("ç³»ç»Ÿè¿è¡Œç¨³å®šï¼Œä¿æŒå½“å‰é…ç½®")
        
        return recommendations


# å‘½ä»¤è¡Œæ¥å£
async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç¨³å®šæ€§å¢å¼ºä¸‹è½½ç³»ç»Ÿ')
    parser.add_argument('url', nargs='?', help='è¦ä¸‹è½½çš„æ–‡æ¡£URL')
    parser.add_argument('-f', '--format', choices=['csv', 'excel', 'xlsx'], 
                       default='csv', help='å¯¼å‡ºæ ¼å¼')
    parser.add_argument('-d', '--download-dir', help='ä¸‹è½½ç›®å½•')
    parser.add_argument('-c', '--cookies', help='ç™»å½•Cookie')
    parser.add_argument('--report', action='store_true', help='æ˜¾ç¤ºç¨³å®šæ€§æŠ¥å‘Š')
    
    args = parser.parse_args()
    
    downloader = StabilityEnhancedDownloader(args.download_dir)
    
    try:
        if args.url:
            print(f"ğŸ“¥ å¼€å§‹ç¨³å®šæ€§å¢å¼ºä¸‹è½½: {args.url}")
            result = await downloader.download_with_stability(
                args.url, args.format, args.cookies
            )
            
            if result['success']:
                print(f"âœ… ä¸‹è½½æˆåŠŸ!")
                if result.get('files'):
                    print(f"ğŸ“ ä¸‹è½½æ–‡ä»¶ ({len(result['files'])}ä¸ª):")
                    for file_path in result['files']:
                        file_size = os.path.getsize(file_path) if os.path.exists(file_path) else 0
                        print(f"   - {Path(file_path).name} ({file_size:,} bytes)")
                print(f"ğŸ”§ ä¸‹è½½æ–¹æ³•: {result.get('download_method', 'unknown')}")
                print(f"ğŸª CookieçŠ¶æ€: {result.get('cookie_status', 'unknown')}")
            else:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {result['error']}")
        
        if args.report or not args.url:
            print("\nğŸ“Š ç¨³å®šæ€§æŠ¥å‘Š:")
            report = await downloader.get_stability_report()
            for key, value in report.items():
                if key == 'recommendations':
                    print(f"   {key}:")
                    for rec in value:
                        print(f"     â€¢ {rec}")
                else:
                    print(f"   {key}: {value}")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main())