#!/usr/bin/env python3
"""
é…ç½®ä¸­å¿ƒè¿é€šæ€§æ·±åº¦æµ‹è¯•
æµ‹è¯•èŒƒå›´ï¼š
1. é…ç½®åŠ è½½å’Œå•ä¾‹æ¨¡å¼
2. åˆ—åæ ‡å‡†åŒ–å’Œåˆ«åå¤„ç†
3. é£é™©åˆ†çº§æ­£ç¡®æ€§
4. æƒé‡å’Œå‚æ•°è·å–
5. é…ç½®ä¸€è‡´æ€§éªŒè¯
6. æ¨¡å—é—´é…ç½®ä¼ æ’­
"""

import sys
import json
from pathlib import Path
from typing import Dict, List, Tuple
import traceback

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '/root/projects/tencent-doc-manager')

def test_config_center_basics():
    """æµ‹è¯•é…ç½®ä¸­å¿ƒåŸºç¡€åŠŸèƒ½"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•1: é…ç½®ä¸­å¿ƒåŸºç¡€åŠŸèƒ½")
    print("="*60)

    results = []

    try:
        # 1. å¯¼å…¥æµ‹è¯•
        from production.config import get_config_center, STANDARD_COLUMNS
        from production.config.config_center import ConfigCenter
        results.append(("é…ç½®ä¸­å¿ƒå¯¼å…¥", "âœ… æˆåŠŸ"))

        # 2. å•ä¾‹æ¨¡å¼æµ‹è¯•
        config1 = get_config_center()
        config2 = get_config_center()
        if config1 is config2:
            results.append(("å•ä¾‹æ¨¡å¼", "âœ… æ­£ç¡®"))
        else:
            results.append(("å•ä¾‹æ¨¡å¼", "âŒ å¤±è´¥ - ä¸æ˜¯å•ä¾‹"))

        # 3. æ ‡å‡†åˆ—è·å–
        columns = config1.get_standard_columns()
        if len(columns) == 19:
            results.append(("æ ‡å‡†åˆ—æ•°é‡", f"âœ… æ­£ç¡® - 19åˆ—"))
        else:
            results.append(("æ ‡å‡†åˆ—æ•°é‡", f"âŒ é”™è¯¯ - {len(columns)}åˆ—"))

        # 4. å…³é”®åˆ—åéªŒè¯
        key_columns = {
            14: "å®Œæˆé“¾æ¥",
            15: "ç»ç†åˆ†æå¤ç›˜",
            16: "æœ€æ–°å¤ç›˜æ—¶é—´"
        }

        for idx, expected in key_columns.items():
            actual = columns[idx]
            if actual == expected:
                results.append((f"åˆ—{idx}åç§°", f"âœ… {actual}"))
            else:
                results.append((f"åˆ—{idx}åç§°", f"âŒ æœŸæœ›'{expected}'ï¼Œå®é™…'{actual}'"))

    except Exception as e:
        results.append(("åŸºç¡€åŠŸèƒ½æµ‹è¯•", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_column_aliases():
    """æµ‹è¯•åˆ—ååˆ«åå¤„ç†"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•2: åˆ—ååˆ«åå’Œæ ‡å‡†åŒ–")
    print("="*60)

    results = []

    try:
        from production.config import normalize_column_name

        # æµ‹è¯•æ—§åˆ—åè½¬æ¢
        test_cases = [
            ("å½¢æˆè®¡åˆ’æ¸…å•", "å®Œæˆé“¾æ¥"),
            ("è¿›åº¦åˆ†ææ€»ç»“", "ç»ç†åˆ†æå¤ç›˜"),
            ("å¤ç›˜æ—¶é—´", "æœ€æ–°å¤ç›˜æ—¶é—´"),
            ("å®Œæˆé“¾æ¥", "å®Œæˆé“¾æ¥"),  # å·²ç»æ˜¯æ–°åç§°
            ("åºå·", "åºå·")  # æ— åˆ«åçš„åˆ—
        ]

        for old_name, expected in test_cases:
            actual = normalize_column_name(old_name)
            if actual == expected:
                results.append((f"åˆ«å'{old_name}'", f"âœ… â†’ '{actual}'"))
            else:
                results.append((f"åˆ«å'{old_name}'", f"âŒ æœŸæœ›'{expected}'ï¼Œå®é™…'{actual}'"))

    except Exception as e:
        results.append(("åˆ«åå¤„ç†æµ‹è¯•", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_risk_classification():
    """æµ‹è¯•é£é™©åˆ†çº§é…ç½®"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•3: é£é™©åˆ†çº§é…ç½®")
    print("="*60)

    results = []

    try:
        from production.config import (
            L1_COLUMNS, L2_COLUMNS, L3_COLUMNS,
            get_column_risk_level
        )

        # 1. åˆ†çº§æ•°é‡éªŒè¯
        total = len(L1_COLUMNS) + len(L2_COLUMNS) + len(L3_COLUMNS)
        if total == 19:
            results.append(("é£é™©åˆ†çº§æ€»æ•°", f"âœ… {total}åˆ—"))
        else:
            results.append(("é£é™©åˆ†çº§æ€»æ•°", f"âŒ {total}åˆ—ï¼Œåº”ä¸º19åˆ—"))

        results.append(("L1é«˜é£é™©", f"ğŸ“Š {len(L1_COLUMNS)}åˆ—"))
        results.append(("L2ä¸­é£é™©", f"ğŸ“Š {len(L2_COLUMNS)}åˆ—"))
        results.append(("L3ä½é£é™©", f"ğŸ“Š {len(L3_COLUMNS)}åˆ—"))

        # 2. å…³é”®åˆ—é£é™©çº§åˆ«éªŒè¯
        test_columns = {
            "é‡è¦ç¨‹åº¦": "L1",
            "è´Ÿè´£äºº": "L2",
            "å®Œæˆé“¾æ¥": "L3",
            "ç»ç†åˆ†æå¤ç›˜": "L3",
            "æœ€æ–°å¤ç›˜æ—¶é—´": "L3"
        }

        for col, expected_level in test_columns.items():
            actual_level = get_column_risk_level(col)
            if actual_level == expected_level:
                results.append((f"'{col}'é£é™©çº§åˆ«", f"âœ… {actual_level}"))
            else:
                results.append((f"'{col}'é£é™©çº§åˆ«", f"âŒ æœŸæœ›{expected_level}ï¼Œå®é™…{actual_level}"))

        # 3. æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤
        all_risk_columns = L1_COLUMNS + L2_COLUMNS + L3_COLUMNS
        if len(all_risk_columns) == len(set(all_risk_columns)):
            results.append(("åˆ—åˆ†çº§é‡å¤æ£€æŸ¥", "âœ… æ— é‡å¤"))
        else:
            results.append(("åˆ—åˆ†çº§é‡å¤æ£€æŸ¥", "âŒ å­˜åœ¨é‡å¤åˆ—"))

    except Exception as e:
        results.append(("é£é™©åˆ†çº§æµ‹è¯•", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_scoring_parameters():
    """æµ‹è¯•æ‰“åˆ†å‚æ•°é…ç½®"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•4: æ‰“åˆ†å‚æ•°é…ç½®")
    print("="*60)

    results = []

    try:
        from production.config import get_column_weight
        from production.config.scoring_parameters import (
            BASE_SCORES, FORCE_THRESHOLDS, DIFFUSION_PARAMS
        )

        # 1. æƒé‡è·å–æµ‹è¯•
        test_weights = {
            "é‡è¦ç¨‹åº¦": 1.4,  # L1æƒé‡
            "è´Ÿè´£äºº": 1.2,    # L2æƒé‡
            "åºå·": 1.0       # L3æƒé‡ï¼ˆé»˜è®¤ï¼‰
        }

        for col, expected_weight in test_weights.items():
            actual_weight = get_column_weight(col)
            if abs(actual_weight - expected_weight) < 0.01:
                results.append((f"'{col}'æƒé‡", f"âœ… {actual_weight}"))
            else:
                results.append((f"'{col}'æƒé‡", f"âŒ æœŸæœ›{expected_weight}ï¼Œå®é™…{actual_weight}"))

        # 2. åŸºç¡€åˆ†æ•°é…ç½®
        if BASE_SCORES:
            results.append(("åŸºç¡€åˆ†æ•°é…ç½®", f"âœ… {len(BASE_SCORES)}é¡¹"))
        else:
            results.append(("åŸºç¡€åˆ†æ•°é…ç½®", "âš ï¸ æœªé…ç½®"))

        # 3. é˜ˆå€¼é…ç½®
        if FORCE_THRESHOLDS:
            results.append(("å¼ºåˆ¶é˜ˆå€¼é…ç½®", f"âœ… {len(FORCE_THRESHOLDS)}é¡¹"))
        else:
            results.append(("å¼ºåˆ¶é˜ˆå€¼é…ç½®", "âš ï¸ æœªé…ç½®"))

        # 4. æ‰©æ•£å‚æ•°
        if DIFFUSION_PARAMS:
            results.append(("æ‰©æ•£ç®—æ³•å‚æ•°", f"âœ… {len(DIFFUSION_PARAMS)}é¡¹"))
        else:
            results.append(("æ‰©æ•£ç®—æ³•å‚æ•°", "âš ï¸ æœªé…ç½®"))

    except Exception as e:
        results.append(("æ‰“åˆ†å‚æ•°æµ‹è¯•", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_module_integration():
    """æµ‹è¯•å„æ¨¡å—çš„é…ç½®é›†æˆ"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•5: æ¨¡å—é›†æˆæµ‹è¯•")
    print("="*60)

    results = []

    # æµ‹è¯•ä¸åŒæ¨¡å—çš„é…ç½®ä½¿ç”¨
    modules_to_test = [
        ("comparison_to_scoring_adapter", "å¯¹æ¯”åˆ°æ‰“åˆ†é€‚é…å™¨"),
        ("csv_comparison", "CSVå¯¹æ¯”æ¨¡å—"),
        ("ai_column_classifier", "AIåˆ—åˆ†ç±»å™¨"),
        ("scoring_engine", "æ‰“åˆ†å¼•æ“")
    ]

    for module_name, description in modules_to_test:
        try:
            module = __import__(f"production.core_modules.{module_name}", fromlist=[module_name])

            # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰ä½¿ç”¨é…ç½®
            has_config = any([
                hasattr(module, 'STANDARD_COLUMNS'),
                hasattr(module, 'L1_COLUMNS'),
                hasattr(module, 'L2_COLUMNS'),
                hasattr(module, 'L3_COLUMNS'),
                'from production.config' in str(module.__dict__.get('__file__', '')),
                'from standard_columns_config' in str(module.__dict__.get('__file__', ''))
            ])

            if has_config:
                results.append((description, "âœ… ä½¿ç”¨é…ç½®"))
            else:
                results.append((description, "âš ï¸ å¯èƒ½æœªä½¿ç”¨é…ç½®"))

        except ImportError as e:
            results.append((description, f"âš ï¸ å¯¼å…¥å¤±è´¥: {str(e)}"))
        except Exception as e:
            results.append((description, f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_config_consistency():
    """æµ‹è¯•é…ç½®ä¸€è‡´æ€§"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•6: é…ç½®ä¸€è‡´æ€§éªŒè¯")
    print("="*60)

    results = []

    try:
        from production.config import get_config_center

        config = get_config_center()

        # éªŒè¯é…ç½®ä¸€è‡´æ€§
        is_consistent = config.validate_config_consistency()

        if is_consistent:
            results.append(("é…ç½®ä¸€è‡´æ€§", "âœ… é€šè¿‡"))
        else:
            results.append(("é…ç½®ä¸€è‡´æ€§", "âŒ ä¸ä¸€è‡´"))

        # è·å–é…ç½®ç»Ÿè®¡
        stats = config.get_config_stats()

        for key, value in stats.items():
            results.append((key, f"ğŸ“Š {value}"))

    except Exception as e:
        results.append(("ä¸€è‡´æ€§éªŒè¯", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_heatmap_server_config():
    """æµ‹è¯•çƒ­åŠ›å›¾æœåŠ¡é…ç½®è¿é€šæ€§"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•7: çƒ­åŠ›å›¾æœåŠ¡é…ç½®è¿é€šæ€§")
    print("="*60)

    results = []

    try:
        # æ£€æŸ¥çƒ­åŠ›å›¾æ•°æ®æ–‡ä»¶
        heatmap_file = Path("/root/projects/tencent-doc-manager/scoring_results/csv_comparison/latest_csv_heatmap.json")

        if heatmap_file.exists():
            with open(heatmap_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ£€æŸ¥åˆ—å
            column_names = data.get('column_names', [])

            # æ£€æŸ¥æ˜¯å¦ä»æœ‰æ—§åˆ—å
            old_names = ["å½¢æˆè®¡åˆ’æ¸…å•", "è¿›åº¦åˆ†ææ€»ç»“", "å¤ç›˜æ—¶é—´"]
            has_old_names = any(name in column_names for name in old_names)

            if has_old_names:
                results.append(("çƒ­åŠ›å›¾æ•°æ®", "âš ï¸ åŒ…å«æ—§åˆ—åï¼ˆç¼“å­˜æ•°æ®ï¼‰"))
                for i, name in enumerate(column_names):
                    if name in old_names:
                        results.append((f"  åˆ—{i}", f"âŒ '{name}' (æ—§)"))
            else:
                results.append(("çƒ­åŠ›å›¾æ•°æ®", "âœ… ä½¿ç”¨æ–°åˆ—å"))

            # æ£€æŸ¥åˆ—æ•°
            if len(column_names) == 19:
                results.append(("åˆ—æ•°é‡", "âœ… 19åˆ—"))
            else:
                results.append(("åˆ—æ•°é‡", f"âŒ {len(column_names)}åˆ—"))

        else:
            results.append(("çƒ­åŠ›å›¾æ•°æ®æ–‡ä»¶", "âš ï¸ ä¸å­˜åœ¨"))

        # æµ‹è¯•æœåŠ¡å™¨å¯¼å…¥
        try:
            # ä¸å®é™…è¿è¡ŒæœåŠ¡å™¨ï¼Œåªæµ‹è¯•å¯¼å…¥
            sys.path.insert(0, '/root/projects/tencent-doc-manager/production/servers')
            import final_heatmap_server

            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨é…ç½®
            server_code = Path("/root/projects/tencent-doc-manager/production/servers/final_heatmap_server.py").read_text()

            if "from standard_columns_config import" in server_code:
                results.append(("æœåŠ¡å™¨é…ç½®å¯¼å…¥", "âœ… ä½¿ç”¨standard_columns_config"))
            elif "from production.config import" in server_code:
                results.append(("æœåŠ¡å™¨é…ç½®å¯¼å…¥", "âœ… ä½¿ç”¨production.config"))
            else:
                results.append(("æœåŠ¡å™¨é…ç½®å¯¼å…¥", "âš ï¸ å¯èƒ½ç¡¬ç¼–ç "))

        except Exception as e:
            results.append(("æœåŠ¡å™¨å¯¼å…¥", f"âŒ å¼‚å¸¸: {str(e)}"))

    except Exception as e:
        results.append(("çƒ­åŠ›å›¾æœåŠ¡æµ‹è¯•", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§"""
    print("\n" + "="*60)
    print("ğŸ“Œ æµ‹è¯•8: å‘åå…¼å®¹æ€§")
    print("="*60)

    results = []

    try:
        # æµ‹è¯•æ—§çš„å¯¼å…¥æ–¹å¼
        from standard_columns_config import STANDARD_COLUMNS as OLD_COLUMNS
        from production.config import STANDARD_COLUMNS as NEW_COLUMNS

        # æ¯”è¾ƒæ˜¯å¦ä¸€è‡´
        if OLD_COLUMNS == NEW_COLUMNS:
            results.append(("æ—§å¯¼å…¥æ–¹å¼", "âœ… å®Œå…¨å…¼å®¹"))
        else:
            results.append(("æ—§å¯¼å…¥æ–¹å¼", "âŒ ä¸å…¼å®¹"))

        # æµ‹è¯•å…¶ä»–å¯¼å…¥
        from standard_columns_config import (
            L1_COLUMNS as OLD_L1,
            L2_COLUMNS as OLD_L2,
            L3_COLUMNS as OLD_L3
        )
        from production.config import (
            L1_COLUMNS as NEW_L1,
            L2_COLUMNS as NEW_L2,
            L3_COLUMNS as NEW_L3
        )

        if OLD_L1 == NEW_L1:
            results.append(("L1åˆ—å…¼å®¹æ€§", "âœ… ä¸€è‡´"))
        else:
            results.append(("L1åˆ—å…¼å®¹æ€§", f"âŒ ä¸ä¸€è‡´"))

        if OLD_L2 == NEW_L2:
            results.append(("L2åˆ—å…¼å®¹æ€§", "âœ… ä¸€è‡´"))
        else:
            results.append(("L2åˆ—å…¼å®¹æ€§", f"âŒ ä¸ä¸€è‡´"))

        if OLD_L3 == NEW_L3:
            results.append(("L3åˆ—å…¼å®¹æ€§", "âœ… ä¸€è‡´"))
        else:
            results.append(("L3åˆ—å…¼å®¹æ€§", f"âŒ ä¸ä¸€è‡´"))

    except Exception as e:
        results.append(("å‘åå…¼å®¹æ€§", f"âŒ å¼‚å¸¸: {str(e)}"))

    return results

def print_results(test_name: str, results: List[Tuple[str, str]]):
    """æ‰“å°æµ‹è¯•ç»“æœ"""
    for item, status in results:
        print(f"  {item:30} {status}")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "ğŸ”¬"*30)
    print("ğŸ”¬ é…ç½®ä¸­å¿ƒè¿é€šæ€§æ·±åº¦æµ‹è¯•æŠ¥å‘Š ğŸ”¬")
    print("ğŸ”¬"*30)

    all_results = {}

    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("åŸºç¡€åŠŸèƒ½", test_config_center_basics),
        ("åˆ—ååˆ«å", test_column_aliases),
        ("é£é™©åˆ†çº§", test_risk_classification),
        ("æ‰“åˆ†å‚æ•°", test_scoring_parameters),
        ("æ¨¡å—é›†æˆ", test_module_integration),
        ("é…ç½®ä¸€è‡´æ€§", test_config_consistency),
        ("çƒ­åŠ›å›¾æœåŠ¡", test_heatmap_server_config),
        ("å‘åå…¼å®¹", test_backward_compatibility)
    ]

    total_tests = 0
    passed_tests = 0
    warnings = 0

    for test_name, test_func in tests:
        try:
            results = test_func()
            all_results[test_name] = results
            print_results(test_name, results)

            # ç»Ÿè®¡ç»“æœ
            for item, status in results:
                total_tests += 1
                if "âœ…" in status:
                    passed_tests += 1
                elif "âš ï¸" in status:
                    warnings += 1

        except Exception as e:
            print(f"\nâŒ æµ‹è¯•'{test_name}'æ‰§è¡Œå¤±è´¥: {str(e)}")
            traceback.print_exc()

    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("="*60)
    print(f"  æ€»æµ‹è¯•é¡¹: {total_tests}")
    print(f"  âœ… é€šè¿‡: {passed_tests}")
    print(f"  âš ï¸ è­¦å‘Š: {warnings}")
    print(f"  âŒ å¤±è´¥: {total_tests - passed_tests - warnings}")
    print(f"  é€šè¿‡ç‡: {passed_tests/total_tests*100:.1f}%")

    # å…³é”®å»ºè®®
    print("\n" + "="*60)
    print("ğŸ’¡ å…³é”®å»ºè®®")
    print("="*60)

    if warnings > 0:
        print("  1. æ¸…ç†ç¼“å­˜æ•°æ®ï¼š")
        print("     rm -f /root/projects/tencent-doc-manager/scoring_results/csv_comparison/latest_csv_heatmap.json")
        print("  2. é‡å¯çƒ­åŠ›å›¾æœåŠ¡ï¼š")
        print("     systemctl restart heatmap-server æˆ– é‡æ–°è¿è¡Œ final_heatmap_server.py")
        print("  3. é‡æ–°ç”Ÿæˆæ•°æ®ä»¥ä½¿ç”¨æ–°é…ç½®")

    if passed_tests == total_tests:
        print("  âœ¨ é…ç½®ä¸­å¿ƒè¿é€šæ€§å®Œç¾ï¼æ‰€æœ‰æµ‹è¯•é€šè¿‡ã€‚")
    elif passed_tests / total_tests > 0.8:
        print("  ğŸ‘ é…ç½®ä¸­å¿ƒè¿é€šæ€§è‰¯å¥½ï¼Œå»ºè®®å¤„ç†è­¦å‘Šé¡¹ã€‚")
    else:
        print("  âš ï¸ é…ç½®ä¸­å¿ƒå­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä¿®å¤å¤±è´¥é¡¹ã€‚")

if __name__ == "__main__":
    main()