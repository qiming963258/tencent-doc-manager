import requests
import asyncio
import aiohttp
import time
import json
from typing import List, Dict, Any
import concurrent.futures
from datetime import datetime

class ClaudeWrapperTestClient:
    """Claudeå°è£…æœåŠ¡æµ‹è¯•å®¢æˆ·ç«¯"""
    
    def __init__(self, base_url: str = "http://localhost:8081"):
        self.base_url = base_url
        self.session = requests.Session()
        
    def test_health(self) -> Dict[str, Any]:
        """æµ‹è¯•å¥åº·æ£€æŸ¥æ¥å£"""
        print("ğŸ” æµ‹è¯•å¥åº·æ£€æŸ¥æ¥å£...")
        try:
            response = self.session.get(f"{self.base_url}/health")
            response.raise_for_status()
            result = response.json()
            print(f"âœ… å¥åº·æ£€æŸ¥æˆåŠŸ:")
            print(f"   çŠ¶æ€: {result['status']}")
            print(f"   è¿è¡Œæ—¶é—´: {result['uptime']:.2f}ç§’")
            print(f"   ä»£ç†URL: {result['proxy_url']}")
            print(f"   å¯ç”¨æ¨¡å‹: {len(result['models_available'])}ä¸ª")
            return result
        except Exception as e:
            print(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {str(e)}")
            return {}
    
    def test_models(self) -> Dict[str, Any]:
        """æµ‹è¯•æ¨¡å‹åˆ—è¡¨æ¥å£"""
        print("\nğŸ” æµ‹è¯•æ¨¡å‹åˆ—è¡¨æ¥å£...")
        try:
            response = self.session.get(f"{self.base_url}/models")
            response.raise_for_status()
            result = response.json()
            print(f"âœ… æ¨¡å‹åˆ—è¡¨è·å–æˆåŠŸ:")
            print(f"   é»˜è®¤æ¨¡å‹: {result['default_model']}")
            print(f"   å¯ç”¨æ¨¡å‹:")
            for model in result['models']:
                print(f"     - {model['id']} ({model['type']})")
            return result
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥: {str(e)}")
            return {}
    
    def test_basic_chat(self) -> Dict[str, Any]:
        """æµ‹è¯•åŸºç¡€èŠå¤©åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•åŸºç¡€èŠå¤©åŠŸèƒ½...")
        try:
            start_time = time.time()
            response = self.session.post(f"{self.base_url}/chat", json={
                "messages": [
                    {"role": "user", "content": "ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}
                ],
                "max_tokens": 100
            })
            response.raise_for_status()
            result = response.json()
            response_time = time.time() - start_time
            
            print(f"âœ… åŸºç¡€èŠå¤©æµ‹è¯•æˆåŠŸ:")
            print(f"   å“åº”æ—¶é—´: {response_time:.2f}ç§’")
            print(f"   ä½¿ç”¨æ¨¡å‹: {result['model']}")
            print(f"   å“åº”å†…å®¹: {result['choices'][0]['message']['content'][:100]}...")
            print(f"   Tokenä½¿ç”¨: {result.get('usage', {})}")
            return result
        except Exception as e:
            print(f"âŒ åŸºç¡€èŠå¤©æµ‹è¯•å¤±è´¥: {str(e)}")
            return {}
    
    def test_intelligent_analyze(self) -> Dict[str, Any]:
        """æµ‹è¯•æ™ºèƒ½åˆ†æåŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•æ™ºèƒ½åˆ†æåŠŸèƒ½...")
        
        test_cases = [
            {
                "content": "é¡¹ç›®è´Ÿè´£äººä»å¼ ä¸‰æ”¹ä¸ºæå››",
                "analysis_type": "risk_assessment",
                "context": {"table_name": "é¡¹ç›®ç®¡ç†è¡¨", "column": "è´Ÿè´£äºº"}
            },
            {
                "content": "ç›®æ ‡å¯¹é½ä»'æå‡ç”¨æˆ·ä½“éªŒ'æ”¹ä¸º'é™ä½è¿è¥æˆæœ¬'",
                "analysis_type": "risk_assessment", 
                "context": {"table_name": "ç›®æ ‡ç®¡ç†è¡¨", "column": "ç›®æ ‡å¯¹é½"}
            },
            {
                "content": "å®Œæˆè¿›åº¦ä»60%æ›´æ–°ä¸º85%",
                "analysis_type": "content_analysis",
                "context": {"table_name": "è¿›åº¦è·Ÿè¸ªè¡¨", "column": "å®Œæˆè¿›åº¦"}
            }
        ]
        
        results = []
        for i, test_case in enumerate(test_cases):
            try:
                start_time = time.time()
                response = self.session.post(f"{self.base_url}/analyze", json=test_case)
                response.raise_for_status()
                result = response.json()
                response_time = time.time() - start_time
                
                print(f"âœ… æ™ºèƒ½åˆ†ææµ‹è¯• {i+1} æˆåŠŸ:")
                print(f"   åˆ†æç±»å‹: {result['analysis_type']}")
                print(f"   é£é™©ç­‰çº§: {result.get('risk_level', 'N/A')}")
                print(f"   ç½®ä¿¡åº¦: {result['confidence']:.2f}")
                print(f"   å¤„ç†æ—¶é—´: {response_time:.2f}ç§’")
                print(f"   åˆ†æç»“æœ: {result['result'][:150]}...")
                results.append(result)
                
            except Exception as e:
                print(f"âŒ æ™ºèƒ½åˆ†ææµ‹è¯• {i+1} å¤±è´¥: {str(e)}")
        
        return results
    
    def test_batch_analyze(self) -> Dict[str, Any]:
        """æµ‹è¯•æ‰¹é‡åˆ†æåŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•æ‰¹é‡åˆ†æåŠŸèƒ½...")
        
        batch_request = {
            "requests": [
                {
                    "content": "è´Ÿè´£äººï¼šå¼ ä¸‰ â†’ æå››",
                    "analysis_type": "risk_assessment",
                    "context": {"column": "è´Ÿè´£äºº"}
                },
                {
                    "content": "é¢„è®¡å®Œæˆæ—¶é—´ï¼š2025-08-15 â†’ 2025-08-20",
                    "analysis_type": "risk_assessment", 
                    "context": {"column": "é¢„è®¡å®Œæˆæ—¶é—´"}
                },
                {
                    "content": "é‡è¦ç¨‹åº¦ï¼šé«˜ â†’ ä¸­",
                    "analysis_type": "risk_assessment",
                    "context": {"column": "é‡è¦ç¨‹åº¦"}
                }
            ],
            "parallel": True
        }
        
        try:
            start_time = time.time()
            response = self.session.post(f"{self.base_url}/batch", json=batch_request)
            response.raise_for_status()
            result = response.json()
            response_time = time.time() - start_time
            
            print(f"âœ… æ‰¹é‡åˆ†ææµ‹è¯•æˆåŠŸ:")
            print(f"   æ€»å¤„ç†æ•°é‡: {result['total_count']}")
            print(f"   æˆåŠŸæ•°é‡: {result['success_count']}")
            print(f"   å¤±è´¥æ•°é‡: {result['failed_count']}")
            print(f"   æ€»å¤„ç†æ—¶é—´: {response_time:.2f}ç§’")
            print(f"   å¹³å‡å¤„ç†æ—¶é—´: {response_time/result['total_count']:.2f}ç§’/ä¸ª")
            return result
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡åˆ†ææµ‹è¯•å¤±è´¥: {str(e)}")
            return {}
    
    def test_stream_chat(self) -> bool:
        """æµ‹è¯•æµå¼èŠå¤©åŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•æµå¼èŠå¤©åŠŸèƒ½...")
        
        try:
            start_time = time.time()
            with self.session.post(f"{self.base_url}/chat/stream", json={
                "messages": [
                    {"role": "user", "content": "è¯·å†™ä¸€ä¸ªç®€çŸ­çš„å…³äºAIæŠ€æœ¯å‘å±•çš„æ€»ç»“ï¼Œå¤§çº¦100å­—ã€‚"}
                ],
                "max_tokens": 200
            }, stream=True) as response:
                
                response.raise_for_status()
                chunks_received = 0
                total_content = ""
                
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        if line_str.startswith('data: ') and line_str != 'data: [DONE]':
                            try:
                                chunk_data = json.loads(line_str[6:])  # å»é™¤ 'data: '
                                if chunk_data.get('choices') and chunk_data['choices'][0].get('delta', {}).get('content'):
                                    content = chunk_data['choices'][0]['delta']['content']
                                    total_content += content
                                    chunks_received += 1
                            except json.JSONDecodeError:
                                continue
                
                response_time = time.time() - start_time
                print(f"âœ… æµå¼èŠå¤©æµ‹è¯•æˆåŠŸ:")
                print(f"   æ¥æ”¶å—æ•°: {chunks_received}")
                print(f"   æ€»å“åº”æ—¶é—´: {response_time:.2f}ç§’")
                print(f"   æµå¼å†…å®¹: {total_content[:200]}...")
                return True
                
        except Exception as e:
            print(f"âŒ æµå¼èŠå¤©æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
    
    def test_concurrent_requests(self, concurrent_count: int = 10) -> Dict[str, Any]:
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ›"""
        print(f"\nğŸ” æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ› ({concurrent_count}ä¸ªå¹¶å‘)...")
        
        def single_request(request_id: int):
            try:
                start_time = time.time()
                response = requests.post(f"{self.base_url}/analyze", json={
                    "content": f"æµ‹è¯•è¯·æ±‚ #{request_id}: è´Ÿè´£äººä»å¼ ä¸‰æ”¹ä¸ºæå››",
                    "analysis_type": "risk_assessment",
                    "context": {"request_id": request_id}
                }, timeout=30)
                response.raise_for_status()
                response_time = time.time() - start_time
                return {
                    "request_id": request_id,
                    "success": True,
                    "response_time": response_time,
                    "result": response.json()
                }
            except Exception as e:
                return {
                    "request_id": request_id,
                    "success": False,
                    "error": str(e),
                    "response_time": None
                }
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        start_time = time.time()
        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_count) as executor:
            futures = [executor.submit(single_request, i) for i in range(concurrent_count)]
            results = [future.result() for future in concurrent.futures.as_completed(futures)]
        
        total_time = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        successful_requests = [r for r in results if r["success"]]
        failed_requests = [r for r in results if not r["success"]]
        
        if successful_requests:
            response_times = [r["response_time"] for r in successful_requests]
            avg_response_time = sum(response_times) / len(response_times)
            min_response_time = min(response_times)
            max_response_time = max(response_times)
        else:
            avg_response_time = min_response_time = max_response_time = 0
        
        print(f"âœ… å¹¶å‘æµ‹è¯•å®Œæˆ:")
        print(f"   æ€»è¯·æ±‚æ•°: {concurrent_count}")
        print(f"   æˆåŠŸè¯·æ±‚æ•°: {len(successful_requests)}")
        print(f"   å¤±è´¥è¯·æ±‚æ•°: {len(failed_requests)}")
        print(f"   æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
        print(f"   æœ€å¿«å“åº”æ—¶é—´: {min_response_time:.2f}ç§’")
        print(f"   æœ€æ…¢å“åº”æ—¶é—´: {max_response_time:.2f}ç§’")
        print(f"   ååé‡: {len(successful_requests)/total_time:.2f} è¯·æ±‚/ç§’")
        
        if failed_requests:
            print(f"âš ï¸ å¤±è´¥è¯·æ±‚è¯¦æƒ…:")
            for req in failed_requests[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå¤±è´¥è¯·æ±‚
                print(f"   è¯·æ±‚#{req['request_id']}: {req['error']}")
        
        return {
            "total_requests": concurrent_count,
            "successful_requests": len(successful_requests),
            "failed_requests": len(failed_requests),
            "total_time": total_time,
            "avg_response_time": avg_response_time,
            "throughput": len(successful_requests)/total_time if total_time > 0 else 0
        }
    
    def run_comprehensive_tests(self):
        """è¿è¡Œå®Œæ•´çš„æµ‹è¯•å¥—ä»¶"""
        print("ğŸ§ª å¼€å§‹è¿è¡ŒClaudeå°è£…ç¨‹åºå®Œæ•´æµ‹è¯•å¥—ä»¶")
        print("=" * 60)
        
        test_results = {}
        
        # åŸºç¡€åŠŸèƒ½æµ‹è¯•
        test_results["health"] = self.test_health()
        test_results["models"] = self.test_models()
        test_results["basic_chat"] = self.test_basic_chat()
        test_results["intelligent_analyze"] = self.test_intelligent_analyze()
        test_results["batch_analyze"] = self.test_batch_analyze()
        test_results["stream_chat"] = self.test_stream_chat()
        
        # æ€§èƒ½æµ‹è¯•
        test_results["concurrent_10"] = self.test_concurrent_requests(10)
        test_results["concurrent_20"] = self.test_concurrent_requests(20)
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print("\n" + "=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»:")
        print(f"   å¥åº·æ£€æŸ¥: {'âœ…' if test_results['health'] else 'âŒ'}")
        print(f"   æ¨¡å‹åˆ—è¡¨: {'âœ…' if test_results['models'] else 'âŒ'}")
        print(f"   åŸºç¡€èŠå¤©: {'âœ…' if test_results['basic_chat'] else 'âŒ'}")
        print(f"   æ™ºèƒ½åˆ†æ: {'âœ…' if test_results['intelligent_analyze'] else 'âŒ'}")
        print(f"   æ‰¹é‡åˆ†æ: {'âœ…' if test_results['batch_analyze'] else 'âŒ'}")
        print(f"   æµå¼èŠå¤©: {'âœ…' if test_results['stream_chat'] else 'âŒ'}")
        print(f"   10å¹¶å‘æµ‹è¯•: æˆåŠŸç‡ {test_results['concurrent_10']['successful_requests']}/{test_results['concurrent_10']['total_requests']}")
        print(f"   20å¹¶å‘æµ‹è¯•: æˆåŠŸç‡ {test_results['concurrent_20']['successful_requests']}/{test_results['concurrent_20']['total_requests']}")
        
        return test_results

if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯
    test_client = ClaudeWrapperTestClient()
    
    # è¿è¡Œå®Œæ•´æµ‹è¯•
    results = test_client.run_comprehensive_tests()
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    with open(f"test_results_{timestamp}.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nğŸ“„ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: test_results_{timestamp}.json")