from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.exceptions import RequestValidationError
from fastapi.staticfiles import StaticFiles
from starlette.exceptions import HTTPException as StarletteHTTPException
import uvicorn
import time
import uuid
import asyncio
import json
import logging
from typing import List, Dict, Any
from datetime import datetime

from config import ClaudeConfig
from models import (
    ChatRequest, ChatResponse, ChatMessage,
    AnalyzeRequest, AnalyzeResponse,
    BatchAnalyzeRequest, BatchAnalyzeResponse,
    HealthResponse, ErrorResponse
)
from claude_client import ClaudeClientWrapper, ClaudeAPIException

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Claude Mini Wrapper",
    description="æœ€å°Claude APIå°è£…æœåŠ¡ - åŸºäºç°æœ‰ä»£ç†å’ŒSKRç çš„æ™ºèƒ½åˆ†ææ¥å£",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€Claudeå®¢æˆ·ç«¯
claude_client = ClaudeClientWrapper()

# å¯åŠ¨æ—¶é—´è®°å½•
start_time = time.time()

# æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•
import os
static_dir = os.path.join(os.path.dirname(__file__), "static")
if not os.path.exists(static_dir):
    os.makedirs(static_dir)
app.mount("/static", StaticFiles(directory=static_dir), name="static")

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger.info("ğŸš€ Claude Mini Wrapper å¯åŠ¨ä¸­...")
    
    # éªŒè¯é…ç½®
    if not ClaudeConfig.validate_config():
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼ŒæœåŠ¡å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ")
    else:
        logger.info("âœ… é…ç½®éªŒè¯æˆåŠŸ")
    
    # æµ‹è¯•APIè¿æ¥
    try:
        async with claude_client as client:
            test_result = await client.chat_completion(
                messages=[{"role": "user", "content": "Hello, this is a connection test."}],
                max_tokens=10
            )
            if test_result.get("success"):
                logger.info("âœ… Claude APIè¿æ¥æµ‹è¯•æˆåŠŸ")
            else:
                logger.warning("âš ï¸ Claude APIè¿æ¥æµ‹è¯•å¤±è´¥")
    except Exception as e:
        logger.error(f"âŒ Claude APIè¿æ¥æµ‹è¯•å¼‚å¸¸: {str(e)}")
    
    logger.info(f"ğŸ¯ æœåŠ¡å·²å¯åŠ¨: http://{ClaudeConfig.HOST}:{ClaudeConfig.PORT}")
    logger.info(f"ğŸ“š APIæ–‡æ¡£: http://{ClaudeConfig.HOST}:{ClaudeConfig.PORT}/docs")

@app.exception_handler(ClaudeAPIException)
async def claude_api_exception_handler(request, exc: ClaudeAPIException):
    """Claude APIå¼‚å¸¸å¤„ç†å™¨"""
    return HTTPException(
        status_code=exc.status_code or 500,
        detail={
            "error": "Claude API Error",
            "message": exc.message,
            "details": exc.details,
            "timestamp": datetime.now().isoformat()
        }
    )

@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request, exc):
    """è¯·æ±‚éªŒè¯å¼‚å¸¸å¤„ç†å™¨"""
    return HTTPException(
        status_code=422,
        detail={
            "error": "Validation Error",
            "message": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
            "details": str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )

@app.get("/", response_class=HTMLResponse)
async def root():
    """è¿”å›Web UIç•Œé¢"""
    html_file = os.path.join(static_dir, "index.html")
    if os.path.exists(html_file):
        with open(html_file, "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    else:
        return HTMLResponse(content="<h1>Claude AI API Service</h1><p>UI file not found. API is running at port 8081.</p>")

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """
    å¥åº·æ£€æŸ¥æ¥å£
    
    è¿”å›æœåŠ¡è¿è¡ŒçŠ¶æ€ã€é…ç½®ä¿¡æ¯å’ŒAPIç»Ÿè®¡
    """
    uptime = time.time() - start_time
    api_stats = claude_client.get_api_stats()
    
    return HealthResponse(
        status="healthy",
        service="Claude Mini Wrapper",
        version="1.0.0",
        uptime=uptime,
        proxy_url=ClaudeConfig.BASE_URL,
        models_available=[model["id"] for model in ClaudeConfig.get_available_models()],
        api_stats=api_stats
    )

@app.get("/models")
async def list_models():
    """
    è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    è¿”å›æ‰€æœ‰é…ç½®çš„Claudeæ¨¡å‹ä¿¡æ¯
    """
    return {
        "models": ClaudeConfig.get_available_models(),
        "default_model": ClaudeConfig.DEFAULT_MODEL
    }

@app.post("/chat")
async def chat_completion(request: ChatRequest):
    """
    æ ‡å‡†èŠå¤©å®Œæˆæ¥å£
    
    å…¼å®¹OpenAI APIæ ¼å¼çš„èŠå¤©æ¥å£
    """
    try:
        async with claude_client as client:
            result = await client.chat_completion(
                messages=[msg.dict() for msg in request.messages],
                model=request.model,
                max_tokens=request.max_tokens,
                temperature=request.temperature,
                stream=False
            )
            
            if result["success"]:
                # æ„å»ºOpenAIæ ¼å¼å“åº”
                response_id = f"chatcmpl-{uuid.uuid4().hex[:8]}"
                created = int(time.time())
                
                return {
                    "id": response_id,
                    "object": "chat.completion",
                    "created": created,
                    "model": result["model"],
                    "choices": [{
                        "index": 0,
                        "message": {
                            "role": "assistant",
                            "content": result["data"]["content"][0]["text"]
                        },
                        "finish_reason": "stop"
                    }],
                    "usage": result.get("usage", {
                        "prompt_tokens": 0,
                        "completion_tokens": 0,
                        "total_tokens": 0
                    })
                }
            else:
                raise HTTPException(status_code=500, detail=result.get("error", "æœªçŸ¥é”™è¯¯"))
                
    except ClaudeAPIException as e:
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        logger.error(f"èŠå¤©å®Œæˆæ¥å£å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼èŠå¤©æ¥å£
    
    æ”¯æŒæœåŠ¡å™¨å‘é€äº‹ä»¶(SSE)çš„å®æ—¶æµå¼å“åº”
    """
    try:
        async def generate_stream():
            response_id = f"chatcmpl-{uuid.uuid4().hex[:8]}"
            created = int(time.time())
            
            async with claude_client as client:
                async for chunk in client.stream_completion(
                    messages=[msg.dict() for msg in request.messages],
                    model=request.model,
                    max_tokens=request.max_tokens,
                    temperature=request.temperature
                ):
                    # æ„å»ºæµå¼å“åº”æ ¼å¼
                    if chunk and chunk != "[DONE]":
                        try:
                            # å°è¯•è§£æJSONå†…å®¹
                            chunk_data = json.loads(chunk)
                            if chunk_data.get("content"):
                                stream_data = {
                                    "id": response_id,
                                    "object": "chat.completion.chunk",
                                    "created": created,
                                    "model": request.model or ClaudeConfig.DEFAULT_MODEL,
                                    "choices": [{
                                        "index": 0,
                                        "delta": {"content": chunk_data["content"]},
                                        "finish_reason": None
                                    }]
                                }
                                yield f"data: {json.dumps(stream_data, ensure_ascii=False)}\n\n"
                        except json.JSONDecodeError:
                            # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥ä½œä¸ºæ–‡æœ¬å†…å®¹
                            stream_data = {
                                "id": response_id,
                                "object": "chat.completion.chunk",
                                "created": created,
                                "model": request.model or ClaudeConfig.DEFAULT_MODEL,
                                "choices": [{
                                    "index": 0,
                                    "delta": {"content": chunk},
                                    "finish_reason": None
                                }]
                            }
                            yield f"data: {json.dumps(stream_data, ensure_ascii=False)}\n\n"
                
                # å‘é€ç»“æŸæ ‡è®°
                final_chunk = {
                    "id": response_id,
                    "object": "chat.completion.chunk", 
                    "created": created,
                    "model": request.model or ClaudeConfig.DEFAULT_MODEL,
                    "choices": [{
                        "index": 0,
                        "delta": {},
                        "finish_reason": "stop"
                    }]
                }
                yield f"data: {json.dumps(final_chunk, ensure_ascii=False)}\n\n"
                yield "data: [DONE]\n\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="text/plain",
            headers={"Cache-Control": "no-cache"}
        )
        
    except Exception as e:
        logger.error(f"æµå¼èŠå¤©æ¥å£å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æµå¼å¤„ç†å¤±è´¥: {str(e)}")

@app.post("/analyze", response_model=AnalyzeResponse)
async def intelligent_analyze(request: AnalyzeRequest):
    """
    æ™ºèƒ½åˆ†ææ¥å£
    
    ä¸“é—¨é’ˆå¯¹è…¾è®¯æ–‡æ¡£åœºæ™¯çš„æ™ºèƒ½åˆ†æåŠŸèƒ½
    æ”¯æŒé£é™©è¯„ä¼°ã€å†…å®¹åˆ†æã€ä¼˜åŒ–å»ºè®®ç­‰åˆ†æç±»å‹
    """
    try:
        async with claude_client as client:
            result = await client.intelligent_analyze(request)
            return result
            
    except ClaudeAPIException as e:
        logger.error(f"æ™ºèƒ½åˆ†æå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ™ºèƒ½åˆ†æå¤±è´¥: {str(e)}")
    except Exception as e:
        logger.error(f"æ™ºèƒ½åˆ†ææ¥å£å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")

@app.post("/api/ai-column-mapping")
async def ai_column_mapping(request: dict):
    """
    åˆ—åæ ‡å‡†åŒ–APIæ¥å£
    
    ä¸“é—¨å¤„ç†CSVå·®å¼‚æ–‡ä»¶ä¸­çš„åˆ—åæ ‡å‡†åŒ–
    é›†æˆIntelligentColumnMatcherè¿›è¡Œæ™ºèƒ½åˆ—åŒ¹é…
    """
    try:
        # æå–å·®å¼‚æ–‡ä»¶ä¸­çš„åˆ—å
        differences = request.get("differences", [])
        columns = list(set([diff.get("åˆ—å", "") for diff in differences if diff.get("åˆ—å")]))
        
        if not columns:
            return {
                "success": False,
                "error": "æœªæ‰¾åˆ°æœ‰æ•ˆçš„åˆ—åæ•°æ®",
                "mapping": {},
                "confidence_scores": {}
            }
        
        # åˆ›å»ºåˆ†æè¯·æ±‚
        analyze_request = AnalyzeRequest(
            content=f"è¯·å¯¹ä»¥ä¸‹CSVåˆ—åè¿›è¡Œæ ‡å‡†åŒ–æ˜ å°„åˆ†æï¼Œå°†å®é™…åˆ—åæ˜ å°„åˆ°æ ‡å‡†åˆ—åã€‚å®é™…åˆ—åï¼š{columns}ã€‚è¯·è¿”å›æ˜ å°„å…³ç³»å’Œç½®ä¿¡åº¦åˆ†æ•°ã€‚",
            analysis_type="content_analysis",
            context={
                "columns": columns,
                "standard_columns": [
                    "åºå·", "é¡¹ç›®ç±»å‹", "æ¥æº", "ä»»åŠ¡å‘èµ·æ—¶é—´", "ç›®æ ‡å¯¹é½",
                    "å…³é”®KRå¯¹é½", "å…·ä½“è®¡åˆ’å†…å®¹", "é‚“æ€»æŒ‡å¯¼ç™»è®°", "è´Ÿè´£äºº",
                    "ååŠ©äºº", "ç›‘ç£äºº", "é‡è¦ç¨‹åº¦", "é¢„è®¡å®Œæˆæ—¶é—´", "å®Œæˆè¿›åº¦", 
                    "å½¢æˆè®¡åˆ’æ¸…å•", "å¤ç›˜æ—¶é—´", "å¯¹ä¸Šæ±‡æŠ¥", "åº”ç”¨æƒ…å†µ", "è¿›åº¦åˆ†ææ€»ç»“"
                ],
                "task": "column_standardization"
            }
        )
        
        # è°ƒç”¨Claude AIè¿›è¡Œæ™ºèƒ½åˆ†æ
        async with claude_client as client:
            result = await client.intelligent_analyze(analyze_request)
            
            # å¤„ç†AnalyzeResponseå¯¹è±¡
            if hasattr(result, 'dict'):
                result_dict = result.dict()
            elif hasattr(result, '__dict__'):
                result_dict = result.__dict__
            else:
                result_dict = result
            
            # æ„å»ºæ ‡å‡†åŒ–å“åº”
            response = {
                "success": True,
                "mapping": result_dict.get("analysis_result", {}).get("mapping", {}),
                "confidence_scores": result_dict.get("analysis_result", {}).get("confidence_scores", {}),
                "analysis_result": result_dict,
                "processed_columns": columns,
                "timestamp": time.time()
            }
            
            return response
            
    except Exception as e:
        logger.error(f"åˆ—åæ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": f"åˆ—åæ ‡å‡†åŒ–å¤±è´¥: {str(e)}",
            "mapping": {},
            "confidence_scores": {}
        }

@app.post("/api/l2-semantic-analysis")
async def l2_semantic_analysis(request: dict):
    """
    L2çº§è¯­ä¹‰åˆ†ææ¥å£
    
    æ¥æ”¶ç¬¬ä¸‰æ­¥åˆ—åæ ‡å‡†åŒ–ç»“æœï¼Œå¯¹L2çº§å­—æ®µè¿›è¡Œæ™ºèƒ½è¯­ä¹‰åˆ†æ
    æä¾›APPROVE/REJECT/REVIEW/CONDITIONALå†³ç­–å»ºè®®
    """
    try:
        # æå–ç¬¬ä¸‰æ­¥è¾“å‡ºçš„æ•°æ®
        processed_columns = request.get("processed_columns", [])
        differences = request.get("original_differences", [])
        
        if not processed_columns or not differences:
            return {
                "success": False,
                "error": "ç¼ºå°‘å¿…è¦çš„è¾“å…¥æ•°æ®ï¼šprocessed_columnsæˆ–original_differences",
                "l2_analysis_results": []
            }
        
        # å®šä¹‰L2çº§å­—æ®µï¼ˆéœ€è¦è¯­ä¹‰å®¡æ ¸çš„å­—æ®µï¼‰
        l2_fields = [
            "é¡¹ç›®ç±»å‹", "å…·ä½“è®¡åˆ’å†…å®¹", "é‚“æ€»æŒ‡å¯¼ç™»è®°", "è´Ÿè´£äºº", 
            "ååŠ©äºº", "ç›‘ç£äºº", "å½¢æˆè®¡åˆ’æ¸…å•"
        ]
        
        # ç­›é€‰L2çº§å­—æ®µçš„å˜æ›´
        l2_changes = []
        for diff in differences:
            column_name = diff.get("åˆ—å", "")
            if column_name in l2_fields and column_name in processed_columns:
                l2_changes.append({
                    "column_name": column_name,
                    "original_value": diff.get("åŸå€¼", ""),
                    "new_value": diff.get("æ–°å€¼", ""),
                    "row_number": diff.get("è¡Œå·", 0),
                    "position": diff.get("ä½ç½®", "")
                })
        
        if not l2_changes:
            return {
                "success": True,
                "message": "æœªå‘ç°L2çº§å­—æ®µå˜æ›´ï¼Œæ— éœ€è¯­ä¹‰åˆ†æ",
                "l2_analysis_results": [],
                "summary": {
                    "total_l2_changes": 0,
                    "approved": 0,
                    "rejected": 0,
                    "review_required": 0,
                    "conditional": 0
                }
            }
        
        # å¯¹æ¯ä¸ªL2å­—æ®µå˜æ›´è¿›è¡Œè¯­ä¹‰åˆ†æ
        analysis_results = []
        
        for change in l2_changes:
            # æ„å»ºè¯­ä¹‰åˆ†æè¯·æ±‚
            analyze_request = AnalyzeRequest(
                content=f"å¯¹L2çº§å­—æ®µ[{change['column_name']}]çš„ä¿®æ”¹è¿›è¡Œä¸“ä¸šè¯­ä¹‰åˆ†æï¼š\nåŸå€¼ï¼š{change['original_value']}\næ–°å€¼ï¼š{change['new_value']}\nè¯·åˆ¤æ–­è¿™ä¸ªä¿®æ”¹çš„åˆç†æ€§å’Œé£é™©çº§åˆ«ã€‚",
                analysis_type="risk_assessment",
                context={
                    "column_name": change['column_name'],
                    "original_value": change['original_value'],
                    "new_value": change['new_value'],
                    "risk_level": "L2",
                    "business_context": "é¡¹ç›®ç®¡ç†ç³»ç»Ÿ",
                    "position": change['position']
                }
            )
            
            # è°ƒç”¨Claudeè¿›è¡Œè¯­ä¹‰åˆ†æ
            async with claude_client as client:
                result = await client.intelligent_analyze(analyze_request)
                
                # è§£æåˆ†æç»“æœ
                if hasattr(result, 'dict'):
                    result_dict = result.dict()
                elif hasattr(result, '__dict__'):
                    result_dict = result.__dict__
                else:
                    result_dict = result
                
                # æå–å†³ç­–å»ºè®®ï¼ˆç®€å•è§£æï¼‰
                analysis_text = result_dict.get("result", "")
                confidence = result_dict.get("confidence", 0.5)
                
                # ç®€å•çš„å†³ç­–é€»è¾‘
                decision = "REVIEW"
                if "APPROVE" in analysis_text.upper() or "æ‰¹å‡†" in analysis_text or "åŒæ„" in analysis_text:
                    decision = "APPROVE"
                elif "REJECT" in analysis_text.upper() or "æ‹’ç»" in analysis_text or "ä¸åˆç†" in analysis_text:
                    decision = "REJECT"
                elif "CONDITIONAL" in analysis_text.upper() or "æ¡ä»¶" in analysis_text:
                    decision = "CONDITIONAL"
                
                analysis_results.append({
                    "column_name": change['column_name'],
                    "original_value": change['original_value'],
                    "new_value": change['new_value'],
                    "position": change['position'],
                    "decision": decision,
                    "confidence_score": confidence,
                    "analysis_result": analysis_text,
                    "risk_level": result_dict.get("risk_level", "L2"),
                    "processing_time": result_dict.get("processing_time", 0),
                    "timestamp": time.time()
                })
        
        # ç»Ÿè®¡åˆ†æç»“æœ
        summary = {
            "total_l2_changes": len(analysis_results),
            "approved": len([r for r in analysis_results if r["decision"] == "APPROVE"]),
            "rejected": len([r for r in analysis_results if r["decision"] == "REJECT"]),
            "review_required": len([r for r in analysis_results if r["decision"] == "REVIEW"]),
            "conditional": len([r for r in analysis_results if r["decision"] == "CONDITIONAL"]),
            "average_confidence": sum(r["confidence_score"] for r in analysis_results) / len(analysis_results) if analysis_results else 0
        }
        
        return {
            "success": True,
            "l2_analysis_results": analysis_results,
            "summary": summary,
            "timestamp": time.time()
        }
        
    except Exception as e:
        logger.error(f"L2è¯­ä¹‰åˆ†æå¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": f"L2è¯­ä¹‰åˆ†æå¤±è´¥: {str(e)}",
            "l2_analysis_results": []
        }

@app.post("/api/risk-scoring")
async def risk_scoring(request: dict):
    """
    ç¬¬äº”æ­¥: æ•°æ®æŒ‰è§„åˆ™æ‰“åˆ†
    
    åŸºäºL1/L2/L3é£é™©ç­‰çº§å’Œç¬¬å››æ­¥AIåˆ†æç»“æœé‡æ–°è®¡ç®—é£é™©åˆ†æ•°
    é›†æˆdocument_change_analyzer.pyçš„é£é™©è¯„çº§ç®—æ³•
    """
    try:
        logger.info(f"ğŸ¯ å¼€å§‹ç¬¬äº”æ­¥é£é™©è¯„åˆ†å¤„ç†")
        
        # æå–è¾“å…¥æ•°æ®
        l2_analysis_results = request.get("l2_analysis_results", [])
        original_differences = request.get("original_differences", [])
        processed_columns = request.get("processed_columns", [])
        
        if not original_differences:
            return {
                "success": False,
                "error": "ç¼ºå°‘åŸå§‹å·®å¼‚æ•°æ®",
                "risk_scoring_results": []
            }
        
        logger.info(f"ğŸ“Š è¾“å…¥æ•°æ®: {len(original_differences)}ä¸ªå·®å¼‚, {len(l2_analysis_results)}ä¸ªL2åˆ†æç»“æœ")
        
        # å®šä¹‰åˆ—é£é™©ç­‰çº§é…ç½®
        column_risk_levels = {
            "åºå·": "L3",                    # å¯è‡ªç”±ç¼–è¾‘
            "é¡¹ç›®ç±»å‹": "L2",                # éœ€è¦è¯­ä¹‰å®¡æ ¸  
            "æ¥æº": "L1",                    # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "ä»»åŠ¡å‘èµ·æ—¶é—´": "L1",            # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "ç›®æ ‡å¯¹é½": "L1",                # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "å…³é”®KRå¯¹é½": "L1",              # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "å…·ä½“è®¡åˆ’å†…å®¹": "L2",            # éœ€è¦è¯­ä¹‰å®¡æ ¸
            "é‚“æ€»æŒ‡å¯¼ç™»è®°": "L2",            # éœ€è¦è¯­ä¹‰å®¡æ ¸
            "è´Ÿè´£äºº": "L2",                  # éœ€è¦è¯­ä¹‰å®¡æ ¸
            "ååŠ©äºº": "L2",                  # éœ€è¦è¯­ä¹‰å®¡æ ¸
            "ç›‘ç£äºº": "L2",                  # éœ€è¦è¯­ä¹‰å®¡æ ¸
            "é‡è¦ç¨‹åº¦": "L1",                # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "é¢„è®¡å®Œæˆæ—¶é—´": "L1",            # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "å®Œæˆè¿›åº¦": "L1",                # ç»å¯¹ä¸èƒ½ä¿®æ”¹
            "å½¢æˆè®¡åˆ’æ¸…å•": "L2",            # éœ€è¦è¯­ä¹‰å®¡æ ¸
            "å¤ç›˜æ—¶é—´": "L3",                # å¯è‡ªç”±ç¼–è¾‘
            "å¯¹ä¸Šæ±‡æŠ¥": "L3",                # å¯è‡ªç”±ç¼–è¾‘
            "åº”ç”¨æƒ…å†µ": "L3",                # å¯è‡ªç”±ç¼–è¾‘
            "è¿›åº¦åˆ†ææ€»ç»“": "L3",            # å¯è‡ªç”±ç¼–è¾‘
            "å‘¨åº¦åˆ†ææ€»ç»“": "L3"             # å¯è‡ªç”±ç¼–è¾‘
        }
        
        # åŸºç¡€é£é™©è¯„åˆ†é…ç½®
        base_risk_scores = {
            "L1": 1.0,    # æœ€é«˜é£é™©
            "L2": 0.6,    # ä¸­ç­‰é£é™©
            "L3": 0.2     # æœ€ä½é£é™©
        }
        
        # åˆ›å»ºL2åˆ†æç»“æœæŸ¥æ‰¾è¡¨
        l2_analysis_lookup = {}
        for result in l2_analysis_results:
            key = f"{result.get('column_name', '')}_{result.get('position', '')}"
            l2_analysis_lookup[key] = result
        
        # å¤„ç†æ¯ä¸ªå·®å¼‚å¹¶è®¡ç®—é£é™©åˆ†æ•°
        risk_scoring_results = []
        risk_distribution = {"L1": 0, "L2": 0, "L3": 0}
        
        for diff in original_differences:
            column_name = diff.get("åˆ—å", "")
            position = diff.get("ä½ç½®", "")
            
            # è·å–åŸºç¡€é£é™©ç­‰çº§
            base_risk_level = column_risk_levels.get(column_name, "L3")
            base_risk_score = base_risk_scores[base_risk_level]
            
            # æŸ¥æ‰¾å¯¹åº”çš„L2åˆ†æç»“æœ
            lookup_key = f"{column_name}_{position}"
            l2_result = l2_analysis_lookup.get(lookup_key)
            
            # è®¡ç®—è°ƒæ•´åçš„é£é™©åˆ†æ•°
            adjusted_risk_score = base_risk_score
            final_risk_level = base_risk_level
            ai_adjustment_factor = 1.0
            
            if l2_result:
                # åŸºäºAIå†³ç­–è°ƒæ•´é£é™©åˆ†æ•°
                ai_decision = l2_result.get("decision", "REVIEW")
                ai_confidence = l2_result.get("confidence_score", 0.5)
                ai_risk_level = l2_result.get("risk_level", base_risk_level)
                
                # å†³ç­–æƒé‡è°ƒæ•´
                decision_weights = {
                    "APPROVE": 0.7,      # é™ä½é£é™©
                    "REVIEW": 1.0,       # ä¿æŒåŸé£é™©
                    "REJECT": 1.5,       # æé«˜é£é™©
                    "CONDITIONAL": 1.2   # ç•¥å¾®æé«˜é£é™©
                }
                
                # ç½®ä¿¡åº¦æƒé‡è°ƒæ•´
                confidence_factor = 0.5 + (ai_confidence * 0.5)  # 0.5-1.0èŒƒå›´
                
                # ç»¼åˆè°ƒæ•´ç³»æ•°
                ai_adjustment_factor = decision_weights.get(ai_decision, 1.0) * confidence_factor
                
                # AIé£é™©ç­‰çº§ä¼˜å…ˆçº§å¤„ç†
                if ai_risk_level in base_risk_scores:
                    ai_risk_score = base_risk_scores[ai_risk_level]
                    # ä½¿ç”¨åŠ æƒå¹³å‡
                    adjusted_risk_score = (base_risk_score * 0.4) + (ai_risk_score * 0.6)
                    adjusted_risk_score *= ai_adjustment_factor
                    
                    # ç¡®å®šæœ€ç»ˆé£é™©ç­‰çº§
                    if adjusted_risk_score >= 0.8:
                        final_risk_level = "L1"
                    elif adjusted_risk_score >= 0.4:
                        final_risk_level = "L2"
                    else:
                        final_risk_level = "L3"
                else:
                    adjusted_risk_score = base_risk_score * ai_adjustment_factor
            
            # é™åˆ¶åˆ†æ•°èŒƒå›´
            adjusted_risk_score = max(0.0, min(1.0, adjusted_risk_score))
            
            # ç»Ÿè®¡é£é™©åˆ†å¸ƒ
            risk_distribution[final_risk_level] += 1
            
            # æ„å»ºé£é™©è¯„åˆ†ç»“æœ
            scoring_result = {
                "åºå·": diff.get("åºå·", 0),
                "è¡Œå·": diff.get("è¡Œå·", 0),
                "åˆ—å": column_name,
                "ä½ç½®": position,
                "åŸå€¼": diff.get("åŸå€¼", ""),
                "æ–°å€¼": diff.get("æ–°å€¼", ""),
                "base_risk_level": base_risk_level,
                "base_risk_score": base_risk_score,
                "final_risk_level": final_risk_level,
                "adjusted_risk_score": round(adjusted_risk_score, 3),
                "ai_adjustment_factor": round(ai_adjustment_factor, 3),
                "ai_decision": l2_result.get("decision", "N/A") if l2_result else "N/A",
                "ai_confidence": l2_result.get("confidence_score", 0.0) if l2_result else 0.0,
                "has_ai_analysis": bool(l2_result)
            }
            
            risk_scoring_results.append(scoring_result)
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        total_changes = len(risk_scoring_results)
        average_risk_score = sum(r["adjusted_risk_score"] for r in risk_scoring_results) / total_changes if total_changes > 0 else 0
        ai_analyzed_count = sum(1 for r in risk_scoring_results if r["has_ai_analysis"])
        
        summary = {
            "total_changes": total_changes,
            "ai_analyzed_changes": ai_analyzed_count,
            "ai_analysis_coverage": round(ai_analyzed_count / total_changes * 100, 1) if total_changes > 0 else 0,
            "risk_distribution": risk_distribution,
            "average_risk_score": round(average_risk_score, 3),
            "highest_risk_score": max(r["adjusted_risk_score"] for r in risk_scoring_results) if risk_scoring_results else 0,
            "lowest_risk_score": min(r["adjusted_risk_score"] for r in risk_scoring_results) if risk_scoring_results else 0,
            "l1_high_risk_count": risk_distribution["L1"],
            "l2_medium_risk_count": risk_distribution["L2"],
            "l3_low_risk_count": risk_distribution["L3"]
        }
        
        logger.info(f"âœ… ç¬¬äº”æ­¥é£é™©è¯„åˆ†å®Œæˆ: {total_changes}ä¸ªå˜æ›´, å¹³å‡é£é™©{average_risk_score:.3f}")
        
        return {
            "success": True,
            "risk_scoring_results": risk_scoring_results,
            "summary": summary,
            "processing_info": {
                "total_processed": total_changes,
                "ai_enhanced": ai_analyzed_count,
                "base_algorithm": "document_change_analyzer",
                "ai_integration": "l2_semantic_analysis",
                "risk_levels": list(column_risk_levels.keys()),
                "adjustment_factors": ["decision_weight", "confidence_factor", "risk_level_override"]
            },
            "timestamp": time.time()
        }
        
    except Exception as e:
        logger.error(f"é£é™©è¯„åˆ†å¤±è´¥: {str(e)}")
        return {
            "success": False,
            "error": f"é£é™©è¯„åˆ†å¤±è´¥: {str(e)}",
            "risk_scoring_results": []
        }

@app.post("/batch", response_model=BatchAnalyzeResponse)
async def batch_analyze(request: BatchAnalyzeRequest):
    """
    æ‰¹é‡åˆ†ææ¥å£
    
    æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªæ™ºèƒ½åˆ†æè¯·æ±‚
    å¯é€‰æ‹©å¹¶è¡Œæˆ–ä¸²è¡Œå¤„ç†æ¨¡å¼
    """
    try:
        async with claude_client as client:
            batch_result = await client.batch_analyze(
                request.requests, 
                request.parallel
            )
            
            return BatchAnalyzeResponse(**batch_result)
            
    except Exception as e:
        logger.error(f"æ‰¹é‡åˆ†ææ¥å£å¼‚å¸¸: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡åˆ†æå¤±è´¥: {str(e)}")

@app.get("/stats")
async def get_api_stats():
    """
    è·å–APIç»Ÿè®¡ä¿¡æ¯
    
    è¿”å›è¯¦ç»†çš„APIè°ƒç”¨ç»Ÿè®¡å’Œæ€§èƒ½æŒ‡æ ‡
    """
    stats = claude_client.get_api_stats()
    uptime = time.time() - start_time
    
    return {
        "service_info": {
            "name": "Claude Mini Wrapper",
            "version": "1.0.0",
            "uptime": uptime,
            "uptime_formatted": f"{int(uptime//3600)}h{int((uptime%3600)//60)}m{int(uptime%60)}s"
        },
        "api_statistics": stats,
        "configuration": {
            "default_model": ClaudeConfig.DEFAULT_MODEL,
            "max_tokens": ClaudeConfig.MAX_TOKENS,
            "max_concurrent": ClaudeConfig.MAX_CONCURRENT_REQUESTS,
            "timeout": ClaudeConfig.DEFAULT_TIMEOUT
        }
    }

@app.get("/")
async def root():
    """æ ¹è·¯å¾„æ¥å£ - æœåŠ¡ä¿¡æ¯"""
    return {
        "service": "Claude Mini Wrapper",
        "version": "1.0.0",
        "description": "åŸºäºç°æœ‰ä»£ç†å’ŒSKRç çš„Claude APIå°è£…æœåŠ¡",
        "endpoints": {
            "health": "/health",
            "models": "/models", 
            "chat": "/chat",
            "chat_stream": "/chat/stream",
            "analyze": "/analyze",
            "batch": "/batch",
            "stats": "/stats",
            "docs": "/docs"
        },
        "proxy_url": ClaudeConfig.BASE_URL,
        "status": "running"
    }

if __name__ == "__main__":
    logger.info("ğŸš€ å¯åŠ¨ Claude Mini Wrapper...")
    
    # éªŒè¯é…ç½®
    if not ClaudeConfig.validate_config():
        logger.error("âŒ é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒå˜é‡")
        exit(1)
    
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        "main:app",
        host=ClaudeConfig.HOST,
        port=ClaudeConfig.PORT,
        reload=False,  # ç”Ÿäº§ç¯å¢ƒå»ºè®®è®¾ç½®ä¸ºFalse
        access_log=True
    )