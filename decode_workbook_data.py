#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§£ç è…¾è®¯æ–‡æ¡£workbookæ•°æ®ï¼ŒéªŒè¯è¡¨æ ¼å†…å®¹
"""

import json
import urllib.parse
import base64
import gzip
import io
from pathlib import Path

def decode_ejs_workbook(file_path):
    """è§£ç EJSæ ¼å¼æ–‡ä»¶ä¸­çš„workbookæ•°æ®"""
    print(f"ğŸ” è§£ç æ–‡ä»¶: {file_path}")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    if len(lines) < 8:
        print("âŒ æ–‡ä»¶è¡Œæ•°ä¸è¶³")
        return None
    
    # ç¬¬8è¡ŒåŒ…å«URLç¼–ç çš„workbookæ•°æ®
    encoded_data = lines[7].strip()  # ç¬¬8è¡Œï¼Œç´¢å¼•7
    
    print(f"ğŸ“¦ ç¼–ç æ•°æ®é•¿åº¦: {len(encoded_data)} å­—ç¬¦")
    print(f"ğŸ”¡ æ•°æ®é¢„è§ˆ: {encoded_data[:100]}...")
    
    try:
        # Step 1: URLè§£ç 
        url_decoded = urllib.parse.unquote(encoded_data)
        print(f"âœ… URLè§£ç æˆåŠŸï¼Œé•¿åº¦: {len(url_decoded)}")
        
        # Step 2: å°è¯•è§£æJSON
        try:
            json_data = json.loads(url_decoded)
            print(f"âœ… JSONè§£ææˆåŠŸ")
            
            if 'workbook' in json_data:
                workbook_data = json_data['workbook']
                print(f"ğŸ“Š æ‰¾åˆ°workbookå­—æ®µï¼Œé•¿åº¦: {len(workbook_data)}")
                
                # Step 3: workbookæ•°æ®é€šå¸¸æ˜¯Base64ç¼–ç çš„å‹ç¼©æ•°æ®
                try:
                    # å°è¯•Base64è§£ç 
                    decoded_bytes = base64.b64decode(workbook_data)
                    print(f"âœ… Base64è§£ç æˆåŠŸï¼Œå­—èŠ‚æ•°: {len(decoded_bytes)}")
                    
                    # Step 4: å°è¯•gzipè§£å‹ç¼©
                    try:
                        with gzip.open(io.BytesIO(decoded_bytes), 'rt', encoding='utf-8') as gz_file:
                            uncompressed_data = gz_file.read()
                        print(f"âœ… Gzipè§£å‹ç¼©æˆåŠŸï¼Œé•¿åº¦: {len(uncompressed_data)}")
                        
                        # åˆ†æè§£å‹åçš„æ•°æ®
                        analyze_workbook_content(uncompressed_data)
                        return uncompressed_data
                        
                    except Exception as e:
                        print(f"âš ï¸ Gzipè§£å‹ç¼©å¤±è´¥: {e}")
                        print("ğŸ” å°è¯•ç›´æ¥åˆ†æBase64è§£ç åçš„æ•°æ®...")
                        
                        # å°è¯•ä½œä¸ºæ–‡æœ¬åˆ†æ
                        try:
                            text_data = decoded_bytes.decode('utf-8', errors='ignore')
                            analyze_workbook_content(text_data)
                            return text_data
                        except:
                            print("âŒ æ— æ³•è§£æä¸ºæ–‡æœ¬")
                            return None
                    
                except Exception as e:
                    print(f"âŒ Base64è§£ç å¤±è´¥: {e}")
                    # å°è¯•ç›´æ¥åˆ†æworkbookå­—ç¬¦ä¸²
                    analyze_workbook_content(workbook_data)
                    return workbook_data
            
            else:
                print("âŒ æœªæ‰¾åˆ°workbookå­—æ®µ")
                print(f"ğŸ” å¯ç”¨å­—æ®µ: {list(json_data.keys())}")
                return None
                
        except Exception as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            return None
    
    except Exception as e:
        print(f"âŒ URLè§£ç å¤±è´¥: {e}")
        return None

def analyze_workbook_content(content):
    """åˆ†æworkbookå†…å®¹ï¼ŒæŸ¥æ‰¾è¡¨æ ¼ç›¸å…³æ•°æ®"""
    print(f"\nğŸ“Š åˆ†æworkbookå†…å®¹...")
    print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
    
    # æ£€æŸ¥è¡¨æ ¼ç›¸å…³å…³é”®è¯
    table_keywords = [
        # è‹±æ–‡å…³é”®è¯
        'cell', 'row', 'column', 'sheet', 'worksheet', 'table',
        'A1', 'B1', 'C1', 'data', 'value', 'formula',
        # ä¸­æ–‡å…³é”®è¯  
        'å•å…ƒæ ¼', 'è¡Œ', 'åˆ—', 'å·¥ä½œè¡¨', 'è¡¨æ ¼', 'æ•°æ®',
        # Excel/Spreadsheetæœ¯è¯­
        'xlsx', 'xls', 'csv', 'spreadsheet'
    ]
    
    found_keywords = []
    for keyword in table_keywords:
        if keyword.lower() in content.lower():
            # è®¡ç®—å‡ºç°æ¬¡æ•°
            count = content.lower().count(keyword.lower())
            found_keywords.append((keyword, count))
    
    if found_keywords:
        print(f"âœ… å‘ç°è¡¨æ ¼ç›¸å…³å…³é”®è¯:")
        for keyword, count in found_keywords[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"   - {keyword}: {count} æ¬¡")
    else:
        print("âš ï¸ æœªå‘ç°æ˜æ˜¾çš„è¡¨æ ¼å…³é”®è¯")
    
    # æŸ¥æ‰¾æ•°å­—æ¨¡å¼ï¼ˆå¯èƒ½æ˜¯å•å…ƒæ ¼æ•°æ®ï¼‰
    import re
    
    # æŸ¥æ‰¾å¯èƒ½çš„å•å…ƒæ ¼å¼•ç”¨ (å¦‚ A1, B2, C3)
    cell_refs = re.findall(r'[A-Z]+\d+', content)
    if cell_refs:
        print(f"âœ… å‘ç° {len(cell_refs)} ä¸ªå¯èƒ½çš„å•å…ƒæ ¼å¼•ç”¨:")
        print(f"   ç¤ºä¾‹: {cell_refs[:10]}")
    
    # æŸ¥æ‰¾æ•°å­—æ•°æ®
    numbers = re.findall(r'\b\d+\.?\d*\b', content)
    if len(numbers) > 20:  # å¦‚æœæœ‰å¾ˆå¤šæ•°å­—ï¼Œå¯èƒ½åŒ…å«è¡¨æ ¼æ•°æ®
        print(f"âœ… å‘ç°å¤§é‡æ•°å­—æ•°æ®: {len(numbers)} ä¸ªæ•°å­—")
        print(f"   ç¤ºä¾‹: {numbers[:10]}")
    
    # æ˜¾ç¤ºå†…å®¹ç‰‡æ®µç”¨äºåˆ†æ
    print(f"\nğŸ“ å†…å®¹ç‰‡æ®µåˆ†æ:")
    
    # æ˜¾ç¤ºå‰500å­—ç¬¦
    print(f"å‰500å­—ç¬¦:")
    print(content[:500])
    
    # å¦‚æœå†…å®¹å¾ˆé•¿ï¼Œä¹Ÿæ˜¾ç¤ºä¸­é—´å’Œæœ«å°¾çš„ä¸€äº›å†…å®¹
    if len(content) > 1000:
        mid_pos = len(content) // 2
        print(f"\nä¸­é—´500å­—ç¬¦ (ä½ç½® {mid_pos}):")
        print(content[mid_pos:mid_pos+500])
        
        print(f"\næœ€å500å­—ç¬¦:")
        print(content[-500:])

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ è§£ç è…¾è®¯æ–‡æ¡£workbookæ•°æ®")
    
    test_files = [
        "/root/projects/tencent-doc-manager/downloads/test_direct_1_csv.csv",
        "/root/projects/tencent-doc-manager/downloads/test_direct_3_csv.csv"
    ]
    
    results = {}
    
    for file_path in test_files:
        if not Path(file_path).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        print("\n" + "="*60)
        
        decoded_data = decode_ejs_workbook(file_path)
        
        results[file_path] = {
            "success": decoded_data is not None,
            "data_length": len(decoded_data) if decoded_data else 0
        }
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ¯ è§£ç ç»“æœæ€»ç»“")
    print("="*60)
    
    successful = 0
    for file_path, result in results.items():
        filename = Path(file_path).name
        status = "âœ…" if result["success"] else "âŒ"
        print(f"{status} {filename}: {'æˆåŠŸ' if result['success'] else 'å¤±è´¥'}")
        if result["success"]:
            print(f"   ğŸ“ æ•°æ®é•¿åº¦: {result['data_length']} å­—ç¬¦")
            successful += 1
    
    print(f"\nğŸ‰ è§£ç å®Œæˆ: {successful}/{len(results)} æ–‡ä»¶æˆåŠŸ")
    
    if successful > 0:
        print("âœ… ç¡®è®¤æ–‡ä»¶åŒ…å«å¯è§£ç çš„è¡¨æ ¼æ•°æ®!")
        print("ğŸ’¡ å¯ä»¥å¼€å§‹å¼€å‘å®Œæ•´çš„æ•°æ®æå–å’Œè½¬æ¢åŠŸèƒ½")

if __name__ == "__main__":
    main()