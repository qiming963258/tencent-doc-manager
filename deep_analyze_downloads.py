#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ·±åº¦åˆ†æä¸‹è½½çš„EJSæ–‡ä»¶ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨
"""

import json
import base64
import urllib.parse
import re
from pathlib import Path
import struct

def analyze_ejs_file(file_path):
    """æ·±åº¦åˆ†æEJSæ–‡ä»¶ç»“æ„"""
    print(f"\n{'='*80}")
    print(f"æ·±åº¦åˆ†ææ–‡ä»¶: {Path(file_path).name}")
    print(f"æ–‡ä»¶å¤§å°: {Path(file_path).stat().st_size} bytes")
    print(f"{'='*80}")
    
    with open(file_path, 'rb') as f:
        raw_bytes = f.read()
    
    # 1. æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    print("\n1. æ–‡ä»¶æ ¼å¼æ£€æŸ¥:")
    print(f"   å‰4å­—èŠ‚(hex): {raw_bytes[:4].hex()}")
    print(f"   å‰4å­—èŠ‚(ascii): {repr(raw_bytes[:4])}")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡å‡†æ ¼å¼
    if raw_bytes[:4] == b'head':
        print("   âœ… æ£€æµ‹åˆ°æ ‡å‡†EJSæ ¼å¼ (headæ ‡è¯†)")
        return analyze_standard_ejs(file_path)
    elif raw_bytes[:4] == b'text':
        print("   âœ… æ£€æµ‹åˆ°textæ ¼å¼EJS")
        return analyze_text_ejs(file_path)
    elif b'"","' in raw_bytes[:20]:
        print("   âœ… æ£€æµ‹åˆ°CSVæ ¼å¼EJS")
        return analyze_csv_ejs(file_path)
    else:
        print("   â“ æœªçŸ¥æ ¼å¼")
        return analyze_unknown_format(file_path)

def analyze_standard_ejs(file_path):
    """åˆ†ææ ‡å‡†EJSæ ¼å¼(head/json/text)"""
    print("\n2. æ ‡å‡†EJSæ ¼å¼åˆ†æ:")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    
    structure = {
        'format': 'standard_ejs',
        'sections': [],
        'has_workbook': False,
        'has_related_sheet': False,
        'metadata': None,
        'data_found': []
    }
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        if line == 'head':
            structure['sections'].append('head')
            print(f"   è¡Œ{i+1}: æ‰¾åˆ°headæ ‡è¯†")
            
        elif line == 'json':
            structure['sections'].append('json')
            if i + 2 < len(lines):
                json_length = int(lines[i + 1])
                json_data = lines[i + 2]
                print(f"   è¡Œ{i+1}: JSONæ®µ, é•¿åº¦={json_length}")
                
                try:
                    metadata = json.loads(json_data)
                    structure['metadata'] = metadata
                    
                    if 'bodyData' in metadata:
                        title = metadata['bodyData'].get('initialTitle', 'N/A')
                        print(f"      æ–‡æ¡£æ ‡é¢˜: {title}")
                        
                    if 'clientVars' in metadata:
                        user_id = metadata['clientVars'].get('userId', 'N/A')
                        print(f"      ç”¨æˆ·ID: {user_id}")
                        
                except Exception as e:
                    print(f"      JSONè§£æå¤±è´¥: {e}")
                    
        elif line == 'text':
            structure['sections'].append('text')
            print(f"   è¡Œ{i+1}: textæ®µ")
            
        elif '%7B%22workbook%22' in line or 'workbook' in line:
            print(f"   è¡Œ{i+1}: æ‰¾åˆ°workbookæ•°æ®")
            structure['has_workbook'] = True
            
            # åˆ†æworkbookå†…å®¹
            try:
                decoded = urllib.parse.unquote(line)
                data = json.loads(decoded)
                
                if 'workbook' in data:
                    wb_length = len(data['workbook'])
                    print(f"      workbook Base64é•¿åº¦: {wb_length}")
                    
                    # å°è¯•è§£ç 
                    wb_bytes = base64.b64decode(data['workbook'])
                    print(f"      è§£ç åå­—èŠ‚æ•°: {len(wb_bytes)}")
                    print(f"      å‰4å­—èŠ‚: {wb_bytes[:4].hex()}")
                    
                    # æ£€æŸ¥å‹ç¼©ç±»å‹
                    if wb_bytes[:2] == b'\x78\x01':
                        print(f"      âœ… zlibå‹ç¼©æ ¼å¼")
                    elif wb_bytes[:2] == b'\x78\x9c':
                        print(f"      âœ… zlibå‹ç¼©æ ¼å¼(é«˜å‹ç¼©)")
                    elif wb_bytes[:2] == b'\x1f\x8b':
                        print(f"      âœ… gzipå‹ç¼©æ ¼å¼")
                    else:
                        print(f"      â“ æœªçŸ¥å‹ç¼©æ ¼å¼")
                    
                if 'related_sheet' in data:
                    structure['has_related_sheet'] = True
                    rs_length = len(data['related_sheet'])
                    print(f"      related_sheeté•¿åº¦: {rs_length}")
                    
                    # å°è¯•è§£ç 
                    rs_bytes = base64.b64decode(data['related_sheet'])
                    print(f"      related_sheetè§£ç å: {len(rs_bytes)} bytes")
                    
                if 'max_row' in data:
                    print(f"      è¡¨æ ¼å¤§å°: {data['max_row']} Ã— {data['max_col']}")
                    
            except Exception as e:
                print(f"      è§£æå¤±è´¥: {e}")
        
        i += 1
    
    return structure

def analyze_text_ejs(file_path):
    """åˆ†ætextæ ¼å¼EJS"""
    print("\n2. Textæ ¼å¼EJSåˆ†æ:")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    
    for i, line in enumerate(lines[:10]):
        print(f"   è¡Œ{i+1}: {line[:80]}{'...' if len(line) > 80 else ''}")
    
    # æŸ¥æ‰¾workbook
    for line in lines:
        if 'workbook' in line:
            print("\n   æ‰¾åˆ°workbookæ•°æ®!")
            break
    
    return {'format': 'text_ejs', 'lines': len(lines)}

def analyze_csv_ejs(file_path):
    """åˆ†æCSVæ ¼å¼EJS"""
    print("\n2. CSVæ ¼å¼EJSåˆ†æ:")
    
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # ä½¿ç”¨CSVè§£æ
    import csv
    import io
    
    csv_reader = csv.reader(io.StringIO(content))
    rows = list(csv_reader)
    
    print(f"   CSVè¡Œæ•°: {len(rows)}")
    print(f"   ç¬¬ä¸€è¡Œåˆ—æ•°: {len(rows[0]) if rows else 0}")
    
    # åˆ†æå†…å®¹ç±»å‹
    all_cells = []
    chinese_cells = []
    number_cells = []
    
    for row in rows:
        for cell in row:
            cell = cell.strip()
            if cell:
                all_cells.append(cell)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ä¸­æ–‡
                if re.search(r'[\u4e00-\u9fff]', cell):
                    chinese_cells.append(cell)
                    
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å­—
                if cell.replace('.', '').replace('-', '').isdigit():
                    number_cells.append(cell)
    
    print(f"   æ€»å•å…ƒæ ¼æ•°: {len(all_cells)}")
    print(f"   ä¸­æ–‡å•å…ƒæ ¼: {len(chinese_cells)}")
    print(f"   æ•°å­—å•å…ƒæ ¼: {len(number_cells)}")
    
    # æŸ¥æ‰¾å…³é”®ä¿¡æ¯
    print("\n   å…³é”®ä¿¡æ¯æŸ¥æ‰¾:")
    
    # ç‰ˆæœ¬å·
    for cell in all_cells:
        if re.match(r'\d+\.\d+\.\d+', cell):
            print(f"      ç‰ˆæœ¬å·: {cell}")
            break
    
    # å·¥ä½œè¡¨ä¿¡æ¯
    for cell in chinese_cells:
        if 'å·¥ä½œè¡¨' in cell:
            print(f"      å·¥ä½œè¡¨: {cell}")
            break
    
    # æ˜¾ç¤ºå‰10ä¸ªä¸­æ–‡å†…å®¹
    if chinese_cells:
        print("\n   å‰10ä¸ªä¸­æ–‡å†…å®¹:")
        for i, cell in enumerate(chinese_cells[:10], 1):
            print(f"      {i}. {cell}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®æ•°æ®
    real_data = []
    for cell in all_cells:
        # æ’é™¤æ˜æ˜¾çš„ç³»ç»Ÿä¿¡æ¯
        if (len(cell) > 2 and 
            not any(k in cell.lower() for k in ['font', 'color', 'calibri', 'arial']) and
            not cell in ['*', ':', 'J', 'B', 'R']):
            real_data.append(cell)
    
    print(f"\n   å¯èƒ½çš„çœŸå®æ•°æ®: {len(real_data)}ä¸ª")
    if real_data:
        print("   ç¤ºä¾‹:")
        for i, data in enumerate(real_data[:5], 1):
            print(f"      {i}. {data[:50]}...")
    
    return {
        'format': 'csv_ejs',
        'rows': len(rows),
        'total_cells': len(all_cells),
        'chinese_cells': len(chinese_cells),
        'real_data': len(real_data)
    }

def analyze_unknown_format(file_path):
    """åˆ†ææœªçŸ¥æ ¼å¼"""
    print("\n2. æœªçŸ¥æ ¼å¼åˆ†æ:")
    
    with open(file_path, 'rb') as f:
        data = f.read()
    
    # æ˜¾ç¤ºå‰100å­—èŠ‚
    print(f"   å‰100å­—èŠ‚(hex):")
    print(f"   {data[:100].hex()}")
    
    # å°è¯•ä½œä¸ºæ–‡æœ¬
    try:
        text = data.decode('utf-8')
        print(f"   UTF-8è§£ç æˆåŠŸ, é•¿åº¦={len(text)}")
        
        # æŸ¥æ‰¾å…³é”®è¯
        if 'workbook' in text:
            print("   âœ… åŒ…å«workbookå…³é”®è¯")
        if 'å·¥ä½œè¡¨' in text:
            print("   âœ… åŒ…å«ä¸­æ–‡'å·¥ä½œè¡¨'")
            
    except:
        print("   âŒ ä¸æ˜¯UTF-8æ–‡æœ¬")
    
    return {'format': 'unknown'}

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ·±åº¦åˆ†æä¸‹è½½çš„EJSæ–‡ä»¶")
    print("="*80)
    
    # åˆ†ææ‰€æœ‰ä¸‹è½½çš„æ–‡ä»¶
    test_dir = Path('/root/projects/tencent-doc-manager/real_test_results')
    ejs_files = list(test_dir.glob('*.ejs'))
    
    if not ejs_files:
        # å°è¯•å…¶ä»–ä½ç½®
        test_dir = Path('/root/projects/tencent-doc-manager')
        ejs_files = list(test_dir.glob('test_*.csv')) + list(test_dir.glob('test_*.xlsx'))
    
    print(f"æ‰¾åˆ° {len(ejs_files)} ä¸ªæ–‡ä»¶å¾…åˆ†æ")
    
    results = []
    for ejs_file in ejs_files:
        result = analyze_ejs_file(str(ejs_file))
        result['file'] = ejs_file.name
        results.append(result)
    
    # æ€»ç»“
    print("\n" + "="*80)
    print("ğŸ“Š åˆ†ææ€»ç»“")
    print("="*80)
    
    for result in results:
        print(f"\næ–‡ä»¶: {result['file']}")
        print(f"   æ ¼å¼: {result.get('format', 'unknown')}")
        
        if result.get('has_workbook'):
            print(f"   âœ… åŒ…å«workbookæ•°æ®")
        if result.get('has_related_sheet'):
            print(f"   âœ… åŒ…å«related_sheetæ•°æ®")
        if result.get('chinese_cells'):
            print(f"   ä¸­æ–‡å†…å®¹: {result['chinese_cells']}ä¸ª")
        if result.get('real_data'):
            print(f"   å¯èƒ½çš„çœŸå®æ•°æ®: {result['real_data']}ä¸ª")
    
    # é—®é¢˜è¯Šæ–­
    print("\n" + "="*80)
    print("ğŸ” é—®é¢˜è¯Šæ–­")
    print("="*80)
    
    csv_format_files = [r for r in results if r.get('format') == 'csv_ejs']
    if csv_format_files:
        print("\né—®é¢˜åŸå› ï¼š")
        print("1. æ–°ä¸‹è½½çš„æ–‡æ¡£ä½¿ç”¨CSVæ ¼å¼è€Œä¸æ˜¯æ ‡å‡†EJSæ ¼å¼")
        print("2. CSVæ ¼å¼ä¸­çš„æ•°æ®å·²ç»éƒ¨åˆ†è§£å¯†ï¼Œä½†ä»åŒ…å«ç¼–ç å†…å®¹")
        print("3. ä¸­æ–‡å†…å®¹å­˜åœ¨ä½†æ˜¯ä¹±ç ï¼Œå¯èƒ½æ˜¯ï¼š")
        print("   - protobufäºŒè¿›åˆ¶æ•°æ®è¯¯è¯»ä¸ºUTF-8")
        print("   - éœ€è¦é¢å¤–çš„è§£ç æ­¥éª¤")
        print("   - æµ‹è¯•æ–‡æ¡£æœ¬èº«æ˜¯ç©ºç™½æˆ–åªæœ‰æ ¼å¼æ²¡æœ‰æ•°æ®")
        
        print("\nè§£å†³æ–¹æ¡ˆï¼š")
        print("1. éœ€è¦è¯†åˆ«å¹¶è·³è¿‡protobufç¼–ç çš„éƒ¨åˆ†")
        print("2. åªæå–çœŸæ­£çš„æ–‡æœ¬å†…å®¹")
        print("3. æˆ–è€…ç”¨åŒ…å«å®é™…æ•°æ®çš„æ–‡æ¡£é‡æ–°æµ‹è¯•")

if __name__ == "__main__":
    main()