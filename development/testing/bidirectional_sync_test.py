#!/usr/bin/env python3
"""
è…¾è®¯æ–‡æ¡£åŒå‘åŒæ­¥å®Œæ•´æµç¨‹
å®ç°ï¼šåŸç‰ˆè¡¨â†’AIåˆ†æâ†’ä¸Šä¼ ç»“æœåˆ°è…¾è®¯æ–‡æ¡£â†’çƒ­åŠ›å›¾é“¾æ¥ç»‘å®š
"""

import requests
import pandas as pd
import json
import time
import os
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Any
import base64
import hashlib

class TencentDocBidirectionalSync:
    """è…¾è®¯æ–‡æ¡£åŒå‘åŒæ­¥å™¨"""
    
    def __init__(self):
        self.ui_server_url = "http://192.140.176.198:8089"
        self.claude_api_url = "http://localhost:8081"
        self.original_file = "/root/projects/tencent-doc-manager/test_original.csv"
        self.modified_file = "/root/projects/tencent-doc-manager/test_modified.csv"
        self.uploads_dir = "/root/projects/tencent-doc-manager/uploads"
        self.test_start_time = datetime.now()
        
        # æ¨¡æ‹Ÿè…¾è®¯æ–‡æ¡£APIé…ç½®
        self.tencent_doc_config = {
            "base_url": "https://docs.qq.com/api/v1",
            "upload_endpoint": "/sheets/create",
            "cookie": "your_tencent_doc_cookie_here"  # å®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®Cookie
        }
        
        os.makedirs(self.uploads_dir, exist_ok=True)
        
    def load_and_compare_tables(self) -> Dict[str, Any]:
        """æ­¥éª¤1-3: åŠ è½½è¡¨æ ¼å¹¶æ‰§è¡Œå¯¹æ¯”åˆ†æ"""
        print("ğŸ”„ æ­¥éª¤1-3: è¡¨æ ¼åŠ è½½ä¸å¯¹æ¯”åˆ†æ...")
        
        # åŠ è½½è¡¨æ ¼
        original_df = pd.read_csv(self.original_file, encoding='utf-8')
        modified_df = pd.read_csv(self.modified_file, encoding='utf-8')
        
        # æ‰§è¡Œå¯¹æ¯”åˆ†æï¼ˆé‡ç”¨ä¹‹å‰çš„é€»è¾‘ï¼‰
        changes = self._compare_tables(original_df, modified_df)
        
        print(f"âœ… å¯¹æ¯”å®Œæˆ: å‘ç° {len(changes['modified_cells'])} å¤„å˜æ›´")
        return {
            'original_df': original_df,
            'modified_df': modified_df,
            'changes': changes
        }
    
    def call_claude_ai_analysis(self, changes: Dict[str, Any]) -> Dict[str, Any]:
        """æ­¥éª¤4: è°ƒç”¨Claude APIè¿›è¡ŒAIè¯­ä¹‰åˆ†æ"""
        print("ğŸ”„ æ­¥éª¤4: è°ƒç”¨Claude APIè¿›è¡ŒAIè¯­ä¹‰åˆ†æ...")
        
        ai_analyses = []
        
        for change in changes['modified_cells']:
            # æ¨¡æ‹ŸClaude APIè°ƒç”¨
            ai_analysis = self._simulate_claude_analysis(change)
            ai_analyses.append(ai_analysis)
            
        print(f"âœ… AIåˆ†æå®Œæˆ: {len(ai_analyses)} ä¸ªå˜æ›´å·²åˆ†æ")
        return {'ai_analyses': ai_analyses}
    
    def create_ai_enhanced_table(self, comparison_data: Dict[str, Any], ai_data: Dict[str, Any]) -> str:
        """æ­¥éª¤5: åˆ›å»ºAIå¢å¼ºçš„åŠå¡«å……è¡¨"""
        print("ğŸ”„ æ­¥éª¤5: åˆ›å»ºAIå¢å¼ºåŠå¡«å……è¡¨...")
        
        original_df = comparison_data['original_df']
        changes = comparison_data['changes']
        ai_analyses = ai_data['ai_analyses']
        
        # åˆ›å»ºAIå¢å¼ºè¡¨æ ¼
        result_df = original_df.copy()
        
        # æ·»åŠ AIåˆ†æåˆ—
        result_df['å˜æ›´æ£€æµ‹'] = ''
        result_df['é£é™©ç­‰çº§'] = ''
        result_df['å˜æ›´å¼ºåº¦'] = ''
        result_df['Claudeæ¨è'] = ''
        result_df['AIç½®ä¿¡åº¦'] = ''
        result_df['AIæ¨ç†'] = ''
        result_df['ä¸šåŠ¡å½±å“'] = ''
        result_df['å»ºè®®è¡ŒåŠ¨'] = ''
        result_df['åˆ†ææ—¶é—´'] = ''
        
        # å¡«å……AIåˆ†æç»“æœ
        for i, change in enumerate(changes['modified_cells']):
            row_idx = change['row']
            ai_analysis = ai_analyses[i] if i < len(ai_analyses) else {}
            
            result_df.loc[row_idx, 'å˜æ›´æ£€æµ‹'] = f"æ£€æµ‹åˆ°å˜æ›´: {change['column']}"
            result_df.loc[row_idx, 'é£é™©ç­‰çº§'] = change['risk_level']
            result_df.loc[row_idx, 'å˜æ›´å¼ºåº¦'] = f"{change['intensity']:.2f}"
            result_df.loc[row_idx, 'Claudeæ¨è'] = ai_analysis.get('recommendation', 'REVIEW')
            result_df.loc[row_idx, 'AIç½®ä¿¡åº¦'] = f"{ai_analysis.get('confidence', 0.85):.2f}"
            result_df.loc[row_idx, 'AIæ¨ç†'] = ai_analysis.get('reasoning', 'éœ€è¦äººå·¥å®¡æ ¸')
            result_df.loc[row_idx, 'ä¸šåŠ¡å½±å“'] = ai_analysis.get('business_impact', 'MEDIUM')
            result_df.loc[row_idx, 'å»ºè®®è¡ŒåŠ¨'] = ai_analysis.get('suggested_action', 'äººå·¥ç¡®è®¤åå¤„ç†')
            result_df.loc[row_idx, 'åˆ†ææ—¶é—´'] = self.test_start_time.isoformat()
        
        # ä¿å­˜AIå¢å¼ºè¡¨æ ¼
        timestamp = int(time.time())
        filename = f"ai_enhanced_result_{timestamp}.csv"
        filepath = os.path.join(self.uploads_dir, filename)
        result_df.to_csv(filepath, index=False, encoding='utf-8')
        
        print(f"âœ… AIå¢å¼ºè¡¨å·²åˆ›å»º: {filename}")
        return filename
    
    def upload_to_tencent_doc(self, local_filename: str) -> str:
        """æ­¥éª¤6: ä¸Šä¼ AIåŠå¡«å……è¡¨åˆ°è…¾è®¯æ–‡æ¡£ï¼ˆå…³é”®æ­¥éª¤ï¼‰"""
        print("ğŸ”„ æ­¥éª¤6: ä¸Šä¼ AIåˆ†æç»“æœåˆ°è…¾è®¯æ–‡æ¡£...")
        
        try:
            # è¯»å–æœ¬åœ°æ–‡ä»¶
            local_filepath = os.path.join(self.uploads_dir, local_filename)
            
            # æ¨¡æ‹Ÿè…¾è®¯æ–‡æ¡£ä¸Šä¼ APIè°ƒç”¨
            # å®é™…åœºæ™¯ä¸­éœ€è¦ä½¿ç”¨çœŸå®çš„è…¾è®¯æ–‡æ¡£API
            upload_result = self._simulate_tencent_upload(local_filepath)
            
            if upload_result['success']:
                tencent_doc_url = upload_result['doc_url']
                print(f"âœ… ä¸Šä¼ æˆåŠŸ: {tencent_doc_url}")
                return tencent_doc_url
            else:
                print(f"âŒ ä¸Šä¼ å¤±è´¥: {upload_result['error']}")
                return None
                
        except Exception as e:
            print(f"âŒ ä¸Šä¼ å¼‚å¸¸: {e}")
            return None
    
    def update_heatmap_with_tencent_links(self, ui_data: Dict[str, Any], tencent_doc_url: str) -> Dict[str, Any]:
        """æ­¥éª¤7: å°†çƒ­åŠ›å›¾è¡¨æ ¼åä¸è…¾è®¯æ–‡æ¡£é“¾æ¥ç»‘å®š"""
        print("ğŸ”„ æ­¥éª¤7: æ›´æ–°çƒ­åŠ›å›¾ï¼Œç»‘å®šè…¾è®¯æ–‡æ¡£é“¾æ¥...")
        
        # æ›´æ–°UIæ•°æ®ï¼Œæ·»åŠ è…¾è®¯æ–‡æ¡£é“¾æ¥ç»‘å®š
        if 'tables' in ui_data and len(ui_data['tables']) > 0:
            # ä¸ºç¬¬ä¸€ä¸ªè¡¨æ ¼ï¼ˆæµ‹è¯•è¡¨ï¼‰æ·»åŠ è…¾è®¯æ–‡æ¡£é“¾æ¥
            ui_data['tables'][0]['tencent_doc_url'] = tencent_doc_url
            ui_data['tables'][0]['tencent_doc_title'] = f"AIåˆ†æç»“æœ-{ui_data['tables'][0]['name']}"
            ui_data['tables'][0]['sync_status'] = 'uploaded'
            ui_data['tables'][0]['sync_timestamp'] = self.test_start_time.isoformat()
            
            # æ·»åŠ åŒå‘åŒæ­¥å…ƒæ•°æ®
            ui_data['bidirectional_sync'] = {
                'enabled': True,
                'upload_success': True,
                'tencent_doc_url': tencent_doc_url,
                'last_sync': self.test_start_time.isoformat(),
                'sync_direction': 'bidirectional'
            }
        
        print(f"âœ… é“¾æ¥ç»‘å®šå®Œæˆ: è¡¨æ ¼åç°åœ¨é“¾æ¥åˆ°è…¾è®¯æ–‡æ¡£")
        return ui_data
    
    def _compare_tables(self, original_df: pd.DataFrame, modified_df: pd.DataFrame) -> Dict[str, Any]:
        """å†…éƒ¨æ–¹æ³•: è¡¨æ ¼å¯¹æ¯”é€»è¾‘"""
        changes = {
            'modified_cells': [],
            'statistics': {}
        }
        
        column_risk_levels = {
            'åºå·': 'L3', 'é¡¹ç›®ç±»å‹': 'L2', 'æ¥æº': 'L1', 'ä»»åŠ¡å‘èµ·æ—¶é—´': 'L1',
            'è´Ÿè´£äºº': 'L2', 'ååŠ©äºº': 'L2', 'å…·ä½“è®¡åˆ’å†…å®¹': 'L2', 'é‡è¦ç¨‹åº¦': 'L1',
            'é¢„è®¡å®Œæˆæ—¶é—´': 'L1', 'å®Œæˆè¿›åº¦': 'L1'
        }
        
        for row_idx in range(min(len(original_df), len(modified_df))):
            for col_idx, col_name in enumerate(original_df.columns):
                if col_name in modified_df.columns:
                    original_val = str(original_df.iloc[row_idx, col_idx])
                    modified_val = str(modified_df.iloc[row_idx, col_idx])
                    
                    if original_val != modified_val:
                        risk_level = column_risk_levels.get(col_name, 'L2')
                        intensity = 0.4 + np.random.random() * 0.4
                        
                        changes['modified_cells'].append({
                            'row': row_idx,
                            'column': col_name,
                            'column_index': col_idx,
                            'original_value': original_val,
                            'modified_value': modified_val,
                            'risk_level': risk_level,
                            'intensity': intensity,
                            'timestamp': self.test_start_time.isoformat()
                        })
        
        changes['statistics'] = {
            'total_changes': len(changes['modified_cells']),
            'table_name': 'æµ‹è¯•é¡¹ç›®ç®¡ç†è¡¨'
        }
        
        return changes
    
    def _simulate_claude_analysis(self, change: Dict[str, Any]) -> Dict[str, Any]:
        """å†…éƒ¨æ–¹æ³•: æ¨¡æ‹ŸClaude AIåˆ†æ"""
        column = change['column']
        original = change['original_value']
        new_value = change['modified_value']
        
        # æ¨¡æ‹Ÿä¸åŒç±»å‹å˜æ›´çš„AIåˆ†æç»“æœ
        if column == 'è´Ÿè´£äºº':
            return {
                'recommendation': 'REVIEW',
                'confidence': 0.85,
                'reasoning': f'äººå‘˜å˜æ›´ä»{original}åˆ°{new_value}éœ€è¦ç¡®è®¤æ–°è´Ÿè´£äººå…·å¤‡ç›¸åº”æŠ€èƒ½å’Œæƒé™',
                'business_impact': 'MEDIUM',
                'suggested_action': 'ç¡®è®¤æ–°è´Ÿè´£äººèµ„è´¨å’Œé¡¹ç›®äº¤æ¥å®Œæˆåæ‰¹å‡†',
                'risk_factors': ['äººå‘˜æƒé™å˜æ›´', 'é¡¹ç›®è¿ç»­æ€§é£é™©'],
                'approval_conditions': ['æ–°è´Ÿè´£äººæŠ€èƒ½è¯„ä¼°', 'é¡¹ç›®äº¤æ¥ç¡®è®¤']
            }
        elif column == 'ååŠ©äºº':
            return {
                'recommendation': 'APPROVE',
                'confidence': 0.92,
                'reasoning': f'ååŠ©äººå˜æ›´ä»{original}åˆ°{new_value}å±äºæ­£å¸¸äººå‘˜è°ƒæ•´',
                'business_impact': 'LOW',
                'suggested_action': 'å¯ç›´æ¥æ‰¹å‡†ï¼Œå»ºè®®é€šçŸ¥ç›¸å…³å›¢é˜Ÿæˆå‘˜',
                'risk_factors': ['å›¢é˜Ÿåä½œè°ƒæ•´'],
                'approval_conditions': ['å›¢é˜Ÿé€šçŸ¥']
            }
        elif column == 'å…·ä½“è®¡åˆ’å†…å®¹':
            return {
                'recommendation': 'APPROVE',
                'confidence': 0.88,
                'reasoning': f'è®¡åˆ’å†…å®¹ä¼˜åŒ–åˆç†ï¼Œä»"{original}"å¢åŠ åˆ°"{new_value}"',
                'business_impact': 'LOW',
                'suggested_action': 'æŠ€æœ¯æ”¹è¿›åˆç†ï¼Œå»ºè®®æ‰¹å‡†å®æ–½',
                'risk_factors': ['æŠ€æœ¯å¤æ‚åº¦å¢åŠ '],
                'approval_conditions': ['æŠ€æœ¯å¯è¡Œæ€§ç¡®è®¤']
            }
        else:
            return {
                'recommendation': 'REVIEW',
                'confidence': 0.75,
                'reasoning': f'éœ€è¦äººå·¥å®¡æ ¸{column}çš„å˜æ›´',
                'business_impact': 'MEDIUM',
                'suggested_action': 'å»ºè®®è¯¦ç»†è¯„ä¼°åå†³å®š',
                'risk_factors': ['å˜æ›´å½±å“å¾…è¯„ä¼°'],
                'approval_conditions': ['è¯¦ç»†è¯„ä¼°']
            }
    
    def _simulate_tencent_upload(self, filepath: str) -> Dict[str, Any]:
        """å†…éƒ¨æ–¹æ³•: æ¨¡æ‹Ÿè…¾è®¯æ–‡æ¡£ä¸Šä¼ """
        # å®é™…åœºæ™¯ä¸­è¿™é‡Œä¼šè°ƒç”¨çœŸå®çš„è…¾è®¯æ–‡æ¡£API
        # ç°åœ¨æ¨¡æ‹Ÿä¸€ä¸ªæˆåŠŸçš„ä¸Šä¼ ç»“æœ
        
        # ç”Ÿæˆæ¨¡æ‹Ÿçš„è…¾è®¯æ–‡æ¡£é“¾æ¥
        timestamp = int(time.time())
        doc_id = f"AI{timestamp}{hash(filepath) % 10000:04d}"
        
        return {
            'success': True,
            'doc_id': doc_id,
            'doc_url': f"https://docs.qq.com/sheet/{doc_id}",
            'doc_title': f"AIåˆ†æç»“æœ-æµ‹è¯•é¡¹ç›®ç®¡ç†è¡¨-{timestamp}",
            'upload_time': self.test_start_time.isoformat()
        }
    
    def run_complete_bidirectional_sync(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´çš„åŒå‘åŒæ­¥æµç¨‹"""
        print("ğŸš€ å¼€å§‹è…¾è®¯æ–‡æ¡£åŒå‘åŒæ­¥å®Œæ•´æµç¨‹")
        print("=" * 70)
        
        test_result = {
            'test_name': 'è…¾è®¯æ–‡æ¡£åŒå‘åŒæ­¥æµç¨‹æµ‹è¯•',
            'start_time': self.test_start_time.isoformat(),
            'steps': [],
            'success': True
        }
        
        try:
            # æ­¥éª¤1-3: è¡¨æ ¼å¯¹æ¯”åˆ†æ
            comparison_data = self.load_and_compare_tables()
            test_result['steps'].append({
                'step': '1-3', 
                'status': 'success', 
                'description': f'è¡¨æ ¼å¯¹æ¯”å®Œæˆï¼Œå‘ç°{len(comparison_data["changes"]["modified_cells"])}å¤„å˜æ›´'
            })
            
            # æ­¥éª¤4: Claude AIåˆ†æ
            ai_data = self.call_claude_ai_analysis(comparison_data['changes'])
            test_result['steps'].append({
                'step': 4, 
                'status': 'success', 
                'description': 'Claude AIè¯­ä¹‰åˆ†æå®Œæˆ'
            })
            
            # æ­¥éª¤5: åˆ›å»ºAIå¢å¼ºè¡¨
            ai_enhanced_filename = self.create_ai_enhanced_table(comparison_data, ai_data)
            test_result['steps'].append({
                'step': 5, 
                'status': 'success', 
                'description': f'AIå¢å¼ºè¡¨å·²åˆ›å»º: {ai_enhanced_filename}'
            })
            
            # æ­¥éª¤6: ä¸Šä¼ åˆ°è…¾è®¯æ–‡æ¡£ï¼ˆå…³é”®æ­¥éª¤ï¼‰
            tencent_doc_url = self.upload_to_tencent_doc(ai_enhanced_filename)
            if tencent_doc_url:
                test_result['steps'].append({
                    'step': 6, 
                    'status': 'success', 
                    'description': f'å·²ä¸Šä¼ åˆ°è…¾è®¯æ–‡æ¡£: {tencent_doc_url}'
                })
            else:
                test_result['steps'].append({
                    'step': 6, 
                    'status': 'failed', 
                    'description': 'è…¾è®¯æ–‡æ¡£ä¸Šä¼ å¤±è´¥'
                })
                
            # æ­¥éª¤7: ç”ŸæˆUIæ•°æ®å¹¶ç»‘å®šé“¾æ¥
            ui_data = self._generate_ui_data(comparison_data, ai_data)
            if tencent_doc_url:
                ui_data = self.update_heatmap_with_tencent_links(ui_data, tencent_doc_url)
            
            test_result['steps'].append({
                'step': 7, 
                'status': 'success', 
                'description': 'çƒ­åŠ›å›¾é“¾æ¥ç»‘å®šå®Œæˆ'
            })
            
            # ä¿å­˜æœ€ç»ˆç»“æœ
            result_file = f"/root/projects/tencent-doc-manager/bidirectional_sync_data_{int(time.time())}.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(ui_data, f, ensure_ascii=False, indent=2)
            
            test_result['summary'] = {
                'total_changes': len(comparison_data['changes']['modified_cells']),
                'ai_enhanced_file': ai_enhanced_filename,
                'tencent_doc_url': tencent_doc_url,
                'ui_data_file': result_file,
                'bidirectional_sync': 'success'
            }
            
        except Exception as e:
            test_result['success'] = False
            test_result['error'] = str(e)
            
        test_result['end_time'] = datetime.now().isoformat()
        return test_result
    
    def _generate_ui_data(self, comparison_data: Dict[str, Any], ai_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”ŸæˆUIæ˜¾ç¤ºæ•°æ®"""
        changes = comparison_data['changes']
        
        return {
            'tables': [{
                'id': 0,
                'name': 'æµ‹è¯•é¡¹ç›®ç®¡ç†è¡¨',
                'url': 'https://docs.qq.com/sheet/test-monitoring-table',
                'columns': ['åºå·', 'é¡¹ç›®ç±»å‹', 'æ¥æº', 'ä»»åŠ¡å‘èµ·æ—¶é—´', 'è´Ÿè´£äºº', 'ååŠ©äºº', 
                          'å…·ä½“è®¡åˆ’å†…å®¹', 'é‡è¦ç¨‹åº¦', 'é¢„è®¡å®Œæˆæ—¶é—´', 'å®Œæˆè¿›åº¦'],
                'maxCellRisk': max([c['intensity'] for c in changes['modified_cells']] + [0]),
                'criticalModifications': len([c for c in changes['modified_cells'] if c['intensity'] > 0.8]),
                'avgRisk': np.mean([c['intensity'] for c in changes['modified_cells']] + [0])
            }],
            'statistics': {
                'totalModifications': len(changes['modified_cells']),
                'ai_analyses_count': len(ai_data['ai_analyses']),
                'approve_count': len([a for a in ai_data['ai_analyses'] if a.get('recommendation') == 'APPROVE']),
                'review_count': len([a for a in ai_data['ai_analyses'] if a.get('recommendation') == 'REVIEW']),
                'reject_count': len([a for a in ai_data['ai_analyses'] if a.get('recommendation') == 'REJECT'])
            }
        }

def main():
    """ä¸»å‡½æ•°"""
    sync_tester = TencentDocBidirectionalSync()
    result = sync_tester.run_complete_bidirectional_sync()
    
    print("\n" + "=" * 70)
    print("ğŸ“Š åŒå‘åŒæ­¥æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    if result['success']:
        print("âœ… æµ‹è¯•çŠ¶æ€: åŒå‘åŒæ­¥æˆåŠŸ")
        print(f"ğŸ“‹ æ£€æµ‹å˜æ›´: {result['summary']['total_changes']}å¤„")
        print(f"ğŸ¤– AIåˆ†ææ–‡ä»¶: {result['summary']['ai_enhanced_file']}")
        print(f"ğŸ“¤ è…¾è®¯æ–‡æ¡£é“¾æ¥: {result['summary']['tencent_doc_url']}")
        print(f"ğŸ”— åŒå‘åŒæ­¥çŠ¶æ€: {result['summary']['bidirectional_sync']}")
        print(f"ğŸŒ UIæ•°æ®æ–‡ä»¶: {result['summary']['ui_data_file']}")
    else:
        print(f"âŒ æµ‹è¯•çŠ¶æ€: å¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
    
    return result

if __name__ == "__main__":
    main()