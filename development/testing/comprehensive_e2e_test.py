#!/usr/bin/env python3
"""
å®Œæ•´ç«¯åˆ°ç«¯æ•°æ®å¤„ç†æµç¨‹æµ‹è¯•
æµ‹è¯•è‡ªé€‚åº”è¡¨æ ¼å¯¹æ¯” + AIè¯­ä¹‰åˆ†æ + Excelå¯è§†åŒ–çš„å®Œæ•´æµç¨‹
"""

import asyncio
import pandas as pd
import sys
import json
import time
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/projects/tencent-doc-manager')

from claude_wrapper_integration import ClaudeWrapperClient, ClaudeWrapperConfig, AISemanticAnalysisOrchestrator
from adaptive_table_comparator import AdaptiveTableComparator, IntelligentColumnMatcher
from document_change_analyzer import DocumentChangeAnalyzer

class ComprehensiveE2ETest:
    """å®Œæ•´çš„ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def __init__(self):
        self.analyzer = DocumentChangeAnalyzer()
        self.comparator = AdaptiveTableComparator()
        self.ai_orchestrator = AISemanticAnalysisOrchestrator()
        
    async def run_complete_workflow_test(self):
        """è¿è¡Œå®Œæ•´å·¥ä½œæµæµ‹è¯•"""
        print("ğŸš€ å¼€å§‹ç«¯åˆ°ç«¯æ•°æ®å¤„ç†æµç¨‹æµ‹è¯•")
        print("=" * 60)
        
        # ç¬¬1é˜¶æ®µï¼šæ•°æ®åŠ è½½
        print("ğŸ“Š ç¬¬1é˜¶æ®µï¼šæ•°æ®åŠ è½½å’Œè§£æ")
        try:
            original_df = pd.read_csv('enterprise_test_original.csv', encoding='utf-8-sig')
            modified_df = pd.read_csv('enterprise_test_modified.csv', encoding='utf-8-sig')
            print(f"âœ… åŸå§‹è¡¨æ ¼: {len(original_df)}è¡Œ x {len(original_df.columns)}åˆ—")
            print(f"âœ… ä¿®æ”¹è¡¨æ ¼: {len(modified_df)}è¡Œ x {len(modified_df.columns)}åˆ—")
            print(f"ğŸ“‹ åˆ—å: {list(original_df.columns)}")
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return
        
        # ç¬¬2é˜¶æ®µï¼šè‡ªé€‚åº”è¡¨æ ¼å¯¹æ¯”
        print(f"\\nğŸ” ç¬¬2é˜¶æ®µï¼šè‡ªé€‚åº”è¡¨æ ¼å¯¹æ¯”åˆ†æ")
        try:
            # è½¬æ¢ä¸ºç³»ç»Ÿéœ€è¦çš„æ ¼å¼
            original_tables = [{
                "name": "ä¼ä¸šé¡¹ç›®ç®¡ç†è¡¨_åŸå§‹ç‰ˆ",
                "data": [original_df.columns.tolist()] + original_df.values.tolist()
            }]
            
            modified_tables = [{
                "name": "ä¼ä¸šé¡¹ç›®ç®¡ç†è¡¨_ä¿®æ”¹ç‰ˆ", 
                "data": [modified_df.columns.tolist()] + modified_df.values.tolist()
            }]
            
            # æ‰§è¡Œè‡ªé€‚åº”å¯¹æ¯”
            comparison_result = self.comparator.adaptive_compare_tables(
                modified_tables, original_tables
            )
            
            print(f"âœ… è‡ªé€‚åº”å¯¹æ¯”å®Œæˆ")
            print(f"ğŸ“Š å¯¹æ¯”ç»“æœæ•°é‡: {len(comparison_result.get('comparison_results', []))}")
            
            # åˆ†æå˜æ›´è¯¦æƒ…
            changes_found = []
            l1_changes = 0
            l2_changes = 0  
            l3_changes = 0
            
            for comp in comparison_result.get("comparison_results", []):
                change_result = comp.get("change_detection_result", {})
                if "changes" in change_result:
                    for change in change_result["changes"]:
                        changes_found.append(change)
                        risk_level = change.get("risk_level", "L3")
                        if risk_level == "L1":
                            l1_changes += 1
                        elif risk_level == "L2":
                            l2_changes += 1
                        else:
                            l3_changes += 1
            
            print(f"ğŸ“ˆ å‘ç°å˜æ›´æ€»æ•°: {len(changes_found)}")
            print(f"âš ï¸ L1çº§åˆ«å˜æ›´: {l1_changes}ä¸ª (ç»å¯¹ç¦æ­¢)")
            print(f"ğŸ” L2çº§åˆ«å˜æ›´: {l2_changes}ä¸ª (éœ€AIåˆ†æ)")
            print(f"âœ… L3çº§åˆ«å˜æ›´: {l3_changes}ä¸ª (å¯è‡ªç”±ç¼–è¾‘)")
            
        except Exception as e:
            print(f"âŒ è¡¨æ ¼å¯¹æ¯”å¤±è´¥: {e}")
            return
        
        # ç¬¬3é˜¶æ®µï¼šAIè¯­ä¹‰åˆ†æ (ä»…L2çº§åˆ«)
        if l2_changes > 0:
            print(f"\\nğŸ¤– ç¬¬3é˜¶æ®µï¼šAIè¯­ä¹‰åˆ†æ (å¤„ç†{l2_changes}ä¸ªL2ä¿®æ”¹)")
            try:
                # æ„é€ L2ä¿®æ”¹åˆ†æè¯·æ±‚
                l2_modifications = []
                for change in changes_found:
                    if change.get("risk_level") == "L2":
                        # åˆ›å»ºå…¼å®¹çš„ä¿®æ”¹è¯·æ±‚
                        mod_request = {
                            "modification_id": f"mod_{change.get('row_index', 0)}_{change.get('column_name', 'unknown')}",
                            "table_name": "ä¼ä¸šé¡¹ç›®ç®¡ç†è¡¨",
                            "column_name": change.get("column_name", "unknown"),
                            "original_value": str(change.get("original_value", "")),
                            "new_value": str(change.get("new_value", "")),
                            "change_context": f"è¡Œ{change.get('row_index', 0)}çš„{change.get('column_name', '')}å­—æ®µä¿®æ”¹"
                        }
                        l2_modifications.append(mod_request)
                
                if l2_modifications:
                    # è°ƒç”¨AIåˆ†æ
                    ai_results = await self.ai_orchestrator.analyze_modifications_with_caching(
                        l2_modifications, use_cache=True
                    )
                    
                    print(f"âœ… AIåˆ†æå®Œæˆï¼Œå¤„ç†äº†{len(ai_results)}ä¸ªä¿®æ”¹")
                    
                    # åˆ†æAIç»“æœ
                    approve_count = 0
                    reject_count = 0
                    review_count = 0
                    high_confidence_rejections = 0
                    
                    for result in ai_results:
                        if hasattr(result, '__dict__'):
                            result_dict = result.__dict__
                        else:
                            result_dict = result
                            
                        recommendation = result_dict.get("recommendation", "REVIEW")
                        confidence = result_dict.get("confidence", 0)
                        
                        if recommendation == "APPROVE":
                            approve_count += 1
                        elif recommendation == "REJECT":
                            reject_count += 1
                            if confidence > 0.8:
                                high_confidence_rejections += 1
                        else:
                            review_count += 1
                    
                    print(f"ğŸ“Š AIåˆ†æç»“æœåˆ†å¸ƒ:")
                    print(f"   âœ… å»ºè®®æ‰¹å‡†: {approve_count}ä¸ª")
                    print(f"   âŒ å»ºè®®æ‹’ç»: {reject_count}ä¸ª (é«˜ç½®ä¿¡åº¦æ‹’ç»: {high_confidence_rejections}ä¸ª)")
                    print(f"   ğŸ” éœ€è¦å®¡æ ¸: {review_count}ä¸ª")
                    
                    # å±•ç¤ºå…·ä½“åˆ†æç»“æœ
                    print(f"\\nğŸ“‹ è¯¦ç»†AIåˆ†æç»“æœ:")
                    for i, result in enumerate(ai_results[:3], 1):  # å±•ç¤ºå‰3ä¸ª
                        if hasattr(result, '__dict__'):
                            result_dict = result.__dict__
                        else:
                            result_dict = result
                        
                        print(f"   ä¿®æ”¹{i}: {result_dict.get('modification_id', 'unknown')}")
                        print(f"   æ¨è: {result_dict.get('recommendation', 'REVIEW')}")
                        print(f"   ç½®ä¿¡åº¦: {result_dict.get('confidence', 0):.2f}")
                        print(f"   ä¸šåŠ¡å½±å“: {result_dict.get('business_impact', 'MEDIUM')}")
                        reasoning = result_dict.get('reasoning', '')[:100] + '...' if len(result_dict.get('reasoning', '')) > 100 else result_dict.get('reasoning', '')
                        print(f"   åˆ†æç†ç”±: {reasoning}")
                        print()
                else:
                    print("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„L2ä¿®æ”¹è¿›è¡ŒAIåˆ†æ")
                    
            except Exception as e:
                print(f"âŒ AIåˆ†æå¤±è´¥: {e}")
                import traceback
                print(traceback.format_exc())
        else:
            print(f"\\nğŸ¤– ç¬¬3é˜¶æ®µï¼šAIè¯­ä¹‰åˆ†æ - è·³è¿‡ (æ— L2çº§åˆ«ä¿®æ”¹)")
        
        # ç¬¬4é˜¶æ®µï¼šç”Ÿæˆå¯è§†åŒ–æ•°æ®ç»“æ„
        print(f"\\nğŸ¨ ç¬¬4é˜¶æ®µï¼šç”Ÿæˆå¯è§†åŒ–æ•°æ®ç»“æ„")
        try:
            # æ„å»ºçƒ­åŠ›å›¾æ•°æ® (æ¨¡æ‹Ÿ30x19çŸ©é˜µ)
            heatmap_data = {
                "matrix_size": (4, 19),  # å®é™…æ•°æ®åªæœ‰4è¡Œï¼Œ19åˆ—
                "risk_matrix": [],
                "modification_locations": [],
                "risk_distribution": {"L1": l1_changes, "L2": l2_changes, "L3": l3_changes}
            }
            
            # æ„å»ºé£é™©çŸ©é˜µ
            standard_columns = [
                "åºå·", "é¡¹ç›®ç±»å‹", "æ¥æº", "ä»»åŠ¡å‘èµ·æ—¶é—´", "ç›®æ ‡å¯¹é½", "å…³é”®KRå¯¹é½", 
                "å…·ä½“è®¡åˆ’å†…å®¹", "é‚“æ€»æŒ‡å¯¼ç™»è®°", "è´Ÿè´£äºº", "ååŠ©äºº", "ç›‘ç£äºº", 
                "é‡è¦ç¨‹åº¦", "é¢„è®¡å®Œæˆæ—¶é—´", "å®Œæˆè¿›åº¦", "å½¢æˆè®¡åˆ’æ¸…å•", "å¤ç›˜æ—¶é—´", 
                "å¯¹ä¸Šæ±‡æŠ¥", "åº”ç”¨æƒ…å†µ", "è¿›åº¦åˆ†ææ€»ç»“"
            ]
            
            # åˆå§‹åŒ–é£é™©çŸ©é˜µ
            risk_matrix = [[0 for _ in range(19)] for _ in range(4)]
            
            # å¡«å……å®é™…å˜æ›´çš„é£é™©ç­‰çº§
            for change in changes_found:
                row_idx = change.get("row_index", 0)
                col_name = change.get("column_name", "")
                if col_name in standard_columns:
                    col_idx = standard_columns.index(col_name)
                    risk_level = change.get("risk_level", "L3")
                    risk_value = {"L1": 3, "L2": 2, "L3": 1}.get(risk_level, 1)
                    if 0 <= row_idx < 4 and 0 <= col_idx < 19:
                        risk_matrix[row_idx][col_idx] = risk_value
                        
                        heatmap_data["modification_locations"].append({
                            "row": row_idx,
                            "col": col_idx,
                            "column_name": col_name,
                            "risk_level": risk_level,
                            "change_type": change.get("change_type", "modification")
                        })
            
            heatmap_data["risk_matrix"] = risk_matrix
            
            print(f"âœ… çƒ­åŠ›å›¾æ•°æ®ç”Ÿæˆå®Œæˆ")
            print(f"ğŸ“Š çŸ©é˜µå°ºå¯¸: {heatmap_data['matrix_size']}")
            print(f"ğŸ“ ä¿®æ”¹ä½ç½®: {len(heatmap_data['modification_locations'])}ä¸ª")
            print(f"ğŸ¯ é£é™©åˆ†å¸ƒ: {heatmap_data['risk_distribution']}")
            
            # ä¿å­˜å¯è§†åŒ–æ•°æ®
            with open("end_to_end_visualization_data.json", "w", encoding="utf-8") as f:
                json.dump(heatmap_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å¯è§†åŒ–æ•°æ®å·²ä¿å­˜åˆ°: end_to_end_visualization_data.json")
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        
        # ç¬¬5é˜¶æ®µï¼šç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print(f"\\nğŸ“‹ ç¬¬5é˜¶æ®µï¼šç”Ÿæˆå®Œæ•´æµ‹è¯•æŠ¥å‘Š")
        
        test_summary = {
            "test_execution_time": datetime.now().isoformat(),
            "data_processing_results": {
                "original_records": len(original_df),
                "modified_records": len(modified_df),
                "columns_analyzed": len(original_df.columns),
                "total_changes_detected": len(changes_found),
                "risk_distribution": {"L1": l1_changes, "L2": l2_changes, "L3": l3_changes}
            },
            "ai_analysis_results": {
                "l2_modifications_analyzed": l2_changes,
                "ai_processing_successful": l2_changes > 0,
                "recommendations_generated": l2_changes > 0
            },
            "visualization_results": {
                "heatmap_data_generated": True,
                "modification_locations_mapped": len(heatmap_data["modification_locations"]),
                "matrix_dimensions": heatmap_data["matrix_size"]
            },
            "overall_success": True
        }
        
        # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
        with open("end_to_end_test_report.json", "w", encoding="utf-8") as f:
            json.dump(test_summary, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç«¯åˆ°ç«¯æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š æµ‹è¯•æ€»ç»“:")
        print(f"   ğŸ“„ å¤„ç†è®°å½•: {test_summary['data_processing_results']['original_records']} â†’ {test_summary['data_processing_results']['modified_records']}")
        print(f"   ğŸ“‹ åˆ†æåˆ—æ•°: {test_summary['data_processing_results']['columns_analyzed']}")
        print(f"   ğŸ” æ£€æµ‹å˜æ›´: {test_summary['data_processing_results']['total_changes_detected']}ä¸ª")
        print(f"   ğŸ¤– AIåˆ†æ: {test_summary['ai_analysis_results']['l2_modifications_analyzed']}ä¸ªL2ä¿®æ”¹")
        print(f"   ğŸ¨ å¯è§†åŒ–: {test_summary['visualization_results']['modification_locations_mapped']}ä¸ªä½ç½®æ ‡è®°")
        
        print(f"\\nğŸ’¾ ç”Ÿæˆæ–‡ä»¶:")
        print(f"   ğŸ“Š å¯è§†åŒ–æ•°æ®: end_to_end_visualization_data.json")
        print(f"   ğŸ“‹ æµ‹è¯•æŠ¥å‘Š: end_to_end_test_report.json")
        
        return test_summary

async def main():
    """ä¸»å‡½æ•°"""
    tester = ComprehensiveE2ETest()
    
    try:
        result = await tester.run_complete_workflow_test()
        print(f"\\nğŸ‰ ç«¯åˆ°ç«¯æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        return result
    except Exception as e:
        print(f"\\nâŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(traceback.format_exc())
        return None

if __name__ == "__main__":
    asyncio.run(main())