#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´çš„è¡¨æ ¼å¯¹æ¯”æµ‹è¯•ç¨‹åº
ç”¨äºè¯¦ç»†åˆ†æä¿®æ”¹è¯†åˆ«çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
"""

import os
import sys
import json
import pandas as pd
from datetime import datetime
import time

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/root/projects/tencent-doc-manager')

from document_change_analyzer import DocumentChangeAnalyzer

def log_message(message):
    """è®°å½•æ—¥å¿—æ¶ˆæ¯"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    print(f"[{timestamp}] {message}")
    return f"[{timestamp}] {message}\n"

def load_test_files():
    """åŠ è½½æµ‹è¯•æ–‡ä»¶"""
    log_message("=== åŠ è½½æµ‹è¯•æ–‡ä»¶ ===")
    
    original_file = "/root/projects/tencent-doc-manager/refer/æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨-å·¥ä½œè¡¨2.csv"
    modified_file = "/root/projects/tencent-doc-manager/test_modified_obvious.csv"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(original_file):
        log_message(f"âŒ åŸå§‹æ–‡ä»¶ä¸å­˜åœ¨: {original_file}")
        return None, None
    
    if not os.path.exists(modified_file):
        log_message(f"âŒ ä¿®æ”¹æ–‡ä»¶ä¸å­˜åœ¨: {modified_file}")
        return None, None
    
    try:
        # è¯»å–åŸå§‹æ–‡ä»¶
        original_df = pd.read_csv(original_file, encoding='utf-8', header=1)
        log_message(f"âœ… åŸå§‹æ–‡ä»¶åŠ è½½æˆåŠŸ: {original_df.shape[0]}è¡Œ Ã— {original_df.shape[1]}åˆ—")
        
        # è¯»å–ä¿®æ”¹æ–‡ä»¶
        modified_df = pd.read_csv(modified_file, encoding='utf-8', header=1)
        log_message(f"âœ… ä¿®æ”¹æ–‡ä»¶åŠ è½½æˆåŠŸ: {modified_df.shape[0]}è¡Œ Ã— {modified_df.shape[1]}åˆ—")
        
        return original_df, modified_df
        
    except Exception as e:
        log_message(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
        return None, None

def analyze_data_structure(original_df, modified_df):
    """åˆ†ææ•°æ®ç»“æ„"""
    log_message("=== åˆ†ææ•°æ®ç»“æ„ ===")
    
    analysis_result = {
        "original_info": {
            "shape": original_df.shape,
            "columns": list(original_df.columns),
            "dtypes": original_df.dtypes.to_dict()
        },
        "modified_info": {
            "shape": modified_df.shape,
            "columns": list(modified_df.columns),
            "dtypes": modified_df.dtypes.to_dict()
        }
    }
    
    log_message(f"åŸå§‹æ•°æ®: {original_df.shape[0]}è¡Œ Ã— {original_df.shape[1]}åˆ—")
    log_message(f"ä¿®æ”¹æ•°æ®: {modified_df.shape[0]}è¡Œ Ã— {modified_df.shape[1]}åˆ—")
    
    # åˆ—åå¯¹æ¯”
    original_cols = set(original_df.columns)
    modified_cols = set(modified_df.columns)
    
    if original_cols == modified_cols:
        log_message("âœ… åˆ—ç»“æ„ä¸€è‡´")
    else:
        log_message("âš ï¸ åˆ—ç»“æ„å­˜åœ¨å·®å¼‚")
        if original_cols - modified_cols:
            log_message(f"åŸå§‹æ–‡ä»¶ç‹¬æœ‰åˆ—: {original_cols - modified_cols}")
        if modified_cols - original_cols:
            log_message(f"ä¿®æ”¹æ–‡ä»¶ç‹¬æœ‰åˆ—: {modified_cols - original_cols}")
    
    return analysis_result

def perform_detailed_comparison(original_df, modified_df):
    """æ‰§è¡Œè¯¦ç»†å¯¹æ¯”"""
    log_message("=== æ‰§è¡Œè¯¦ç»†å¯¹æ¯”åˆ†æ ===")
    
    analyzer = DocumentChangeAnalyzer()
    
    # å¼€å§‹å¯¹æ¯”
    start_time = time.time()
    log_message("å¼€å§‹æ‰§è¡Œè¡¨æ ¼å¯¹æ¯”...")
    
    try:
        comparison_result = analyzer.compare_dataframes(original_df, modified_df)
        end_time = time.time()
        
        log_message(f"âœ… å¯¹æ¯”å®Œæˆï¼Œè€—æ—¶: {end_time - start_time:.2f}ç§’")
        log_message(f"æ£€æµ‹åˆ° {len(comparison_result.get('changes', []))} ä¸ªå˜æ›´")
        
        return comparison_result
        
    except Exception as e:
        log_message(f"âŒ å¯¹æ¯”æ‰§è¡Œå¤±è´¥: {str(e)}")
        return None

def analyze_changes_in_detail(changes):
    """è¯¦ç»†åˆ†æå˜æ›´"""
    log_message("=== è¯¦ç»†åˆ†æå˜æ›´å†…å®¹ ===")
    
    if not changes:
        log_message("æœªæ£€æµ‹åˆ°ä»»ä½•å˜æ›´")
        return {}
    
    # æŒ‰ç±»å‹åˆ†ç»„ç»Ÿè®¡
    change_stats = {
        "total_changes": len(changes),
        "by_type": {},
        "by_column": {},
        "by_risk_level": {}
    }
    
    # è¯¦ç»†å˜æ›´åˆ—è¡¨
    detailed_changes = []
    
    for i, change in enumerate(changes):
        log_message(f"å˜æ›´ {i+1}: {change}")
        
        # ç»Ÿè®¡ç±»å‹
        change_type = change.get('change_type', 'unknown')
        change_stats["by_type"][change_type] = change_stats["by_type"].get(change_type, 0) + 1
        
        # ç»Ÿè®¡åˆ—
        column = change.get('column', 'unknown')
        change_stats["by_column"][column] = change_stats["by_column"].get(column, 0) + 1
        
        # ç»Ÿè®¡é£é™©ç­‰çº§
        risk_level = change.get('risk_level', 'unknown')
        change_stats["by_risk_level"][risk_level] = change_stats["by_risk_level"].get(risk_level, 0) + 1
        
        # æ”¶é›†è¯¦ç»†ä¿¡æ¯
        detailed_changes.append({
            "change_id": i + 1,
            "change_type": change_type,
            "column": column,
            "row_index": change.get('row_index', 'unknown'),
            "original_value": change.get('original_value', ''),
            "new_value": change.get('new_value', ''),
            "risk_level": risk_level,
            "confidence": change.get('confidence', 0.0)
        })
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    log_message(f"æ€»å˜æ›´æ•°: {change_stats['total_changes']}")
    log_message(f"æŒ‰ç±»å‹ç»Ÿè®¡: {change_stats['by_type']}")
    log_message(f"æŒ‰åˆ—ç»Ÿè®¡: {change_stats['by_column']}")
    log_message(f"æŒ‰é£é™©ç­‰çº§ç»Ÿè®¡: {change_stats['by_risk_level']}")
    
    return {
        "statistics": change_stats,
        "detailed_changes": detailed_changes
    }

def find_specific_test_changes(original_df, modified_df):
    """æŸ¥æ‰¾ç‰¹å®šçš„æµ‹è¯•å˜æ›´"""
    log_message("=== æŸ¥æ‰¾ç‰¹å®šæµ‹è¯•å˜æ›´ ===")
    
    # æˆ‘ä»¬çŸ¥é“çš„æµ‹è¯•å˜æ›´
    test_changes = []
    
    # æ£€æŸ¥è´Ÿè´£äººå­—æ®µå˜æ›´
    log_message("æ£€æŸ¥ã€è´Ÿè´£äººã€‘å­—æ®µå˜æ›´...")
    for idx in range(min(len(original_df), len(modified_df))):
        if 'è´Ÿè´£äºº' in original_df.columns and 'è´Ÿè´£äºº' in modified_df.columns:
            orig_val = str(original_df.iloc[idx]['è´Ÿè´£äºº']) if pd.notna(original_df.iloc[idx]['è´Ÿè´£äºº']) else ''
            new_val = str(modified_df.iloc[idx]['è´Ÿè´£äºº']) if pd.notna(modified_df.iloc[idx]['è´Ÿè´£äºº']) else ''
            
            if orig_val != new_val:
                test_changes.append({
                    "row": idx,
                    "column": "è´Ÿè´£äºº",
                    "original": orig_val,
                    "modified": new_val,
                    "change_type": "è´£ä»»äººå˜æ›´"
                })
                log_message(f"  å‘ç°å˜æ›´ è¡Œ{idx}: '{orig_val}' â†’ '{new_val}'")
    
    # æ£€æŸ¥å…·ä½“è®¡åˆ’å†…å®¹å­—æ®µå˜æ›´
    log_message("æ£€æŸ¥ã€å…·ä½“è®¡åˆ’å†…å®¹ã€‘å­—æ®µå˜æ›´...")
    for idx in range(min(len(original_df), len(modified_df))):
        if 'å…·ä½“è®¡åˆ’å†…å®¹' in original_df.columns and 'å…·ä½“è®¡åˆ’å†…å®¹' in modified_df.columns:
            orig_val = str(original_df.iloc[idx]['å…·ä½“è®¡åˆ’å†…å®¹']) if pd.notna(original_df.iloc[idx]['å…·ä½“è®¡åˆ’å†…å®¹']) else ''
            new_val = str(modified_df.iloc[idx]['å…·ä½“è®¡åˆ’å†…å®¹']) if pd.notna(modified_df.iloc[idx]['å…·ä½“è®¡åˆ’å†…å®¹']) else ''
            
            if orig_val != new_val:
                test_changes.append({
                    "row": idx,
                    "column": "å…·ä½“è®¡åˆ’å†…å®¹", 
                    "original": orig_val,
                    "modified": new_val,
                    "change_type": "è®¡åˆ’å†…å®¹æ›´æ–°"
                })
                log_message(f"  å‘ç°å˜æ›´ è¡Œ{idx}: '{orig_val}' â†’ '{new_val}'")
    
    log_message(f"æ‰‹åŠ¨æ£€æŸ¥å‘ç° {len(test_changes)} ä¸ªå˜æ›´")
    return test_changes

def generate_comprehensive_report(original_df, modified_df, comparison_result, change_analysis, manual_changes):
    """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
    log_message("=== ç”Ÿæˆç»¼åˆæµ‹è¯•æŠ¥å‘Š ===")
    
    report = {
        "test_metadata": {
            "test_time": datetime.now().isoformat(),
            "test_purpose": "éªŒè¯è¡¨æ ¼å¯¹æ¯”ç¨‹åºçš„ä¿®æ”¹è¯†åˆ«å‡†ç¡®æ€§",
            "original_file": "refer/æµ‹è¯•ç‰ˆæœ¬-å°çº¢ä¹¦éƒ¨é—¨-å·¥ä½œè¡¨2.csv",
            "modified_file": "test_modified_obvious.csv"
        },
        "data_structure_analysis": {
            "original_shape": original_df.shape,
            "modified_shape": modified_df.shape,
            "columns_count": len(original_df.columns),
            "columns_list": list(original_df.columns)
        },
        "comparison_results": comparison_result or {},
        "change_analysis": change_analysis,
        "manual_verification": {
            "manual_found_changes": manual_changes,
            "manual_change_count": len(manual_changes)
        },
        "accuracy_assessment": {},
        "conclusions": []
    }
    
    # å‡†ç¡®æ€§è¯„ä¼°
    program_change_count = len(comparison_result.get('changes', [])) if comparison_result else 0
    manual_change_count = len(manual_changes)
    
    report["accuracy_assessment"] = {
        "program_detected": program_change_count,
        "manual_verified": manual_change_count,
        "detection_accuracy": "éœ€è¦è¿›ä¸€æ­¥åˆ†æ" if program_change_count != manual_change_count else "æ£€æµ‹æ•°é‡åŒ¹é…"
    }
    
    # ç»“è®º
    if program_change_count > 0:
        report["conclusions"].append(f"âœ… ç¨‹åºæˆåŠŸæ£€æµ‹åˆ° {program_change_count} ä¸ªå˜æ›´")
    else:
        report["conclusions"].append("âŒ ç¨‹åºæœªæ£€æµ‹åˆ°ä»»ä½•å˜æ›´")
    
    if manual_change_count > 0:
        report["conclusions"].append(f"âœ… æ‰‹åŠ¨éªŒè¯å‘ç° {manual_change_count} ä¸ªçœŸå®å˜æ›´")
    
    if program_change_count == manual_change_count and manual_change_count > 0:
        report["conclusions"].append("ğŸ¯ æ£€æµ‹æ•°é‡å®Œå…¨åŒ¹é…ï¼Œå‡†ç¡®æ€§è‰¯å¥½")
    elif program_change_count > manual_change_count:
        report["conclusions"].append("âš ï¸ ç¨‹åºæ£€æµ‹æ•°é‡è¶…è¿‡é¢„æœŸï¼Œå¯èƒ½å­˜åœ¨è¯¯æŠ¥")
    elif program_change_count < manual_change_count:
        report["conclusions"].append("âš ï¸ ç¨‹åºæ£€æµ‹æ•°é‡ä¸è¶³ï¼Œå¯èƒ½å­˜åœ¨æ¼æŠ¥")
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    log_file_lines = []
    
    print("=" * 80)
    print("è…¾è®¯æ–‡æ¡£æ™ºèƒ½ç›‘æ§ç³»ç»Ÿ - å®Œæ•´å¯¹æ¯”æµ‹è¯•")
    print("=" * 80)
    
    # 1. åŠ è½½æµ‹è¯•æ–‡ä»¶
    original_df, modified_df = load_test_files()
    if original_df is None or modified_df is None:
        print("âŒ æµ‹è¯•æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # 2. åˆ†ææ•°æ®ç»“æ„
    structure_analysis = analyze_data_structure(original_df, modified_df)
    
    # 3. æ‰§è¡Œç¨‹åºå¯¹æ¯”
    comparison_result = perform_detailed_comparison(original_df, modified_df)
    
    # 4. åˆ†æå˜æ›´è¯¦æƒ…
    change_analysis = analyze_changes_in_detail(comparison_result.get('changes', []) if comparison_result else [])
    
    # 5. æ‰‹åŠ¨éªŒè¯ç‰¹å®šå˜æ›´
    manual_changes = find_specific_test_changes(original_df, modified_df)
    
    # 6. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
    comprehensive_report = generate_comprehensive_report(
        original_df, modified_df, comparison_result, change_analysis, manual_changes
    )
    
    # 7. ä¿å­˜å®Œæ•´ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_file = f"complete_comparison_test_report_{timestamp}.json"
    
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_report, f, ensure_ascii=False, indent=2, default=str)
        
        log_message(f"âœ… å®Œæ•´æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºå…³é”®ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ¯ æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 60)
        for conclusion in comprehensive_report["conclusions"]:
            print(conclusion)
        
        print(f"\nğŸ“Š è¯¦ç»†æŠ¥å‘Šæ–‡ä»¶: {report_file}")
        print("ğŸ“ æµ‹è¯•å®Œæˆï¼")
        
    except Exception as e:
        log_message(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    main()