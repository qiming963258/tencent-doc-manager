#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥è§£å‹zlibå‹ç¼©çš„æ–‡ä»¶
"""

import zlib
import gzip
from pathlib import Path

def decompress_file(file_path):
    """å°è¯•è§£å‹æ–‡ä»¶"""
    print(f"\nè§£å‹æ–‡ä»¶: {Path(file_path).name}")
    print("="*60)
    
    with open(file_path, 'rb') as f:
        compressed_data = f.read()
    
    print(f"æ–‡ä»¶å¤§å°: {len(compressed_data)} bytes")
    print(f"å‰16å­—èŠ‚(hex): {compressed_data[:16].hex()}")
    
    # æ£€æŸ¥æ–‡ä»¶å¤´
    if compressed_data[:2] == b'\x78\x01':
        print("âœ… æ£€æµ‹åˆ°zlibå‹ç¼© (78 01)")
    elif compressed_data[:2] == b'\x78\x9c':
        print("âœ… æ£€æµ‹åˆ°zlibå‹ç¼© (78 9c)")
    elif compressed_data[:2] == b'\x78\xda':
        print("âœ… æ£€æµ‹åˆ°zlibå‹ç¼© (78 da)")
    elif compressed_data[:2] == b'\x1f\x8b':
        print("âœ… æ£€æµ‹åˆ°gzipå‹ç¼© (1f 8b)")
    else:
        print(f"â“ æœªçŸ¥å‹ç¼©æ ¼å¼: {compressed_data[:2].hex()}")
    
    # å°è¯•å¤šç§è§£å‹æ–¹æ³•
    methods = [
        ("zlib.decompress (é»˜è®¤)", lambda d: zlib.decompress(d)),
        ("zlib.decompress (-15)", lambda d: zlib.decompress(d, -15)),  # raw deflate
        ("zlib.decompress (15)", lambda d: zlib.decompress(d, 15)),    # with header
        ("zlib.decompress (31)", lambda d: zlib.decompress(d, 31)),    # auto detect
        ("gzip.decompress", lambda d: gzip.decompress(d)),
    ]
    
    for method_name, decompress_func in methods:
        try:
            print(f"\nå°è¯• {method_name}...")
            decompressed = decompress_func(compressed_data)
            print(f"âœ… æˆåŠŸ! è§£å‹åå¤§å°: {len(decompressed)} bytes")
            
            # åˆ†æè§£å‹åçš„æ•°æ®
            try:
                # å°è¯•UTF-8è§£ç 
                text = decompressed.decode('utf-8')
                print(f"UTF-8è§£ç æˆåŠŸ, é•¿åº¦: {len(text)} å­—ç¬¦")
                
                # æ£€æŸ¥å†…å®¹
                if ',' in text[:1000] or '\t' in text[:1000]:
                    print("ğŸ“Š çœ‹èµ·æ¥æ˜¯è¡¨æ ¼æ•°æ®ï¼ˆCSVæ ¼å¼ï¼‰")
                    lines = text.split('\n')[:5]
                    for i, line in enumerate(lines, 1):
                        print(f"  ç¬¬{i}è¡Œ: {line[:100]}{'...' if len(line) > 100 else ''}")
                    
                    # ä¿å­˜è§£å‹åçš„æ–‡ä»¶
                    output_file = file_path.replace('.xlsx', '_decompressed.csv').replace('_extracted.csv', '_final.csv')
                    with open(output_file, 'w', encoding='utf-8') as f:
                        f.write(text)
                    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")
                    
                elif text.startswith('<?xml') or '<html' in text[:1000]:
                    print("ğŸ“„ çœ‹èµ·æ¥æ˜¯XML/HTMLæ•°æ®")
                    print(f"é¢„è§ˆ: {text[:500]}...")
                    
                elif text.startswith('{') or text.startswith('['):
                    print("ğŸ“Š çœ‹èµ·æ¥æ˜¯JSONæ•°æ®")
                    import json
                    data = json.loads(text)
                    print(f"JSONç±»å‹: {type(data)}")
                    if isinstance(data, dict):
                        print(f"Keys: {list(data.keys())[:10]}")
                    
                    # ä¿å­˜JSONæ–‡ä»¶
                    output_file = file_path.replace('.xlsx', '_decompressed.json').replace('_extracted.csv', '_final.json')
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")
                else:
                    print("ğŸ“ æ–‡æœ¬æ•°æ®")
                    print(f"é¢„è§ˆ: {text[:500]}...")
                    
                return True
                
            except UnicodeDecodeError:
                print("âŒ UTF-8è§£ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç ...")
                
                # å°è¯•å…¶ä»–ç¼–ç 
                for encoding in ['gbk', 'utf-16', 'latin1']:
                    try:
                        text = decompressed.decode(encoding)
                        print(f"âœ… {encoding}è§£ç æˆåŠŸ")
                        print(f"é¢„è§ˆ: {text[:200]}...")
                        
                        output_file = file_path.replace('.xlsx', f'_decompressed_{encoding}.txt').replace('_extracted.csv', f'_final_{encoding}.txt')
                        with open(output_file, 'w', encoding='utf-8') as f:
                            f.write(text)
                        print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")
                        return True
                    except:
                        continue
                
                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œä¿å­˜ä¸ºäºŒè¿›åˆ¶
                print("ä¿å­˜ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶...")
                output_file = file_path.replace('.xlsx', '_decompressed.bin').replace('_extracted.csv', '_final.bin')
                with open(output_file, 'wb') as f:
                    f.write(decompressed)
                print(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {output_file}")
                return True
                
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    # æµ‹è¯•æ–‡ä»¶åˆ—è¡¨
    test_files = [
        "/root/projects/tencent-doc-manager/test_DWEVjZndkR2xVSWJN_CSVæ ¼å¼_20250827_231718_extracted.csv",
        "/root/projects/tencent-doc-manager/test_DWEVjZndkR2xVSWJN_Excelæ ¼å¼_20250827_231720.xlsx"
    ]
    
    success_count = 0
    
    for file_path in test_files:
        if not Path(file_path).exists():
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue
        
        if decompress_file(file_path):
            success_count += 1
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†å®Œæˆ: {success_count}/{len(test_files)} æ–‡ä»¶æˆåŠŸè§£å‹")
    
    if success_count > 0:
        print("âœ… æˆåŠŸè§£å‹æ–‡ä»¶!")
        print("ğŸ’¡ ç°åœ¨å¯ä»¥æŸ¥çœ‹è§£å‹åçš„æ•°æ®")

if __name__ == "__main__":
    main()