# 📊 腾讯文档智能评分体系规范 (T-RICE+)

**版本**: v1.0  
**创建日期**: 2025-09-07  
**状态**: 正式发布

---

## 1. 概述

### 1.1 背景
基于国际最佳实践研究，融合RICE框架、5×5风险矩阵、DAMA数据质量标准，为30份腾讯文档表格设计的企业级智能评分体系。

### 1.2 核心目标
- **标准化评分**：为30份表格×19列×数百单元格提供统一评分标准
- **智能化决策**：通过多维度评分支持自动化决策
- **风险分级**：5级风险分类确保重点关注高危变更
- **批量处理**：优化算法支持大规模表格并发评分

---

## 2. T-RICE+ 评分框架

### 2.1 核心公式

```python
总体评分 = (R × I × C × Q) / E × W

# 参数定义
R = Reach（影响范围）     # 25%权重
I = Impact（业务影响）    # 30%权重  
C = Confidence（置信度）  # 15%权重
Q = Quality（质量维度）   # 15%权重
E = Effort（处理成本）    # 10%权重
W = Weight（表格权重）    # 5%权重
```

### 2.2 评分区间
- 总分范围：0.00 - 1.25
- 标准化后：0.00 - 1.00

---

## 3. 六维度详细评分规则

### 3.1 Reach（影响范围） - 25%权重

#### 计算公式
```python
def calculate_reach_score(modifications):
    """计算影响范围评分"""
    modified_cells = len(modifications)
    total_cells = 19 * avg_rows  # 19列 × 平均行数
    
    # 基础比例
    base_ratio = modified_cells / total_cells
    
    # 范围系数
    if is_single_cell(modifications):
        scope_factor = 0.2
    elif is_single_row(modifications):
        scope_factor = 0.4
    elif is_single_column(modifications):
        scope_factor = 0.6
    elif is_multiple_areas(modifications):
        scope_factor = 0.8
    else:  # 全表影响
        scope_factor = 1.0
    
    return min(base_ratio * scope_factor * 1.2, 1.0)
```

#### 评分标准
| 影响范围 | 范围系数 | 典型场景 |
|---------|---------|---------|
| 单个单元格 | 0.2 | 个别数据修正 |
| 单行影响 | 0.4 | 单条记录更新 |
| 单列影响 | 0.6 | 字段批量更新 |
| 多行多列 | 0.8 | 结构性调整 |
| 全表影响 | 1.0 | 重大变更 |

### 3.2 Impact（业务影响） - 30%权重

#### 19列权重分配

##### L1级关键列（权重1.5）
```python
L1_COLUMNS = {
    "来源": 1.5,
    "任务发起时间": 1.5,
    "目标对齐": 1.5,
    "关键KR对齐": 1.5,
    "重要程度": 1.5,
    "预计完成时间": 1.5,
    "完成进度": 1.5
}
```

##### L2级重要列（权重1.2）
```python
L2_COLUMNS = {
    "项目类型": 1.2,
    "具体计划内容": 1.2,
    "邓总指导登记": 1.2,
    "负责人": 1.2,
    "协助人": 1.2,
    "监督人": 1.2,
    "完成链接": 1.2
}
```

##### L3级普通列（权重1.0）
```python
L3_COLUMNS = {
    "序号": 1.0,
    "最新复盘时间": 1.0,
    "对上汇报": 1.0,
    "应用情况": 1.0,
    "经理分析复盘": 1.0
}
```

#### 计算方法
```python
def calculate_impact_score(modifications):
    """计算业务影响评分"""
    total_impact = 0
    
    for mod in modifications:
        column_name = mod['column_name']
        change_magnitude = calculate_change_magnitude(
            mod['old_value'], 
            mod['new_value']
        )
        
        # 获取列权重
        column_weight = get_column_weight(column_name)
        
        # 累加影响分
        total_impact += column_weight * change_magnitude
    
    # 归一化到0-1
    return min(total_impact / len(modifications), 1.0)
```

### 3.3 Confidence（置信度） - 15%权重

#### AI决策因子
```python
AI_DECISION_FACTORS = {
    "REJECT": 0.4,      # AI拒绝
    "REVIEW": 0.6,      # 需要审核
    "CONDITIONAL": 0.8, # 条件批准
    "APPROVE": 1.0      # AI批准
}
```

#### 数据完整性评分
```python
def calculate_data_completeness(table):
    """计算数据完整性"""
    non_empty_cells = count_non_empty(table)
    total_cells = table.rows * table.columns
    
    completeness_ratio = non_empty_cells / total_cells
    
    if completeness_ratio > 0.95:
        return 1.0
    elif completeness_ratio > 0.85:
        return 0.8
    elif completeness_ratio > 0.75:
        return 0.6
    else:
        return 0.4
```

### 3.4 Quality（质量维度） - 15%权重

基于DAMA六维度数据质量标准：

```python
QUALITY_DIMENSIONS = {
    "accuracy": 0.30,      # 准确性
    "completeness": 0.20,  # 完整性
    "consistency": 0.20,   # 一致性
    "uniqueness": 0.10,    # 唯一性
    "timeliness": 0.10,    # 及时性
    "validity": 0.10       # 有效性
}

def calculate_quality_score(data):
    """计算质量评分"""
    scores = {
        "accuracy": calculate_accuracy(data),
        "completeness": calculate_completeness(data),
        "consistency": calculate_consistency(data),
        "uniqueness": calculate_uniqueness(data),
        "timeliness": calculate_timeliness(data),
        "validity": calculate_validity(data)
    }
    
    weighted_score = sum(
        scores[dim] * weight 
        for dim, weight in QUALITY_DIMENSIONS.items()
    )
    
    return weighted_score
```

### 3.5 Effort（处理成本） - 10%权重

反向指标（成本越高，分数越低）：

```python
EFFORT_LEVELS = {
    "automated": 0.1,      # 自动处理
    "semi_automated": 0.3, # 半自动处理
    "manual_review": 0.5,  # 人工审核
    "investigation": 0.8,  # 深度调查
    "urgent_intervention": 1.0  # 紧急干预
}

def calculate_effort_score(change_type):
    """计算处理成本评分"""
    effort_cost = EFFORT_LEVELS.get(change_type, 0.5)
    
    # 反向计算：成本越高，分数越低
    return 1 / (1 + effort_cost)
```

### 3.6 Weight（表格权重） - 5%权重

30份表格分级管理：

```python
TABLE_CATEGORIES = {
    # 核心业务表（10个）
    "core_business": {
        "weight": 1.5,
        "tables": [
            "项目进度表", "资金流水表", "人员分配表",
            "合同管理表", "风险监控表", "KPI考核表",
            "预算执行表", "客户信息表", "产品库存表", "销售数据表"
        ]
    },
    
    # 重要业务表（10个）
    "important_business": {
        "weight": 1.2,
        "tables": [
            "会议记录表", "培训计划表", "采购清单表",
            "考勤统计表", "报销明细表", "设备管理表",
            "供应商表", "质量检查表", "维修记录表", "访客登记表"
        ]
    },
    
    # 辅助业务表（10个）
    "auxiliary_business": {
        "weight": 1.0,
        "tables": [
            "备忘录表", "参考资料表", "历史记录表",
            "通讯录表", "节假日表", "值班安排表",
            "图书借阅表", "车辆使用表", "会议室预定表", "意见反馈表"
        ]
    }
}
```

---

## 4. 风险等级映射

### 4.1 5×5风险矩阵

```python
RISK_MATRIX = [
    # 影响度 →
    # ↓ 概率   极低    低     中     高    极高
    [0.05, 0.10, 0.15, 0.20, 0.25],  # 极低概率
    [0.10, 0.20, 0.30, 0.40, 0.50],  # 低概率
    [0.15, 0.30, 0.45, 0.60, 0.75],  # 中概率
    [0.20, 0.40, 0.60, 0.80, 1.00],  # 高概率
    [0.25, 0.50, 0.75, 1.00, 1.25],  # 极高概率
]
```

### 4.2 风险等级定义

| 风险等级 | 分数区间 | 标识 | 处理策略 | SLA |
|---------|---------|------|---------|-----|
| 极高风险 | 0.80-1.25 | 🔴 | 立即升级，人工介入 | 15分钟 |
| 高风险 | 0.60-0.80 | 🟠 | 优先处理，建议审核 | 1小时 |
| 中风险 | 0.40-0.60 | 🟡 | 常规监控，定期检查 | 4小时 |
| 低风险 | 0.20-0.40 | 🟢 | 自动通过，记录备案 | 24小时 |
| 极低风险 | 0.00-0.20 | ⚪ | 忽略变更，仅做日志 | 无需处理 |

---

## 5. ICE快速评分模型

### 5.1 应用场景
当需要快速决策或资源有限时，使用ICE简化评分：

```python
def calculate_ice_score(change):
    """ICE快速评分"""
    impact = rate_impact(change)        # 1-10分
    confidence = rate_confidence(change) # 0-100%
    ease = rate_ease(change)            # 1-10分
    
    ice_score = impact * confidence * ease
    
    return {
        "score": ice_score,
        "decision": get_ice_decision(ice_score)
    }

def get_ice_decision(score):
    """ICE决策阈值"""
    if score > 500:
        return "IMMEDIATE"  # 立即处理
    elif score > 200:
        return "PLANNED"    # 计划处理
    else:
        return "DEFERRED"   # 暂缓处理
```

---

## 6. 批量处理算法

### 6.1 智能批处理架构

```python
class BatchScoringEngine:
    """30份表格批量评分引擎"""
    
    def __init__(self):
        self.batch_size = 5        # 每批5个表格
        self.parallel_workers = 3   # 3个并发处理器
        self.cache_ttl = 86400     # 24小时缓存
        self.redis_client = Redis()
        
    async def process_all_tables(self, tables):
        """批量处理30份表格"""
        # 1. 智能分组
        groups = self.intelligent_grouping(tables)
        
        # 2. 并行处理
        tasks = []
        for group in groups:
            task = asyncio.create_task(
                self.process_group(group)
            )
            tasks.append(task)
        
        # 3. 收集结果
        results = await asyncio.gather(*tasks)
        
        # 4. 聚合评分
        return self.aggregate_results(results)
    
    def intelligent_grouping(self, tables):
        """基于相似度和重要性分组"""
        groups = []
        
        # 按表格类别分组
        for category in ['core', 'important', 'auxiliary']:
            category_tables = [
                t for t in tables 
                if t.category == category
            ]
            
            # 按批次大小分割
            for i in range(0, len(category_tables), self.batch_size):
                groups.append(
                    category_tables[i:i+self.batch_size]
                )
        
        return groups
```

### 6.2 缓存策略

```python
def get_cached_score(self, table_id, modification_hash):
    """获取缓存的评分结果"""
    cache_key = f"score:{table_id}:{modification_hash}"
    
    cached = self.redis_client.get(cache_key)
    if cached:
        self.stats['cache_hits'] += 1
        return json.loads(cached)
    
    return None

def cache_score(self, table_id, modification_hash, score):
    """缓存评分结果"""
    cache_key = f"score:{table_id}:{modification_hash}"
    
    self.redis_client.setex(
        cache_key,
        self.cache_ttl,
        json.dumps(score)
    )
```

---

## 7. 评分输出规范

### 7.1 标准输出格式

```json
{
  "summary": {
    "overall_score": 0.62,
    "risk_level": "HIGH",
    "trend": "INCREASING",
    "attention_items": 15,
    "processed_tables": 30,
    "processing_time": 3.2
  },
  
  "risk_distribution": {
    "extreme_high": {"count": 2, "percentage": 6.7},
    "high": {"count": 5, "percentage": 16.7},
    "medium": {"count": 8, "percentage": 26.7},
    "low": {"count": 10, "percentage": 33.3},
    "extreme_low": {"count": 5, "percentage": 16.7}
  },
  
  "column_analysis": {
    "highest_risk": {
      "column": "负责人",
      "score": 0.85,
      "changes": 32
    },
    "most_modified": {
      "column": "经理分析复盘",
      "count": 145
    },
    "highest_impact": {
      "column": "预计完成时间",
      "affected_tables": 12
    }
  },
  
  "top_tables": [
    {
      "name": "项目进度表",
      "score": 0.89,
      "risk_level": "EXTREME_HIGH",
      "recommendation": "立即审核",
      "key_changes": [
        "负责人变更3次",
        "完成时间推迟2周",
        "预算增加20%"
      ]
    }
  ],
  
  "recommendations": [
    "建议立即审核项目进度表的负责人变更",
    "关注资金流水表的异常波动",
    "定期检查预计完成时间的批量修改"
  ]
}
```

### 7.2 可视化要求

评分结果需支持以下可视化展示：
1. **仪表盘**：总体风险评分表盘
2. **饼图**：风险等级分布
3. **柱状图**：列维度风险对比
4. **趋势图**：历史评分趋势
5. **热力表**：30×19矩阵风险热度

---

## 8. 实施计划

### 8.1 部署阶段
1. **Phase 1**（第1周）：核心评分引擎开发
2. **Phase 2**（第2周）：批处理优化和缓存实现
3. **Phase 3**（第3周）：API接口和可视化开发
4. **Phase 4**（第4周）：测试优化和上线

### 8.2 性能指标
- 单表评分耗时：< 100ms
- 30表批量评分：< 3秒
- 缓存命中率：> 70%
- API响应时间：< 200ms
- 并发处理能力：100 QPS

---

## 9. 维护和优化

### 9.1 定期校准
- **每周**：检查评分阈值合理性
- **每月**：调整列权重分配
- **每季度**：优化评分算法
- **每半年**：全面评估体系效果

### 9.2 反馈机制
```python
class FeedbackLoop:
    """评分反馈和自动优化"""
    
    def collect_feedback(self, score_id, actual_risk):
        """收集实际风险反馈"""
        predicted_risk = self.get_predicted_risk(score_id)
        
        # 计算偏差
        deviation = abs(predicted_risk - actual_risk)
        
        # 记录反馈
        self.feedback_db.insert({
            "score_id": score_id,
            "predicted": predicted_risk,
            "actual": actual_risk,
            "deviation": deviation,
            "timestamp": datetime.now()
        })
        
    def auto_calibrate(self):
        """基于反馈自动校准权重"""
        recent_feedback = self.get_recent_feedback(days=30)
        
        if len(recent_feedback) > 100:
            # 使用机器学习优化权重
            new_weights = self.ml_optimizer.optimize(
                recent_feedback
            )
            
            # 更新权重配置
            self.update_weights(new_weights)
```

---

## 10. 附录

### 10.1 参考标准
- RICE Framework (Intercom)
- ICE Scoring Model
- WSJF (SAFe)
- DAMA-DMBOK Data Quality Dimensions
- ISO 8000 Data Quality Standards

### 10.2 版本历史
| 版本 | 日期 | 修改内容 | 作者 |
|-----|------|---------|------|
| v1.0 | 2025-09-07 | 初始版本发布 | 系统生成 |

### 10.3 联系方式
- 技术支持：ai-scoring@tencent-docs.com
- 反馈渠道：http://feedback.tencent-docs.com/scoring

---

*本规范基于国际最佳实践和腾讯文档实际需求制定，将持续优化迭代。*