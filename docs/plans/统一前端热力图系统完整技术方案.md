# ğŸ“Š ç»Ÿä¸€å‰ç«¯çƒ­åŠ›å›¾ç›‘æ§ç³»ç»Ÿ - å®Œæ•´æŠ€æœ¯å®ç°æ–¹æ¡ˆ

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**åˆ›å»ºæ—¥æœŸ**: 2025-09-11  
**ç³»ç»Ÿå®šä½**: ä»¥8089ä¸ºç»Ÿä¸€å‰ç«¯çš„è…¾è®¯æ–‡æ¡£æ™ºèƒ½ç›‘æ§ç³»ç»Ÿ  
**æ ¸å¿ƒç‰¹æ€§**: å…¨è‡ªåŠ¨åŒ–ã€å¹¶å‘å¤„ç†ã€å¯è§†åŒ–å±•ç¤ºã€ä¸€é”®è·³è½¬  

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šç³»ç»Ÿæ€»ä½“æ¶æ„

### 1.1 æ¶æ„è®¾è®¡ç†å¿µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    8089 ç»Ÿä¸€å‰ç«¯                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  è¾“å…¥åŒºï¼šURLåˆ—è¡¨ | Cookie | å®šæ—¶è®¾ç½® | å¼€å§‹æŒ‰é’®    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  çƒ­åŠ›å›¾å±•ç¤ºåŒºï¼šå¯ç‚¹å‡»è¡Œæ ‡é¢˜ â†’ è·³è½¬æ¶‚è‰²Excel        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          åç«¯æœåŠ¡ç¼–æ’å±‚                â”‚
        â”‚     (Service Orchestration Layer)      â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†™              â†˜
         å¹¶å‘æµç¨‹1                   å¹¶å‘æµç¨‹2
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  CSVåˆ†æé“¾   â”‚           â”‚  Excelå¤„ç†é“¾  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æœåŠ¡è§’è‰²å®šä¹‰

| æœåŠ¡ç«¯å£ | æ–°è§’è‰²å®šä½ | æ ¸å¿ƒèŒè´£ | è°ƒç”¨æ—¶æœº |
|---------|-----------|---------|---------|
| **8089** | ç»Ÿä¸€å‰ç«¯+è°ƒåº¦ä¸­å¿ƒ | ç”¨æˆ·äº¤äº’ã€ä»»åŠ¡è°ƒåº¦ã€ç»“æœå±•ç¤º | å…¨ç¨‹ä¸»æ§ |
| **8093** | ä¸‹è½½æœåŠ¡ | è…¾è®¯æ–‡æ¡£ä¸‹è½½ï¼ˆCSV/XLSXï¼‰ | ç¬¬1æ­¥ |
| **8094** | CSVå¯¹æ¯”æœåŠ¡ | CSVæ–‡ä»¶å¯¹æ¯”åˆ†æ | å¹¶å‘1-æ­¥éª¤2 |
| **8098** | AIåˆ†ææœåŠ¡ | åˆ—æ ‡å‡†åŒ–ã€L2è¯­ä¹‰åˆ†æ | å¹¶å‘1-æ­¥éª¤3,4 |
| **8100** | æ‰“åˆ†æœåŠ¡ | è¯¦ç»†æ‰“åˆ†ã€ç»¼åˆæ‰“åˆ†è®¡ç®— | å¹¶å‘1-æ­¥éª¤5,6 |
| **8093** | ä¸Šä¼ æœåŠ¡ | Excelæ¶‚è‰²åä¸Šä¼  | å¹¶å‘2-æ­¥éª¤3 |

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒæ•°æ®æµç¨‹

### 2.1 ä¸»æµç¨‹æ—¶åºå›¾

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as 8089å‰ç«¯
    participant O as ç¼–æ’å±‚
    participant D as 8093ä¸‹è½½
    participant C1 as å¹¶å‘é“¾1
    participant C2 as å¹¶å‘é“¾2
    participant H as çƒ­åŠ›å›¾æ¸²æŸ“

    U->>F: è¾“å…¥URLåˆ—è¡¨+Cookie
    F->>O: å¯åŠ¨ä»»åŠ¡
    
    loop æ¯ä¸ªæ–‡æ¡£URL
        O->>D: è¯·æ±‚ä¸‹è½½
        D-->>O: è¿”å›CSV+XLSX
        
        par CSVå¤„ç†é“¾
            O->>C1: å¤„ç†CSV
            C1-->>O: è¿”å›æ‰“åˆ†ç»“æœ
        and Excelå¤„ç†é“¾
            O->>C2: å¤„ç†Excel
            C2-->>O: è¿”å›æ¶‚è‰²URL
        end
    end
    
    O->>H: æ±‡æ€»æ‰€æœ‰ç»“æœ
    H->>F: æ¸²æŸ“çƒ­åŠ›å›¾
    F->>U: å±•ç¤ºå¯ç‚¹å‡»çƒ­åŠ›å›¾
```

### 2.2 å¹¶å‘å¤„ç†é“¾è¯¦ç»†è®¾è®¡

#### 2.2.1 å¹¶å‘é“¾1ï¼šCSVåˆ†æå¤„ç†é“¾

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/core_modules/csv_analysis_chain.py

class CSVAnalysisChain:
    """CSVåˆ†æå¤„ç†é“¾ - å¹¶å‘é“¾1çš„å®ç°"""
    
    def __init__(self):
        self.stages = [
            ('download', self._download_csv),      # æ­¥éª¤1ï¼šä¸‹è½½CSV
            ('compare', self._compare_csv),        # æ­¥éª¤2ï¼šCSVå¯¹æ¯”
            ('standardize', self._standardize),    # æ­¥éª¤3ï¼šåˆ—æ ‡å‡†åŒ–
            ('l2_analysis', self._l2_semantic),    # æ­¥éª¤4ï¼šL2è¯­ä¹‰åˆ†æ
            ('l1l2l3_score', self._calculate_scores), # æ­¥éª¤5ï¼šL1L2L3æ‰“åˆ†
            ('detailed_score', self._detailed_scoring), # æ­¥éª¤6ï¼šè¯¦ç»†æ‰“åˆ†
            ('comprehensive', self._comprehensive_score) # æ­¥éª¤7ï¼šç»¼åˆæ‰“åˆ†
        ]
    
    async def process(self, doc_url: str, doc_name: str, cookie: str) -> dict:
        """æ‰§è¡Œå®Œæ•´çš„CSVå¤„ç†é“¾"""
        context = {
            'doc_url': doc_url,
            'doc_name': doc_name,
            'cookie': cookie,
            'timestamp': datetime.now().isoformat()
        }
        
        for stage_name, stage_func in self.stages:
            try:
                context[stage_name] = await stage_func(context)
                context['status'] = f'{stage_name}_completed'
            except Exception as e:
                context['error'] = f'{stage_name}_failed: {str(e)}'
                break
        
        return context
    
    async def _download_csv(self, context: dict) -> dict:
        """æ­¥éª¤1ï¼šè°ƒç”¨8093ä¸‹è½½CSV"""
        response = await aiohttp.post(
            'http://localhost:8093/api/download',
            json={
                'url': context['doc_url'],
                'format': 'csv',
                'cookie': context['cookie']
            }
        )
        return {
            'csv_path': response['file_path'],
            'download_time': response['duration']
        }
    
    async def _compare_csv(self, context: dict) -> dict:
        """æ­¥éª¤2ï¼šè°ƒç”¨8094è¿›è¡ŒCSVå¯¹æ¯”"""
        # è·å–åŸºå‡†æ–‡ä»¶
        baseline_path = self._get_baseline_path(context['doc_name'])
        
        response = await aiohttp.post(
            'http://localhost:8094/api/compare',
            json={
                'baseline': baseline_path,
                'target': context['download']['csv_path']
            }
        )
        return {
            'changes': response['changes'],
            'similarity': response['similarity']
        }
    
    async def _standardize(self, context: dict) -> dict:
        """æ­¥éª¤3ï¼šè°ƒç”¨8098è¿›è¡Œåˆ—æ ‡å‡†åŒ–"""
        response = await aiohttp.post(
            'http://localhost:8098/api/standardize',
            json={
                'columns': context['compare']['changes']['columns'],
                'use_ai': True
            }
        )
        return {
            'standardized_columns': response['result'],
            'mapping': response['mapping']
        }
    
    async def _l2_semantic(self, context: dict) -> dict:
        """æ­¥éª¤4ï¼šè°ƒç”¨8098è¿›è¡ŒL2è¯­ä¹‰åˆ†æ"""
        response = await aiohttp.post(
            'http://localhost:8098/api/semantic_analysis',
            json={
                'changes': context['compare']['changes'],
                'standardized': context['standardize']['standardized_columns']
            }
        )
        return {
            'semantic_results': response['analysis'],
            'risk_level': response['risk_level']
        }
    
    async def _calculate_scores(self, context: dict) -> dict:
        """æ­¥éª¤5ï¼šè®¡ç®—L1/L2/L3é£é™©ç­‰çº§"""
        changes = context['compare']['changes']
        semantic = context['l2_analysis']['semantic_results']
        
        return {
            'L1': self._calculate_l1_score(changes),  # æ ¼å¼é£é™©
            'L2': self._calculate_l2_score(semantic), # è¯­ä¹‰é£é™©
            'L3': self._calculate_l3_score(changes, semantic) # ä¸šåŠ¡é£é™©
        }
    
    async def _detailed_scoring(self, context: dict) -> dict:
        """æ­¥éª¤6ï¼šè°ƒç”¨8100ç”Ÿæˆè¯¦ç»†æ‰“åˆ†"""
        response = await aiohttp.post(
            'http://localhost:8100/api/detailed_score',
            json={
                'changes': context['compare']['changes'],
                'l1l2l3': context['l1l2l3_score'],
                'semantic': context['l2_analysis']
            }
        )
        return {
            'detailed_scores': response['scores'],
            'change_details': response['details']
        }
    
    async def _comprehensive_score(self, context: dict) -> dict:
        """æ­¥éª¤7ï¼šç”Ÿæˆç»¼åˆæ‰“åˆ†"""
        response = await aiohttp.post(
            'http://localhost:8100/api/comprehensive_score',
            json={
                'detailed': context['detailed_score'],
                'original_columns': context['compare']['changes']['original_columns']
            }
        )
        return {
            'final_score': response['score'],
            'risk_matrix': response['matrix']
        }
```

#### 2.2.2 å¹¶å‘é“¾2ï¼šExcelå¤„ç†é“¾

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/core_modules/excel_processing_chain.py

class ExcelProcessingChain:
    """Excelå¤„ç†é“¾ - å¹¶å‘é“¾2çš„å®ç°"""
    
    def __init__(self):
        self.stages = [
            ('download', self._download_excel),    # æ­¥éª¤1ï¼šä¸‹è½½XLSX
            ('apply_colors', self._apply_colors),  # æ­¥éª¤2ï¼šåº”ç”¨æ¶‚è‰²
            ('upload', self._upload_excel),        # æ­¥éª¤3ï¼šä¸Šä¼ 
            ('collect_url', self._collect_url)     # æ­¥éª¤4ï¼šæ”¶é›†URL
        ]
    
    async def process(self, doc_url: str, doc_name: str, cookie: str, 
                     scoring_data: dict) -> dict:
        """æ‰§è¡ŒExcelå¤„ç†é“¾"""
        context = {
            'doc_url': doc_url,
            'doc_name': doc_name,
            'cookie': cookie,
            'scoring': scoring_data  # æ¥è‡ªå¹¶å‘é“¾1çš„æ‰“åˆ†æ•°æ®
        }
        
        for stage_name, stage_func in self.stages:
            context[stage_name] = await stage_func(context)
        
        return context
    
    async def _download_excel(self, context: dict) -> dict:
        """æ­¥éª¤1ï¼šä¸‹è½½Excelæ–‡ä»¶"""
        response = await aiohttp.post(
            'http://localhost:8093/api/download',
            json={
                'url': context['doc_url'],
                'format': 'xlsx',
                'cookie': context['cookie']
            }
        )
        return {
            'excel_path': response['file_path'],
            'original_name': response['filename']
        }
    
    async def _apply_colors(self, context: dict) -> dict:
        """æ­¥éª¤2ï¼šæ ¹æ®è¯¦ç»†æ‰“åˆ†åº”ç”¨æ¶‚è‰²"""
        import openpyxl
        from openpyxl.styles import PatternFill
        
        wb = openpyxl.load_workbook(context['download']['excel_path'])
        ws = wb.active
        
        # é¢œè‰²æ˜ å°„
        color_map = {
            'L1': 'FFCCCC',  # æµ…çº¢ - é«˜é£é™©
            'L2': 'FFFFCC',  # æµ…é»„ - ä¸­é£é™©
            'L3': 'CCFFCC',  # æµ…ç»¿ - ä½é£é™©
            'unchanged': None  # ä¸æ¶‚è‰²
        }
        
        # åº”ç”¨æ¶‚è‰²é€»è¾‘
        for row_idx, row_score in enumerate(context['scoring']['detailed_scores'], 1):
            for col_idx, cell_score in enumerate(row_score['cells'], 1):
                if cell_score['risk_level'] in color_map:
                    color = color_map[cell_score['risk_level']]
                    if color:
                        cell = ws.cell(row=row_idx, column=col_idx)
                        cell.fill = PatternFill(
                            start_color=color,
                            end_color=color,
                            fill_type='solid'
                        )
                        # æ·»åŠ æ‰¹æ³¨
                        cell.comment = Comment(
                            text=f"é£é™©ç­‰çº§: {cell_score['risk_level']}\n"
                                 f"å˜æ›´ç±»å‹: {cell_score['change_type']}\n"
                                 f"ç½®ä¿¡åº¦: {cell_score['confidence']}",
                            author="AIåˆ†æç³»ç»Ÿ"
                        )
        
        # ä¿å­˜æ¶‚è‰²åçš„æ–‡ä»¶
        colored_path = context['download']['excel_path'].replace('.xlsx', '_colored.xlsx')
        wb.save(colored_path)
        
        return {
            'colored_excel_path': colored_path,
            'color_stats': self._calculate_color_stats(context['scoring'])
        }
    
    async def _upload_excel(self, context: dict) -> dict:
        """æ­¥éª¤3ï¼šä¸Šä¼ æ¶‚è‰²åçš„Excel"""
        response = await aiohttp.post(
            'http://localhost:8093/api/upload',
            data={
                'file_path': context['apply_colors']['colored_excel_path'],
                'cookie': context['cookie'],
                'parent_url': context['doc_url']
            }
        )
        return {
            'upload_url': response['new_doc_url'],
            'upload_time': response['duration']
        }
    
    async def _collect_url(self, context: dict) -> dict:
        """æ­¥éª¤4ï¼šæ”¶é›†å¹¶æ ¼å¼åŒ–URLä¿¡æ¯"""
        return {
            'original_url': context['doc_url'],
            'original_name': context['doc_name'],
            'colored_url': context['upload']['upload_url'],
            'colored_name': f"[AIåˆ†æ]{context['doc_name']}_{datetime.now().strftime('%Y%m%d')}",
            'clickable_link': f"<a href='{context['upload']['upload_url']}' target='_blank'>{context['doc_name']}</a>"
        }
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼š8089å‰ç«¯ç»Ÿä¸€ç•Œé¢è®¾è®¡

### 3.1 ç•Œé¢å¸ƒå±€è§„èŒƒ

```html
<!-- ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/servers/unified_heatmap_ui.html -->

<!DOCTYPE html>
<html>
<head>
    <title>è…¾è®¯æ–‡æ¡£æ™ºèƒ½ç›‘æ§ä¸­å¿ƒ - ç»Ÿä¸€æ§åˆ¶å°</title>
    <style>
        .container {
            display: grid;
            grid-template-areas:
                "header header"
                "input control"
                "progress progress"
                "heatmap details";
            grid-template-columns: 70% 30%;
            gap: 20px;
        }
        
        .input-panel {
            grid-area: input;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            border-radius: 10px;
        }
        
        .control-panel {
            grid-area: control;
            background: #f7f8fc;
            padding: 20px;
            border-radius: 10px;
        }
        
        .heatmap-container {
            grid-area: heatmap;
            position: relative;
        }
        
        .heatmap-row {
            display: flex;
            align-items: center;
            margin: 2px 0;
            cursor: pointer;
            transition: transform 0.2s;
        }
        
        .heatmap-row:hover {
            transform: translateX(5px);
        }
        
        .row-label {
            width: 200px;
            padding: 5px 10px;
            background: #fff;
            border-right: 2px solid #e0e0e0;
            font-weight: 500;
            text-decoration: none;
            color: #333;
        }
        
        .row-label:hover {
            background: #f0f0f0;
            color: #667eea;
        }
        
        .heatmap-cells {
            display: flex;
            flex: 1;
        }
        
        .heatmap-cell {
            width: 30px;
            height: 30px;
            margin: 1px;
            position: relative;
        }
        
        /* çƒ­åŠ›å›¾é¢œè‰²ç­‰çº§ */
        .risk-l1 { background: #ff4444; }  /* é«˜é£é™© - çº¢ */
        .risk-l2 { background: #ffaa00; }  /* ä¸­é£é™© - æ©™ */
        .risk-l3 { background: #ffdd00; }  /* ä½é£é™© - é»„ */
        .risk-safe { background: #00dd00; } /* å®‰å…¨ - ç»¿ */
        .risk-none { background: #e0e0e0; } /* æ— å˜åŒ– - ç° */
    </style>
</head>
<body>
    <div class="container">
        <!-- è¾“å…¥é¢æ¿ -->
        <div class="input-panel">
            <h3>ğŸ“ æ–‡æ¡£ç›‘æ§é…ç½®</h3>
            
            <!-- URLè¾“å…¥è¡¨æ ¼ -->
            <div class="url-table">
                <table id="urlTable">
                    <thead>
                        <tr>
                            <th>åºå·</th>
                            <th>æ–‡æ¡£åç§°</th>
                            <th>æ–‡æ¡£URL</th>
                            <th>æ“ä½œ</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1</td>
                            <td><input type="text" placeholder="é”€å”®æ•°æ®è¡¨" /></td>
                            <td><input type="text" placeholder="https://docs.qq.com/sheet/..." /></td>
                            <td><button onclick="removeRow(this)">åˆ é™¤</button></td>
                        </tr>
                    </tbody>
                </table>
                <button onclick="addRow()">â• æ·»åŠ æ–‡æ¡£</button>
            </div>
            
            <!-- Cookieè¾“å…¥ -->
            <div class="cookie-input">
                <label>ğŸ” Cookieè®¤è¯ï¼š</label>
                <textarea id="cookie" rows="3" placeholder="ç²˜è´´æ‚¨çš„Cookie..."></textarea>
            </div>
        </div>
        
        <!-- æ§åˆ¶é¢æ¿ -->
        <div class="control-panel">
            <h3>âš™ï¸ æ‰§è¡Œæ§åˆ¶</h3>
            
            <!-- æ‰§è¡Œæ¨¡å¼ -->
            <div class="execution-mode">
                <label>æ‰§è¡Œæ¨¡å¼ï¼š</label>
                <select id="executionMode">
                    <option value="immediate">ç«‹å³æ‰§è¡Œ</option>
                    <option value="scheduled">å®šæ—¶æ‰§è¡Œ</option>
                </select>
            </div>
            
            <!-- å®šæ—¶è®¾ç½® -->
            <div id="scheduleSettings" style="display:none;">
                <label>æ‰§è¡Œæ—¶é—´ï¼š</label>
                <input type="time" id="scheduleTime" />
                <label>é‡å¤å‘¨æœŸï¼š</label>
                <select id="repeatCycle">
                    <option value="daily">æ¯å¤©</option>
                    <option value="weekly">æ¯å‘¨</option>
                    <option value="monthly">æ¯æœˆ</option>
                </select>
            </div>
            
            <!-- æ‰§è¡ŒæŒ‰é’® -->
            <button class="execute-btn" onclick="startAnalysis()">
                ğŸš€ å¼€å§‹åˆ†æ
            </button>
            
            <!-- è¿›åº¦æ˜¾ç¤º -->
            <div class="progress-info">
                <div id="currentTask">ç­‰å¾…æ‰§è¡Œ...</div>
                <div class="progress-bar">
                    <div id="progressFill" style="width: 0%"></div>
                </div>
            </div>
        </div>
        
        <!-- çƒ­åŠ›å›¾å±•ç¤ºåŒº -->
        <div class="heatmap-container">
            <h3>ğŸ”¥ é£é™©çƒ­åŠ›å›¾ï¼ˆç‚¹å‡»æ–‡æ¡£åè·³è½¬æ¶‚è‰²ç‰ˆæœ¬ï¼‰</h3>
            <div id="heatmapContent">
                <!-- åŠ¨æ€ç”Ÿæˆçš„çƒ­åŠ›å›¾ -->
            </div>
        </div>
        
        <!-- è¯¦æƒ…é¢æ¿ -->
        <div class="details-panel">
            <h3>ğŸ“Š åˆ†æç»Ÿè®¡</h3>
            <div id="statistics">
                <!-- åŠ¨æ€ç»Ÿè®¡ä¿¡æ¯ -->
            </div>
        </div>
    </div>
</body>
</html>
```

### 3.2 å‰ç«¯JavaScriptæ§åˆ¶é€»è¾‘

```javascript
// ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/servers/unified_heatmap_ui.js

class UnifiedMonitoringSystem {
    constructor() {
        this.documents = [];
        this.results = new Map();
        this.ws = null;
        this.initWebSocket();
    }
    
    initWebSocket() {
        // å»ºç«‹WebSocketè¿æ¥ç”¨äºå®æ—¶æ›´æ–°
        this.ws = new WebSocket('ws://localhost:8089/ws');
        
        this.ws.onmessage = (event) => {
            const data = JSON.parse(event.data);
            this.handleRealtimeUpdate(data);
        };
    }
    
    async startAnalysis() {
        // æ”¶é›†è¾“å…¥æ•°æ®
        const config = this.collectConfiguration();
        
        // å‘é€åˆ°åç«¯
        const response = await fetch('http://localhost:8089/api/start_analysis', {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify(config)
        });
        
        const result = await response.json();
        this.trackProgress(result.task_id);
    }
    
    collectConfiguration() {
        const documents = [];
        const rows = document.querySelectorAll('#urlTable tbody tr');
        
        rows.forEach(row => {
            const name = row.querySelector('input[type="text"]:nth-child(1)').value;
            const url = row.querySelector('input[type="text"]:nth-child(2)').value;
            if (name && url) {
                documents.push({name, url});
            }
        });
        
        return {
            documents: documents,
            cookie: document.getElementById('cookie').value,
            mode: document.getElementById('executionMode').value,
            schedule: this.getScheduleSettings()
        };
    }
    
    handleRealtimeUpdate(data) {
        switch(data.type) {
            case 'progress':
                this.updateProgress(data);
                break;
            case 'document_completed':
                this.addDocumentResult(data);
                break;
            case 'analysis_completed':
                this.renderFinalHeatmap(data);
                break;
        }
    }
    
    renderFinalHeatmap(data) {
        const container = document.getElementById('heatmapContent');
        container.innerHTML = '';
        
        data.documents.forEach(doc => {
            const row = this.createHeatmapRow(doc);
            container.appendChild(row);
        });
    }
    
    createHeatmapRow(doc) {
        const row = document.createElement('div');
        row.className = 'heatmap-row';
        
        // åˆ›å»ºå¯ç‚¹å‡»çš„æ–‡æ¡£æ ‡ç­¾
        const label = document.createElement('a');
        label.className = 'row-label';
        label.href = doc.colored_excel_url;
        label.target = '_blank';
        label.textContent = doc.name;
        label.title = `ç‚¹å‡»æŸ¥çœ‹æ¶‚è‰²ç‰ˆæœ¬: ${doc.name}`;
        
        // åˆ›å»ºçƒ­åŠ›å›¾å•å…ƒæ ¼
        const cells = document.createElement('div');
        cells.className = 'heatmap-cells';
        
        doc.risk_matrix.forEach(risk => {
            const cell = document.createElement('div');
            cell.className = `heatmap-cell risk-${risk.level.toLowerCase()}`;
            cell.title = `åˆ—: ${risk.column}\né£é™©: ${risk.level}\nç½®ä¿¡åº¦: ${risk.confidence}`;
            cells.appendChild(cell);
        });
        
        row.appendChild(label);
        row.appendChild(cells);
        
        return row;
    }
}

// åˆå§‹åŒ–ç³»ç»Ÿ
const monitoringSystem = new UnifiedMonitoringSystem();
```

---

## ç¬¬å››éƒ¨åˆ†ï¼šåç«¯æœåŠ¡é›†æˆ

### 4.1 8089ä¸»æ§æœåŠ¡æ”¹é€ 

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/servers/unified_heatmap_server.py

from flask import Flask, request, jsonify, render_template
from flask_socketio import SocketIO, emit
import asyncio
from concurrent.futures import ThreadPoolExecutor
import aiohttp
from datetime import datetime
from pathlib import Path
import json

app = Flask(__name__)
socketio = SocketIO(app, cors_allowed_origins="*")

class UnifiedOrchestrator:
    """ç»Ÿä¸€ç¼–æ’å™¨ - åè°ƒæ‰€æœ‰åç«¯æœåŠ¡"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.tasks = {}
        self.results = {}
        
    async def orchestrate_analysis(self, config):
        """ç¼–æ’æ•´ä¸ªåˆ†ææµç¨‹"""
        task_id = self.generate_task_id()
        self.tasks[task_id] = {
            'status': 'running',
            'started': datetime.now(),
            'config': config
        }
        
        results = []
        total_docs = len(config['documents'])
        
        for idx, doc in enumerate(config['documents']):
            # æ›´æ–°è¿›åº¦
            self.emit_progress(task_id, idx, total_docs, f"å¤„ç†æ–‡æ¡£: {doc['name']}")
            
            # ä¸²è¡Œä¸‹è½½
            download_result = await self.download_document(doc, config['cookie'])
            
            # å¹¶å‘å¤„ç†CSVå’ŒExcel
            csv_task = asyncio.create_task(
                self.process_csv_chain(doc, download_result['csv_path'], config['cookie'])
            )
            excel_task = asyncio.create_task(
                self.process_excel_chain(doc, download_result['xlsx_path'], config['cookie'])
            )
            
            # ç­‰å¾…ä¸¤ä¸ªå¹¶å‘ä»»åŠ¡å®Œæˆ
            csv_result, excel_result = await asyncio.gather(csv_task, excel_task)
            
            # åˆå¹¶ç»“æœ
            merged_result = self.merge_results(doc, csv_result, excel_result)
            results.append(merged_result)
            
            # å‘é€å•ä¸ªæ–‡æ¡£å®Œæˆäº‹ä»¶
            self.emit_document_completed(task_id, merged_result)
        
        # ç”Ÿæˆæœ€ç»ˆçƒ­åŠ›å›¾æ•°æ®
        heatmap_data = self.generate_heatmap_data(results)
        
        self.tasks[task_id]['status'] = 'completed'
        self.results[task_id] = heatmap_data
        
        # å‘é€å®Œæˆäº‹ä»¶
        self.emit_analysis_completed(task_id, heatmap_data)
        
        return task_id
    
    async def download_document(self, doc, cookie):
        """è°ƒç”¨8093ä¸‹è½½æœåŠ¡"""
        async with aiohttp.ClientSession() as session:
            # ä¸‹è½½CSV
            csv_response = await session.post(
                'http://localhost:8093/api/download',
                json={
                    'url': doc['url'],
                    'format': 'csv',
                    'cookie': cookie
                }
            )
            csv_data = await csv_response.json()
            
            # ä¸‹è½½XLSX
            xlsx_response = await session.post(
                'http://localhost:8093/api/download',
                json={
                    'url': doc['url'],
                    'format': 'xlsx',
                    'cookie': cookie
                }
            )
            xlsx_data = await xlsx_response.json()
            
            return {
                'csv_path': csv_data['file_path'],
                'xlsx_path': xlsx_data['file_path']
            }
    
    async def process_csv_chain(self, doc, csv_path, cookie):
        """æ‰§è¡ŒCSVå¤„ç†é“¾"""
        from production.core_modules.csv_analysis_chain import CSVAnalysisChain
        
        chain = CSVAnalysisChain()
        result = await chain.process(doc['url'], doc['name'], cookie)
        return result
    
    async def process_excel_chain(self, doc, xlsx_path, cookie):
        """æ‰§è¡ŒExcelå¤„ç†é“¾"""
        # ç­‰å¾…CSVé“¾å®Œæˆä»¥è·å–æ‰“åˆ†æ•°æ®
        await asyncio.sleep(0.1)  # ç¡®ä¿CSVé“¾å·²å¼€å§‹
        
        # è·å–æ‰“åˆ†æ•°æ®ï¼ˆä»å…±äº«å­˜å‚¨æˆ–ç¼“å­˜ï¼‰
        scoring_data = await self.get_scoring_data(doc['name'])
        
        from production.core_modules.excel_processing_chain import ExcelProcessingChain
        
        chain = ExcelProcessingChain()
        result = await chain.process(doc['url'], doc['name'], cookie, scoring_data)
        return result
    
    def merge_results(self, doc, csv_result, excel_result):
        """åˆå¹¶CSVå’ŒExcelå¤„ç†ç»“æœ"""
        return {
            'name': doc['name'],
            'url': doc['url'],
            'colored_excel_url': excel_result['collect_url']['colored_url'],
            'risk_matrix': csv_result['comprehensive']['risk_matrix'],
            'final_score': csv_result['comprehensive']['final_score'],
            'statistics': {
                'total_changes': len(csv_result['compare']['changes']),
                'l1_count': csv_result['l1l2l3_score']['L1']['count'],
                'l2_count': csv_result['l1l2l3_score']['L2']['count'],
                'l3_count': csv_result['l1l2l3_score']['L3']['count'],
            }
        }
    
    def generate_heatmap_data(self, results):
        """ç”Ÿæˆçƒ­åŠ›å›¾æ•°æ®ç»“æ„"""
        heatmap = {
            'documents': [],
            'timestamp': datetime.now().isoformat(),
            'summary': {
                'total_documents': len(results),
                'high_risk': 0,
                'medium_risk': 0,
                'low_risk': 0
            }
        }
        
        for result in results:
            # è®¡ç®—é£é™©ç­‰çº§
            risk_level = self.calculate_overall_risk(result['final_score'])
            
            heatmap['documents'].append({
                'name': result['name'],
                'colored_excel_url': result['colored_excel_url'],
                'risk_level': risk_level,
                'risk_matrix': result['risk_matrix'],
                'score': result['final_score']
            })
            
            # æ›´æ–°ç»Ÿè®¡
            if risk_level == 'HIGH':
                heatmap['summary']['high_risk'] += 1
            elif risk_level == 'MEDIUM':
                heatmap['summary']['medium_risk'] += 1
            else:
                heatmap['summary']['low_risk'] += 1
        
        return heatmap
    
    def emit_progress(self, task_id, current, total, message):
        """å‘é€è¿›åº¦æ›´æ–°"""
        socketio.emit('progress', {
            'task_id': task_id,
            'current': current,
            'total': total,
            'percentage': (current / total) * 100,
            'message': message
        })
    
    def emit_document_completed(self, task_id, result):
        """å‘é€å•ä¸ªæ–‡æ¡£å®Œæˆäº‹ä»¶"""
        socketio.emit('document_completed', {
            'task_id': task_id,
            'document': result
        })
    
    def emit_analysis_completed(self, task_id, heatmap_data):
        """å‘é€åˆ†æå®Œæˆäº‹ä»¶"""
        socketio.emit('analysis_completed', {
            'task_id': task_id,
            'type': 'analysis_completed',
            'documents': heatmap_data['documents']
        })

# åˆå§‹åŒ–ç¼–æ’å™¨
orchestrator = UnifiedOrchestrator()

@app.route('/')
def index():
    """æ¸²æŸ“ä¸»ç•Œé¢"""
    return render_template('unified_heatmap_ui.html')

@app.route('/api/start_analysis', methods=['POST'])
async def start_analysis():
    """å¯åŠ¨åˆ†æä»»åŠ¡"""
    config = request.json
    
    # å¼‚æ­¥æ‰§è¡Œåˆ†æ
    task_id = await orchestrator.orchestrate_analysis(config)
    
    return jsonify({
        'success': True,
        'task_id': task_id,
        'message': 'åˆ†æä»»åŠ¡å·²å¯åŠ¨'
    })

@app.route('/api/task_status/<task_id>')
def get_task_status(task_id):
    """è·å–ä»»åŠ¡çŠ¶æ€"""
    if task_id in orchestrator.tasks:
        return jsonify(orchestrator.tasks[task_id])
    return jsonify({'error': 'Task not found'}), 404

@app.route('/api/task_result/<task_id>')
def get_task_result(task_id):
    """è·å–ä»»åŠ¡ç»“æœ"""
    if task_id in orchestrator.results:
        return jsonify(orchestrator.results[task_id])
    return jsonify({'error': 'Result not found'}), 404

if __name__ == '__main__':
    socketio.run(app, host='0.0.0.0', port=8089, debug=False)
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šæ•°æ®å­˜å‚¨ä¸è·¯å¾„ç®¡ç†

### 5.1 ç»Ÿä¸€è·¯å¾„é…ç½®

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/config/unified_paths.py

from pathlib import Path
from datetime import datetime

class UnifiedPathManager:
    """ç»Ÿä¸€è·¯å¾„ç®¡ç†å™¨"""
    
    BASE_DIR = Path('/root/projects/tencent-doc-manager')
    
    # åŸºç¡€ç›®å½•
    DOWNLOADS_DIR = BASE_DIR / 'downloads'
    CSV_VERSIONS_DIR = BASE_DIR / 'csv_versions'
    COMPARISON_RESULTS_DIR = BASE_DIR / 'comparison_results'
    SCORING_RESULTS_DIR = BASE_DIR / 'scoring_results'
    EXCEL_UPLOADS_DIR = BASE_DIR / 'excel_uploads'
    SEMANTIC_RESULTS_DIR = BASE_DIR / 'semantic_results'
    HEATMAP_CACHE_DIR = BASE_DIR / 'heatmap_cache'
    
    @classmethod
    def get_week_path(cls, base_dir, doc_name):
        """è·å–åŸºäºå‘¨çš„è·¯å¾„"""
        from production.core_modules.week_time_manager import WeekTimeManager
        
        wm = WeekTimeManager()
        current_week = wm.get_current_week_number()
        year = datetime.now().year
        
        week_dir = base_dir / f'{year}_W{current_week:02d}'
        week_dir.mkdir(parents=True, exist_ok=True)
        
        return week_dir
    
    @classmethod
    def get_document_path(cls, doc_name, file_type='csv'):
        """è·å–æ–‡æ¡£å­˜å‚¨è·¯å¾„"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{doc_name}_{timestamp}.{file_type}"
        
        if file_type in ['csv', 'xlsx']:
            return cls.DOWNLOADS_DIR / filename
        elif file_type == 'comparison':
            return cls.COMPARISON_RESULTS_DIR / f"{filename}.json"
        elif file_type == 'scoring':
            week_dir = cls.get_week_path(cls.SCORING_RESULTS_DIR, doc_name)
            return week_dir / f"{filename}.json"
        
    @classmethod
    def get_baseline_path(cls, doc_name):
        """è·å–åŸºå‡†æ–‡ä»¶è·¯å¾„"""
        wm = WeekTimeManager()
        baseline_week = wm.get_baseline_week()
        year = datetime.now().year
        
        baseline_dir = cls.CSV_VERSIONS_DIR / f'{year}_W{baseline_week:02d}' / 'baseline'
        pattern = f"*{doc_name}*_baseline_W{baseline_week}.csv"
        
        files = list(baseline_dir.glob(pattern))
        if files:
            return files[0]
        return None
```

### 5.2 æ•°æ®ç¼“å­˜æœºåˆ¶

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/core_modules/cache_manager.py

import redis
import json
import hashlib
from datetime import timedelta

class CacheManager:
    """ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self):
        self.redis_client = redis.Redis(
            host='localhost',
            port=6379,
            decode_responses=True
        )
        self.ttl = timedelta(hours=24)
    
    def get_cache_key(self, doc_url, operation):
        """ç”Ÿæˆç¼“å­˜é”®"""
        hash_obj = hashlib.md5(f"{doc_url}_{operation}".encode())
        return f"tencent_doc:{hash_obj.hexdigest()}"
    
    def get(self, doc_url, operation):
        """è·å–ç¼“å­˜æ•°æ®"""
        key = self.get_cache_key(doc_url, operation)
        data = self.redis_client.get(key)
        if data:
            return json.loads(data)
        return None
    
    def set(self, doc_url, operation, data):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        key = self.get_cache_key(doc_url, operation)
        self.redis_client.setex(
            key,
            self.ttl,
            json.dumps(data)
        )
    
    def invalidate(self, doc_url):
        """ä½¿æ–‡æ¡£çš„æ‰€æœ‰ç¼“å­˜å¤±æ•ˆ"""
        pattern = f"tencent_doc:*{hashlib.md5(doc_url.encode()).hexdigest()[:8]}*"
        keys = self.redis_client.keys(pattern)
        if keys:
            self.redis_client.delete(*keys)
```

---

## ç¬¬å…­éƒ¨åˆ†ï¼šå®šæ—¶ä»»åŠ¡ä¸è‡ªåŠ¨åŒ–

### 6.1 å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/schedulers/task_scheduler.py

from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
import json
from datetime import datetime

class TaskScheduler:
    """ä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self, orchestrator):
        self.scheduler = BackgroundScheduler()
        self.orchestrator = orchestrator
        self.jobs = {}
        self.scheduler.start()
    
    def schedule_analysis(self, config, schedule_settings):
        """è°ƒåº¦åˆ†æä»»åŠ¡"""
        job_id = f"job_{datetime.now().timestamp()}"
        
        if schedule_settings['mode'] == 'daily':
            trigger = CronTrigger(
                hour=schedule_settings['hour'],
                minute=schedule_settings['minute']
            )
        elif schedule_settings['mode'] == 'weekly':
            trigger = CronTrigger(
                day_of_week=schedule_settings['day'],
                hour=schedule_settings['hour'],
                minute=schedule_settings['minute']
            )
        else:  # monthly
            trigger = CronTrigger(
                day=schedule_settings['day'],
                hour=schedule_settings['hour'],
                minute=schedule_settings['minute']
            )
        
        job = self.scheduler.add_job(
            func=self.execute_scheduled_task,
            trigger=trigger,
            args=[config],
            id=job_id
        )
        
        self.jobs[job_id] = {
            'config': config,
            'schedule': schedule_settings,
            'created': datetime.now().isoformat()
        }
        
        return job_id
    
    async def execute_scheduled_task(self, config):
        """æ‰§è¡Œå®šæ—¶ä»»åŠ¡"""
        # è®°å½•æ—¥å¿—
        print(f"[{datetime.now()}] æ‰§è¡Œå®šæ—¶ä»»åŠ¡")
        
        # è°ƒç”¨ç¼–æ’å™¨
        await self.orchestrator.orchestrate_analysis(config)
    
    def cancel_job(self, job_id):
        """å–æ¶ˆå®šæ—¶ä»»åŠ¡"""
        if job_id in self.jobs:
            self.scheduler.remove_job(job_id)
            del self.jobs[job_id]
            return True
        return False
    
    def get_all_jobs(self):
        """è·å–æ‰€æœ‰å®šæ—¶ä»»åŠ¡"""
        return self.jobs
```

---

## ç¬¬ä¸ƒéƒ¨åˆ†ï¼šé”™è¯¯å¤„ç†ä¸ç›‘æ§

### 7.1 ç»Ÿä¸€é”™è¯¯å¤„ç†

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/core_modules/error_handler.py

class UnifiedErrorHandler:
    """ç»Ÿä¸€é”™è¯¯å¤„ç†å™¨"""
    
    ERROR_CODES = {
        'DOWNLOAD_FAILED': {'code': 1001, 'severity': 'HIGH'},
        'COMPARISON_FAILED': {'code': 1002, 'severity': 'MEDIUM'},
        'AI_ANALYSIS_FAILED': {'code': 1003, 'severity': 'HIGH'},
        'EXCEL_PROCESS_FAILED': {'code': 1004, 'severity': 'MEDIUM'},
        'UPLOAD_FAILED': {'code': 1005, 'severity': 'HIGH'},
        'COOKIE_EXPIRED': {'code': 2001, 'severity': 'CRITICAL'},
        'NETWORK_ERROR': {'code': 3001, 'severity': 'HIGH'},
    }
    
    @classmethod
    def handle_error(cls, error_type, context, exception=None):
        """å¤„ç†é”™è¯¯"""
        error_info = cls.ERROR_CODES.get(error_type, {
            'code': 9999,
            'severity': 'UNKNOWN'
        })
        
        error_record = {
            'timestamp': datetime.now().isoformat(),
            'type': error_type,
            'code': error_info['code'],
            'severity': error_info['severity'],
            'context': context,
            'exception': str(exception) if exception else None,
            'traceback': traceback.format_exc() if exception else None
        }
        
        # è®°å½•åˆ°æ—¥å¿—
        logger.error(f"Error occurred: {json.dumps(error_record)}")
        
        # å‘é€é€šçŸ¥ï¼ˆå¦‚æœæ˜¯é«˜ä¸¥é‡æ€§ï¼‰
        if error_info['severity'] in ['HIGH', 'CRITICAL']:
            cls.send_alert(error_record)
        
        # å°è¯•æ¢å¤
        recovery_action = cls.get_recovery_action(error_type)
        if recovery_action:
            return recovery_action(context)
        
        return error_record
```

### 7.2 æ€§èƒ½ç›‘æ§

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/production/core_modules/performance_monitor.py

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics = {
            'download_times': [],
            'comparison_times': [],
            'ai_analysis_times': [],
            'excel_process_times': [],
            'upload_times': [],
            'total_process_times': []
        }
    
    def record_metric(self, metric_type, duration, metadata=None):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        metric = {
            'timestamp': datetime.now().isoformat(),
            'duration': duration,
            'metadata': metadata
        }
        
        if metric_type in self.metrics:
            self.metrics[metric_type].append(metric)
            
            # ä¿æŒæœ€è¿‘1000æ¡è®°å½•
            if len(self.metrics[metric_type]) > 1000:
                self.metrics[metric_type] = self.metrics[metric_type][-1000:]
    
    def get_statistics(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        stats = {}
        
        for metric_type, values in self.metrics.items():
            if values:
                durations = [v['duration'] for v in values]
                stats[metric_type] = {
                    'avg': sum(durations) / len(durations),
                    'min': min(durations),
                    'max': max(durations),
                    'count': len(durations)
                }
        
        return stats
```

---

## ç¬¬å…«éƒ¨åˆ†ï¼šç³»ç»Ÿéƒ¨ç½²ä¸é…ç½®

### 8.1 Dockeréƒ¨ç½²é…ç½®

```dockerfile
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/Dockerfile

FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    chromium \
    chromium-driver \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONPATH=/app
ENV FLASK_APP=production.servers.unified_heatmap_server

# æš´éœ²ç«¯å£
EXPOSE 8089 8093 8094 8098 8100

# å¯åŠ¨è„šæœ¬
CMD ["python", "production/servers/unified_heatmap_server.py"]
```

### 8.2 ç³»ç»Ÿé…ç½®æ–‡ä»¶

```yaml
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/config/system_config.yaml

system:
  name: "è…¾è®¯æ–‡æ¡£æ™ºèƒ½ç›‘æ§ç³»ç»Ÿ"
  version: "2.0.0"
  environment: "production"

services:
  frontend:
    port: 8089
    host: "0.0.0.0"
    websocket: true
    
  backend:
    download_service:
      port: 8093
      timeout: 60
      
    comparison_service:
      port: 8094
      max_file_size: 100MB
      
    ai_service:
      port: 8098
      model: "deepseek-v3"
      api_key: "${DEEPSEEK_API_KEY}"
      
    scoring_service:
      port: 8100
      cache_ttl: 3600

performance:
  max_concurrent_documents: 10
  max_workers: 20
  request_timeout: 300
  
monitoring:
  enable_metrics: true
  metrics_port: 9090
  log_level: "INFO"
  
storage:
  base_path: "/root/projects/tencent-doc-manager"
  max_storage_days: 30
  cleanup_schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹æ¸…ç†
```

---

## ç¬¬ä¹éƒ¨åˆ†ï¼šæµ‹è¯•ä¸éªŒè¯

### 9.1 ç«¯åˆ°ç«¯æµ‹è¯•ç”¨ä¾‹

```python
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/tests/e2e_test.py

import pytest
import asyncio
from production.servers.unified_heatmap_server import UnifiedOrchestrator

class TestUnifiedSystem:
    """ç»Ÿä¸€ç³»ç»Ÿç«¯åˆ°ç«¯æµ‹è¯•"""
    
    @pytest.fixture
    def orchestrator(self):
        return UnifiedOrchestrator()
    
    @pytest.mark.asyncio
    async def test_complete_flow(self, orchestrator):
        """æµ‹è¯•å®Œæ•´æµç¨‹"""
        config = {
            'documents': [
                {
                    'name': 'æµ‹è¯•é”€å”®è¡¨',
                    'url': 'https://docs.qq.com/sheet/test123'
                }
            ],
            'cookie': 'test_cookie_value'
        }
        
        # æ‰§è¡Œåˆ†æ
        task_id = await orchestrator.orchestrate_analysis(config)
        
        # éªŒè¯ä»»åŠ¡åˆ›å»º
        assert task_id in orchestrator.tasks
        assert orchestrator.tasks[task_id]['status'] == 'completed'
        
        # éªŒè¯ç»“æœ
        assert task_id in orchestrator.results
        result = orchestrator.results[task_id]
        
        assert 'documents' in result
        assert len(result['documents']) == 1
        assert 'colored_excel_url' in result['documents'][0]
```

---

## ç¬¬åéƒ¨åˆ†ï¼šè¿ç»´æŒ‡å—

### 10.1 å¯åŠ¨é¡ºåº

```bash
# å¯åŠ¨è„šæœ¬
#!/bin/bash
# ä½ç½®ï¼š/root/projects/tencent-doc-manager/start_unified_system.sh

echo "å¯åŠ¨è…¾è®¯æ–‡æ¡£æ™ºèƒ½ç›‘æ§ç³»ç»Ÿ..."

# 1. å¯åŠ¨Redisï¼ˆç¼“å­˜æœåŠ¡ï¼‰
redis-server --daemonize yes

# 2. å¯åŠ¨åç«¯æœåŠ¡
python3 production_integrated_test_system_8093.py &  # ä¸‹è½½/ä¸Šä¼ æœåŠ¡
sleep 2
python3 production_integrated_test_system_8094.py &  # CSVå¯¹æ¯”æœåŠ¡
sleep 2
python3 deepseek_enhanced_server_with_semantic.py &  # AIåˆ†ææœåŠ¡
sleep 2
python3 integrated_scoring_test_server.py &          # æ‰“åˆ†æœåŠ¡
sleep 2

# 3. å¯åŠ¨ç»Ÿä¸€å‰ç«¯ï¼ˆæœ€åå¯åŠ¨ï¼‰
python3 production/servers/unified_heatmap_server.py

echo "ç³»ç»Ÿå¯åŠ¨å®Œæˆï¼"
echo "è®¿é—® http://localhost:8089 ä½¿ç”¨ç³»ç»Ÿ"
```

### 10.2 ç›‘æ§æ£€æŸ¥æ¸…å•

| æ£€æŸ¥é¡¹ | å‘½ä»¤ | æ­£å¸¸å€¼ |
|--------|------|--------|
| æœåŠ¡çŠ¶æ€ | `netstat -tulpn | grep -E "808[9\|3\|4\|8]\\|8100"` | 5ä¸ªç«¯å£ç›‘å¬ |
| å†…å­˜ä½¿ç”¨ | `free -h` | <80% |
| ç£ç›˜ç©ºé—´ | `df -h /root/projects` | >10GB |
| æ—¥å¿—æ£€æŸ¥ | `tail -f logs/unified_system.log` | æ— ERROR |
| ç¼“å­˜çŠ¶æ€ | `redis-cli ping` | PONG |

---

## é™„å½•Aï¼šæ•°æ®ç»“æ„å®šä¹‰

### A.1 çƒ­åŠ›å›¾æ•°æ®ç»“æ„

```json
{
  "heatmap_data": {
    "timestamp": "2025-09-11T10:30:00",
    "documents": [
      {
        "name": "é”€å”®æ•°æ®è¡¨",
        "url": "https://docs.qq.com/sheet/xxx",
        "colored_excel_url": "https://docs.qq.com/sheet/xxx_colored",
        "risk_matrix": [
          {"column": "é”€å”®é¢", "risk": "L1", "confidence": 0.95},
          {"column": "å®¢æˆ·æ•°", "risk": "L2", "confidence": 0.80},
          {"column": "æ—¥æœŸ", "risk": "L3", "confidence": 0.60}
        ],
        "overall_risk": "MEDIUM",
        "score": 75.5
      }
    ],
    "statistics": {
      "total_documents": 5,
      "high_risk": 1,
      "medium_risk": 2,
      "low_risk": 2
    }
  }
}
```

---

## é™„å½•Bï¼šæ•…éšœæ’æŸ¥æŒ‡å—

### B.1 å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

| é—®é¢˜ | å¯èƒ½åŸå›  | è§£å†³æ–¹æ¡ˆ |
|------|---------|---------|
| çƒ­åŠ›å›¾ä¸æ˜¾ç¤º | WebSocketè¿æ¥å¤±è´¥ | æ£€æŸ¥8089ç«¯å£é˜²ç«å¢™ |
| ä¸‹è½½å¤±è´¥ | Cookieè¿‡æœŸ | æ›´æ–°Cookieå€¼ |
| AIåˆ†æè¶…æ—¶ | APIé™æµ | è°ƒæ•´å¹¶å‘æ•°é‡ |
| Excelæ¶‚è‰²é”™è¯¯ | æ ¼å¼ä¸å…¼å®¹ | æ£€æŸ¥Excelç‰ˆæœ¬ |
| ä¸Šä¼ å¤±è´¥ | æƒé™é—®é¢˜ | ç¡®è®¤æ–‡æ¡£ç¼–è¾‘æƒé™ |

---

**æ–‡æ¡£å®Œæˆæ—¶é—´**: 2025-09-11  
**ä½œè€…**: AIæ¶æ„å¸ˆ  
**ç‰ˆæœ¬**: v1.0.0  
**çŠ¶æ€**: ç”Ÿäº§å°±ç»ª