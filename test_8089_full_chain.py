#!/usr/bin/env python3
"""
8089ç›‘æ§å…¨æµç¨‹æµ‹è¯• - å®Œå…¨çœŸå®ï¼Œæ— ä»»ä½•æ¨¡æ‹Ÿ
æµ‹è¯•ä»ç›‘æ§è®¾ç½®è¾“å…¥åˆ°æœ€ç»ˆURLè¾“å‡ºçš„å®Œæ•´é“¾è·¯
"""

import asyncio
import json
import os
import sys
from pathlib import Path
from datetime import datetime
import csv
import logging
from typing import Optional, Dict, List
import aiohttp

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class FullChainTester:
    """8089å…¨é“¾è·¯æµ‹è¯•å™¨"""

    def __init__(self):
        self.base_dir = Path('/root/projects/tencent-doc-manager')
        self.api_url = 'http://localhost:8089'
        self.test_url = 'https://docs.qq.com/sheet/DWEFNU25TemFnZXJN'  # æµ‹è¯•ç”¨è…¾è®¯æ–‡æ¡£

    async def step1_submit_config(self) -> bool:
        """æ­¥éª¤1: æäº¤ç›‘æ§é…ç½®åˆ°8089"""
        logger.info("=" * 60)
        logger.info("æ­¥éª¤1: æäº¤ç›‘æ§é…ç½®åˆ°8089")

        # è¯»å–Cookie
        cookie_file = self.base_dir / 'config/cookies.json'
        with open(cookie_file) as f:
            cookie_data = json.load(f)

        # å‡†å¤‡é…ç½®æ•°æ®
        config_data = {
            "links": [
                {
                    "name": "æµ‹è¯•æ–‡æ¡£-å‡ºå›½é”€å”®è®¡åˆ’è¡¨",
                    "url": self.test_url,
                    "category": "é”€å”®",
                    "description": "å…¨é“¾è·¯æµ‹è¯•æ–‡æ¡£"
                }
            ]
        }

        # å‘é€åˆ°8089 API
        async with aiohttp.ClientSession() as session:
            # ä¿å­˜ä¸‹è½½é“¾æ¥é…ç½®
            async with session.post(
                f'{self.api_url}/api/save-download-links',
                json=config_data
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    logger.info(f"âœ… é…ç½®ä¿å­˜æˆåŠŸ: {result}")
                    return True
                else:
                    logger.error(f"âŒ é…ç½®ä¿å­˜å¤±è´¥: {response.status}")
                    return False

    async def step2_trigger_download(self) -> Optional[str]:
        """æ­¥éª¤2: è§¦å‘ç«‹å³åˆ·æ–°/ä¸‹è½½"""
        logger.info("=" * 60)
        logger.info("æ­¥éª¤2: è§¦å‘ç«‹å³ä¸‹è½½")

        # ä½¿ç”¨PlaywrightDownloaderè¿›è¡ŒçœŸå®ä¸‹è½½
        sys.path.append(str(self.base_dir))
        from production.core_modules.playwright_downloader import PlaywrightDownloader

        # è¯»å–Cookie
        cookie_file = self.base_dir / 'config/cookies.json'
        with open(cookie_file) as f:
            cookie_data = json.load(f)
        cookie_string = cookie_data.get('current_cookies', '')

        # åˆ›å»ºä¸‹è½½ç›®å½•
        from production.core_modules.week_time_manager import WeekTimeManager
        week_mgr = WeekTimeManager()
        week_info = week_mgr.get_current_week_info()
        download_dir = self.base_dir / f"csv_versions/2025_W{week_info['week_number']}/test"
        download_dir.mkdir(parents=True, exist_ok=True)

        # æ‰§è¡Œä¸‹è½½
        downloader = PlaywrightDownloader()
        try:
            result = await downloader.download(
                url=self.test_url,
                cookies=cookie_string,
                format='csv',
                download_dir=str(download_dir)
            )

            if result and result.get('success'):
                csv_file = result.get('file_path')
                logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {csv_file}")
                return csv_file
            else:
                logger.error(f"âŒ ä¸‹è½½å¤±è´¥: {result}")
                return None
        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            return None

    async def step3_process_and_score(self, csv_file: str) -> Optional[Dict]:
        """æ­¥éª¤3: å¯¹æ¯”å’Œæ‰“åˆ†"""
        logger.info("=" * 60)
        logger.info("æ­¥éª¤3: å¯¹æ¯”å’Œæ‰“åˆ†å¤„ç†")

        # æŸ¥æ‰¾åŸºçº¿æ–‡ä»¶
        from production.core_modules.week_time_manager import WeekTimeManager
        week_mgr = WeekTimeManager()
        week_info = week_mgr.get_current_week_info()
        baseline_dir = self.base_dir / f"csv_versions/2025_W{week_info['week_number']}/baseline"

        # æŸ¥æ‰¾åŒ¹é…çš„åŸºçº¿æ–‡ä»¶
        baseline_files = list(baseline_dir.glob("*å‡ºå›½é”€å”®*.csv"))
        if not baseline_files:
            logger.warning("æœªæ‰¾åˆ°åŸºçº¿æ–‡ä»¶ï¼Œä½¿ç”¨å½“å‰æ–‡ä»¶ä½œä¸ºåŸºçº¿")
            baseline_file = csv_file
        else:
            baseline_file = str(baseline_files[0])
            logger.info(f"ä½¿ç”¨åŸºçº¿æ–‡ä»¶: {baseline_file}")

        # æ‰§è¡Œå¯¹æ¯”
        changes = []
        with open(csv_file, 'r', encoding='utf-8') as f1, \
             open(baseline_file, 'r', encoding='utf-8') as f2:
            current_reader = list(csv.reader(f1))
            baseline_reader = list(csv.reader(f2))

            # å¯¹æ¯”æ•°æ®
            for row_idx, (row_current, row_baseline) in enumerate(zip(current_reader, baseline_reader)):
                for col_idx, (val_current, val_baseline) in enumerate(zip(row_current, row_baseline)):
                    if val_current.strip() != val_baseline.strip():
                        changes.append({
                            "row": row_idx,
                            "col": col_idx,
                            "old_value": val_baseline,
                            "new_value": val_current
                        })

        logger.info(f"å‘ç° {len(changes)} å¤„å˜æ›´")

        # è¿›è¡Œé£é™©è¯„åˆ†
        from production.config import L1_COLUMNS, L2_COLUMNS, L3_COLUMNS

        scores = []
        for change in changes:
            col_idx = change['col']
            if col_idx < len(L1_COLUMNS) and col_idx in range(len(L1_COLUMNS)):
                risk_level = "HIGH"
                score = 85
            elif col_idx < len(L1_COLUMNS) + len(L2_COLUMNS):
                risk_level = "MEDIUM"
                score = 50
            else:
                risk_level = "LOW"
                score = 20

            change['risk_level'] = risk_level
            change['score'] = score
            scores.append(score)

        avg_score = sum(scores) / len(scores) if scores else 0

        result = {
            "total_changes": len(changes),
            "average_score": avg_score,
            "risk_distribution": {
                "HIGH": len([c for c in changes if c['risk_level'] == 'HIGH']),
                "MEDIUM": len([c for c in changes if c['risk_level'] == 'MEDIUM']),
                "LOW": len([c for c in changes if c['risk_level'] == 'LOW'])
            },
            "changes": changes[:10]  # åªè¿”å›å‰10ä¸ªå˜æ›´
        }

        return result

    async def step4_generate_excel(self, csv_file: str, scoring_result: Dict) -> Optional[str]:
        """æ­¥éª¤4: ç”Ÿæˆæ¶‚è‰²Excel"""
        logger.info("=" * 60)
        logger.info("æ­¥éª¤4: ç”Ÿæˆæ¶‚è‰²Excel")

        from openpyxl import Workbook
        from openpyxl.styles import PatternFill, Font

        # åˆ›å»ºExcel
        wb = Workbook()
        ws = wb.active
        ws.title = "æµ‹è¯•æ–‡æ¡£"

        # è¯»å–CSVæ•°æ®
        with open(csv_file, 'r', encoding='utf-8') as f:
            csv_reader = csv.reader(f)
            for row_idx, row in enumerate(csv_reader, 1):
                for col_idx, value in enumerate(row, 1):
                    ws.cell(row=row_idx, column=col_idx, value=value)

        # åº”ç”¨æ¶‚è‰²ï¼ˆåŸºäºå˜æ›´ï¼‰
        color_map = {
            "HIGH": "FFCCCC",
            "MEDIUM": "FFFFCC",
            "LOW": "CCFFCC"
        }

        for change in scoring_result.get('changes', []):
            row = change['row'] + 1
            col = change['col'] + 1
            risk = change['risk_level']
            color = color_map.get(risk, "FFFFFF")

            cell = ws.cell(row=row, column=col)
            cell.fill = PatternFill(
                start_color=color,
                end_color=color,
                fill_type="solid"  # å…³é”®ï¼šå¿…é¡»ä½¿ç”¨solid
            )

        # ä¿å­˜Excel
        excel_dir = self.base_dir / "excel_outputs/test_8089"
        excel_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        excel_file = excel_dir / f"test_8089_{timestamp}.xlsx"
        wb.save(excel_file)

        logger.info(f"âœ… Excelç”ŸæˆæˆåŠŸ: {excel_file}")
        return str(excel_file)

    async def step5_upload_to_tencent(self, excel_file: str) -> Optional[str]:
        """æ­¥éª¤5: ä¸Šä¼ åˆ°è…¾è®¯æ–‡æ¡£"""
        logger.info("=" * 60)
        logger.info("æ­¥éª¤5: ä¸Šä¼ åˆ°è…¾è®¯æ–‡æ¡£")

        # è¯»å–Cookie
        cookie_file = self.base_dir / 'config/cookies.json'
        with open(cookie_file) as f:
            cookie_data = json.load(f)
        cookie_string = cookie_data.get('current_cookies', '')

        # ä½¿ç”¨quick_upload_v3
        from production.core_modules.tencent_doc_upload_production_v3 import quick_upload_v3

        try:
            result = await quick_upload_v3(
                cookie_string=cookie_string,
                file_path=excel_file,
                headless=True
            )

            if result and result.get('success'):
                url = result.get('url')
                logger.info(f"âœ… ä¸Šä¼ æˆåŠŸ: {url}")
                return url
            else:
                logger.error(f"âŒ ä¸Šä¼ å¤±è´¥: {result}")
                return None
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¼ å¼‚å¸¸: {e}")
            return None

    async def step6_update_ui(self, upload_url: str) -> bool:
        """æ­¥éª¤6: æ›´æ–°8089 UIæ˜¾ç¤º"""
        logger.info("=" * 60)
        logger.info("æ­¥éª¤6: æ›´æ–°UIæ˜¾ç¤º")

        # å‡†å¤‡æ›´æ–°æ•°æ®
        update_data = {
            "table_urls": {
                "æµ‹è¯•æ–‡æ¡£-å‡ºå›½é”€å”®è®¡åˆ’è¡¨": upload_url
            },
            "last_update": datetime.now().isoformat()
        }

        # å‘é€æ›´æ–°åˆ°8089
        async with aiohttp.ClientSession() as session:
            async with session.post(
                f'{self.api_url}/api/update-table-urls',
                json=update_data
            ) as response:
                if response.status == 200:
                    logger.info(f"âœ… UIæ›´æ–°æˆåŠŸ")
                    return True
                else:
                    # å¦‚æœAPIä¸å­˜åœ¨ï¼Œå°è¯•ç›´æ¥æ›´æ–°é…ç½®æ–‡ä»¶
                    logger.info("å°è¯•ç›´æ¥æ›´æ–°é…ç½®æ–‡ä»¶")
                    config_file = self.base_dir / 'scoring_results/comprehensive/table_urls.json'
                    with open(config_file, 'w') as f:
                        json.dump(update_data, f, indent=2)
                    logger.info(f"âœ… é…ç½®æ–‡ä»¶æ›´æ–°æˆåŠŸ")
                    return True

    async def run_full_test(self):
        """è¿è¡Œå®Œæ•´æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹8089å…¨é“¾è·¯æµ‹è¯•")
        logger.info("=" * 60)

        results = {
            "start_time": datetime.now().isoformat(),
            "steps": {}
        }

        try:
            # æ­¥éª¤1: æäº¤é…ç½®
            success = await self.step1_submit_config()
            results["steps"]["config"] = {"success": success}
            if not success:
                logger.error("é…ç½®æäº¤å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
                return results

            # æ­¥éª¤2: è§¦å‘ä¸‹è½½
            csv_file = await self.step2_trigger_download()
            results["steps"]["download"] = {"success": csv_file is not None, "file": csv_file}
            if not csv_file:
                logger.error("ä¸‹è½½å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
                return results

            # æ­¥éª¤3: å¯¹æ¯”å’Œæ‰“åˆ†
            scoring_result = await self.step3_process_and_score(csv_file)
            results["steps"]["scoring"] = {
                "success": scoring_result is not None,
                "total_changes": scoring_result.get("total_changes", 0) if scoring_result else 0
            }
            if not scoring_result:
                logger.error("æ‰“åˆ†å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
                return results

            # æ­¥éª¤4: ç”ŸæˆExcel
            excel_file = await self.step4_generate_excel(csv_file, scoring_result)
            results["steps"]["excel"] = {"success": excel_file is not None, "file": excel_file}
            if not excel_file:
                logger.error("Excelç”Ÿæˆå¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
                return results

            # æ­¥éª¤5: ä¸Šä¼ 
            upload_url = await self.step5_upload_to_tencent(excel_file)
            results["steps"]["upload"] = {"success": upload_url is not None, "url": upload_url}
            if not upload_url:
                logger.error("ä¸Šä¼ å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
                return results

            # æ­¥éª¤6: æ›´æ–°UI
            ui_updated = await self.step6_update_ui(upload_url)
            results["steps"]["ui_update"] = {"success": ui_updated}

            # æ€»ç»“
            results["end_time"] = datetime.now().isoformat()
            results["success"] = True
            results["final_url"] = upload_url

            logger.info("=" * 60)
            logger.info("ğŸ‰ æµ‹è¯•å®Œæˆï¼")
            logger.info(f"ğŸ“Š æ€»å˜æ›´æ•°: {scoring_result['total_changes']}")
            logger.info(f"ğŸ”— æœ€ç»ˆURL: {upload_url}")
            logger.info(f"âœ… æ‰€æœ‰æ­¥éª¤æˆåŠŸ")
            logger.info("=" * 60)

        except Exception as e:
            logger.error(f"æµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
            results["error"] = str(e)
            results["success"] = False

        # ä¿å­˜æµ‹è¯•ç»“æœ
        result_file = self.base_dir / f"test_results/test_8089_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        result_file.parent.mkdir(parents=True, exist_ok=True)
        with open(result_file, 'w') as f:
            json.dump(results, f, indent=2)
        logger.info(f"æµ‹è¯•ç»“æœä¿å­˜åˆ°: {result_file}")

        return results

async def main():
    """ä¸»å‡½æ•°"""
    tester = FullChainTester()
    results = await tester.run_full_test()

    # éªŒè¯é“¾æ¥è·³è½¬
    if results.get("final_url"):
        print(f"\nè¯·è®¿é—®ä»¥ä¸‹URLéªŒè¯ç»“æœ:")
        print(f"  8089ç›‘æ§UI: http://202.140.143.88:8089/")
        print(f"  ä¸Šä¼ çš„æ–‡æ¡£: {results['final_url']}")
        print("\néªŒè¯è¦ç‚¹:")
        print("  1. UIä¸­åº”æ˜¾ç¤ºæœ€æ–°çš„çƒ­åŠ›å›¾æ•°æ®")
        print("  2. ç‚¹å‡»è¡¨æ ¼åç§°åº”è·³è½¬åˆ°ä¸Šä¼ çš„URL")
        print("  3. æ¶‚è‰²åº”è¯¥æ­£ç¡®æ˜¾ç¤ºï¼ˆsolidå¡«å……ï¼‰")

if __name__ == "__main__":
    asyncio.run(main())